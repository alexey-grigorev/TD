{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qH5q1y8nGL0s"
   },
   "source": [
    "### 1. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2018 NVIDIA Corporation\r\n",
      "Built on Sat_Aug_25_21:08:01_CDT_2018\r\n",
      "Cuda compilation tools, release 10.0, V10.0.130\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep  2 08:23:18 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 430.40       Driver Version: 430.40       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:19:00.0 Off |                  N/A |\r\n",
      "|  0%   33C    P8    10W / 250W |  10775MiB / 11178MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:1A:00.0 Off |                  N/A |\r\n",
      "|  0%   39C    P8     9W / 250W |     18MiB / 11176MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      5082      C   ...okholyan/miniconda/envs/py36/bin/python 10763MiB |\r\n",
      "|    1      1997      G   /usr/lib/xorg/Xorg                             9MiB |\r\n",
      "|    1      2032      G   /usr/bin/gnome-shell                           6MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\t\t\tmodel.ckpt.index  saved_model\r\n",
      "frozen_inference_graph.pb\tmodel.ckpt.meta\r\n",
      "model.ckpt.data-00000-of-00001\tpipeline.config\r\n"
     ]
    }
   ],
   "source": [
    "!cd /home/alexeygrigoriev/Projects/TD/frozen_model/faster_rcnn_resnet50_coco_2018_01_28; ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard --logdir=data_dir/checkpoints/ --port=6129\n",
    "# ssh -NfL localhost:8898:localhost:6129 alexeygrigoriev@10.55.229.103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alexeygrigoriev/miniconda/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/alexeygrigoriev/miniconda/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/alexeygrigoriev/miniconda/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/alexeygrigoriev/miniconda/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/alexeygrigoriev/miniconda/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/alexeygrigoriev/miniconda/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/alexeygrigoriev/miniconda/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/alexeygrigoriev/miniconda/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/alexeygrigoriev/miniconda/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/alexeygrigoriev/miniconda/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/alexeygrigoriev/miniconda/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/alexeygrigoriev/miniconda/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0902 08:23:26.844886 139792788920128 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0902 08:23:26.969571 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W0902 08:23:26.976329 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "W0902 08:23:26.983075 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/legacy/train.py:55: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W0902 08:23:26.983161 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/legacy/train.py:55: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "W0902 08:23:26.983461 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/legacy/train.py:184: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "W0902 08:23:26.983729 139792788920128 deprecation.py:323] From /home/alexeygrigoriev/miniconda/envs/tensorflow_gpu/lib/python3.6/site-packages/absl/app.py:251: main (from __main__) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use object_detection/model_main.py.\n",
      "W0902 08:23:26.983804 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/legacy/train.py:90: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "W0902 08:23:26.983982 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0902 08:23:26.986274 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/legacy/train.py:95: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
      "\n",
      "W0902 08:23:26.988617 139792788920128 deprecation.py:323] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/legacy/trainer.py:266: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.create_global_step\n",
      "W0902 08:23:26.991608 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "W0902 08:23:26.991713 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
      "\n",
      "W0902 08:23:27.000043 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "W0902 08:23:27.001450 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/builders/dataset_builder.py:71: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n",
      "W0902 08:23:27.001510 139792788920128 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n",
      "W0902 08:23:27.005371 139792788920128 deprecation.py:323] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "W0902 08:23:27.005446 139792788920128 deprecation.py:323] From /home/alexeygrigoriev/miniconda/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0902 08:23:27.022218 139792788920128 deprecation.py:323] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0902 08:23:27.135623 139792788920128 deprecation.py:323] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/builders/dataset_builder.py:43: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "W0902 08:23:27.139889 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/builders/dataset_builder.py:44: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "W0902 08:23:27.142586 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/core/preprocessor.py:626: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0902 08:23:27.168288 139792788920128 deprecation.py:323] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "W0902 08:23:27.170871 139792788920128 deprecation.py:323] From /home/alexeygrigoriev/miniconda/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorflow/python/training/input.py:753: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0902 08:23:27.171538 139792788920128 deprecation.py:323] From /home/alexeygrigoriev/miniconda/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorflow/python/training/input.py:753: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0902 08:23:27.177266 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/core/prefetcher.py:58: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "W0902 08:23:27.357000 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/core/preprocessor.py:2660: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "I0902 08:23:27.426676 139792788920128 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "I0902 08:23:28.934980 139792788920128 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "I0902 08:23:28.945027 139792788920128 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "W0902 08:23:28.945291 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "I0902 08:23:28.945348 139792788920128 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "W0902 08:23:28.976172 139792788920128 deprecation.py:323] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/core/box_list_ops.py:174: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0902 08:23:32.568838 139792788920128 deprecation.py:506] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/utils/spatial_transform_ops.py:418: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "I0902 08:23:32.590018 139792788920128 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "W0902 08:23:32.793980 139792788920128 deprecation.py:323] From /home/alexeygrigoriev/miniconda/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "I0902 08:23:32.920491 139792788920128 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "I0902 08:23:33.085441 139792788920128 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "W0902 08:23:34.506682 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
      "\n",
      "W0902 08:23:34.507601 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
      "\n",
      "W0902 08:23:34.543819 139792788920128 deprecation.py:323] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/core/losses.py:350: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "W0902 08:23:35.328812 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/legacy/trainer.py:208: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.\n",
      "\n",
      "W0902 08:23:35.329084 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/builders/optimizer_builder.py:95: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "W0902 08:23:35.334409 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/builders/optimizer_builder.py:58: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n",
      "W0902 08:23:39.514515 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/legacy/trainer.py:353: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "W0902 08:23:39.727172 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/legacy/trainer.py:355: The name tf.losses.get_losses is deprecated. Please use tf.compat.v1.losses.get_losses instead.\n",
      "\n",
      "W0902 08:23:39.729937 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/legacy/trainer.py:359: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.\n",
      "\n",
      "W0902 08:23:39.731775 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/legacy/trainer.py:368: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "W0902 08:23:39.737394 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/legacy/trainer.py:376: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0902 08:23:39.991762 139792788920128 deprecation.py:323] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2650: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "W0902 08:23:39.993251 139792788920128 deprecation_wrapper.py:119] From /home/alexeygrigoriev/Projects/TD/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
      "\n",
      "W0902 08:23:39.994851 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.994923 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.994965 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995000 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995032 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995066 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995096 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995126 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995160 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995189 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995229 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995260 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995289 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995318 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995351 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995379 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995424 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995457 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995486 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995516 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995549 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995578 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995608 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995641 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995671 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995700 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995734 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995763 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995793 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995825 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995855 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995884 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995916 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995946 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.995975 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996007 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996037 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996066 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996099 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996128 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996157 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996190 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996219 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996248 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996280 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996308 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996337 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996369 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996399 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996446 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996480 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996510 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996558 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996594 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996626 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996658 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996694 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996726 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996758 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996794 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996828 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996860 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996896 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996929 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996962 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.996997 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997029 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997061 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997097 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997130 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997163 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997198 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997231 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997263 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997299 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997332 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997364 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997400 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997432 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997465 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997501 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997534 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997565 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997611 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997641 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997670 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997702 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997731 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997761 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997794 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997823 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997852 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997884 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997914 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997943 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.997976 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998006 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_3/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998035 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_3/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998068 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_3/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998098 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998127 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998159 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998191 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998220 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998252 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998281 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_4/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998310 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_4/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998342 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_4/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998371 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998400 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998433 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998462 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998491 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998523 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998553 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_5/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998582 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_5/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998614 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_5/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998643 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998672 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998704 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998733 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998762 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998794 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998823 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998853 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998885 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.998988 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999018 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999051 139792788920128 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_50/conv1/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999081 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999111 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999144 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999174 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999203 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999236 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999265 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999294 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999326 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999355 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999385 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999418 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999448 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999476 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999509 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999539 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999568 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999601 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999631 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_2/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999660 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_2/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999693 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_2/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999722 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999752 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999785 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999814 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999843 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999876 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999906 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999935 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
      "W0902 08:23:39.999967 139792788920128 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0902 08:23:40.371249 139792788920128 deprecation.py:323] From /home/alexeygrigoriev/miniconda/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorflow/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n",
      "2019-09-02 08:23:41.194865: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2019-09-02 08:23:41.201828: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "2019-09-02 08:23:41.316732: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f65b26b2d0 executing computations on platform CUDA. Devices:\n",
      "2019-09-02 08:23:41.316795: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2019-09-02 08:23:41.340803: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2600000000 Hz\n",
      "2019-09-02 08:23:41.343565: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f667cd4670 executing computations on platform Host. Devices:\n",
      "2019-09-02 08:23:41.343611: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-09-02 08:23:41.349040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6325\n",
      "pciBusID: 0000:1a:00.0\n",
      "2019-09-02 08:23:41.349421: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-09-02 08:23:41.351603: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-09-02 08:23:41.353504: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2019-09-02 08:23:41.354043: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2019-09-02 08:23:41.356563: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2019-09-02 08:23:41.358453: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2019-09-02 08:23:41.364650: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-09-02 08:23:41.366391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2019-09-02 08:23:41.366452: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-09-02 08:23:41.367967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-09-02 08:23:41.367985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2019-09-02 08:23:41.367995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2019-09-02 08:23:41.373800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10462 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:1a:00.0, compute capability: 6.1)\n",
      "W0902 08:23:41.378164 139792788920128 deprecation.py:323] From /home/alexeygrigoriev/miniconda/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "I0902 08:23:41.379824 139792788920128 saver.py:1280] Restoring parameters from data_dir/mixed_experiment/checkpoints_v2/model.ckpt-38158\n",
      "2019-09-02 08:23:42.610496: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "W0902 08:23:42.794445 139792788920128 deprecation.py:323] From /home/alexeygrigoriev/miniconda/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "I0902 08:23:42.801082 139792788920128 session_manager.py:500] Running local_init_op.\n",
      "I0902 08:23:43.255201 139792788920128 session_manager.py:502] Done running local_init_op.\n",
      "I0902 08:23:49.031486 139792788920128 learning.py:754] Starting Session.\n",
      "I0902 08:23:49.270255 139778953570048 supervisor.py:1117] Saving checkpoint to path data_dir/mixed_experiment/checkpoints_v2/model.ckpt\n",
      "I0902 08:23:49.274635 139792788920128 learning.py:768] Starting Queues.\n",
      "2019-09-02 08:23:55.187344: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "I0902 08:23:55.594150 139778945177344 supervisor.py:1099] global_step/sec: 0\n",
      "2019-09-02 08:23:56.458347: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "I0902 08:23:58.509849 139778936784640 supervisor.py:1050] Recording summary at step 38158.\n",
      "2019-09-02 08:24:04.847968: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.00GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2019-09-02 08:24:05.000607: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2019-09-02 08:24:05.152764: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.82GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2019-09-02 08:24:05.242514: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.86GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "I0902 08:24:06.865821 139792788920128 learning.py:507] global step 38159: loss = 0.1300 (17.344 sec/step)\n",
      "I0902 08:24:08.027460 139792788920128 learning.py:507] global step 38160: loss = 0.1760 (0.936 sec/step)\n",
      "I0902 08:24:08.951259 139792788920128 learning.py:507] global step 38161: loss = 0.0763 (0.922 sec/step)\n",
      "I0902 08:24:09.881698 139792788920128 learning.py:507] global step 38162: loss = 0.1298 (0.929 sec/step)\n",
      "I0902 08:24:10.821012 139792788920128 learning.py:507] global step 38163: loss = 0.1164 (0.938 sec/step)\n",
      "I0902 08:24:11.757840 139792788920128 learning.py:507] global step 38164: loss = 0.1017 (0.935 sec/step)\n",
      "I0902 08:24:12.693097 139792788920128 learning.py:507] global step 38165: loss = 0.1167 (0.934 sec/step)\n",
      "I0902 08:24:13.628525 139792788920128 learning.py:507] global step 38166: loss = 0.1840 (0.934 sec/step)\n",
      "I0902 08:24:14.581139 139792788920128 learning.py:507] global step 38167: loss = 0.1596 (0.951 sec/step)\n",
      "I0902 08:24:15.538337 139792788920128 learning.py:507] global step 38168: loss = 0.0860 (0.956 sec/step)\n",
      "I0902 08:24:16.467598 139792788920128 learning.py:507] global step 38169: loss = 0.0697 (0.928 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:24:17.397474 139792788920128 learning.py:507] global step 38170: loss = 0.0994 (0.928 sec/step)\n",
      "I0902 08:24:18.340091 139792788920128 learning.py:507] global step 38171: loss = 0.0614 (0.941 sec/step)\n",
      "I0902 08:24:19.285062 139792788920128 learning.py:507] global step 38172: loss = 0.0956 (0.943 sec/step)\n",
      "I0902 08:24:20.207755 139792788920128 learning.py:507] global step 38173: loss = 0.1524 (0.921 sec/step)\n",
      "I0902 08:24:21.162257 139792788920128 learning.py:507] global step 38174: loss = 0.1925 (0.953 sec/step)\n",
      "I0902 08:24:22.112738 139792788920128 learning.py:507] global step 38175: loss = 0.0998 (0.949 sec/step)\n",
      "I0902 08:24:23.058194 139792788920128 learning.py:507] global step 38176: loss = 0.0714 (0.944 sec/step)\n",
      "I0902 08:24:23.990272 139792788920128 learning.py:507] global step 38177: loss = 0.1781 (0.930 sec/step)\n",
      "I0902 08:24:24.919509 139792788920128 learning.py:507] global step 38178: loss = 0.1806 (0.928 sec/step)\n",
      "I0902 08:24:25.854790 139792788920128 learning.py:507] global step 38179: loss = 0.0575 (0.934 sec/step)\n",
      "I0902 08:24:26.788320 139792788920128 learning.py:507] global step 38180: loss = 0.1233 (0.932 sec/step)\n",
      "I0902 08:24:27.746582 139792788920128 learning.py:507] global step 38181: loss = 0.0735 (0.957 sec/step)\n",
      "I0902 08:24:28.672006 139792788920128 learning.py:507] global step 38182: loss = 0.1387 (0.924 sec/step)\n",
      "I0902 08:24:29.618314 139792788920128 learning.py:507] global step 38183: loss = 0.1892 (0.945 sec/step)\n",
      "I0902 08:24:30.573981 139792788920128 learning.py:507] global step 38184: loss = 0.1551 (0.954 sec/step)\n",
      "I0902 08:24:31.510959 139792788920128 learning.py:507] global step 38185: loss = 0.0998 (0.936 sec/step)\n",
      "I0902 08:24:32.464854 139792788920128 learning.py:507] global step 38186: loss = 0.1868 (0.952 sec/step)\n",
      "I0902 08:24:33.402161 139792788920128 learning.py:507] global step 38187: loss = 0.1610 (0.936 sec/step)\n",
      "I0902 08:24:34.328208 139792788920128 learning.py:507] global step 38188: loss = 0.1424 (0.925 sec/step)\n",
      "I0902 08:24:35.256854 139792788920128 learning.py:507] global step 38189: loss = 0.0816 (0.927 sec/step)\n",
      "I0902 08:24:36.194101 139792788920128 learning.py:507] global step 38190: loss = 0.1409 (0.935 sec/step)\n",
      "I0902 08:24:37.131952 139792788920128 learning.py:507] global step 38191: loss = 0.2153 (0.936 sec/step)\n",
      "I0902 08:24:38.069116 139792788920128 learning.py:507] global step 38192: loss = 0.1509 (0.935 sec/step)\n",
      "I0902 08:24:39.016235 139792788920128 learning.py:507] global step 38193: loss = 0.1402 (0.945 sec/step)\n",
      "I0902 08:24:39.955544 139792788920128 learning.py:507] global step 38194: loss = 0.2214 (0.938 sec/step)\n",
      "I0902 08:24:40.900493 139792788920128 learning.py:507] global step 38195: loss = 0.0751 (0.943 sec/step)\n",
      "I0902 08:24:41.847001 139792788920128 learning.py:507] global step 38196: loss = 0.1006 (0.945 sec/step)\n",
      "I0902 08:24:42.806655 139792788920128 learning.py:507] global step 38197: loss = 0.1623 (0.958 sec/step)\n",
      "I0902 08:24:43.760411 139792788920128 learning.py:507] global step 38198: loss = 0.0848 (0.952 sec/step)\n",
      "I0902 08:24:44.705867 139792788920128 learning.py:507] global step 38199: loss = 0.1136 (0.944 sec/step)\n",
      "I0902 08:24:45.679072 139792788920128 learning.py:507] global step 38200: loss = 0.0817 (0.972 sec/step)\n",
      "I0902 08:24:46.627259 139792788920128 learning.py:507] global step 38201: loss = 0.1723 (0.946 sec/step)\n",
      "I0902 08:24:47.573760 139792788920128 learning.py:507] global step 38202: loss = 0.0525 (0.945 sec/step)\n",
      "I0902 08:24:48.528354 139792788920128 learning.py:507] global step 38203: loss = 0.0872 (0.953 sec/step)\n",
      "I0902 08:24:49.479920 139792788920128 learning.py:507] global step 38204: loss = 0.1013 (0.950 sec/step)\n",
      "I0902 08:24:50.435169 139792788920128 learning.py:507] global step 38205: loss = 0.1078 (0.954 sec/step)\n",
      "I0902 08:24:51.396157 139792788920128 learning.py:507] global step 38206: loss = 0.0961 (0.959 sec/step)\n",
      "I0902 08:24:52.333312 139792788920128 learning.py:507] global step 38207: loss = 0.1313 (0.936 sec/step)\n",
      "I0902 08:24:53.280111 139792788920128 learning.py:507] global step 38208: loss = 0.2081 (0.945 sec/step)\n",
      "I0902 08:24:54.218638 139792788920128 learning.py:507] global step 38209: loss = 0.2211 (0.937 sec/step)\n",
      "I0902 08:24:55.150109 139792788920128 learning.py:507] global step 38210: loss = 0.0510 (0.930 sec/step)\n",
      "I0902 08:24:56.099344 139792788920128 learning.py:507] global step 38211: loss = 0.0738 (0.948 sec/step)\n",
      "I0902 08:24:57.045221 139792788920128 learning.py:507] global step 38212: loss = 0.1151 (0.944 sec/step)\n",
      "I0902 08:24:57.996931 139792788920128 learning.py:507] global step 38213: loss = 0.0891 (0.950 sec/step)\n",
      "I0902 08:24:58.947520 139792788920128 learning.py:507] global step 38214: loss = 0.1133 (0.949 sec/step)\n",
      "I0902 08:24:59.911280 139792788920128 learning.py:507] global step 38215: loss = 0.1109 (0.962 sec/step)\n",
      "I0902 08:25:00.863401 139792788920128 learning.py:507] global step 38216: loss = 0.1449 (0.950 sec/step)\n",
      "I0902 08:25:01.812723 139792788920128 learning.py:507] global step 38217: loss = 0.1258 (0.948 sec/step)\n",
      "I0902 08:25:02.766680 139792788920128 learning.py:507] global step 38218: loss = 0.3495 (0.952 sec/step)\n",
      "I0902 08:25:03.702465 139792788920128 learning.py:507] global step 38219: loss = 0.1002 (0.934 sec/step)\n",
      "I0902 08:25:04.648293 139792788920128 learning.py:507] global step 38220: loss = 0.3844 (0.944 sec/step)\n",
      "I0902 08:25:05.609161 139792788920128 learning.py:507] global step 38221: loss = 0.1760 (0.959 sec/step)\n",
      "I0902 08:25:06.566145 139792788920128 learning.py:507] global step 38222: loss = 0.0775 (0.955 sec/step)\n",
      "I0902 08:25:07.507680 139792788920128 learning.py:507] global step 38223: loss = 0.0741 (0.940 sec/step)\n",
      "I0902 08:25:08.456840 139792788920128 learning.py:507] global step 38224: loss = 0.1091 (0.947 sec/step)\n",
      "I0902 08:25:09.407337 139792788920128 learning.py:507] global step 38225: loss = 0.0868 (0.949 sec/step)\n",
      "I0902 08:25:10.371839 139792788920128 learning.py:507] global step 38226: loss = 0.1482 (0.963 sec/step)\n",
      "I0902 08:25:11.325115 139792788920128 learning.py:507] global step 38227: loss = 0.0555 (0.952 sec/step)\n",
      "I0902 08:25:12.276037 139792788920128 learning.py:507] global step 38228: loss = 0.1448 (0.949 sec/step)\n",
      "I0902 08:25:13.222512 139792788920128 learning.py:507] global step 38229: loss = 0.0926 (0.945 sec/step)\n",
      "I0902 08:25:14.182343 139792788920128 learning.py:507] global step 38230: loss = 0.1757 (0.958 sec/step)\n",
      "I0902 08:25:15.114026 139792788920128 learning.py:507] global step 38231: loss = 0.1080 (0.930 sec/step)\n",
      "I0902 08:25:16.049293 139792788920128 learning.py:507] global step 38232: loss = 0.0742 (0.933 sec/step)\n",
      "I0902 08:25:16.974740 139792788920128 learning.py:507] global step 38233: loss = 0.1332 (0.924 sec/step)\n",
      "I0902 08:25:17.914461 139792788920128 learning.py:507] global step 38234: loss = 0.1428 (0.938 sec/step)\n",
      "I0902 08:25:18.861646 139792788920128 learning.py:507] global step 38235: loss = 0.0628 (0.945 sec/step)\n",
      "I0902 08:25:19.814444 139792788920128 learning.py:507] global step 38236: loss = 0.0873 (0.951 sec/step)\n",
      "I0902 08:25:20.748532 139792788920128 learning.py:507] global step 38237: loss = 0.0794 (0.932 sec/step)\n",
      "I0902 08:25:21.706775 139792788920128 learning.py:507] global step 38238: loss = 0.0747 (0.957 sec/step)\n",
      "I0902 08:25:22.654644 139792788920128 learning.py:507] global step 38239: loss = 0.0691 (0.946 sec/step)\n",
      "I0902 08:25:23.619134 139792788920128 learning.py:507] global step 38240: loss = 0.0926 (0.963 sec/step)\n",
      "I0902 08:25:24.565950 139792788920128 learning.py:507] global step 38241: loss = 0.1004 (0.945 sec/step)\n",
      "I0902 08:25:25.521815 139792788920128 learning.py:507] global step 38242: loss = 0.1218 (0.954 sec/step)\n",
      "I0902 08:25:26.461129 139792788920128 learning.py:507] global step 38243: loss = 0.0826 (0.938 sec/step)\n",
      "I0902 08:25:27.411926 139792788920128 learning.py:507] global step 38244: loss = 0.0945 (0.949 sec/step)\n",
      "I0902 08:25:28.360018 139792788920128 learning.py:507] global step 38245: loss = 0.0982 (0.946 sec/step)\n",
      "I0902 08:25:29.290119 139792788920128 learning.py:507] global step 38246: loss = 0.0548 (0.928 sec/step)\n",
      "I0902 08:25:30.254366 139792788920128 learning.py:507] global step 38247: loss = 0.0714 (0.963 sec/step)\n",
      "I0902 08:25:31.218785 139792788920128 learning.py:507] global step 38248: loss = 0.0907 (0.963 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:25:32.163311 139792788920128 learning.py:507] global step 38249: loss = 0.0598 (0.943 sec/step)\n",
      "I0902 08:25:33.114567 139792788920128 learning.py:507] global step 38250: loss = 0.1625 (0.950 sec/step)\n",
      "I0902 08:25:34.064878 139792788920128 learning.py:507] global step 38251: loss = 0.0886 (0.949 sec/step)\n",
      "I0902 08:25:35.020357 139792788920128 learning.py:507] global step 38252: loss = 0.0661 (0.954 sec/step)\n",
      "I0902 08:25:35.999594 139792788920128 learning.py:507] global step 38253: loss = 0.0502 (0.978 sec/step)\n",
      "I0902 08:25:36.975679 139792788920128 learning.py:507] global step 38254: loss = 0.1369 (0.974 sec/step)\n",
      "I0902 08:25:37.930329 139792788920128 learning.py:507] global step 38255: loss = 0.1684 (0.953 sec/step)\n",
      "I0902 08:25:38.879904 139792788920128 learning.py:507] global step 38256: loss = 0.2349 (0.948 sec/step)\n",
      "I0902 08:25:39.815799 139792788920128 learning.py:507] global step 38257: loss = 0.0928 (0.934 sec/step)\n",
      "I0902 08:25:40.770646 139792788920128 learning.py:507] global step 38258: loss = 0.1032 (0.953 sec/step)\n",
      "I0902 08:25:41.714221 139792788920128 learning.py:507] global step 38259: loss = 0.0843 (0.942 sec/step)\n",
      "I0902 08:25:42.643319 139792788920128 learning.py:507] global step 38260: loss = 0.4636 (0.927 sec/step)\n",
      "I0902 08:25:43.600698 139792788920128 learning.py:507] global step 38261: loss = 0.1769 (0.956 sec/step)\n",
      "I0902 08:25:44.554297 139792788920128 learning.py:507] global step 38262: loss = 0.0893 (0.952 sec/step)\n",
      "I0902 08:25:45.498146 139792788920128 learning.py:507] global step 38263: loss = 0.1280 (0.942 sec/step)\n",
      "I0902 08:25:46.462193 139792788920128 learning.py:507] global step 38264: loss = 0.0975 (0.962 sec/step)\n",
      "I0902 08:25:47.425407 139792788920128 learning.py:507] global step 38265: loss = 0.0845 (0.962 sec/step)\n",
      "I0902 08:25:48.380916 139792788920128 learning.py:507] global step 38266: loss = 0.0808 (0.954 sec/step)\n",
      "I0902 08:25:49.348737 139792788920128 learning.py:507] global step 38267: loss = 0.0840 (0.956 sec/step)\n",
      "I0902 08:25:49.984494 139778936784640 supervisor.py:1050] Recording summary at step 38267.\n",
      "I0902 08:25:50.588117 139792788920128 learning.py:507] global step 38268: loss = 0.0960 (1.227 sec/step)\n",
      "I0902 08:25:51.542957 139792788920128 learning.py:507] global step 38269: loss = 0.2547 (0.953 sec/step)\n",
      "I0902 08:25:52.483639 139792788920128 learning.py:507] global step 38270: loss = 0.0634 (0.939 sec/step)\n",
      "I0902 08:25:53.459398 139792788920128 learning.py:507] global step 38271: loss = 0.1009 (0.974 sec/step)\n",
      "I0902 08:25:54.407509 139792788920128 learning.py:507] global step 38272: loss = 0.0783 (0.947 sec/step)\n",
      "I0902 08:25:54.526600 139778945177344 supervisor.py:1099] global_step/sec: 0.958527\n",
      "I0902 08:25:55.362238 139792788920128 learning.py:507] global step 38273: loss = 0.1200 (0.953 sec/step)\n",
      "I0902 08:25:56.315538 139792788920128 learning.py:507] global step 38274: loss = 0.1074 (0.952 sec/step)\n",
      "I0902 08:25:57.276901 139792788920128 learning.py:507] global step 38275: loss = 0.1181 (0.960 sec/step)\n",
      "I0902 08:25:58.250979 139792788920128 learning.py:507] global step 38276: loss = 0.2087 (0.972 sec/step)\n",
      "I0902 08:25:59.212112 139792788920128 learning.py:507] global step 38277: loss = 0.0573 (0.959 sec/step)\n",
      "I0902 08:26:00.172616 139792788920128 learning.py:507] global step 38278: loss = 0.1890 (0.959 sec/step)\n",
      "I0902 08:26:01.127535 139792788920128 learning.py:507] global step 38279: loss = 0.1145 (0.953 sec/step)\n",
      "I0902 08:26:02.082558 139792788920128 learning.py:507] global step 38280: loss = 0.1123 (0.953 sec/step)\n",
      "I0902 08:26:03.037481 139792788920128 learning.py:507] global step 38281: loss = 0.3251 (0.953 sec/step)\n",
      "I0902 08:26:03.983674 139792788920128 learning.py:507] global step 38282: loss = 0.1640 (0.945 sec/step)\n",
      "I0902 08:26:04.914572 139792788920128 learning.py:507] global step 38283: loss = 0.1961 (0.929 sec/step)\n",
      "I0902 08:26:05.884283 139792788920128 learning.py:507] global step 38284: loss = 0.3121 (0.968 sec/step)\n",
      "I0902 08:26:06.853795 139792788920128 learning.py:507] global step 38285: loss = 0.1239 (0.968 sec/step)\n",
      "I0902 08:26:07.810221 139792788920128 learning.py:507] global step 38286: loss = 0.1133 (0.955 sec/step)\n",
      "I0902 08:26:08.770330 139792788920128 learning.py:507] global step 38287: loss = 0.1091 (0.959 sec/step)\n",
      "I0902 08:26:09.723895 139792788920128 learning.py:507] global step 38288: loss = 0.2323 (0.952 sec/step)\n",
      "I0902 08:26:10.694244 139792788920128 learning.py:507] global step 38289: loss = 0.1261 (0.969 sec/step)\n",
      "I0902 08:26:11.632472 139792788920128 learning.py:507] global step 38290: loss = 0.0520 (0.937 sec/step)\n",
      "I0902 08:26:12.597492 139792788920128 learning.py:507] global step 38291: loss = 0.1272 (0.963 sec/step)\n",
      "I0902 08:26:13.567336 139792788920128 learning.py:507] global step 38292: loss = 0.0762 (0.968 sec/step)\n",
      "I0902 08:26:14.508713 139792788920128 learning.py:507] global step 38293: loss = 0.1430 (0.940 sec/step)\n",
      "I0902 08:26:15.493867 139792788920128 learning.py:507] global step 38294: loss = 0.1392 (0.984 sec/step)\n",
      "I0902 08:26:16.434829 139792788920128 learning.py:507] global step 38295: loss = 0.1546 (0.939 sec/step)\n",
      "I0902 08:26:17.382509 139792788920128 learning.py:507] global step 38296: loss = 0.1599 (0.946 sec/step)\n",
      "I0902 08:26:18.362895 139792788920128 learning.py:507] global step 38297: loss = 0.0842 (0.979 sec/step)\n",
      "I0902 08:26:19.321197 139792788920128 learning.py:507] global step 38298: loss = 0.1583 (0.957 sec/step)\n",
      "I0902 08:26:20.270540 139792788920128 learning.py:507] global step 38299: loss = 0.1553 (0.948 sec/step)\n",
      "I0902 08:26:21.247481 139792788920128 learning.py:507] global step 38300: loss = 0.1050 (0.975 sec/step)\n",
      "I0902 08:26:22.214023 139792788920128 learning.py:507] global step 38301: loss = 0.3731 (0.965 sec/step)\n",
      "I0902 08:26:23.163676 139792788920128 learning.py:507] global step 38302: loss = 0.1373 (0.948 sec/step)\n",
      "I0902 08:26:24.115912 139792788920128 learning.py:507] global step 38303: loss = 0.1786 (0.951 sec/step)\n",
      "I0902 08:26:25.072865 139792788920128 learning.py:507] global step 38304: loss = 0.0980 (0.955 sec/step)\n",
      "I0902 08:26:26.026723 139792788920128 learning.py:507] global step 38305: loss = 0.2504 (0.952 sec/step)\n",
      "I0902 08:26:26.977760 139792788920128 learning.py:507] global step 38306: loss = 0.1191 (0.949 sec/step)\n",
      "I0902 08:26:27.941872 139792788920128 learning.py:507] global step 38307: loss = 0.0749 (0.963 sec/step)\n",
      "I0902 08:26:28.908070 139792788920128 learning.py:507] global step 38308: loss = 0.1521 (0.965 sec/step)\n",
      "I0902 08:26:29.862196 139792788920128 learning.py:507] global step 38309: loss = 0.0825 (0.952 sec/step)\n",
      "I0902 08:26:30.813184 139792788920128 learning.py:507] global step 38310: loss = 0.1936 (0.949 sec/step)\n",
      "I0902 08:26:31.768789 139792788920128 learning.py:507] global step 38311: loss = 0.1306 (0.954 sec/step)\n",
      "I0902 08:26:32.723236 139792788920128 learning.py:507] global step 38312: loss = 0.1278 (0.953 sec/step)\n",
      "I0902 08:26:33.684609 139792788920128 learning.py:507] global step 38313: loss = 0.1526 (0.960 sec/step)\n",
      "I0902 08:26:34.629462 139792788920128 learning.py:507] global step 38314: loss = 0.0896 (0.943 sec/step)\n",
      "I0902 08:26:35.581053 139792788920128 learning.py:507] global step 38315: loss = 0.1517 (0.950 sec/step)\n",
      "I0902 08:26:36.552305 139792788920128 learning.py:507] global step 38316: loss = 0.1070 (0.970 sec/step)\n",
      "I0902 08:26:37.517944 139792788920128 learning.py:507] global step 38317: loss = 0.1529 (0.964 sec/step)\n",
      "I0902 08:26:38.476611 139792788920128 learning.py:507] global step 38318: loss = 0.2183 (0.957 sec/step)\n",
      "I0902 08:26:39.443524 139792788920128 learning.py:507] global step 38319: loss = 0.0647 (0.965 sec/step)\n",
      "I0902 08:26:40.401680 139792788920128 learning.py:507] global step 38320: loss = 0.1373 (0.957 sec/step)\n",
      "I0902 08:26:41.357178 139792788920128 learning.py:507] global step 38321: loss = 0.1188 (0.954 sec/step)\n",
      "I0902 08:26:42.321436 139792788920128 learning.py:507] global step 38322: loss = 0.0623 (0.963 sec/step)\n",
      "I0902 08:26:43.289203 139792788920128 learning.py:507] global step 38323: loss = 0.0812 (0.966 sec/step)\n",
      "I0902 08:26:44.223479 139792788920128 learning.py:507] global step 38324: loss = 0.1117 (0.933 sec/step)\n",
      "I0902 08:26:45.181234 139792788920128 learning.py:507] global step 38325: loss = 0.1214 (0.956 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:26:46.155959 139792788920128 learning.py:507] global step 38326: loss = 0.1295 (0.973 sec/step)\n",
      "I0902 08:26:47.131251 139792788920128 learning.py:507] global step 38327: loss = 0.1391 (0.974 sec/step)\n",
      "I0902 08:26:48.099271 139792788920128 learning.py:507] global step 38328: loss = 0.2281 (0.966 sec/step)\n",
      "I0902 08:26:49.077028 139792788920128 learning.py:507] global step 38329: loss = 0.1004 (0.976 sec/step)\n",
      "I0902 08:26:50.053241 139792788920128 learning.py:507] global step 38330: loss = 0.1749 (0.975 sec/step)\n",
      "I0902 08:26:50.994182 139792788920128 learning.py:507] global step 38331: loss = 0.0483 (0.939 sec/step)\n",
      "I0902 08:26:51.965126 139792788920128 learning.py:507] global step 38332: loss = 0.0991 (0.969 sec/step)\n",
      "I0902 08:26:52.911886 139792788920128 learning.py:507] global step 38333: loss = 0.1028 (0.945 sec/step)\n",
      "I0902 08:26:53.886527 139792788920128 learning.py:507] global step 38334: loss = 0.1807 (0.973 sec/step)\n",
      "I0902 08:26:54.845435 139792788920128 learning.py:507] global step 38335: loss = 0.0877 (0.957 sec/step)\n",
      "I0902 08:26:55.817945 139792788920128 learning.py:507] global step 38336: loss = 0.1776 (0.971 sec/step)\n",
      "I0902 08:26:56.787837 139792788920128 learning.py:507] global step 38337: loss = 0.1421 (0.968 sec/step)\n",
      "I0902 08:26:57.751673 139792788920128 learning.py:507] global step 38338: loss = 0.1481 (0.962 sec/step)\n",
      "I0902 08:26:58.720326 139792788920128 learning.py:507] global step 38339: loss = 0.0768 (0.967 sec/step)\n",
      "I0902 08:26:59.708279 139792788920128 learning.py:507] global step 38340: loss = 0.1341 (0.986 sec/step)\n",
      "I0902 08:27:00.687492 139792788920128 learning.py:507] global step 38341: loss = 0.1721 (0.977 sec/step)\n",
      "I0902 08:27:01.642468 139792788920128 learning.py:507] global step 38342: loss = 0.0942 (0.953 sec/step)\n",
      "I0902 08:27:02.577876 139792788920128 learning.py:507] global step 38343: loss = 0.0816 (0.934 sec/step)\n",
      "I0902 08:27:03.523666 139792788920128 learning.py:507] global step 38344: loss = 0.1561 (0.944 sec/step)\n",
      "I0902 08:27:04.502339 139792788920128 learning.py:507] global step 38345: loss = 0.1433 (0.977 sec/step)\n",
      "I0902 08:27:05.448689 139792788920128 learning.py:507] global step 38346: loss = 0.1125 (0.945 sec/step)\n",
      "I0902 08:27:06.414092 139792788920128 learning.py:507] global step 38347: loss = 0.1449 (0.964 sec/step)\n",
      "I0902 08:27:07.374186 139792788920128 learning.py:507] global step 38348: loss = 0.1225 (0.958 sec/step)\n",
      "I0902 08:27:08.336382 139792788920128 learning.py:507] global step 38349: loss = 0.0771 (0.961 sec/step)\n",
      "I0902 08:27:09.283578 139792788920128 learning.py:507] global step 38350: loss = 0.0993 (0.946 sec/step)\n",
      "I0902 08:27:10.258028 139792788920128 learning.py:507] global step 38351: loss = 0.0804 (0.973 sec/step)\n",
      "I0902 08:27:11.227451 139792788920128 learning.py:507] global step 38352: loss = 0.1501 (0.968 sec/step)\n",
      "I0902 08:27:12.190165 139792788920128 learning.py:507] global step 38353: loss = 0.1102 (0.961 sec/step)\n",
      "I0902 08:27:13.151771 139792788920128 learning.py:507] global step 38354: loss = 0.1425 (0.960 sec/step)\n",
      "I0902 08:27:14.090494 139792788920128 learning.py:507] global step 38355: loss = 0.0697 (0.937 sec/step)\n",
      "I0902 08:27:15.052336 139792788920128 learning.py:507] global step 38356: loss = 0.0870 (0.960 sec/step)\n",
      "I0902 08:27:16.011961 139792788920128 learning.py:507] global step 38357: loss = 0.3217 (0.958 sec/step)\n",
      "I0902 08:27:16.966645 139792788920128 learning.py:507] global step 38358: loss = 0.0880 (0.953 sec/step)\n",
      "I0902 08:27:17.936963 139792788920128 learning.py:507] global step 38359: loss = 0.2168 (0.969 sec/step)\n",
      "I0902 08:27:18.896772 139792788920128 learning.py:507] global step 38360: loss = 0.2076 (0.958 sec/step)\n",
      "I0902 08:27:19.865340 139792788920128 learning.py:507] global step 38361: loss = 0.1085 (0.967 sec/step)\n",
      "I0902 08:27:20.847421 139792788920128 learning.py:507] global step 38362: loss = 0.1550 (0.981 sec/step)\n",
      "I0902 08:27:21.825788 139792788920128 learning.py:507] global step 38363: loss = 0.0805 (0.977 sec/step)\n",
      "I0902 08:27:22.788099 139792788920128 learning.py:507] global step 38364: loss = 0.1294 (0.961 sec/step)\n",
      "I0902 08:27:23.758916 139792788920128 learning.py:507] global step 38365: loss = 0.2135 (0.969 sec/step)\n",
      "I0902 08:27:24.712990 139792788920128 learning.py:507] global step 38366: loss = 0.1046 (0.952 sec/step)\n",
      "I0902 08:27:25.668323 139792788920128 learning.py:507] global step 38367: loss = 0.2314 (0.954 sec/step)\n",
      "I0902 08:27:26.631532 139792788920128 learning.py:507] global step 38368: loss = 0.1730 (0.961 sec/step)\n",
      "I0902 08:27:27.581549 139792788920128 learning.py:507] global step 38369: loss = 0.1589 (0.948 sec/step)\n",
      "I0902 08:27:28.576691 139792788920128 learning.py:507] global step 38370: loss = 0.1612 (0.993 sec/step)\n",
      "I0902 08:27:29.536072 139792788920128 learning.py:507] global step 38371: loss = 0.0824 (0.958 sec/step)\n",
      "I0902 08:27:30.504268 139792788920128 learning.py:507] global step 38372: loss = 0.1501 (0.966 sec/step)\n",
      "I0902 08:27:31.458694 139792788920128 learning.py:507] global step 38373: loss = 0.1394 (0.953 sec/step)\n",
      "I0902 08:27:32.420253 139792788920128 learning.py:507] global step 38374: loss = 0.0955 (0.960 sec/step)\n",
      "I0902 08:27:33.394192 139792788920128 learning.py:507] global step 38375: loss = 0.2194 (0.972 sec/step)\n",
      "I0902 08:27:34.343707 139792788920128 learning.py:507] global step 38376: loss = 0.1470 (0.948 sec/step)\n",
      "I0902 08:27:35.318378 139792788920128 learning.py:507] global step 38377: loss = 0.1039 (0.973 sec/step)\n",
      "I0902 08:27:36.274310 139792788920128 learning.py:507] global step 38378: loss = 0.1760 (0.954 sec/step)\n",
      "I0902 08:27:37.247953 139792788920128 learning.py:507] global step 38379: loss = 0.1093 (0.972 sec/step)\n",
      "I0902 08:27:38.209728 139792788920128 learning.py:507] global step 38380: loss = 0.0897 (0.961 sec/step)\n",
      "I0902 08:27:39.166552 139792788920128 learning.py:507] global step 38381: loss = 0.1135 (0.955 sec/step)\n",
      "I0902 08:27:40.140269 139792788920128 learning.py:507] global step 38382: loss = 0.1164 (0.972 sec/step)\n",
      "I0902 08:27:41.093968 139792788920128 learning.py:507] global step 38383: loss = 0.3155 (0.952 sec/step)\n",
      "I0902 08:27:42.066416 139792788920128 learning.py:507] global step 38384: loss = 0.1021 (0.971 sec/step)\n",
      "I0902 08:27:43.025756 139792788920128 learning.py:507] global step 38385: loss = 0.2285 (0.958 sec/step)\n",
      "I0902 08:27:43.968412 139792788920128 learning.py:507] global step 38386: loss = 0.1672 (0.941 sec/step)\n",
      "I0902 08:27:44.932721 139792788920128 learning.py:507] global step 38387: loss = 0.2720 (0.963 sec/step)\n",
      "I0902 08:27:45.876559 139792788920128 learning.py:507] global step 38388: loss = 0.1014 (0.943 sec/step)\n",
      "I0902 08:27:46.841708 139792788920128 learning.py:507] global step 38389: loss = 0.1738 (0.964 sec/step)\n",
      "I0902 08:27:47.796545 139792788920128 learning.py:507] global step 38390: loss = 0.1879 (0.954 sec/step)\n",
      "I0902 08:27:48.773717 139792788920128 learning.py:507] global step 38391: loss = 0.0735 (0.976 sec/step)\n",
      "I0902 08:27:49.884149 139792788920128 learning.py:507] global step 38392: loss = 0.1294 (1.103 sec/step)\n",
      "I0902 08:27:50.200476 139778936784640 supervisor.py:1050] Recording summary at step 38392.\n",
      "I0902 08:27:50.983836 139792788920128 learning.py:507] global step 38393: loss = 0.1067 (1.095 sec/step)\n",
      "I0902 08:27:51.950995 139792788920128 learning.py:507] global step 38394: loss = 0.1085 (0.966 sec/step)\n",
      "I0902 08:27:52.907786 139792788920128 learning.py:507] global step 38395: loss = 0.0786 (0.955 sec/step)\n",
      "I0902 08:27:53.888674 139792788920128 learning.py:507] global step 38396: loss = 0.0954 (0.979 sec/step)\n",
      "I0902 08:27:54.526644 139778945177344 supervisor.py:1099] global_step/sec: 1.03333\n",
      "I0902 08:27:54.857574 139792788920128 learning.py:507] global step 38397: loss = 0.1457 (0.967 sec/step)\n",
      "I0902 08:27:55.811266 139792788920128 learning.py:507] global step 38398: loss = 0.1550 (0.952 sec/step)\n",
      "I0902 08:27:56.761403 139792788920128 learning.py:507] global step 38399: loss = 0.1636 (0.949 sec/step)\n",
      "I0902 08:27:57.746458 139792788920128 learning.py:507] global step 38400: loss = 0.0840 (0.984 sec/step)\n",
      "I0902 08:27:58.723788 139792788920128 learning.py:507] global step 38401: loss = 0.1220 (0.976 sec/step)\n",
      "I0902 08:27:59.683674 139792788920128 learning.py:507] global step 38402: loss = 0.1423 (0.958 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:28:00.638370 139792788920128 learning.py:507] global step 38403: loss = 0.1564 (0.953 sec/step)\n",
      "I0902 08:28:01.598750 139792788920128 learning.py:507] global step 38404: loss = 0.2629 (0.959 sec/step)\n",
      "I0902 08:28:02.587080 139792788920128 learning.py:507] global step 38405: loss = 0.1293 (0.987 sec/step)\n",
      "I0902 08:28:03.557139 139792788920128 learning.py:507] global step 38406: loss = 0.0931 (0.968 sec/step)\n",
      "I0902 08:28:04.515945 139792788920128 learning.py:507] global step 38407: loss = 0.1807 (0.957 sec/step)\n",
      "I0902 08:28:05.483837 139792788920128 learning.py:507] global step 38408: loss = 0.2144 (0.966 sec/step)\n",
      "I0902 08:28:06.468668 139792788920128 learning.py:507] global step 38409: loss = 0.0965 (0.983 sec/step)\n",
      "I0902 08:28:07.448136 139792788920128 learning.py:507] global step 38410: loss = 0.2295 (0.978 sec/step)\n",
      "I0902 08:28:08.412956 139792788920128 learning.py:507] global step 38411: loss = 0.1242 (0.963 sec/step)\n",
      "I0902 08:28:09.391819 139792788920128 learning.py:507] global step 38412: loss = 0.2083 (0.977 sec/step)\n",
      "I0902 08:28:10.364584 139792788920128 learning.py:507] global step 38413: loss = 0.0759 (0.971 sec/step)\n",
      "I0902 08:28:11.347170 139792788920128 learning.py:507] global step 38414: loss = 0.1661 (0.981 sec/step)\n",
      "I0902 08:28:12.308197 139792788920128 learning.py:507] global step 38415: loss = 0.1990 (0.959 sec/step)\n",
      "I0902 08:28:13.298737 139792788920128 learning.py:507] global step 38416: loss = 0.1353 (0.989 sec/step)\n",
      "I0902 08:28:14.258613 139792788920128 learning.py:507] global step 38417: loss = 0.1771 (0.958 sec/step)\n",
      "I0902 08:28:15.261441 139792788920128 learning.py:507] global step 38418: loss = 0.1769 (1.001 sec/step)\n",
      "I0902 08:28:16.243721 139792788920128 learning.py:507] global step 38419: loss = 0.0605 (0.981 sec/step)\n",
      "I0902 08:28:17.215469 139792788920128 learning.py:507] global step 38420: loss = 0.1257 (0.970 sec/step)\n",
      "I0902 08:28:18.193238 139792788920128 learning.py:507] global step 38421: loss = 0.0708 (0.976 sec/step)\n",
      "I0902 08:28:19.155210 139792788920128 learning.py:507] global step 38422: loss = 0.4510 (0.960 sec/step)\n",
      "I0902 08:28:20.126352 139792788920128 learning.py:507] global step 38423: loss = 0.0981 (0.969 sec/step)\n",
      "I0902 08:28:21.098664 139792788920128 learning.py:507] global step 38424: loss = 0.1537 (0.971 sec/step)\n",
      "I0902 08:28:22.070423 139792788920128 learning.py:507] global step 38425: loss = 0.0418 (0.970 sec/step)\n",
      "I0902 08:28:23.045904 139792788920128 learning.py:507] global step 38426: loss = 0.2041 (0.974 sec/step)\n",
      "I0902 08:28:24.025914 139792788920128 learning.py:507] global step 38427: loss = 0.2827 (0.978 sec/step)\n",
      "I0902 08:28:25.325463 139792788920128 learning.py:507] global step 38428: loss = 0.1263 (1.298 sec/step)\n",
      "I0902 08:28:26.311871 139792788920128 learning.py:507] global step 38429: loss = 0.1551 (0.985 sec/step)\n",
      "I0902 08:28:27.301608 139792788920128 learning.py:507] global step 38430: loss = 0.1015 (0.988 sec/step)\n",
      "I0902 08:28:28.288890 139792788920128 learning.py:507] global step 38431: loss = 0.1030 (0.986 sec/step)\n",
      "I0902 08:28:29.273529 139792788920128 learning.py:507] global step 38432: loss = 0.1795 (0.983 sec/step)\n",
      "I0902 08:28:30.254849 139792788920128 learning.py:507] global step 38433: loss = 0.1144 (0.979 sec/step)\n",
      "I0902 08:28:31.236675 139792788920128 learning.py:507] global step 38434: loss = 0.1465 (0.980 sec/step)\n",
      "I0902 08:28:32.240539 139792788920128 learning.py:507] global step 38435: loss = 0.1251 (1.002 sec/step)\n",
      "I0902 08:28:33.223353 139792788920128 learning.py:507] global step 38436: loss = 0.1266 (0.981 sec/step)\n",
      "I0902 08:28:34.191408 139792788920128 learning.py:507] global step 38437: loss = 0.0839 (0.966 sec/step)\n",
      "I0902 08:28:35.164647 139792788920128 learning.py:507] global step 38438: loss = 0.1024 (0.972 sec/step)\n",
      "I0902 08:28:36.149126 139792788920128 learning.py:507] global step 38439: loss = 0.0738 (0.983 sec/step)\n",
      "I0902 08:28:37.095551 139792788920128 learning.py:507] global step 38440: loss = 0.1221 (0.945 sec/step)\n",
      "I0902 08:28:38.049934 139792788920128 learning.py:507] global step 38441: loss = 0.1214 (0.953 sec/step)\n",
      "I0902 08:28:39.025534 139792788920128 learning.py:507] global step 38442: loss = 0.1008 (0.974 sec/step)\n",
      "I0902 08:28:39.998194 139792788920128 learning.py:507] global step 38443: loss = 0.1224 (0.971 sec/step)\n",
      "I0902 08:28:40.975167 139792788920128 learning.py:507] global step 38444: loss = 0.1482 (0.975 sec/step)\n",
      "I0902 08:28:41.960577 139792788920128 learning.py:507] global step 38445: loss = 0.1720 (0.984 sec/step)\n",
      "I0902 08:28:42.992985 139792788920128 learning.py:507] global step 38446: loss = 0.1393 (1.031 sec/step)\n",
      "I0902 08:28:43.951473 139792788920128 learning.py:507] global step 38447: loss = 0.0623 (0.957 sec/step)\n",
      "I0902 08:28:44.925912 139792788920128 learning.py:507] global step 38448: loss = 0.0795 (0.973 sec/step)\n",
      "I0902 08:28:45.910302 139792788920128 learning.py:507] global step 38449: loss = 0.1499 (0.983 sec/step)\n",
      "I0902 08:28:46.901724 139792788920128 learning.py:507] global step 38450: loss = 0.0988 (0.990 sec/step)\n",
      "I0902 08:28:47.874856 139792788920128 learning.py:507] global step 38451: loss = 0.1162 (0.972 sec/step)\n",
      "I0902 08:28:48.860516 139792788920128 learning.py:507] global step 38452: loss = 0.2154 (0.984 sec/step)\n",
      "I0902 08:28:49.812598 139792788920128 learning.py:507] global step 38453: loss = 0.1324 (0.951 sec/step)\n",
      "I0902 08:28:50.785288 139792788920128 learning.py:507] global step 38454: loss = 0.0921 (0.971 sec/step)\n",
      "I0902 08:28:51.772465 139792788920128 learning.py:507] global step 38455: loss = 0.1847 (0.986 sec/step)\n",
      "I0902 08:28:52.724105 139792788920128 learning.py:507] global step 38456: loss = 0.1988 (0.950 sec/step)\n",
      "I0902 08:28:53.708929 139792788920128 learning.py:507] global step 38457: loss = 0.2314 (0.983 sec/step)\n",
      "I0902 08:28:54.680906 139792788920128 learning.py:507] global step 38458: loss = 0.0613 (0.970 sec/step)\n",
      "I0902 08:28:55.642310 139792788920128 learning.py:507] global step 38459: loss = 0.0991 (0.960 sec/step)\n",
      "I0902 08:28:56.616050 139792788920128 learning.py:507] global step 38460: loss = 0.0606 (0.972 sec/step)\n",
      "I0902 08:28:57.610465 139792788920128 learning.py:507] global step 38461: loss = 0.0670 (0.993 sec/step)\n",
      "I0902 08:28:58.609742 139792788920128 learning.py:507] global step 38462: loss = 0.0822 (0.998 sec/step)\n",
      "I0902 08:28:59.589380 139792788920128 learning.py:507] global step 38463: loss = 0.2718 (0.978 sec/step)\n",
      "I0902 08:29:00.577868 139792788920128 learning.py:507] global step 38464: loss = 0.3443 (0.987 sec/step)\n",
      "I0902 08:29:01.557732 139792788920128 learning.py:507] global step 38465: loss = 0.1210 (0.978 sec/step)\n",
      "I0902 08:29:02.529030 139792788920128 learning.py:507] global step 38466: loss = 0.1553 (0.970 sec/step)\n",
      "I0902 08:29:03.521505 139792788920128 learning.py:507] global step 38467: loss = 0.1396 (0.991 sec/step)\n",
      "I0902 08:29:04.467773 139792788920128 learning.py:507] global step 38468: loss = 0.3854 (0.945 sec/step)\n",
      "I0902 08:29:05.446390 139792788920128 learning.py:507] global step 38469: loss = 0.1383 (0.977 sec/step)\n",
      "I0902 08:29:06.425464 139792788920128 learning.py:507] global step 38470: loss = 0.0532 (0.977 sec/step)\n",
      "I0902 08:29:07.411180 139792788920128 learning.py:507] global step 38471: loss = 0.1856 (0.984 sec/step)\n",
      "I0902 08:29:08.384251 139792788920128 learning.py:507] global step 38472: loss = 0.0914 (0.971 sec/step)\n",
      "I0902 08:29:09.386560 139792788920128 learning.py:507] global step 38473: loss = 0.1912 (1.001 sec/step)\n",
      "I0902 08:29:10.371203 139792788920128 learning.py:507] global step 38474: loss = 0.1517 (0.983 sec/step)\n",
      "I0902 08:29:11.337875 139792788920128 learning.py:507] global step 38475: loss = 0.0625 (0.965 sec/step)\n",
      "I0902 08:29:12.318722 139792788920128 learning.py:507] global step 38476: loss = 0.1167 (0.979 sec/step)\n",
      "I0902 08:29:13.285898 139792788920128 learning.py:507] global step 38477: loss = 0.1290 (0.966 sec/step)\n",
      "I0902 08:29:14.244750 139792788920128 learning.py:507] global step 38478: loss = 0.0570 (0.957 sec/step)\n",
      "I0902 08:29:15.220161 139792788920128 learning.py:507] global step 38479: loss = 0.0679 (0.974 sec/step)\n",
      "I0902 08:29:16.190255 139792788920128 learning.py:507] global step 38480: loss = 0.0832 (0.968 sec/step)\n",
      "I0902 08:29:17.156414 139792788920128 learning.py:507] global step 38481: loss = 0.1114 (0.965 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:29:18.136790 139792788920128 learning.py:507] global step 38482: loss = 0.0801 (0.979 sec/step)\n",
      "I0902 08:29:19.094595 139792788920128 learning.py:507] global step 38483: loss = 0.0856 (0.956 sec/step)\n",
      "I0902 08:29:20.061048 139792788920128 learning.py:507] global step 38484: loss = 0.1080 (0.965 sec/step)\n",
      "I0902 08:29:21.049204 139792788920128 learning.py:507] global step 38485: loss = 0.0796 (0.986 sec/step)\n",
      "I0902 08:29:22.015835 139792788920128 learning.py:507] global step 38486: loss = 0.0585 (0.965 sec/step)\n",
      "I0902 08:29:22.986330 139792788920128 learning.py:507] global step 38487: loss = 0.0959 (0.969 sec/step)\n",
      "I0902 08:29:23.954408 139792788920128 learning.py:507] global step 38488: loss = 0.0832 (0.967 sec/step)\n",
      "I0902 08:29:24.948247 139792788920128 learning.py:507] global step 38489: loss = 0.1538 (0.992 sec/step)\n",
      "I0902 08:29:25.928979 139792788920128 learning.py:507] global step 38490: loss = 0.2457 (0.979 sec/step)\n",
      "I0902 08:29:26.908805 139792788920128 learning.py:507] global step 38491: loss = 0.0552 (0.978 sec/step)\n",
      "I0902 08:29:27.869629 139792788920128 learning.py:507] global step 38492: loss = 0.1793 (0.959 sec/step)\n",
      "I0902 08:29:28.849386 139792788920128 learning.py:507] global step 38493: loss = 0.0928 (0.978 sec/step)\n",
      "I0902 08:29:29.840701 139792788920128 learning.py:507] global step 38494: loss = 0.3563 (0.990 sec/step)\n",
      "I0902 08:29:30.809479 139792788920128 learning.py:507] global step 38495: loss = 0.1011 (0.967 sec/step)\n",
      "I0902 08:29:31.776546 139792788920128 learning.py:507] global step 38496: loss = 0.1286 (0.965 sec/step)\n",
      "I0902 08:29:32.754150 139792788920128 learning.py:507] global step 38497: loss = 0.2816 (0.976 sec/step)\n",
      "I0902 08:29:33.727835 139792788920128 learning.py:507] global step 38498: loss = 0.0514 (0.972 sec/step)\n",
      "I0902 08:29:34.692573 139792788920128 learning.py:507] global step 38499: loss = 0.1118 (0.963 sec/step)\n",
      "I0902 08:29:35.658129 139792788920128 learning.py:507] global step 38500: loss = 0.1430 (0.964 sec/step)\n",
      "I0902 08:29:36.660493 139792788920128 learning.py:507] global step 38501: loss = 0.0922 (1.001 sec/step)\n",
      "I0902 08:29:37.641505 139792788920128 learning.py:507] global step 38502: loss = 0.2651 (0.979 sec/step)\n",
      "I0902 08:29:38.597180 139792788920128 learning.py:507] global step 38503: loss = 0.0704 (0.954 sec/step)\n",
      "I0902 08:29:39.577456 139792788920128 learning.py:507] global step 38504: loss = 0.0738 (0.979 sec/step)\n",
      "I0902 08:29:40.544462 139792788920128 learning.py:507] global step 38505: loss = 0.1906 (0.965 sec/step)\n",
      "I0902 08:29:41.515657 139792788920128 learning.py:507] global step 38506: loss = 0.1386 (0.970 sec/step)\n",
      "I0902 08:29:42.514394 139792788920128 learning.py:507] global step 38507: loss = 0.1491 (0.997 sec/step)\n",
      "I0902 08:29:43.483575 139792788920128 learning.py:507] global step 38508: loss = 0.1765 (0.968 sec/step)\n",
      "I0902 08:29:44.460922 139792788920128 learning.py:507] global step 38509: loss = 0.0881 (0.976 sec/step)\n",
      "I0902 08:29:45.462941 139792788920128 learning.py:507] global step 38510: loss = 0.1418 (1.000 sec/step)\n",
      "I0902 08:29:46.446432 139792788920128 learning.py:507] global step 38511: loss = 0.1106 (0.982 sec/step)\n",
      "I0902 08:29:47.402743 139792788920128 learning.py:507] global step 38512: loss = 0.0648 (0.955 sec/step)\n",
      "I0902 08:29:48.386761 139792788920128 learning.py:507] global step 38513: loss = 0.1969 (0.982 sec/step)\n",
      "I0902 08:29:49.367560 139792788920128 learning.py:507] global step 38514: loss = 0.1396 (0.977 sec/step)\n",
      "I0902 08:29:50.017305 139778936784640 supervisor.py:1050] Recording summary at step 38514.\n",
      "I0902 08:29:50.651378 139792788920128 learning.py:507] global step 38515: loss = 0.1172 (1.282 sec/step)\n",
      "I0902 08:29:51.625535 139792788920128 learning.py:507] global step 38516: loss = 0.2875 (0.973 sec/step)\n",
      "I0902 08:29:52.590802 139792788920128 learning.py:507] global step 38517: loss = 0.0949 (0.964 sec/step)\n",
      "I0902 08:29:53.578018 139792788920128 learning.py:507] global step 38518: loss = 0.1516 (0.986 sec/step)\n",
      "I0902 08:29:54.526532 139778945177344 supervisor.py:1099] global_step/sec: 1.01667\n",
      "I0902 08:29:54.556475 139792788920128 learning.py:507] global step 38519: loss = 0.0746 (0.977 sec/step)\n",
      "I0902 08:29:55.534192 139792788920128 learning.py:507] global step 38520: loss = 0.1130 (0.976 sec/step)\n",
      "I0902 08:29:56.524834 139792788920128 learning.py:507] global step 38521: loss = 0.0753 (0.989 sec/step)\n",
      "I0902 08:29:57.491834 139792788920128 learning.py:507] global step 38522: loss = 0.0934 (0.965 sec/step)\n",
      "I0902 08:29:58.485187 139792788920128 learning.py:507] global step 38523: loss = 0.0687 (0.992 sec/step)\n",
      "I0902 08:29:59.474046 139792788920128 learning.py:507] global step 38524: loss = 0.0637 (0.987 sec/step)\n",
      "I0902 08:30:00.458656 139792788920128 learning.py:507] global step 38525: loss = 0.0921 (0.983 sec/step)\n",
      "I0902 08:30:01.419322 139792788920128 learning.py:507] global step 38526: loss = 0.0799 (0.959 sec/step)\n",
      "I0902 08:30:02.393803 139792788920128 learning.py:507] global step 38527: loss = 0.0857 (0.973 sec/step)\n",
      "I0902 08:30:03.380899 139792788920128 learning.py:507] global step 38528: loss = 0.2585 (0.985 sec/step)\n",
      "I0902 08:30:04.374669 139792788920128 learning.py:507] global step 38529: loss = 0.1359 (0.992 sec/step)\n",
      "I0902 08:30:05.360134 139792788920128 learning.py:507] global step 38530: loss = 0.0541 (0.984 sec/step)\n",
      "I0902 08:30:06.355891 139792788920128 learning.py:507] global step 38531: loss = 0.1106 (0.994 sec/step)\n",
      "I0902 08:30:07.343157 139792788920128 learning.py:507] global step 38532: loss = 0.1291 (0.986 sec/step)\n",
      "I0902 08:30:08.340421 139792788920128 learning.py:507] global step 38533: loss = 0.1417 (0.996 sec/step)\n",
      "I0902 08:30:09.308786 139792788920128 learning.py:507] global step 38534: loss = 0.0387 (0.967 sec/step)\n",
      "I0902 08:30:10.272172 139792788920128 learning.py:507] global step 38535: loss = 0.0747 (0.962 sec/step)\n",
      "I0902 08:30:11.240121 139792788920128 learning.py:507] global step 38536: loss = 0.0888 (0.966 sec/step)\n",
      "I0902 08:30:12.232195 139792788920128 learning.py:507] global step 38537: loss = 0.0731 (0.990 sec/step)\n",
      "I0902 08:30:13.231477 139792788920128 learning.py:507] global step 38538: loss = 0.1073 (0.998 sec/step)\n",
      "I0902 08:30:14.223662 139792788920128 learning.py:507] global step 38539: loss = 0.1487 (0.991 sec/step)\n",
      "I0902 08:30:15.204288 139792788920128 learning.py:507] global step 38540: loss = 0.0727 (0.979 sec/step)\n",
      "I0902 08:30:16.228459 139792788920128 learning.py:507] global step 38541: loss = 0.0877 (1.023 sec/step)\n",
      "I0902 08:30:17.198399 139792788920128 learning.py:507] global step 38542: loss = 0.1691 (0.968 sec/step)\n",
      "I0902 08:30:18.193281 139792788920128 learning.py:507] global step 38543: loss = 0.1351 (0.993 sec/step)\n",
      "I0902 08:30:19.158320 139792788920128 learning.py:507] global step 38544: loss = 0.0544 (0.963 sec/step)\n",
      "I0902 08:30:20.132053 139792788920128 learning.py:507] global step 38545: loss = 0.0579 (0.972 sec/step)\n",
      "I0902 08:30:21.114172 139792788920128 learning.py:507] global step 38546: loss = 0.2280 (0.980 sec/step)\n",
      "I0902 08:30:22.077466 139792788920128 learning.py:507] global step 38547: loss = 0.0929 (0.962 sec/step)\n",
      "I0902 08:30:23.053271 139792788920128 learning.py:507] global step 38548: loss = 0.1152 (0.974 sec/step)\n",
      "I0902 08:30:24.026150 139792788920128 learning.py:507] global step 38549: loss = 0.1722 (0.971 sec/step)\n",
      "I0902 08:30:24.996679 139792788920128 learning.py:507] global step 38550: loss = 0.0538 (0.969 sec/step)\n",
      "I0902 08:30:25.990056 139792788920128 learning.py:507] global step 38551: loss = 0.1418 (0.992 sec/step)\n",
      "I0902 08:30:26.996227 139792788920128 learning.py:507] global step 38552: loss = 0.0664 (1.005 sec/step)\n",
      "I0902 08:30:27.985729 139792788920128 learning.py:507] global step 38553: loss = 0.0977 (0.988 sec/step)\n",
      "I0902 08:30:28.965010 139792788920128 learning.py:507] global step 38554: loss = 0.1374 (0.978 sec/step)\n",
      "I0902 08:30:29.923483 139792788920128 learning.py:507] global step 38555: loss = 0.0635 (0.957 sec/step)\n",
      "I0902 08:30:30.903684 139792788920128 learning.py:507] global step 38556: loss = 0.1822 (0.979 sec/step)\n",
      "I0902 08:30:31.876929 139792788920128 learning.py:507] global step 38557: loss = 0.3016 (0.972 sec/step)\n",
      "I0902 08:30:32.842020 139792788920128 learning.py:507] global step 38558: loss = 0.0895 (0.964 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:30:33.797558 139792788920128 learning.py:507] global step 38559: loss = 0.0638 (0.954 sec/step)\n",
      "I0902 08:30:34.805984 139792788920128 learning.py:507] global step 38560: loss = 0.0788 (1.007 sec/step)\n",
      "I0902 08:30:35.795018 139792788920128 learning.py:507] global step 38561: loss = 0.0751 (0.988 sec/step)\n",
      "I0902 08:30:36.780145 139792788920128 learning.py:507] global step 38562: loss = 0.0996 (0.984 sec/step)\n",
      "I0902 08:30:37.771632 139792788920128 learning.py:507] global step 38563: loss = 0.0643 (0.990 sec/step)\n",
      "I0902 08:30:38.741412 139792788920128 learning.py:507] global step 38564: loss = 0.1933 (0.968 sec/step)\n",
      "I0902 08:30:39.733829 139792788920128 learning.py:507] global step 38565: loss = 0.1790 (0.991 sec/step)\n",
      "I0902 08:30:40.688952 139792788920128 learning.py:507] global step 38566: loss = 0.1119 (0.953 sec/step)\n",
      "I0902 08:30:41.656567 139792788920128 learning.py:507] global step 38567: loss = 0.2522 (0.966 sec/step)\n",
      "I0902 08:30:42.626946 139792788920128 learning.py:507] global step 38568: loss = 0.0911 (0.969 sec/step)\n",
      "I0902 08:30:43.608545 139792788920128 learning.py:507] global step 38569: loss = 0.0984 (0.980 sec/step)\n",
      "I0902 08:30:44.615543 139792788920128 learning.py:507] global step 38570: loss = 0.1262 (1.005 sec/step)\n",
      "I0902 08:30:45.595788 139792788920128 learning.py:507] global step 38571: loss = 0.2076 (0.979 sec/step)\n",
      "I0902 08:30:46.591426 139792788920128 learning.py:507] global step 38572: loss = 0.1103 (0.994 sec/step)\n",
      "I0902 08:30:47.572020 139792788920128 learning.py:507] global step 38573: loss = 0.0794 (0.979 sec/step)\n",
      "I0902 08:30:48.561110 139792788920128 learning.py:507] global step 38574: loss = 0.0921 (0.987 sec/step)\n",
      "I0902 08:30:49.529703 139792788920128 learning.py:507] global step 38575: loss = 0.1993 (0.967 sec/step)\n",
      "I0902 08:30:50.499839 139792788920128 learning.py:507] global step 38576: loss = 0.1095 (0.969 sec/step)\n",
      "I0902 08:30:51.496187 139792788920128 learning.py:507] global step 38577: loss = 0.2958 (0.995 sec/step)\n",
      "I0902 08:30:52.466778 139792788920128 learning.py:507] global step 38578: loss = 0.2535 (0.969 sec/step)\n",
      "I0902 08:30:53.426411 139792788920128 learning.py:507] global step 38579: loss = 0.1035 (0.958 sec/step)\n",
      "I0902 08:30:54.393164 139792788920128 learning.py:507] global step 38580: loss = 0.1430 (0.965 sec/step)\n",
      "I0902 08:30:55.363949 139792788920128 learning.py:507] global step 38581: loss = 0.1366 (0.969 sec/step)\n",
      "I0902 08:30:56.339811 139792788920128 learning.py:507] global step 38582: loss = 0.1204 (0.974 sec/step)\n",
      "I0902 08:30:57.311511 139792788920128 learning.py:507] global step 38583: loss = 0.0508 (0.970 sec/step)\n",
      "I0902 08:30:58.281083 139792788920128 learning.py:507] global step 38584: loss = 0.0788 (0.968 sec/step)\n",
      "I0902 08:30:59.232509 139792788920128 learning.py:507] global step 38585: loss = 0.0764 (0.950 sec/step)\n",
      "I0902 08:31:00.201208 139792788920128 learning.py:507] global step 38586: loss = 0.1353 (0.967 sec/step)\n",
      "I0902 08:31:01.181336 139792788920128 learning.py:507] global step 38587: loss = 0.1143 (0.979 sec/step)\n",
      "I0902 08:31:02.141132 139792788920128 learning.py:507] global step 38588: loss = 0.1198 (0.958 sec/step)\n",
      "I0902 08:31:03.106547 139792788920128 learning.py:507] global step 38589: loss = 0.1399 (0.964 sec/step)\n",
      "I0902 08:31:04.071257 139792788920128 learning.py:507] global step 38590: loss = 0.1131 (0.963 sec/step)\n",
      "I0902 08:31:05.037523 139792788920128 learning.py:507] global step 38591: loss = 0.1377 (0.965 sec/step)\n",
      "I0902 08:31:05.995963 139792788920128 learning.py:507] global step 38592: loss = 0.0848 (0.957 sec/step)\n",
      "I0902 08:31:06.959067 139792788920128 learning.py:507] global step 38593: loss = 0.1160 (0.962 sec/step)\n",
      "I0902 08:31:07.926577 139792788920128 learning.py:507] global step 38594: loss = 0.2213 (0.966 sec/step)\n",
      "I0902 08:31:08.892463 139792788920128 learning.py:507] global step 38595: loss = 0.0572 (0.964 sec/step)\n",
      "I0902 08:31:09.862778 139792788920128 learning.py:507] global step 38596: loss = 0.1303 (0.969 sec/step)\n",
      "I0902 08:31:10.831687 139792788920128 learning.py:507] global step 38597: loss = 0.1342 (0.968 sec/step)\n",
      "I0902 08:31:11.792139 139792788920128 learning.py:507] global step 38598: loss = 0.1290 (0.959 sec/step)\n",
      "I0902 08:31:12.742478 139792788920128 learning.py:507] global step 38599: loss = 0.0959 (0.949 sec/step)\n",
      "I0902 08:31:13.739148 139792788920128 learning.py:507] global step 38600: loss = 0.1925 (0.995 sec/step)\n",
      "I0902 08:31:14.723456 139792788920128 learning.py:507] global step 38601: loss = 0.1283 (0.983 sec/step)\n",
      "I0902 08:31:15.706374 139792788920128 learning.py:507] global step 38602: loss = 0.1618 (0.981 sec/step)\n",
      "I0902 08:31:16.670503 139792788920128 learning.py:507] global step 38603: loss = 0.1297 (0.962 sec/step)\n",
      "I0902 08:31:17.631509 139792788920128 learning.py:507] global step 38604: loss = 0.1032 (0.959 sec/step)\n",
      "I0902 08:31:18.606601 139792788920128 learning.py:507] global step 38605: loss = 0.1819 (0.973 sec/step)\n",
      "I0902 08:31:19.570104 139792788920128 learning.py:507] global step 38606: loss = 0.0641 (0.962 sec/step)\n",
      "I0902 08:31:20.519671 139792788920128 learning.py:507] global step 38607: loss = 0.1261 (0.948 sec/step)\n",
      "I0902 08:31:21.503804 139792788920128 learning.py:507] global step 38608: loss = 0.0975 (0.982 sec/step)\n",
      "I0902 08:31:22.492659 139792788920128 learning.py:507] global step 38609: loss = 0.1331 (0.987 sec/step)\n",
      "I0902 08:31:23.457480 139792788920128 learning.py:507] global step 38610: loss = 0.1086 (0.963 sec/step)\n",
      "I0902 08:31:24.428941 139792788920128 learning.py:507] global step 38611: loss = 0.1441 (0.970 sec/step)\n",
      "I0902 08:31:25.381922 139792788920128 learning.py:507] global step 38612: loss = 0.0673 (0.951 sec/step)\n",
      "I0902 08:31:26.349419 139792788920128 learning.py:507] global step 38613: loss = 0.2281 (0.966 sec/step)\n",
      "I0902 08:31:27.305304 139792788920128 learning.py:507] global step 38614: loss = 0.1038 (0.954 sec/step)\n",
      "I0902 08:31:28.316588 139792788920128 learning.py:507] global step 38615: loss = 0.0736 (1.010 sec/step)\n",
      "I0902 08:31:29.267079 139792788920128 learning.py:507] global step 38616: loss = 0.0735 (0.949 sec/step)\n",
      "I0902 08:31:30.250020 139792788920128 learning.py:507] global step 38617: loss = 0.2630 (0.981 sec/step)\n",
      "I0902 08:31:31.221251 139792788920128 learning.py:507] global step 38618: loss = 0.1727 (0.970 sec/step)\n",
      "I0902 08:31:32.173542 139792788920128 learning.py:507] global step 38619: loss = 0.1154 (0.951 sec/step)\n",
      "I0902 08:31:33.151318 139792788920128 learning.py:507] global step 38620: loss = 0.0453 (0.976 sec/step)\n",
      "I0902 08:31:34.110838 139792788920128 learning.py:507] global step 38621: loss = 0.1891 (0.958 sec/step)\n",
      "I0902 08:31:35.066619 139792788920128 learning.py:507] global step 38622: loss = 0.1013 (0.954 sec/step)\n",
      "I0902 08:31:36.054173 139792788920128 learning.py:507] global step 38623: loss = 0.0929 (0.986 sec/step)\n",
      "I0902 08:31:37.029349 139792788920128 learning.py:507] global step 38624: loss = 0.1267 (0.974 sec/step)\n",
      "I0902 08:31:37.993688 139792788920128 learning.py:507] global step 38625: loss = 0.2068 (0.963 sec/step)\n",
      "I0902 08:31:38.939604 139792788920128 learning.py:507] global step 38626: loss = 0.1791 (0.944 sec/step)\n",
      "I0902 08:31:39.902983 139792788920128 learning.py:507] global step 38627: loss = 0.0782 (0.962 sec/step)\n",
      "I0902 08:31:40.869922 139792788920128 learning.py:507] global step 38628: loss = 0.1533 (0.965 sec/step)\n",
      "I0902 08:31:41.856815 139792788920128 learning.py:507] global step 38629: loss = 0.0883 (0.985 sec/step)\n",
      "I0902 08:31:42.823140 139792788920128 learning.py:507] global step 38630: loss = 0.2002 (0.964 sec/step)\n",
      "I0902 08:31:43.784285 139792788920128 learning.py:507] global step 38631: loss = 0.0832 (0.959 sec/step)\n",
      "I0902 08:31:44.747947 139792788920128 learning.py:507] global step 38632: loss = 0.4893 (0.962 sec/step)\n",
      "I0902 08:31:45.705376 139792788920128 learning.py:507] global step 38633: loss = 0.0720 (0.956 sec/step)\n",
      "I0902 08:31:46.664006 139792788920128 learning.py:507] global step 38634: loss = 0.1160 (0.957 sec/step)\n",
      "I0902 08:31:47.621981 139792788920128 learning.py:507] global step 38635: loss = 0.2014 (0.957 sec/step)\n",
      "I0902 08:31:48.581439 139792788920128 learning.py:507] global step 38636: loss = 0.0972 (0.958 sec/step)\n",
      "I0902 08:31:49.535871 139792788920128 learning.py:507] global step 38637: loss = 0.0924 (0.950 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:31:50.165985 139778936784640 supervisor.py:1050] Recording summary at step 38637.\n",
      "I0902 08:31:50.766119 139792788920128 learning.py:507] global step 38638: loss = 0.1501 (1.218 sec/step)\n",
      "I0902 08:31:51.725312 139792788920128 learning.py:507] global step 38639: loss = 0.1422 (0.958 sec/step)\n",
      "I0902 08:31:52.684700 139792788920128 learning.py:507] global step 38640: loss = 0.0888 (0.958 sec/step)\n",
      "I0902 08:31:53.678301 139792788920128 learning.py:507] global step 38641: loss = 0.1228 (0.992 sec/step)\n",
      "I0902 08:31:54.526516 139778945177344 supervisor.py:1099] global_step/sec: 1.025\n",
      "I0902 08:31:54.656168 139792788920128 learning.py:507] global step 38642: loss = 0.0642 (0.976 sec/step)\n",
      "I0902 08:31:55.622595 139792788920128 learning.py:507] global step 38643: loss = 0.0564 (0.965 sec/step)\n",
      "I0902 08:31:56.598242 139792788920128 learning.py:507] global step 38644: loss = 0.0661 (0.974 sec/step)\n",
      "I0902 08:31:57.579309 139792788920128 learning.py:507] global step 38645: loss = 0.0797 (0.979 sec/step)\n",
      "I0902 08:31:58.556127 139792788920128 learning.py:507] global step 38646: loss = 0.0729 (0.975 sec/step)\n",
      "I0902 08:31:59.530120 139792788920128 learning.py:507] global step 38647: loss = 0.0881 (0.972 sec/step)\n",
      "I0902 08:32:00.492513 139792788920128 learning.py:507] global step 38648: loss = 0.0760 (0.961 sec/step)\n",
      "I0902 08:32:01.469272 139792788920128 learning.py:507] global step 38649: loss = 0.1630 (0.975 sec/step)\n",
      "I0902 08:32:02.462842 139792788920128 learning.py:507] global step 38650: loss = 0.0475 (0.992 sec/step)\n",
      "I0902 08:32:03.431459 139792788920128 learning.py:507] global step 38651: loss = 0.1097 (0.967 sec/step)\n",
      "I0902 08:32:04.407946 139792788920128 learning.py:507] global step 38652: loss = 0.1530 (0.975 sec/step)\n",
      "I0902 08:32:05.388770 139792788920128 learning.py:507] global step 38653: loss = 0.0503 (0.979 sec/step)\n",
      "I0902 08:32:06.357555 139792788920128 learning.py:507] global step 38654: loss = 0.1354 (0.967 sec/step)\n",
      "I0902 08:32:07.341077 139792788920128 learning.py:507] global step 38655: loss = 0.1468 (0.982 sec/step)\n",
      "I0902 08:32:08.312163 139792788920128 learning.py:507] global step 38656: loss = 0.1745 (0.969 sec/step)\n",
      "I0902 08:32:09.287050 139792788920128 learning.py:507] global step 38657: loss = 0.2129 (0.973 sec/step)\n",
      "I0902 08:32:10.279778 139792788920128 learning.py:507] global step 38658: loss = 0.1057 (0.991 sec/step)\n",
      "I0902 08:32:11.254160 139792788920128 learning.py:507] global step 38659: loss = 0.1032 (0.973 sec/step)\n",
      "I0902 08:32:12.261402 139792788920128 learning.py:507] global step 38660: loss = 0.0945 (1.006 sec/step)\n",
      "I0902 08:32:13.216921 139792788920128 learning.py:507] global step 38661: loss = 0.0977 (0.954 sec/step)\n",
      "I0902 08:32:14.194588 139792788920128 learning.py:507] global step 38662: loss = 0.0929 (0.976 sec/step)\n",
      "I0902 08:32:15.208781 139792788920128 learning.py:507] global step 38663: loss = 0.0469 (1.013 sec/step)\n",
      "I0902 08:32:16.203664 139792788920128 learning.py:507] global step 38664: loss = 0.1526 (0.993 sec/step)\n",
      "I0902 08:32:17.173397 139792788920128 learning.py:507] global step 38665: loss = 0.1589 (0.968 sec/step)\n",
      "I0902 08:32:18.152584 139792788920128 learning.py:507] global step 38666: loss = 0.1763 (0.978 sec/step)\n",
      "I0902 08:32:19.129575 139792788920128 learning.py:507] global step 38667: loss = 0.1517 (0.975 sec/step)\n",
      "I0902 08:32:20.104071 139792788920128 learning.py:507] global step 38668: loss = 0.0704 (0.973 sec/step)\n",
      "I0902 08:32:21.068307 139792788920128 learning.py:507] global step 38669: loss = 0.1531 (0.963 sec/step)\n",
      "I0902 08:32:22.040209 139792788920128 learning.py:507] global step 38670: loss = 0.1993 (0.970 sec/step)\n",
      "I0902 08:32:23.009878 139792788920128 learning.py:507] global step 38671: loss = 0.1375 (0.968 sec/step)\n",
      "I0902 08:32:23.982716 139792788920128 learning.py:507] global step 38672: loss = 0.1292 (0.971 sec/step)\n",
      "I0902 08:32:24.947690 139792788920128 learning.py:507] global step 38673: loss = 0.1140 (0.963 sec/step)\n",
      "I0902 08:32:25.916326 139792788920128 learning.py:507] global step 38674: loss = 0.1063 (0.967 sec/step)\n",
      "I0902 08:32:26.876969 139792788920128 learning.py:507] global step 38675: loss = 0.0677 (0.959 sec/step)\n",
      "I0902 08:32:27.879396 139792788920128 learning.py:507] global step 38676: loss = 0.1709 (1.001 sec/step)\n",
      "I0902 08:32:28.857363 139792788920128 learning.py:507] global step 38677: loss = 0.1992 (0.976 sec/step)\n",
      "I0902 08:32:29.842627 139792788920128 learning.py:507] global step 38678: loss = 0.1211 (0.984 sec/step)\n",
      "I0902 08:32:30.829100 139792788920128 learning.py:507] global step 38679: loss = 0.1824 (0.985 sec/step)\n",
      "I0902 08:32:31.809247 139792788920128 learning.py:507] global step 38680: loss = 0.0749 (0.978 sec/step)\n",
      "I0902 08:32:32.807566 139792788920128 learning.py:507] global step 38681: loss = 0.1664 (0.997 sec/step)\n",
      "I0902 08:32:33.773430 139792788920128 learning.py:507] global step 38682: loss = 0.1123 (0.964 sec/step)\n",
      "I0902 08:32:34.735775 139792788920128 learning.py:507] global step 38683: loss = 0.1191 (0.961 sec/step)\n",
      "I0902 08:32:35.708826 139792788920128 learning.py:507] global step 38684: loss = 0.0698 (0.971 sec/step)\n",
      "I0902 08:32:36.677059 139792788920128 learning.py:507] global step 38685: loss = 0.1181 (0.967 sec/step)\n",
      "I0902 08:32:37.630455 139792788920128 learning.py:507] global step 38686: loss = 0.0686 (0.952 sec/step)\n",
      "I0902 08:32:38.594096 139792788920128 learning.py:507] global step 38687: loss = 0.1695 (0.962 sec/step)\n",
      "I0902 08:32:39.584493 139792788920128 learning.py:507] global step 38688: loss = 0.1263 (0.989 sec/step)\n",
      "I0902 08:32:40.549203 139792788920128 learning.py:507] global step 38689: loss = 0.0706 (0.963 sec/step)\n",
      "I0902 08:32:41.501050 139792788920128 learning.py:507] global step 38690: loss = 0.0713 (0.950 sec/step)\n",
      "I0902 08:32:42.477089 139792788920128 learning.py:507] global step 38691: loss = 0.1102 (0.974 sec/step)\n",
      "I0902 08:32:43.470645 139792788920128 learning.py:507] global step 38692: loss = 0.0532 (0.992 sec/step)\n",
      "I0902 08:32:44.465286 139792788920128 learning.py:507] global step 38693: loss = 0.0742 (0.993 sec/step)\n",
      "I0902 08:32:45.450941 139792788920128 learning.py:507] global step 38694: loss = 0.0743 (0.984 sec/step)\n",
      "I0902 08:32:46.423601 139792788920128 learning.py:507] global step 38695: loss = 0.1475 (0.971 sec/step)\n",
      "I0902 08:32:47.418141 139792788920128 learning.py:507] global step 38696: loss = 0.0895 (0.993 sec/step)\n",
      "I0902 08:32:48.390700 139792788920128 learning.py:507] global step 38697: loss = 0.1100 (0.971 sec/step)\n",
      "I0902 08:32:49.363963 139792788920128 learning.py:507] global step 38698: loss = 0.0850 (0.972 sec/step)\n",
      "I0902 08:32:50.328545 139792788920128 learning.py:507] global step 38699: loss = 0.1247 (0.963 sec/step)\n",
      "I0902 08:32:51.296609 139792788920128 learning.py:507] global step 38700: loss = 0.0536 (0.966 sec/step)\n",
      "I0902 08:32:52.266432 139792788920128 learning.py:507] global step 38701: loss = 0.1192 (0.968 sec/step)\n",
      "I0902 08:32:53.229220 139792788920128 learning.py:507] global step 38702: loss = 0.0440 (0.961 sec/step)\n",
      "I0902 08:32:54.189770 139792788920128 learning.py:507] global step 38703: loss = 0.1431 (0.959 sec/step)\n",
      "I0902 08:32:55.145004 139792788920128 learning.py:507] global step 38704: loss = 0.0800 (0.954 sec/step)\n",
      "I0902 08:32:56.124200 139792788920128 learning.py:507] global step 38705: loss = 0.1254 (0.977 sec/step)\n",
      "I0902 08:32:57.087385 139792788920128 learning.py:507] global step 38706: loss = 0.0624 (0.962 sec/step)\n",
      "I0902 08:32:58.066794 139792788920128 learning.py:507] global step 38707: loss = 0.2504 (0.978 sec/step)\n",
      "I0902 08:32:59.040836 139792788920128 learning.py:507] global step 38708: loss = 0.1624 (0.972 sec/step)\n",
      "I0902 08:33:00.002506 139792788920128 learning.py:507] global step 38709: loss = 0.1356 (0.960 sec/step)\n",
      "I0902 08:33:00.989985 139792788920128 learning.py:507] global step 38710: loss = 0.1245 (0.986 sec/step)\n",
      "I0902 08:33:01.971441 139792788920128 learning.py:507] global step 38711: loss = 0.2710 (0.980 sec/step)\n",
      "I0902 08:33:02.933860 139792788920128 learning.py:507] global step 38712: loss = 0.1372 (0.961 sec/step)\n",
      "I0902 08:33:03.918124 139792788920128 learning.py:507] global step 38713: loss = 0.0627 (0.983 sec/step)\n",
      "I0902 08:33:04.893294 139792788920128 learning.py:507] global step 38714: loss = 0.1140 (0.973 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:33:05.858162 139792788920128 learning.py:507] global step 38715: loss = 0.1420 (0.963 sec/step)\n",
      "I0902 08:33:06.823075 139792788920128 learning.py:507] global step 38716: loss = 0.1457 (0.963 sec/step)\n",
      "I0902 08:33:07.781181 139792788920128 learning.py:507] global step 38717: loss = 0.1133 (0.956 sec/step)\n",
      "I0902 08:33:08.746888 139792788920128 learning.py:507] global step 38718: loss = 0.0667 (0.964 sec/step)\n",
      "I0902 08:33:09.721068 139792788920128 learning.py:507] global step 38719: loss = 0.1195 (0.973 sec/step)\n",
      "I0902 08:33:10.669119 139792788920128 learning.py:507] global step 38720: loss = 0.0837 (0.946 sec/step)\n",
      "I0902 08:33:11.645920 139792788920128 learning.py:507] global step 38721: loss = 0.1030 (0.975 sec/step)\n",
      "I0902 08:33:12.601597 139792788920128 learning.py:507] global step 38722: loss = 0.0925 (0.954 sec/step)\n",
      "I0902 08:33:13.556152 139792788920128 learning.py:507] global step 38723: loss = 0.2465 (0.953 sec/step)\n",
      "I0902 08:33:14.534546 139792788920128 learning.py:507] global step 38724: loss = 0.1440 (0.977 sec/step)\n",
      "I0902 08:33:15.478574 139792788920128 learning.py:507] global step 38725: loss = 0.0851 (0.942 sec/step)\n",
      "I0902 08:33:16.444671 139792788920128 learning.py:507] global step 38726: loss = 0.0910 (0.965 sec/step)\n",
      "I0902 08:33:17.411319 139792788920128 learning.py:507] global step 38727: loss = 0.0818 (0.965 sec/step)\n",
      "I0902 08:33:18.384831 139792788920128 learning.py:507] global step 38728: loss = 0.3366 (0.972 sec/step)\n",
      "I0902 08:33:19.341565 139792788920128 learning.py:507] global step 38729: loss = 0.1229 (0.955 sec/step)\n",
      "I0902 08:33:20.307867 139792788920128 learning.py:507] global step 38730: loss = 0.1854 (0.965 sec/step)\n",
      "I0902 08:33:21.274084 139792788920128 learning.py:507] global step 38731: loss = 0.2085 (0.965 sec/step)\n",
      "I0902 08:33:22.233106 139792788920128 learning.py:507] global step 38732: loss = 0.0694 (0.957 sec/step)\n",
      "I0902 08:33:23.201829 139792788920128 learning.py:507] global step 38733: loss = 0.2237 (0.967 sec/step)\n",
      "I0902 08:33:24.166672 139792788920128 learning.py:507] global step 38734: loss = 0.1386 (0.963 sec/step)\n",
      "I0902 08:33:25.148371 139792788920128 learning.py:507] global step 38735: loss = 0.0625 (0.980 sec/step)\n",
      "I0902 08:33:26.121168 139792788920128 learning.py:507] global step 38736: loss = 0.1098 (0.971 sec/step)\n",
      "I0902 08:33:27.095152 139792788920128 learning.py:507] global step 38737: loss = 0.0566 (0.972 sec/step)\n",
      "I0902 08:33:28.073956 139792788920128 learning.py:507] global step 38738: loss = 0.2283 (0.977 sec/step)\n",
      "I0902 08:33:29.040035 139792788920128 learning.py:507] global step 38739: loss = 0.0705 (0.965 sec/step)\n",
      "I0902 08:33:30.006739 139792788920128 learning.py:507] global step 38740: loss = 0.1073 (0.965 sec/step)\n",
      "I0902 08:33:30.973063 139792788920128 learning.py:507] global step 38741: loss = 0.1992 (0.965 sec/step)\n",
      "I0902 08:33:31.934762 139792788920128 learning.py:507] global step 38742: loss = 0.1960 (0.960 sec/step)\n",
      "I0902 08:33:32.884458 139792788920128 learning.py:507] global step 38743: loss = 0.0996 (0.948 sec/step)\n",
      "I0902 08:33:33.866043 139792788920128 learning.py:507] global step 38744: loss = 0.1893 (0.980 sec/step)\n",
      "I0902 08:33:34.840159 139792788920128 learning.py:507] global step 38745: loss = 0.2733 (0.973 sec/step)\n",
      "I0902 08:33:35.824031 139792788920128 learning.py:507] global step 38746: loss = 0.1472 (0.982 sec/step)\n",
      "I0902 08:33:36.772065 139792788920128 learning.py:507] global step 38747: loss = 0.1465 (0.946 sec/step)\n",
      "I0902 08:33:37.740889 139792788920128 learning.py:507] global step 38748: loss = 0.1209 (0.967 sec/step)\n",
      "I0902 08:33:38.737717 139792788920128 learning.py:507] global step 38749: loss = 0.1057 (0.995 sec/step)\n",
      "I0902 08:33:39.696077 139792788920128 learning.py:507] global step 38750: loss = 0.0852 (0.957 sec/step)\n",
      "I0902 08:33:40.682785 139792788920128 learning.py:507] global step 38751: loss = 0.1113 (0.985 sec/step)\n",
      "I0902 08:33:41.621906 139792788920128 learning.py:507] global step 38752: loss = 0.1040 (0.938 sec/step)\n",
      "I0902 08:33:42.590060 139792788920128 learning.py:507] global step 38753: loss = 0.1561 (0.967 sec/step)\n",
      "I0902 08:33:43.563093 139792788920128 learning.py:507] global step 38754: loss = 0.1135 (0.971 sec/step)\n",
      "I0902 08:33:44.532321 139792788920128 learning.py:507] global step 38755: loss = 0.0819 (0.968 sec/step)\n",
      "I0902 08:33:45.520475 139792788920128 learning.py:507] global step 38756: loss = 0.0864 (0.987 sec/step)\n",
      "I0902 08:33:46.499101 139792788920128 learning.py:507] global step 38757: loss = 0.2007 (0.977 sec/step)\n",
      "I0902 08:33:47.439589 139792788920128 learning.py:507] global step 38758: loss = 0.1795 (0.939 sec/step)\n",
      "I0902 08:33:48.409811 139792788920128 learning.py:507] global step 38759: loss = 0.1883 (0.969 sec/step)\n",
      "I0902 08:33:49.270375 139778953570048 supervisor.py:1117] Saving checkpoint to path data_dir/mixed_experiment/checkpoints_v2/model.ckpt\n",
      "I0902 08:33:49.373784 139792788920128 learning.py:507] global step 38760: loss = 0.1205 (0.960 sec/step)\n",
      "W0902 08:33:49.510269 139778953570048 deprecation.py:323] From /home/alexeygrigoriev/miniconda/envs/tensorflow_gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "I0902 08:33:49.886670 139778936784640 supervisor.py:1050] Recording summary at step 38760.\n",
      "I0902 08:33:50.599539 139792788920128 learning.py:507] global step 38761: loss = 0.2186 (1.212 sec/step)\n",
      "I0902 08:33:51.567867 139792788920128 learning.py:507] global step 38762: loss = 0.1220 (0.967 sec/step)\n",
      "I0902 08:33:52.543689 139792788920128 learning.py:507] global step 38763: loss = 0.1950 (0.974 sec/step)\n",
      "I0902 08:33:53.523279 139792788920128 learning.py:507] global step 38764: loss = 0.1097 (0.978 sec/step)\n",
      "I0902 08:33:54.470717 139792788920128 learning.py:507] global step 38765: loss = 0.2556 (0.946 sec/step)\n",
      "I0902 08:33:54.526363 139778945177344 supervisor.py:1099] global_step/sec: 1.03333\n",
      "I0902 08:33:55.436606 139792788920128 learning.py:507] global step 38766: loss = 0.1065 (0.964 sec/step)\n",
      "I0902 08:33:56.398199 139792788920128 learning.py:507] global step 38767: loss = 0.1084 (0.960 sec/step)\n",
      "I0902 08:33:57.361507 139792788920128 learning.py:507] global step 38768: loss = 0.0834 (0.962 sec/step)\n",
      "I0902 08:33:58.307781 139792788920128 learning.py:507] global step 38769: loss = 0.1114 (0.945 sec/step)\n",
      "I0902 08:33:59.263316 139792788920128 learning.py:507] global step 38770: loss = 0.0781 (0.954 sec/step)\n",
      "I0902 08:34:00.232028 139792788920128 learning.py:507] global step 38771: loss = 0.1311 (0.967 sec/step)\n",
      "I0902 08:34:01.199445 139792788920128 learning.py:507] global step 38772: loss = 0.1179 (0.966 sec/step)\n",
      "I0902 08:34:02.164787 139792788920128 learning.py:507] global step 38773: loss = 0.1116 (0.964 sec/step)\n",
      "I0902 08:34:03.155652 139792788920128 learning.py:507] global step 38774: loss = 0.0946 (0.989 sec/step)\n",
      "I0902 08:34:04.109691 139792788920128 learning.py:507] global step 38775: loss = 0.1109 (0.952 sec/step)\n",
      "I0902 08:34:05.059930 139792788920128 learning.py:507] global step 38776: loss = 0.1105 (0.949 sec/step)\n",
      "I0902 08:34:06.015416 139792788920128 learning.py:507] global step 38777: loss = 0.1272 (0.954 sec/step)\n",
      "I0902 08:34:06.971633 139792788920128 learning.py:507] global step 38778: loss = 0.1346 (0.954 sec/step)\n",
      "I0902 08:34:07.948740 139792788920128 learning.py:507] global step 38779: loss = 0.1391 (0.975 sec/step)\n",
      "I0902 08:34:08.915835 139792788920128 learning.py:507] global step 38780: loss = 0.0829 (0.965 sec/step)\n",
      "I0902 08:34:09.886567 139792788920128 learning.py:507] global step 38781: loss = 0.1245 (0.969 sec/step)\n",
      "I0902 08:34:10.894080 139792788920128 learning.py:507] global step 38782: loss = 0.2000 (1.006 sec/step)\n",
      "I0902 08:34:11.873292 139792788920128 learning.py:507] global step 38783: loss = 0.0720 (0.978 sec/step)\n",
      "I0902 08:34:12.834075 139792788920128 learning.py:507] global step 38784: loss = 0.1433 (0.959 sec/step)\n",
      "I0902 08:34:13.805190 139792788920128 learning.py:507] global step 38785: loss = 0.1421 (0.969 sec/step)\n",
      "I0902 08:34:14.776847 139792788920128 learning.py:507] global step 38786: loss = 0.0954 (0.970 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:34:15.768713 139792788920128 learning.py:507] global step 38787: loss = 0.1787 (0.990 sec/step)\n",
      "I0902 08:34:16.750931 139792788920128 learning.py:507] global step 38788: loss = 0.1075 (0.981 sec/step)\n",
      "I0902 08:34:17.715593 139792788920128 learning.py:507] global step 38789: loss = 0.0693 (0.963 sec/step)\n",
      "I0902 08:34:18.706674 139792788920128 learning.py:507] global step 38790: loss = 0.1218 (0.989 sec/step)\n",
      "I0902 08:34:19.692231 139792788920128 learning.py:507] global step 38791: loss = 0.1801 (0.984 sec/step)\n",
      "I0902 08:34:20.688808 139792788920128 learning.py:507] global step 38792: loss = 0.0793 (0.995 sec/step)\n",
      "I0902 08:34:21.664294 139792788920128 learning.py:507] global step 38793: loss = 0.0982 (0.974 sec/step)\n",
      "I0902 08:34:22.621876 139792788920128 learning.py:507] global step 38794: loss = 0.1793 (0.956 sec/step)\n",
      "I0902 08:34:23.600637 139792788920128 learning.py:507] global step 38795: loss = 0.1253 (0.977 sec/step)\n",
      "I0902 08:34:24.568966 139792788920128 learning.py:507] global step 38796: loss = 0.1960 (0.967 sec/step)\n",
      "I0902 08:34:25.527993 139792788920128 learning.py:507] global step 38797: loss = 0.2118 (0.957 sec/step)\n",
      "I0902 08:34:26.504531 139792788920128 learning.py:507] global step 38798: loss = 0.0708 (0.975 sec/step)\n",
      "I0902 08:34:27.474688 139792788920128 learning.py:507] global step 38799: loss = 0.0917 (0.969 sec/step)\n",
      "I0902 08:34:28.446841 139792788920128 learning.py:507] global step 38800: loss = 0.0898 (0.970 sec/step)\n",
      "I0902 08:34:29.418467 139792788920128 learning.py:507] global step 38801: loss = 0.0709 (0.970 sec/step)\n",
      "I0902 08:34:30.373041 139792788920128 learning.py:507] global step 38802: loss = 0.0689 (0.953 sec/step)\n",
      "I0902 08:34:31.339189 139792788920128 learning.py:507] global step 38803: loss = 0.2329 (0.964 sec/step)\n",
      "I0902 08:34:32.327145 139792788920128 learning.py:507] global step 38804: loss = 0.2164 (0.986 sec/step)\n",
      "I0902 08:34:33.298655 139792788920128 learning.py:507] global step 38805: loss = 0.1237 (0.970 sec/step)\n",
      "I0902 08:34:34.288124 139792788920128 learning.py:507] global step 38806: loss = 0.0506 (0.988 sec/step)\n",
      "I0902 08:34:35.282668 139792788920128 learning.py:507] global step 38807: loss = 0.1437 (0.993 sec/step)\n",
      "I0902 08:34:36.255884 139792788920128 learning.py:507] global step 38808: loss = 0.2105 (0.972 sec/step)\n",
      "I0902 08:34:37.227911 139792788920128 learning.py:507] global step 38809: loss = 0.1208 (0.970 sec/step)\n",
      "I0902 08:34:38.199137 139792788920128 learning.py:507] global step 38810: loss = 0.2279 (0.970 sec/step)\n",
      "I0902 08:34:39.170479 139792788920128 learning.py:507] global step 38811: loss = 0.0462 (0.970 sec/step)\n",
      "I0902 08:34:40.143851 139792788920128 learning.py:507] global step 38812: loss = 0.2268 (0.972 sec/step)\n",
      "I0902 08:34:41.134051 139792788920128 learning.py:507] global step 38813: loss = 0.0863 (0.989 sec/step)\n",
      "I0902 08:34:42.098743 139792788920128 learning.py:507] global step 38814: loss = 0.1033 (0.963 sec/step)\n",
      "I0902 08:34:43.067861 139792788920128 learning.py:507] global step 38815: loss = 0.0590 (0.967 sec/step)\n",
      "I0902 08:34:44.037117 139792788920128 learning.py:507] global step 38816: loss = 0.1096 (0.967 sec/step)\n",
      "I0902 08:34:45.012078 139792788920128 learning.py:507] global step 38817: loss = 0.2060 (0.973 sec/step)\n",
      "I0902 08:34:45.964246 139792788920128 learning.py:507] global step 38818: loss = 0.0725 (0.951 sec/step)\n",
      "I0902 08:34:46.939297 139792788920128 learning.py:507] global step 38819: loss = 0.1137 (0.973 sec/step)\n",
      "I0902 08:34:47.910450 139792788920128 learning.py:507] global step 38820: loss = 0.0722 (0.970 sec/step)\n",
      "I0902 08:34:48.866163 139792788920128 learning.py:507] global step 38821: loss = 0.0782 (0.954 sec/step)\n",
      "I0902 08:34:49.846626 139792788920128 learning.py:507] global step 38822: loss = 0.1204 (0.979 sec/step)\n",
      "I0902 08:34:50.828786 139792788920128 learning.py:507] global step 38823: loss = 0.1904 (0.981 sec/step)\n",
      "I0902 08:34:51.794703 139792788920128 learning.py:507] global step 38824: loss = 0.1113 (0.964 sec/step)\n",
      "I0902 08:34:52.765357 139792788920128 learning.py:507] global step 38825: loss = 0.1302 (0.969 sec/step)\n",
      "I0902 08:34:53.732019 139792788920128 learning.py:507] global step 38826: loss = 0.0906 (0.965 sec/step)\n",
      "I0902 08:34:54.746181 139792788920128 learning.py:507] global step 38827: loss = 0.0607 (1.012 sec/step)\n",
      "I0902 08:34:55.743719 139792788920128 learning.py:507] global step 38828: loss = 0.1086 (0.996 sec/step)\n",
      "I0902 08:34:56.718889 139792788920128 learning.py:507] global step 38829: loss = 0.0789 (0.974 sec/step)\n",
      "I0902 08:34:57.691587 139792788920128 learning.py:507] global step 38830: loss = 0.0968 (0.971 sec/step)\n",
      "I0902 08:34:58.662807 139792788920128 learning.py:507] global step 38831: loss = 0.1200 (0.970 sec/step)\n",
      "I0902 08:34:59.635597 139792788920128 learning.py:507] global step 38832: loss = 0.1025 (0.971 sec/step)\n",
      "I0902 08:35:00.609955 139792788920128 learning.py:507] global step 38833: loss = 0.1410 (0.972 sec/step)\n",
      "I0902 08:35:01.567812 139792788920128 learning.py:507] global step 38834: loss = 0.0873 (0.956 sec/step)\n",
      "I0902 08:35:02.534612 139792788920128 learning.py:507] global step 38835: loss = 0.0846 (0.965 sec/step)\n",
      "I0902 08:35:03.522879 139792788920128 learning.py:507] global step 38836: loss = 0.0996 (0.987 sec/step)\n",
      "I0902 08:35:04.504343 139792788920128 learning.py:507] global step 38837: loss = 0.0887 (0.980 sec/step)\n",
      "I0902 08:35:05.490330 139792788920128 learning.py:507] global step 38838: loss = 0.0774 (0.984 sec/step)\n",
      "I0902 08:35:06.484651 139792788920128 learning.py:507] global step 38839: loss = 0.1334 (0.993 sec/step)\n",
      "I0902 08:35:07.449020 139792788920128 learning.py:507] global step 38840: loss = 0.1333 (0.963 sec/step)\n",
      "I0902 08:35:08.429401 139792788920128 learning.py:507] global step 38841: loss = 0.1969 (0.979 sec/step)\n",
      "I0902 08:35:09.426426 139792788920128 learning.py:507] global step 38842: loss = 0.1500 (0.995 sec/step)\n",
      "I0902 08:35:10.397534 139792788920128 learning.py:507] global step 38843: loss = 0.1686 (0.970 sec/step)\n",
      "I0902 08:35:11.396585 139792788920128 learning.py:507] global step 38844: loss = 0.0799 (0.998 sec/step)\n",
      "I0902 08:35:12.362989 139792788920128 learning.py:507] global step 38845: loss = 0.1138 (0.965 sec/step)\n",
      "I0902 08:35:13.341061 139792788920128 learning.py:507] global step 38846: loss = 0.1285 (0.977 sec/step)\n",
      "I0902 08:35:14.324747 139792788920128 learning.py:507] global step 38847: loss = 0.1382 (0.982 sec/step)\n",
      "I0902 08:35:15.293384 139792788920128 learning.py:507] global step 38848: loss = 0.0794 (0.967 sec/step)\n",
      "I0902 08:35:16.280753 139792788920128 learning.py:507] global step 38849: loss = 0.0839 (0.986 sec/step)\n",
      "I0902 08:35:17.242983 139792788920128 learning.py:507] global step 38850: loss = 0.2270 (0.960 sec/step)\n",
      "I0902 08:35:18.230081 139792788920128 learning.py:507] global step 38851: loss = 0.0952 (0.985 sec/step)\n",
      "I0902 08:35:19.208929 139792788920128 learning.py:507] global step 38852: loss = 0.1995 (0.977 sec/step)\n",
      "I0902 08:35:20.170536 139792788920128 learning.py:507] global step 38853: loss = 0.2606 (0.960 sec/step)\n",
      "I0902 08:35:21.151208 139792788920128 learning.py:507] global step 38854: loss = 0.0692 (0.979 sec/step)\n",
      "I0902 08:35:22.121830 139792788920128 learning.py:507] global step 38855: loss = 0.0614 (0.969 sec/step)\n",
      "I0902 08:35:23.096001 139792788920128 learning.py:507] global step 38856: loss = 0.0957 (0.973 sec/step)\n",
      "I0902 08:35:24.058462 139792788920128 learning.py:507] global step 38857: loss = 0.1144 (0.961 sec/step)\n",
      "I0902 08:35:25.043267 139792788920128 learning.py:507] global step 38858: loss = 0.1241 (0.983 sec/step)\n",
      "I0902 08:35:25.993789 139792788920128 learning.py:507] global step 38859: loss = 0.1145 (0.949 sec/step)\n",
      "I0902 08:35:26.972813 139792788920128 learning.py:507] global step 38860: loss = 0.1337 (0.977 sec/step)\n",
      "I0902 08:35:27.939124 139792788920128 learning.py:507] global step 38861: loss = 0.0800 (0.965 sec/step)\n",
      "I0902 08:35:28.923550 139792788920128 learning.py:507] global step 38862: loss = 0.1088 (0.983 sec/step)\n",
      "I0902 08:35:29.885031 139792788920128 learning.py:507] global step 38863: loss = 0.1487 (0.960 sec/step)\n",
      "I0902 08:35:30.865444 139792788920128 learning.py:507] global step 38864: loss = 0.1170 (0.979 sec/step)\n",
      "I0902 08:35:31.818729 139792788920128 learning.py:507] global step 38865: loss = 0.1138 (0.952 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:35:32.803904 139792788920128 learning.py:507] global step 38866: loss = 0.0862 (0.983 sec/step)\n",
      "I0902 08:35:33.766538 139792788920128 learning.py:507] global step 38867: loss = 0.1036 (0.961 sec/step)\n",
      "I0902 08:35:34.737094 139792788920128 learning.py:507] global step 38868: loss = 0.0756 (0.969 sec/step)\n",
      "I0902 08:35:35.729225 139792788920128 learning.py:507] global step 38869: loss = 0.0801 (0.990 sec/step)\n",
      "I0902 08:35:36.724390 139792788920128 learning.py:507] global step 38870: loss = 0.1461 (0.994 sec/step)\n",
      "I0902 08:35:37.719996 139792788920128 learning.py:507] global step 38871: loss = 0.2783 (0.994 sec/step)\n",
      "I0902 08:35:38.732344 139792788920128 learning.py:507] global step 38872: loss = 0.0633 (1.011 sec/step)\n",
      "I0902 08:35:39.714039 139792788920128 learning.py:507] global step 38873: loss = 0.1559 (0.980 sec/step)\n",
      "I0902 08:35:40.710588 139792788920128 learning.py:507] global step 38874: loss = 0.0788 (0.995 sec/step)\n",
      "I0902 08:35:41.673268 139792788920128 learning.py:507] global step 38875: loss = 0.0913 (0.961 sec/step)\n",
      "I0902 08:35:42.641067 139792788920128 learning.py:507] global step 38876: loss = 0.1011 (0.966 sec/step)\n",
      "I0902 08:35:43.595002 139792788920128 learning.py:507] global step 38877: loss = 0.1658 (0.952 sec/step)\n",
      "I0902 08:35:44.578102 139792788920128 learning.py:507] global step 38878: loss = 0.0712 (0.981 sec/step)\n",
      "I0902 08:35:45.545647 139792788920128 learning.py:507] global step 38879: loss = 0.1006 (0.966 sec/step)\n",
      "I0902 08:35:46.504546 139792788920128 learning.py:507] global step 38880: loss = 0.0982 (0.957 sec/step)\n",
      "I0902 08:35:47.458451 139792788920128 learning.py:507] global step 38881: loss = 0.1029 (0.952 sec/step)\n",
      "I0902 08:35:48.423637 139792788920128 learning.py:507] global step 38882: loss = 0.1480 (0.964 sec/step)\n",
      "I0902 08:35:49.385905 139792788920128 learning.py:507] global step 38883: loss = 0.1262 (0.958 sec/step)\n",
      "I0902 08:35:50.028761 139778936784640 supervisor.py:1050] Recording summary at step 38883.\n",
      "I0902 08:35:50.645247 139792788920128 learning.py:507] global step 38884: loss = 0.1725 (1.246 sec/step)\n",
      "I0902 08:35:51.637186 139792788920128 learning.py:507] global step 38885: loss = 0.1617 (0.990 sec/step)\n",
      "I0902 08:35:52.616140 139792788920128 learning.py:507] global step 38886: loss = 0.1238 (0.977 sec/step)\n",
      "I0902 08:35:53.562040 139792788920128 learning.py:507] global step 38887: loss = 0.2106 (0.944 sec/step)\n",
      "I0902 08:35:54.512355 139792788920128 learning.py:507] global step 38888: loss = 0.1573 (0.949 sec/step)\n",
      "I0902 08:35:54.526428 139778945177344 supervisor.py:1099] global_step/sec: 1.025\n",
      "I0902 08:35:55.475601 139792788920128 learning.py:507] global step 38889: loss = 0.2046 (0.962 sec/step)\n",
      "I0902 08:35:56.442015 139792788920128 learning.py:507] global step 38890: loss = 0.1838 (0.965 sec/step)\n",
      "I0902 08:35:57.407962 139792788920128 learning.py:507] global step 38891: loss = 0.0700 (0.964 sec/step)\n",
      "I0902 08:35:58.360068 139792788920128 learning.py:507] global step 38892: loss = 0.1562 (0.950 sec/step)\n",
      "I0902 08:35:59.329065 139792788920128 learning.py:507] global step 38893: loss = 0.1165 (0.967 sec/step)\n",
      "I0902 08:36:00.288155 139792788920128 learning.py:507] global step 38894: loss = 0.1474 (0.957 sec/step)\n",
      "I0902 08:36:01.252216 139792788920128 learning.py:507] global step 38895: loss = 0.0767 (0.962 sec/step)\n",
      "I0902 08:36:02.222035 139792788920128 learning.py:507] global step 38896: loss = 0.0979 (0.968 sec/step)\n",
      "I0902 08:36:03.167592 139792788920128 learning.py:507] global step 38897: loss = 0.0997 (0.944 sec/step)\n",
      "I0902 08:36:04.146082 139792788920128 learning.py:507] global step 38898: loss = 0.3376 (0.977 sec/step)\n",
      "I0902 08:36:05.121824 139792788920128 learning.py:507] global step 38899: loss = 0.1131 (0.974 sec/step)\n",
      "I0902 08:36:06.094455 139792788920128 learning.py:507] global step 38900: loss = 0.2456 (0.971 sec/step)\n",
      "I0902 08:36:07.068422 139792788920128 learning.py:507] global step 38901: loss = 0.2737 (0.972 sec/step)\n",
      "I0902 08:36:08.032125 139792788920128 learning.py:507] global step 38902: loss = 0.2627 (0.962 sec/step)\n",
      "I0902 08:36:09.002688 139792788920128 learning.py:507] global step 38903: loss = 0.1272 (0.969 sec/step)\n",
      "I0902 08:36:09.961002 139792788920128 learning.py:507] global step 38904: loss = 0.5344 (0.957 sec/step)\n",
      "I0902 08:36:10.904115 139792788920128 learning.py:507] global step 38905: loss = 0.1312 (0.942 sec/step)\n",
      "I0902 08:36:11.858247 139792788920128 learning.py:507] global step 38906: loss = 0.1420 (0.952 sec/step)\n",
      "I0902 08:36:12.825931 139792788920128 learning.py:507] global step 38907: loss = 0.0679 (0.966 sec/step)\n",
      "I0902 08:36:13.774253 139792788920128 learning.py:507] global step 38908: loss = 0.1264 (0.947 sec/step)\n",
      "I0902 08:36:14.737779 139792788920128 learning.py:507] global step 38909: loss = 0.1791 (0.962 sec/step)\n",
      "I0902 08:36:15.706079 139792788920128 learning.py:507] global step 38910: loss = 0.1555 (0.967 sec/step)\n",
      "I0902 08:36:16.664313 139792788920128 learning.py:507] global step 38911: loss = 0.1521 (0.957 sec/step)\n",
      "I0902 08:36:17.624279 139792788920128 learning.py:507] global step 38912: loss = 0.1158 (0.958 sec/step)\n",
      "I0902 08:36:18.577491 139792788920128 learning.py:507] global step 38913: loss = 0.2016 (0.952 sec/step)\n",
      "I0902 08:36:19.522002 139792788920128 learning.py:507] global step 38914: loss = 0.1594 (0.943 sec/step)\n",
      "I0902 08:36:20.501132 139792788920128 learning.py:507] global step 38915: loss = 0.1073 (0.977 sec/step)\n",
      "I0902 08:36:21.476716 139792788920128 learning.py:507] global step 38916: loss = 0.1991 (0.974 sec/step)\n",
      "I0902 08:36:22.446684 139792788920128 learning.py:507] global step 38917: loss = 0.1952 (0.968 sec/step)\n",
      "I0902 08:36:23.420411 139792788920128 learning.py:507] global step 38918: loss = 0.0903 (0.972 sec/step)\n",
      "I0902 08:36:24.380141 139792788920128 learning.py:507] global step 38919: loss = 0.0771 (0.958 sec/step)\n",
      "I0902 08:36:25.345494 139792788920128 learning.py:507] global step 38920: loss = 0.1455 (0.964 sec/step)\n",
      "I0902 08:36:26.313464 139792788920128 learning.py:507] global step 38921: loss = 0.0731 (0.966 sec/step)\n",
      "I0902 08:36:27.287623 139792788920128 learning.py:507] global step 38922: loss = 0.2541 (0.972 sec/step)\n",
      "I0902 08:36:28.284108 139792788920128 learning.py:507] global step 38923: loss = 0.0812 (0.995 sec/step)\n",
      "I0902 08:36:29.271910 139792788920128 learning.py:507] global step 38924: loss = 0.0695 (0.986 sec/step)\n",
      "I0902 08:36:30.246312 139792788920128 learning.py:507] global step 38925: loss = 0.1568 (0.973 sec/step)\n",
      "I0902 08:36:31.217851 139792788920128 learning.py:507] global step 38926: loss = 0.1097 (0.970 sec/step)\n",
      "I0902 08:36:32.178536 139792788920128 learning.py:507] global step 38927: loss = 0.1541 (0.959 sec/step)\n",
      "I0902 08:36:33.176256 139792788920128 learning.py:507] global step 38928: loss = 0.0653 (0.996 sec/step)\n",
      "I0902 08:36:34.127339 139792788920128 learning.py:507] global step 38929: loss = 0.1338 (0.949 sec/step)\n",
      "I0902 08:36:35.080692 139792788920128 learning.py:507] global step 38930: loss = 0.0910 (0.952 sec/step)\n",
      "I0902 08:36:36.045906 139792788920128 learning.py:507] global step 38931: loss = 0.0833 (0.964 sec/step)\n",
      "I0902 08:36:37.018246 139792788920128 learning.py:507] global step 38932: loss = 0.0709 (0.971 sec/step)\n",
      "I0902 08:36:37.973354 139792788920128 learning.py:507] global step 38933: loss = 0.0756 (0.953 sec/step)\n",
      "I0902 08:36:38.927303 139792788920128 learning.py:507] global step 38934: loss = 0.1014 (0.952 sec/step)\n",
      "I0902 08:36:39.897432 139792788920128 learning.py:507] global step 38935: loss = 0.0813 (0.969 sec/step)\n",
      "I0902 08:36:40.874145 139792788920128 learning.py:507] global step 38936: loss = 0.0963 (0.975 sec/step)\n",
      "I0902 08:36:41.856683 139792788920128 learning.py:507] global step 38937: loss = 0.2004 (0.981 sec/step)\n",
      "I0902 08:36:42.827114 139792788920128 learning.py:507] global step 38938: loss = 0.1455 (0.969 sec/step)\n",
      "I0902 08:36:43.810669 139792788920128 learning.py:507] global step 38939: loss = 0.4584 (0.982 sec/step)\n",
      "I0902 08:36:44.777679 139792788920128 learning.py:507] global step 38940: loss = 0.1213 (0.965 sec/step)\n",
      "I0902 08:36:45.732457 139792788920128 learning.py:507] global step 38941: loss = 0.1041 (0.953 sec/step)\n",
      "I0902 08:36:46.686023 139792788920128 learning.py:507] global step 38942: loss = 0.1918 (0.952 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:36:47.670764 139792788920128 learning.py:507] global step 38943: loss = 0.1609 (0.983 sec/step)\n",
      "I0902 08:36:48.622646 139792788920128 learning.py:507] global step 38944: loss = 0.0780 (0.950 sec/step)\n",
      "I0902 08:36:49.614818 139792788920128 learning.py:507] global step 38945: loss = 0.0752 (0.990 sec/step)\n",
      "I0902 08:36:50.594624 139792788920128 learning.py:507] global step 38946: loss = 0.0613 (0.978 sec/step)\n",
      "I0902 08:36:51.562922 139792788920128 learning.py:507] global step 38947: loss = 0.0951 (0.967 sec/step)\n",
      "I0902 08:36:52.521491 139792788920128 learning.py:507] global step 38948: loss = 0.0834 (0.957 sec/step)\n",
      "I0902 08:36:53.487557 139792788920128 learning.py:507] global step 38949: loss = 0.0873 (0.964 sec/step)\n",
      "I0902 08:36:54.474226 139792788920128 learning.py:507] global step 38950: loss = 0.1837 (0.985 sec/step)\n",
      "I0902 08:36:55.431561 139792788920128 learning.py:507] global step 38951: loss = 0.0941 (0.956 sec/step)\n",
      "I0902 08:36:56.396380 139792788920128 learning.py:507] global step 38952: loss = 0.1644 (0.963 sec/step)\n",
      "I0902 08:36:57.375223 139792788920128 learning.py:507] global step 38953: loss = 0.0797 (0.977 sec/step)\n",
      "I0902 08:36:58.364216 139792788920128 learning.py:507] global step 38954: loss = 0.1778 (0.987 sec/step)\n",
      "I0902 08:36:59.340102 139792788920128 learning.py:507] global step 38955: loss = 0.0990 (0.974 sec/step)\n",
      "I0902 08:37:00.322768 139792788920128 learning.py:507] global step 38956: loss = 0.1157 (0.981 sec/step)\n",
      "I0902 08:37:01.291688 139792788920128 learning.py:507] global step 38957: loss = 0.1396 (0.968 sec/step)\n",
      "I0902 08:37:02.239755 139792788920128 learning.py:507] global step 38958: loss = 0.1280 (0.946 sec/step)\n",
      "I0902 08:37:03.197722 139792788920128 learning.py:507] global step 38959: loss = 0.1532 (0.956 sec/step)\n",
      "I0902 08:37:04.179403 139792788920128 learning.py:507] global step 38960: loss = 0.0955 (0.980 sec/step)\n",
      "I0902 08:37:05.136478 139792788920128 learning.py:507] global step 38961: loss = 0.1352 (0.955 sec/step)\n",
      "I0902 08:37:06.109208 139792788920128 learning.py:507] global step 38962: loss = 0.0690 (0.971 sec/step)\n",
      "I0902 08:37:07.073997 139792788920128 learning.py:507] global step 38963: loss = 0.1710 (0.963 sec/step)\n",
      "I0902 08:37:08.038833 139792788920128 learning.py:507] global step 38964: loss = 0.0698 (0.963 sec/step)\n",
      "I0902 08:37:09.019536 139792788920128 learning.py:507] global step 38965: loss = 0.0686 (0.979 sec/step)\n",
      "I0902 08:37:09.981248 139792788920128 learning.py:507] global step 38966: loss = 0.2898 (0.960 sec/step)\n",
      "I0902 08:37:10.964101 139792788920128 learning.py:507] global step 38967: loss = 0.1214 (0.981 sec/step)\n",
      "I0902 08:37:11.962247 139792788920128 learning.py:507] global step 38968: loss = 0.1395 (0.996 sec/step)\n",
      "I0902 08:37:12.949849 139792788920128 learning.py:507] global step 38969: loss = 0.0910 (0.986 sec/step)\n",
      "I0902 08:37:13.925072 139792788920128 learning.py:507] global step 38970: loss = 0.1461 (0.973 sec/step)\n",
      "I0902 08:37:14.893757 139792788920128 learning.py:507] global step 38971: loss = 0.0638 (0.967 sec/step)\n",
      "I0902 08:37:15.861397 139792788920128 learning.py:507] global step 38972: loss = 0.1643 (0.966 sec/step)\n",
      "I0902 08:37:16.833369 139792788920128 learning.py:507] global step 38973: loss = 0.1393 (0.970 sec/step)\n",
      "I0902 08:37:17.822998 139792788920128 learning.py:507] global step 38974: loss = 0.0951 (0.988 sec/step)\n",
      "I0902 08:37:18.798345 139792788920128 learning.py:507] global step 38975: loss = 0.2403 (0.974 sec/step)\n",
      "I0902 08:37:19.776671 139792788920128 learning.py:507] global step 38976: loss = 0.1074 (0.977 sec/step)\n",
      "I0902 08:37:20.752185 139792788920128 learning.py:507] global step 38977: loss = 0.1314 (0.974 sec/step)\n",
      "I0902 08:37:21.714804 139792788920128 learning.py:507] global step 38978: loss = 0.1691 (0.961 sec/step)\n",
      "I0902 08:37:22.680840 139792788920128 learning.py:507] global step 38979: loss = 0.0980 (0.964 sec/step)\n",
      "I0902 08:37:23.640858 139792788920128 learning.py:507] global step 38980: loss = 0.0763 (0.958 sec/step)\n",
      "I0902 08:37:24.591546 139792788920128 learning.py:507] global step 38981: loss = 0.1298 (0.949 sec/step)\n",
      "I0902 08:37:25.550655 139792788920128 learning.py:507] global step 38982: loss = 0.1022 (0.958 sec/step)\n",
      "I0902 08:37:26.510905 139792788920128 learning.py:507] global step 38983: loss = 0.0701 (0.959 sec/step)\n",
      "I0902 08:37:27.526675 139792788920128 learning.py:507] global step 38984: loss = 0.0911 (1.014 sec/step)\n",
      "I0902 08:37:28.486066 139792788920128 learning.py:507] global step 38985: loss = 0.1155 (0.958 sec/step)\n",
      "I0902 08:37:29.453933 139792788920128 learning.py:507] global step 38986: loss = 0.1517 (0.966 sec/step)\n",
      "I0902 08:37:30.436251 139792788920128 learning.py:507] global step 38987: loss = 0.0559 (0.981 sec/step)\n",
      "I0902 08:37:31.409708 139792788920128 learning.py:507] global step 38988: loss = 0.0989 (0.972 sec/step)\n",
      "I0902 08:37:32.393287 139792788920128 learning.py:507] global step 38989: loss = 0.1573 (0.982 sec/step)\n",
      "I0902 08:37:33.355443 139792788920128 learning.py:507] global step 38990: loss = 0.0780 (0.960 sec/step)\n",
      "I0902 08:37:34.323319 139792788920128 learning.py:507] global step 38991: loss = 0.1110 (0.966 sec/step)\n",
      "I0902 08:37:35.312737 139792788920128 learning.py:507] global step 38992: loss = 0.2338 (0.988 sec/step)\n",
      "I0902 08:37:36.289366 139792788920128 learning.py:507] global step 38993: loss = 0.1089 (0.975 sec/step)\n",
      "I0902 08:37:37.264819 139792788920128 learning.py:507] global step 38994: loss = 0.1106 (0.974 sec/step)\n",
      "I0902 08:37:38.220153 139792788920128 learning.py:507] global step 38995: loss = 0.2406 (0.954 sec/step)\n",
      "I0902 08:37:39.183953 139792788920128 learning.py:507] global step 38996: loss = 0.0737 (0.962 sec/step)\n",
      "I0902 08:37:40.148674 139792788920128 learning.py:507] global step 38997: loss = 0.0844 (0.963 sec/step)\n",
      "I0902 08:37:41.106894 139792788920128 learning.py:507] global step 38998: loss = 0.1668 (0.956 sec/step)\n",
      "I0902 08:37:42.073565 139792788920128 learning.py:507] global step 38999: loss = 0.0817 (0.965 sec/step)\n",
      "I0902 08:37:43.030158 139792788920128 learning.py:507] global step 39000: loss = 0.0780 (0.955 sec/step)\n",
      "I0902 08:37:43.992587 139792788920128 learning.py:507] global step 39001: loss = 0.1442 (0.961 sec/step)\n",
      "I0902 08:37:44.960207 139792788920128 learning.py:507] global step 39002: loss = 0.1302 (0.966 sec/step)\n",
      "I0902 08:37:45.925781 139792788920128 learning.py:507] global step 39003: loss = 0.4136 (0.964 sec/step)\n",
      "I0902 08:37:46.897207 139792788920128 learning.py:507] global step 39004: loss = 0.1366 (0.970 sec/step)\n",
      "I0902 08:37:47.863232 139792788920128 learning.py:507] global step 39005: loss = 0.1386 (0.965 sec/step)\n",
      "I0902 08:37:48.824925 139792788920128 learning.py:507] global step 39006: loss = 0.1652 (0.960 sec/step)\n",
      "I0902 08:37:49.933882 139792788920128 learning.py:507] global step 39007: loss = 0.2518 (1.105 sec/step)\n",
      "I0902 08:37:50.257160 139778936784640 supervisor.py:1050] Recording summary at step 39007.\n",
      "I0902 08:37:51.011641 139792788920128 learning.py:507] global step 39008: loss = 0.1403 (1.074 sec/step)\n",
      "I0902 08:37:51.987700 139792788920128 learning.py:507] global step 39009: loss = 0.2827 (0.974 sec/step)\n",
      "I0902 08:37:52.954523 139792788920128 learning.py:507] global step 39010: loss = 0.1658 (0.965 sec/step)\n",
      "I0902 08:37:53.914218 139792788920128 learning.py:507] global step 39011: loss = 0.1562 (0.958 sec/step)\n",
      "I0902 08:37:54.526502 139778945177344 supervisor.py:1099] global_step/sec: 1.025\n",
      "I0902 08:37:54.871332 139792788920128 learning.py:507] global step 39012: loss = 0.1158 (0.955 sec/step)\n",
      "I0902 08:37:55.828552 139792788920128 learning.py:507] global step 39013: loss = 0.0953 (0.956 sec/step)\n",
      "I0902 08:37:56.827264 139792788920128 learning.py:507] global step 39014: loss = 0.1462 (0.997 sec/step)\n",
      "I0902 08:37:57.776194 139792788920128 learning.py:507] global step 39015: loss = 0.1630 (0.947 sec/step)\n",
      "I0902 08:37:58.767692 139792788920128 learning.py:507] global step 39016: loss = 0.3180 (0.990 sec/step)\n",
      "I0902 08:37:59.769843 139792788920128 learning.py:507] global step 39017: loss = 0.0975 (1.000 sec/step)\n",
      "I0902 08:38:00.738640 139792788920128 learning.py:507] global step 39018: loss = 0.0567 (0.967 sec/step)\n",
      "I0902 08:38:01.719994 139792788920128 learning.py:507] global step 39019: loss = 0.0504 (0.980 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:38:02.706368 139792788920128 learning.py:507] global step 39020: loss = 0.1598 (0.985 sec/step)\n",
      "I0902 08:38:03.671368 139792788920128 learning.py:507] global step 39021: loss = 0.1743 (0.963 sec/step)\n",
      "I0902 08:38:04.662152 139792788920128 learning.py:507] global step 39022: loss = 0.1537 (0.989 sec/step)\n",
      "I0902 08:38:05.655473 139792788920128 learning.py:507] global step 39023: loss = 0.1415 (0.992 sec/step)\n",
      "I0902 08:38:06.628388 139792788920128 learning.py:507] global step 39024: loss = 0.2121 (0.971 sec/step)\n",
      "I0902 08:38:07.605925 139792788920128 learning.py:507] global step 39025: loss = 0.0813 (0.976 sec/step)\n",
      "I0902 08:38:08.574324 139792788920128 learning.py:507] global step 39026: loss = 0.0626 (0.967 sec/step)\n",
      "I0902 08:38:09.530099 139792788920128 learning.py:507] global step 39027: loss = 0.1038 (0.954 sec/step)\n",
      "I0902 08:38:10.509602 139792788920128 learning.py:507] global step 39028: loss = 0.1251 (0.978 sec/step)\n",
      "I0902 08:38:11.478043 139792788920128 learning.py:507] global step 39029: loss = 0.1009 (0.967 sec/step)\n",
      "I0902 08:38:12.449732 139792788920128 learning.py:507] global step 39030: loss = 0.0730 (0.970 sec/step)\n",
      "I0902 08:38:13.410963 139792788920128 learning.py:507] global step 39031: loss = 0.1157 (0.960 sec/step)\n",
      "I0902 08:38:14.384073 139792788920128 learning.py:507] global step 39032: loss = 0.2441 (0.972 sec/step)\n",
      "I0902 08:38:15.359529 139792788920128 learning.py:507] global step 39033: loss = 0.1202 (0.974 sec/step)\n",
      "I0902 08:38:16.332167 139792788920128 learning.py:507] global step 39034: loss = 0.0813 (0.971 sec/step)\n",
      "I0902 08:38:17.312218 139792788920128 learning.py:507] global step 39035: loss = 0.1348 (0.979 sec/step)\n",
      "I0902 08:38:18.281503 139792788920128 learning.py:507] global step 39036: loss = 0.1153 (0.967 sec/step)\n",
      "I0902 08:38:19.266514 139792788920128 learning.py:507] global step 39037: loss = 0.1404 (0.983 sec/step)\n",
      "I0902 08:38:20.237671 139792788920128 learning.py:507] global step 39038: loss = 0.1229 (0.970 sec/step)\n",
      "I0902 08:38:21.216330 139792788920128 learning.py:507] global step 39039: loss = 0.1431 (0.977 sec/step)\n",
      "I0902 08:38:22.173461 139792788920128 learning.py:507] global step 39040: loss = 0.0642 (0.955 sec/step)\n",
      "I0902 08:38:23.143973 139792788920128 learning.py:507] global step 39041: loss = 0.1055 (0.969 sec/step)\n",
      "I0902 08:38:24.100467 139792788920128 learning.py:507] global step 39042: loss = 0.1208 (0.955 sec/step)\n",
      "I0902 08:38:25.084934 139792788920128 learning.py:507] global step 39043: loss = 0.1564 (0.983 sec/step)\n",
      "I0902 08:38:26.060239 139792788920128 learning.py:507] global step 39044: loss = 0.0973 (0.974 sec/step)\n",
      "I0902 08:38:27.025348 139792788920128 learning.py:507] global step 39045: loss = 0.0880 (0.963 sec/step)\n",
      "I0902 08:38:28.010465 139792788920128 learning.py:507] global step 39046: loss = 0.1120 (0.983 sec/step)\n",
      "I0902 08:38:28.973141 139792788920128 learning.py:507] global step 39047: loss = 0.0797 (0.961 sec/step)\n",
      "I0902 08:38:29.938602 139792788920128 learning.py:507] global step 39048: loss = 0.0928 (0.964 sec/step)\n",
      "I0902 08:38:30.905465 139792788920128 learning.py:507] global step 39049: loss = 0.0973 (0.965 sec/step)\n",
      "I0902 08:38:31.894687 139792788920128 learning.py:507] global step 39050: loss = 0.1258 (0.988 sec/step)\n",
      "I0902 08:38:32.858879 139792788920128 learning.py:507] global step 39051: loss = 0.1550 (0.962 sec/step)\n",
      "I0902 08:38:33.827977 139792788920128 learning.py:507] global step 39052: loss = 0.0988 (0.967 sec/step)\n",
      "I0902 08:38:34.780099 139792788920128 learning.py:507] global step 39053: loss = 0.0923 (0.951 sec/step)\n",
      "I0902 08:38:35.757072 139792788920128 learning.py:507] global step 39054: loss = 0.1832 (0.975 sec/step)\n",
      "I0902 08:38:36.743707 139792788920128 learning.py:507] global step 39055: loss = 0.1057 (0.985 sec/step)\n",
      "I0902 08:38:37.723593 139792788920128 learning.py:507] global step 39056: loss = 0.1160 (0.978 sec/step)\n",
      "I0902 08:38:38.689142 139792788920128 learning.py:507] global step 39057: loss = 0.1341 (0.964 sec/step)\n",
      "I0902 08:38:39.647374 139792788920128 learning.py:507] global step 39058: loss = 0.0737 (0.957 sec/step)\n",
      "I0902 08:38:40.645069 139792788920128 learning.py:507] global step 39059: loss = 0.1015 (0.996 sec/step)\n",
      "I0902 08:38:41.633982 139792788920128 learning.py:507] global step 39060: loss = 0.1756 (0.987 sec/step)\n",
      "I0902 08:38:42.637892 139792788920128 learning.py:507] global step 39061: loss = 0.1048 (1.003 sec/step)\n",
      "I0902 08:38:43.609327 139792788920128 learning.py:507] global step 39062: loss = 0.0800 (0.970 sec/step)\n",
      "I0902 08:38:44.596806 139792788920128 learning.py:507] global step 39063: loss = 0.1484 (0.986 sec/step)\n",
      "I0902 08:38:45.569473 139792788920128 learning.py:507] global step 39064: loss = 0.0773 (0.971 sec/step)\n",
      "I0902 08:38:46.561124 139792788920128 learning.py:507] global step 39065: loss = 0.0933 (0.990 sec/step)\n",
      "I0902 08:38:47.538034 139792788920128 learning.py:507] global step 39066: loss = 0.1470 (0.975 sec/step)\n",
      "I0902 08:38:48.504539 139792788920128 learning.py:507] global step 39067: loss = 0.0626 (0.965 sec/step)\n",
      "I0902 08:38:49.477387 139792788920128 learning.py:507] global step 39068: loss = 0.0639 (0.971 sec/step)\n",
      "I0902 08:38:50.443881 139792788920128 learning.py:507] global step 39069: loss = 0.0865 (0.965 sec/step)\n",
      "I0902 08:38:51.423070 139792788920128 learning.py:507] global step 39070: loss = 0.2362 (0.978 sec/step)\n",
      "I0902 08:38:52.385118 139792788920128 learning.py:507] global step 39071: loss = 0.1181 (0.960 sec/step)\n",
      "I0902 08:38:53.367226 139792788920128 learning.py:507] global step 39072: loss = 0.1267 (0.980 sec/step)\n",
      "I0902 08:38:54.334235 139792788920128 learning.py:507] global step 39073: loss = 0.0608 (0.966 sec/step)\n",
      "I0902 08:38:55.324866 139792788920128 learning.py:507] global step 39074: loss = 0.1654 (0.989 sec/step)\n",
      "I0902 08:38:56.305928 139792788920128 learning.py:507] global step 39075: loss = 0.0914 (0.979 sec/step)\n",
      "I0902 08:38:57.292376 139792788920128 learning.py:507] global step 39076: loss = 0.1043 (0.985 sec/step)\n",
      "I0902 08:38:58.256260 139792788920128 learning.py:507] global step 39077: loss = 0.0721 (0.962 sec/step)\n",
      "I0902 08:38:59.235652 139792788920128 learning.py:507] global step 39078: loss = 0.1066 (0.978 sec/step)\n",
      "I0902 08:39:00.220648 139792788920128 learning.py:507] global step 39079: loss = 0.0457 (0.983 sec/step)\n",
      "I0902 08:39:01.197783 139792788920128 learning.py:507] global step 39080: loss = 0.1935 (0.976 sec/step)\n",
      "I0902 08:39:02.159456 139792788920128 learning.py:507] global step 39081: loss = 0.1073 (0.960 sec/step)\n",
      "I0902 08:39:03.160346 139792788920128 learning.py:507] global step 39082: loss = 0.1247 (0.999 sec/step)\n",
      "I0902 08:39:04.137796 139792788920128 learning.py:507] global step 39083: loss = 0.1071 (0.976 sec/step)\n",
      "I0902 08:39:05.124105 139792788920128 learning.py:507] global step 39084: loss = 0.2613 (0.985 sec/step)\n",
      "I0902 08:39:06.076770 139792788920128 learning.py:507] global step 39085: loss = 0.1163 (0.951 sec/step)\n",
      "I0902 08:39:07.041195 139792788920128 learning.py:507] global step 39086: loss = 0.0685 (0.963 sec/step)\n",
      "I0902 08:39:08.015409 139792788920128 learning.py:507] global step 39087: loss = 0.1236 (0.973 sec/step)\n",
      "I0902 08:39:08.980598 139792788920128 learning.py:507] global step 39088: loss = 0.1430 (0.964 sec/step)\n",
      "I0902 08:39:09.951861 139792788920128 learning.py:507] global step 39089: loss = 0.1249 (0.970 sec/step)\n",
      "I0902 08:39:10.929011 139792788920128 learning.py:507] global step 39090: loss = 0.0473 (0.975 sec/step)\n",
      "I0902 08:39:11.902587 139792788920128 learning.py:507] global step 39091: loss = 0.0820 (0.972 sec/step)\n",
      "I0902 08:39:12.879461 139792788920128 learning.py:507] global step 39092: loss = 0.1350 (0.975 sec/step)\n",
      "I0902 08:39:13.858497 139792788920128 learning.py:507] global step 39093: loss = 0.1047 (0.978 sec/step)\n",
      "I0902 08:39:14.823162 139792788920128 learning.py:507] global step 39094: loss = 0.0823 (0.963 sec/step)\n",
      "I0902 08:39:15.800158 139792788920128 learning.py:507] global step 39095: loss = 0.1416 (0.975 sec/step)\n",
      "I0902 08:39:16.772812 139792788920128 learning.py:507] global step 39096: loss = 0.0940 (0.971 sec/step)\n",
      "I0902 08:39:17.732748 139792788920128 learning.py:507] global step 39097: loss = 0.0837 (0.958 sec/step)\n",
      "I0902 08:39:18.686083 139792788920128 learning.py:507] global step 39098: loss = 0.2000 (0.952 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:39:19.657414 139792788920128 learning.py:507] global step 39099: loss = 0.0737 (0.970 sec/step)\n",
      "I0902 08:39:20.619879 139792788920128 learning.py:507] global step 39100: loss = 0.0525 (0.961 sec/step)\n",
      "I0902 08:39:21.584939 139792788920128 learning.py:507] global step 39101: loss = 0.1022 (0.963 sec/step)\n",
      "I0902 08:39:22.565085 139792788920128 learning.py:507] global step 39102: loss = 0.1078 (0.979 sec/step)\n",
      "I0902 08:39:23.537493 139792788920128 learning.py:507] global step 39103: loss = 0.1027 (0.971 sec/step)\n",
      "I0902 08:39:24.509640 139792788920128 learning.py:507] global step 39104: loss = 0.1745 (0.970 sec/step)\n",
      "I0902 08:39:25.485619 139792788920128 learning.py:507] global step 39105: loss = 0.1400 (0.974 sec/step)\n",
      "I0902 08:39:26.461628 139792788920128 learning.py:507] global step 39106: loss = 0.1122 (0.974 sec/step)\n",
      "I0902 08:39:27.435490 139792788920128 learning.py:507] global step 39107: loss = 0.1554 (0.972 sec/step)\n",
      "I0902 08:39:28.428142 139792788920128 learning.py:507] global step 39108: loss = 0.0709 (0.991 sec/step)\n",
      "I0902 08:39:29.410439 139792788920128 learning.py:507] global step 39109: loss = 0.1353 (0.981 sec/step)\n",
      "I0902 08:39:30.363168 139792788920128 learning.py:507] global step 39110: loss = 0.1138 (0.951 sec/step)\n",
      "I0902 08:39:31.345418 139792788920128 learning.py:507] global step 39111: loss = 0.2200 (0.981 sec/step)\n",
      "I0902 08:39:32.322238 139792788920128 learning.py:507] global step 39112: loss = 0.0909 (0.975 sec/step)\n",
      "I0902 08:39:33.295799 139792788920128 learning.py:507] global step 39113: loss = 0.1961 (0.972 sec/step)\n",
      "I0902 08:39:34.275094 139792788920128 learning.py:507] global step 39114: loss = 0.1758 (0.978 sec/step)\n",
      "I0902 08:39:35.262062 139792788920128 learning.py:507] global step 39115: loss = 0.1065 (0.985 sec/step)\n",
      "I0902 08:39:36.256525 139792788920128 learning.py:507] global step 39116: loss = 0.1299 (0.993 sec/step)\n",
      "I0902 08:39:37.234793 139792788920128 learning.py:507] global step 39117: loss = 0.1382 (0.977 sec/step)\n",
      "I0902 08:39:38.211283 139792788920128 learning.py:507] global step 39118: loss = 0.0927 (0.975 sec/step)\n",
      "I0902 08:39:39.220687 139792788920128 learning.py:507] global step 39119: loss = 0.0446 (1.008 sec/step)\n",
      "I0902 08:39:40.190303 139792788920128 learning.py:507] global step 39120: loss = 0.1266 (0.968 sec/step)\n",
      "I0902 08:39:41.195741 139792788920128 learning.py:507] global step 39121: loss = 0.1676 (1.004 sec/step)\n",
      "I0902 08:39:42.161918 139792788920128 learning.py:507] global step 39122: loss = 0.1836 (0.964 sec/step)\n",
      "I0902 08:39:43.126956 139792788920128 learning.py:507] global step 39123: loss = 0.1134 (0.963 sec/step)\n",
      "I0902 08:39:44.106039 139792788920128 learning.py:507] global step 39124: loss = 0.2625 (0.978 sec/step)\n",
      "I0902 08:39:45.064013 139792788920128 learning.py:507] global step 39125: loss = 0.0779 (0.956 sec/step)\n",
      "I0902 08:39:46.054230 139792788920128 learning.py:507] global step 39126: loss = 0.0926 (0.988 sec/step)\n",
      "I0902 08:39:47.010681 139792788920128 learning.py:507] global step 39127: loss = 0.2594 (0.955 sec/step)\n",
      "I0902 08:39:47.995647 139792788920128 learning.py:507] global step 39128: loss = 0.1587 (0.983 sec/step)\n",
      "I0902 08:39:48.986880 139792788920128 learning.py:507] global step 39129: loss = 0.1597 (0.990 sec/step)\n",
      "I0902 08:39:50.144537 139792788920128 learning.py:507] global step 39130: loss = 0.2493 (1.151 sec/step)\n",
      "I0902 08:39:50.321468 139778936784640 supervisor.py:1050] Recording summary at step 39130.\n",
      "I0902 08:39:51.243770 139792788920128 learning.py:507] global step 39131: loss = 0.3093 (1.097 sec/step)\n",
      "I0902 08:39:52.208546 139792788920128 learning.py:507] global step 39132: loss = 0.1727 (0.963 sec/step)\n",
      "I0902 08:39:53.168931 139792788920128 learning.py:507] global step 39133: loss = 0.0826 (0.959 sec/step)\n",
      "I0902 08:39:54.147964 139792788920128 learning.py:507] global step 39134: loss = 0.4884 (0.978 sec/step)\n",
      "I0902 08:39:54.526619 139778945177344 supervisor.py:1099] global_step/sec: 1.025\n",
      "I0902 08:39:55.160593 139792788920128 learning.py:507] global step 39135: loss = 0.1335 (1.011 sec/step)\n",
      "I0902 08:39:56.144663 139792788920128 learning.py:507] global step 39136: loss = 0.0900 (0.982 sec/step)\n",
      "I0902 08:39:57.099999 139792788920128 learning.py:507] global step 39137: loss = 0.0905 (0.954 sec/step)\n",
      "I0902 08:39:58.056829 139792788920128 learning.py:507] global step 39138: loss = 0.0693 (0.955 sec/step)\n",
      "I0902 08:39:59.021880 139792788920128 learning.py:507] global step 39139: loss = 0.1018 (0.963 sec/step)\n",
      "I0902 08:39:59.971139 139792788920128 learning.py:507] global step 39140: loss = 0.1696 (0.948 sec/step)\n",
      "I0902 08:40:00.943126 139792788920128 learning.py:507] global step 39141: loss = 0.2122 (0.970 sec/step)\n",
      "I0902 08:40:01.930964 139792788920128 learning.py:507] global step 39142: loss = 0.0926 (0.986 sec/step)\n",
      "I0902 08:40:02.900626 139792788920128 learning.py:507] global step 39143: loss = 0.2009 (0.968 sec/step)\n",
      "I0902 08:40:03.872674 139792788920128 learning.py:507] global step 39144: loss = 0.1674 (0.970 sec/step)\n",
      "I0902 08:40:04.857928 139792788920128 learning.py:507] global step 39145: loss = 0.0987 (0.983 sec/step)\n",
      "I0902 08:40:05.833315 139792788920128 learning.py:507] global step 39146: loss = 0.1180 (0.974 sec/step)\n",
      "I0902 08:40:06.806063 139792788920128 learning.py:507] global step 39147: loss = 0.0794 (0.971 sec/step)\n",
      "I0902 08:40:07.775710 139792788920128 learning.py:507] global step 39148: loss = 0.0774 (0.968 sec/step)\n",
      "I0902 08:40:08.761830 139792788920128 learning.py:507] global step 39149: loss = 0.1166 (0.985 sec/step)\n",
      "I0902 08:40:09.735683 139792788920128 learning.py:507] global step 39150: loss = 0.1147 (0.972 sec/step)\n",
      "I0902 08:40:10.732930 139792788920128 learning.py:507] global step 39151: loss = 0.0717 (0.995 sec/step)\n",
      "I0902 08:40:11.708259 139792788920128 learning.py:507] global step 39152: loss = 0.0494 (0.974 sec/step)\n",
      "I0902 08:40:12.666392 139792788920128 learning.py:507] global step 39153: loss = 0.1397 (0.957 sec/step)\n",
      "I0902 08:40:13.637094 139792788920128 learning.py:507] global step 39154: loss = 0.1282 (0.969 sec/step)\n",
      "I0902 08:40:14.610429 139792788920128 learning.py:507] global step 39155: loss = 0.1185 (0.972 sec/step)\n",
      "I0902 08:40:15.567742 139792788920128 learning.py:507] global step 39156: loss = 0.1450 (0.956 sec/step)\n",
      "I0902 08:40:16.537935 139792788920128 learning.py:507] global step 39157: loss = 0.1110 (0.968 sec/step)\n",
      "I0902 08:40:17.505161 139792788920128 learning.py:507] global step 39158: loss = 0.0881 (0.965 sec/step)\n",
      "I0902 08:40:18.483826 139792788920128 learning.py:507] global step 39159: loss = 0.0755 (0.977 sec/step)\n",
      "I0902 08:40:19.469401 139792788920128 learning.py:507] global step 39160: loss = 0.1021 (0.984 sec/step)\n",
      "I0902 08:40:20.435011 139792788920128 learning.py:507] global step 39161: loss = 0.0942 (0.964 sec/step)\n",
      "I0902 08:40:21.419453 139792788920128 learning.py:507] global step 39162: loss = 0.1052 (0.983 sec/step)\n",
      "I0902 08:40:22.386310 139792788920128 learning.py:507] global step 39163: loss = 0.0870 (0.965 sec/step)\n",
      "I0902 08:40:23.354794 139792788920128 learning.py:507] global step 39164: loss = 0.1310 (0.967 sec/step)\n",
      "I0902 08:40:24.331569 139792788920128 learning.py:507] global step 39165: loss = 0.0758 (0.975 sec/step)\n",
      "I0902 08:40:25.316385 139792788920128 learning.py:507] global step 39166: loss = 0.1241 (0.984 sec/step)\n",
      "I0902 08:40:26.291348 139792788920128 learning.py:507] global step 39167: loss = 0.1622 (0.974 sec/step)\n",
      "I0902 08:40:27.256001 139792788920128 learning.py:507] global step 39168: loss = 0.0777 (0.963 sec/step)\n",
      "I0902 08:40:28.229869 139792788920128 learning.py:507] global step 39169: loss = 0.1178 (0.973 sec/step)\n",
      "I0902 08:40:29.216601 139792788920128 learning.py:507] global step 39170: loss = 0.1406 (0.985 sec/step)\n",
      "I0902 08:40:30.194199 139792788920128 learning.py:507] global step 39171: loss = 0.1068 (0.976 sec/step)\n",
      "I0902 08:40:31.176011 139792788920128 learning.py:507] global step 39172: loss = 0.1526 (0.980 sec/step)\n",
      "I0902 08:40:32.152914 139792788920128 learning.py:507] global step 39173: loss = 0.0687 (0.975 sec/step)\n",
      "I0902 08:40:33.119746 139792788920128 learning.py:507] global step 39174: loss = 0.0877 (0.966 sec/step)\n",
      "I0902 08:40:34.082519 139792788920128 learning.py:507] global step 39175: loss = 0.0840 (0.962 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:40:35.072361 139792788920128 learning.py:507] global step 39176: loss = 0.0468 (0.989 sec/step)\n",
      "I0902 08:40:36.054987 139792788920128 learning.py:507] global step 39177: loss = 0.1094 (0.981 sec/step)\n",
      "I0902 08:40:37.036745 139792788920128 learning.py:507] global step 39178: loss = 0.1298 (0.980 sec/step)\n",
      "I0902 08:40:38.021205 139792788920128 learning.py:507] global step 39179: loss = 0.1030 (0.983 sec/step)\n",
      "I0902 08:40:38.980586 139792788920128 learning.py:507] global step 39180: loss = 0.1041 (0.958 sec/step)\n",
      "I0902 08:40:39.958807 139792788920128 learning.py:507] global step 39181: loss = 0.0805 (0.976 sec/step)\n",
      "I0902 08:40:40.943588 139792788920128 learning.py:507] global step 39182: loss = 0.1782 (0.983 sec/step)\n",
      "I0902 08:40:41.906228 139792788920128 learning.py:507] global step 39183: loss = 0.1253 (0.961 sec/step)\n",
      "I0902 08:40:42.873443 139792788920128 learning.py:507] global step 39184: loss = 0.2566 (0.966 sec/step)\n",
      "I0902 08:40:43.845688 139792788920128 learning.py:507] global step 39185: loss = 0.0727 (0.971 sec/step)\n",
      "I0902 08:40:44.820749 139792788920128 learning.py:507] global step 39186: loss = 0.1226 (0.973 sec/step)\n",
      "I0902 08:40:45.798085 139792788920128 learning.py:507] global step 39187: loss = 0.1613 (0.976 sec/step)\n",
      "I0902 08:40:46.771625 139792788920128 learning.py:507] global step 39188: loss = 0.0662 (0.972 sec/step)\n",
      "I0902 08:40:47.741817 139792788920128 learning.py:507] global step 39189: loss = 0.3188 (0.969 sec/step)\n",
      "I0902 08:40:48.724381 139792788920128 learning.py:507] global step 39190: loss = 0.1546 (0.981 sec/step)\n",
      "I0902 08:40:49.710852 139792788920128 learning.py:507] global step 39191: loss = 0.1163 (0.985 sec/step)\n",
      "I0902 08:40:50.707932 139792788920128 learning.py:507] global step 39192: loss = 0.0711 (0.995 sec/step)\n",
      "I0902 08:40:51.693747 139792788920128 learning.py:507] global step 39193: loss = 0.1506 (0.984 sec/step)\n",
      "I0902 08:40:52.694170 139792788920128 learning.py:507] global step 39194: loss = 0.2017 (0.999 sec/step)\n",
      "I0902 08:40:53.660577 139792788920128 learning.py:507] global step 39195: loss = 0.0805 (0.965 sec/step)\n",
      "I0902 08:40:54.627275 139792788920128 learning.py:507] global step 39196: loss = 0.1061 (0.965 sec/step)\n",
      "I0902 08:40:55.592537 139792788920128 learning.py:507] global step 39197: loss = 0.1120 (0.964 sec/step)\n",
      "I0902 08:40:56.574270 139792788920128 learning.py:507] global step 39198: loss = 0.0902 (0.980 sec/step)\n",
      "I0902 08:40:57.543134 139792788920128 learning.py:507] global step 39199: loss = 0.2219 (0.967 sec/step)\n",
      "I0902 08:40:58.527762 139792788920128 learning.py:507] global step 39200: loss = 0.1390 (0.983 sec/step)\n",
      "I0902 08:40:59.529253 139792788920128 learning.py:507] global step 39201: loss = 0.1301 (1.000 sec/step)\n",
      "I0902 08:41:00.508730 139792788920128 learning.py:507] global step 39202: loss = 0.1765 (0.978 sec/step)\n",
      "I0902 08:41:01.490801 139792788920128 learning.py:507] global step 39203: loss = 0.0937 (0.981 sec/step)\n",
      "I0902 08:41:02.458914 139792788920128 learning.py:507] global step 39204: loss = 0.2060 (0.966 sec/step)\n",
      "I0902 08:41:03.457377 139792788920128 learning.py:507] global step 39205: loss = 0.0606 (0.997 sec/step)\n",
      "I0902 08:41:04.442391 139792788920128 learning.py:507] global step 39206: loss = 0.0632 (0.983 sec/step)\n",
      "I0902 08:41:05.407537 139792788920128 learning.py:507] global step 39207: loss = 0.4212 (0.963 sec/step)\n",
      "I0902 08:41:06.393864 139792788920128 learning.py:507] global step 39208: loss = 0.2301 (0.985 sec/step)\n",
      "I0902 08:41:07.374218 139792788920128 learning.py:507] global step 39209: loss = 0.0886 (0.979 sec/step)\n",
      "I0902 08:41:08.349641 139792788920128 learning.py:507] global step 39210: loss = 0.2144 (0.974 sec/step)\n",
      "I0902 08:41:09.338604 139792788920128 learning.py:507] global step 39211: loss = 0.1087 (0.987 sec/step)\n",
      "I0902 08:41:10.301520 139792788920128 learning.py:507] global step 39212: loss = 0.1556 (0.961 sec/step)\n",
      "I0902 08:41:11.283953 139792788920128 learning.py:507] global step 39213: loss = 0.0816 (0.981 sec/step)\n",
      "I0902 08:41:12.254239 139792788920128 learning.py:507] global step 39214: loss = 0.1795 (0.969 sec/step)\n",
      "I0902 08:41:13.211957 139792788920128 learning.py:507] global step 39215: loss = 0.1734 (0.956 sec/step)\n",
      "I0902 08:41:14.239131 139792788920128 learning.py:507] global step 39216: loss = 0.1214 (1.026 sec/step)\n",
      "I0902 08:41:15.263707 139792788920128 learning.py:507] global step 39217: loss = 0.0990 (1.023 sec/step)\n",
      "I0902 08:41:16.255108 139792788920128 learning.py:507] global step 39218: loss = 0.0853 (0.989 sec/step)\n",
      "I0902 08:41:17.259852 139792788920128 learning.py:507] global step 39219: loss = 0.1466 (1.003 sec/step)\n",
      "I0902 08:41:18.252476 139792788920128 learning.py:507] global step 39220: loss = 0.1662 (0.991 sec/step)\n",
      "I0902 08:41:19.206621 139792788920128 learning.py:507] global step 39221: loss = 0.1135 (0.952 sec/step)\n",
      "I0902 08:41:20.172333 139792788920128 learning.py:507] global step 39222: loss = 0.2280 (0.964 sec/step)\n",
      "I0902 08:41:21.154647 139792788920128 learning.py:507] global step 39223: loss = 0.1026 (0.981 sec/step)\n",
      "I0902 08:41:22.150770 139792788920128 learning.py:507] global step 39224: loss = 0.0925 (0.994 sec/step)\n",
      "I0902 08:41:23.137925 139792788920128 learning.py:507] global step 39225: loss = 0.0787 (0.985 sec/step)\n",
      "I0902 08:41:24.096663 139792788920128 learning.py:507] global step 39226: loss = 0.0731 (0.957 sec/step)\n",
      "I0902 08:41:25.065095 139792788920128 learning.py:507] global step 39227: loss = 0.1147 (0.967 sec/step)\n",
      "I0902 08:41:26.035750 139792788920128 learning.py:507] global step 39228: loss = 0.0992 (0.969 sec/step)\n",
      "I0902 08:41:27.033494 139792788920128 learning.py:507] global step 39229: loss = 0.0868 (0.996 sec/step)\n",
      "I0902 08:41:27.997067 139792788920128 learning.py:507] global step 39230: loss = 0.1593 (0.962 sec/step)\n",
      "I0902 08:41:28.964825 139792788920128 learning.py:507] global step 39231: loss = 0.0242 (0.966 sec/step)\n",
      "I0902 08:41:29.947391 139792788920128 learning.py:507] global step 39232: loss = 0.1545 (0.981 sec/step)\n",
      "I0902 08:41:30.907548 139792788920128 learning.py:507] global step 39233: loss = 0.0533 (0.959 sec/step)\n",
      "I0902 08:41:31.868792 139792788920128 learning.py:507] global step 39234: loss = 0.0923 (0.960 sec/step)\n",
      "I0902 08:41:32.827328 139792788920128 learning.py:507] global step 39235: loss = 0.2402 (0.957 sec/step)\n",
      "I0902 08:41:33.783633 139792788920128 learning.py:507] global step 39236: loss = 0.2011 (0.955 sec/step)\n",
      "I0902 08:41:34.740039 139792788920128 learning.py:507] global step 39237: loss = 0.1505 (0.955 sec/step)\n",
      "I0902 08:41:35.747532 139792788920128 learning.py:507] global step 39238: loss = 0.0754 (1.006 sec/step)\n",
      "I0902 08:41:36.740454 139792788920128 learning.py:507] global step 39239: loss = 0.0934 (0.991 sec/step)\n",
      "I0902 08:41:37.720223 139792788920128 learning.py:507] global step 39240: loss = 0.0877 (0.978 sec/step)\n",
      "I0902 08:41:38.699630 139792788920128 learning.py:507] global step 39241: loss = 0.1523 (0.978 sec/step)\n",
      "I0902 08:41:39.663905 139792788920128 learning.py:507] global step 39242: loss = 0.0969 (0.963 sec/step)\n",
      "I0902 08:41:40.659909 139792788920128 learning.py:507] global step 39243: loss = 0.1351 (0.994 sec/step)\n",
      "I0902 08:41:41.626044 139792788920128 learning.py:507] global step 39244: loss = 0.1485 (0.964 sec/step)\n",
      "I0902 08:41:42.604984 139792788920128 learning.py:507] global step 39245: loss = 0.0633 (0.977 sec/step)\n",
      "I0902 08:41:43.593358 139792788920128 learning.py:507] global step 39246: loss = 0.0757 (0.987 sec/step)\n",
      "I0902 08:41:44.544119 139792788920128 learning.py:507] global step 39247: loss = 0.0733 (0.949 sec/step)\n",
      "I0902 08:41:45.526236 139792788920128 learning.py:507] global step 39248: loss = 0.0720 (0.980 sec/step)\n",
      "I0902 08:41:46.486461 139792788920128 learning.py:507] global step 39249: loss = 0.1158 (0.959 sec/step)\n",
      "I0902 08:41:47.457149 139792788920128 learning.py:507] global step 39250: loss = 0.2550 (0.969 sec/step)\n",
      "I0902 08:41:48.447182 139792788920128 learning.py:507] global step 39251: loss = 0.0926 (0.989 sec/step)\n",
      "I0902 08:41:49.432647 139792788920128 learning.py:507] global step 39252: loss = 0.1790 (0.981 sec/step)\n",
      "I0902 08:41:50.081385 139778936784640 supervisor.py:1050] Recording summary at step 39252.\n",
      "I0902 08:41:50.705926 139792788920128 learning.py:507] global step 39253: loss = 0.1011 (1.259 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:41:51.661390 139792788920128 learning.py:507] global step 39254: loss = 0.0706 (0.954 sec/step)\n",
      "I0902 08:41:52.624066 139792788920128 learning.py:507] global step 39255: loss = 0.1186 (0.961 sec/step)\n",
      "I0902 08:41:53.590642 139792788920128 learning.py:507] global step 39256: loss = 0.0924 (0.965 sec/step)\n",
      "I0902 08:41:54.526431 139778945177344 supervisor.py:1099] global_step/sec: 1.01667\n",
      "I0902 08:41:54.548776 139792788920128 learning.py:507] global step 39257: loss = 0.1048 (0.956 sec/step)\n",
      "I0902 08:41:55.534652 139792788920128 learning.py:507] global step 39258: loss = 0.1961 (0.984 sec/step)\n",
      "I0902 08:41:56.489605 139792788920128 learning.py:507] global step 39259: loss = 0.0987 (0.953 sec/step)\n",
      "I0902 08:41:57.470750 139792788920128 learning.py:507] global step 39260: loss = 0.2303 (0.980 sec/step)\n",
      "I0902 08:41:58.454582 139792788920128 learning.py:507] global step 39261: loss = 0.0531 (0.982 sec/step)\n",
      "I0902 08:41:59.441697 139792788920128 learning.py:507] global step 39262: loss = 0.1995 (0.985 sec/step)\n",
      "I0902 08:42:00.409823 139792788920128 learning.py:507] global step 39263: loss = 0.0727 (0.967 sec/step)\n",
      "I0902 08:42:01.356108 139792788920128 learning.py:507] global step 39264: loss = 0.1988 (0.945 sec/step)\n",
      "I0902 08:42:02.305280 139792788920128 learning.py:507] global step 39265: loss = 0.1657 (0.947 sec/step)\n",
      "I0902 08:42:03.255555 139792788920128 learning.py:507] global step 39266: loss = 0.1344 (0.948 sec/step)\n",
      "I0902 08:42:04.239457 139792788920128 learning.py:507] global step 39267: loss = 0.1259 (0.982 sec/step)\n",
      "I0902 08:42:05.213938 139792788920128 learning.py:507] global step 39268: loss = 0.1908 (0.973 sec/step)\n",
      "I0902 08:42:06.194358 139792788920128 learning.py:507] global step 39269: loss = 0.2947 (0.979 sec/step)\n",
      "I0902 08:42:07.166038 139792788920128 learning.py:507] global step 39270: loss = 0.0840 (0.970 sec/step)\n",
      "I0902 08:42:08.138912 139792788920128 learning.py:507] global step 39271: loss = 0.1555 (0.971 sec/step)\n",
      "I0902 08:42:09.115159 139792788920128 learning.py:507] global step 39272: loss = 0.0770 (0.975 sec/step)\n",
      "I0902 08:42:10.092777 139792788920128 learning.py:507] global step 39273: loss = 0.0566 (0.976 sec/step)\n",
      "I0902 08:42:11.059986 139792788920128 learning.py:507] global step 39274: loss = 0.0980 (0.966 sec/step)\n",
      "I0902 08:42:12.030024 139792788920128 learning.py:507] global step 39275: loss = 0.1046 (0.968 sec/step)\n",
      "I0902 08:42:12.984918 139792788920128 learning.py:507] global step 39276: loss = 0.2959 (0.953 sec/step)\n",
      "I0902 08:42:13.963812 139792788920128 learning.py:507] global step 39277: loss = 0.0880 (0.977 sec/step)\n",
      "I0902 08:42:14.949454 139792788920128 learning.py:507] global step 39278: loss = 0.1449 (0.984 sec/step)\n",
      "I0902 08:42:15.915806 139792788920128 learning.py:507] global step 39279: loss = 0.0697 (0.965 sec/step)\n",
      "I0902 08:42:16.889959 139792788920128 learning.py:507] global step 39280: loss = 0.0897 (0.973 sec/step)\n",
      "I0902 08:42:17.848348 139792788920128 learning.py:507] global step 39281: loss = 0.0928 (0.957 sec/step)\n",
      "I0902 08:42:18.821235 139792788920128 learning.py:507] global step 39282: loss = 0.1083 (0.971 sec/step)\n",
      "I0902 08:42:19.805723 139792788920128 learning.py:507] global step 39283: loss = 0.0671 (0.983 sec/step)\n",
      "I0902 08:42:20.798134 139792788920128 learning.py:507] global step 39284: loss = 0.1364 (0.991 sec/step)\n",
      "I0902 08:42:21.775737 139792788920128 learning.py:507] global step 39285: loss = 0.1011 (0.976 sec/step)\n",
      "I0902 08:42:22.755386 139792788920128 learning.py:507] global step 39286: loss = 0.0644 (0.978 sec/step)\n",
      "I0902 08:42:23.748679 139792788920128 learning.py:507] global step 39287: loss = 0.1478 (0.992 sec/step)\n",
      "I0902 08:42:24.721323 139792788920128 learning.py:507] global step 39288: loss = 0.0839 (0.971 sec/step)\n",
      "I0902 08:42:25.678819 139792788920128 learning.py:507] global step 39289: loss = 0.0738 (0.956 sec/step)\n",
      "I0902 08:42:26.642012 139792788920128 learning.py:507] global step 39290: loss = 0.0966 (0.961 sec/step)\n",
      "I0902 08:42:27.614499 139792788920128 learning.py:507] global step 39291: loss = 0.1431 (0.971 sec/step)\n",
      "I0902 08:42:28.569450 139792788920128 learning.py:507] global step 39292: loss = 0.1292 (0.953 sec/step)\n",
      "I0902 08:42:29.541719 139792788920128 learning.py:507] global step 39293: loss = 0.0731 (0.971 sec/step)\n",
      "I0902 08:42:30.505381 139792788920128 learning.py:507] global step 39294: loss = 0.2814 (0.962 sec/step)\n",
      "I0902 08:42:31.490869 139792788920128 learning.py:507] global step 39295: loss = 0.1096 (0.984 sec/step)\n",
      "I0902 08:42:32.466424 139792788920128 learning.py:507] global step 39296: loss = 0.0998 (0.974 sec/step)\n",
      "I0902 08:42:33.449635 139792788920128 learning.py:507] global step 39297: loss = 0.1064 (0.982 sec/step)\n",
      "I0902 08:42:34.413074 139792788920128 learning.py:507] global step 39298: loss = 0.1365 (0.962 sec/step)\n",
      "I0902 08:42:35.384209 139792788920128 learning.py:507] global step 39299: loss = 0.1456 (0.969 sec/step)\n",
      "I0902 08:42:36.382136 139792788920128 learning.py:507] global step 39300: loss = 0.1125 (0.996 sec/step)\n",
      "I0902 08:42:37.368521 139792788920128 learning.py:507] global step 39301: loss = 0.1787 (0.985 sec/step)\n",
      "I0902 08:42:38.367928 139792788920128 learning.py:507] global step 39302: loss = 0.2158 (0.998 sec/step)\n",
      "I0902 08:42:39.335537 139792788920128 learning.py:507] global step 39303: loss = 0.1306 (0.966 sec/step)\n",
      "I0902 08:42:40.289325 139792788920128 learning.py:507] global step 39304: loss = 0.1956 (0.952 sec/step)\n",
      "I0902 08:42:41.285063 139792788920128 learning.py:507] global step 39305: loss = 0.1011 (0.994 sec/step)\n",
      "I0902 08:42:42.270384 139792788920128 learning.py:507] global step 39306: loss = 0.1358 (0.984 sec/step)\n",
      "I0902 08:42:43.292375 139792788920128 learning.py:507] global step 39307: loss = 0.1131 (1.020 sec/step)\n",
      "I0902 08:42:44.255781 139792788920128 learning.py:507] global step 39308: loss = 0.2588 (0.962 sec/step)\n",
      "I0902 08:42:45.223062 139792788920128 learning.py:507] global step 39309: loss = 0.1373 (0.966 sec/step)\n",
      "I0902 08:42:46.214080 139792788920128 learning.py:507] global step 39310: loss = 0.1207 (0.989 sec/step)\n",
      "I0902 08:42:47.187505 139792788920128 learning.py:507] global step 39311: loss = 0.2705 (0.972 sec/step)\n",
      "I0902 08:42:48.159555 139792788920128 learning.py:507] global step 39312: loss = 0.1076 (0.970 sec/step)\n",
      "I0902 08:42:49.159026 139792788920128 learning.py:507] global step 39313: loss = 0.0573 (0.998 sec/step)\n",
      "I0902 08:42:50.127575 139792788920128 learning.py:507] global step 39314: loss = 0.2370 (0.967 sec/step)\n",
      "I0902 08:42:51.102119 139792788920128 learning.py:507] global step 39315: loss = 0.1093 (0.973 sec/step)\n",
      "I0902 08:42:52.059680 139792788920128 learning.py:507] global step 39316: loss = 0.0992 (0.956 sec/step)\n",
      "I0902 08:42:53.020978 139792788920128 learning.py:507] global step 39317: loss = 0.1331 (0.960 sec/step)\n",
      "I0902 08:42:53.994705 139792788920128 learning.py:507] global step 39318: loss = 0.1126 (0.972 sec/step)\n",
      "I0902 08:42:54.953483 139792788920128 learning.py:507] global step 39319: loss = 0.0809 (0.957 sec/step)\n",
      "I0902 08:42:55.921691 139792788920128 learning.py:507] global step 39320: loss = 0.1036 (0.967 sec/step)\n",
      "I0902 08:42:56.900212 139792788920128 learning.py:507] global step 39321: loss = 0.1648 (0.977 sec/step)\n",
      "I0902 08:42:57.868340 139792788920128 learning.py:507] global step 39322: loss = 0.0648 (0.966 sec/step)\n",
      "I0902 08:42:58.825674 139792788920128 learning.py:507] global step 39323: loss = 0.1615 (0.956 sec/step)\n",
      "I0902 08:42:59.803575 139792788920128 learning.py:507] global step 39324: loss = 0.1472 (0.976 sec/step)\n",
      "I0902 08:43:00.786988 139792788920128 learning.py:507] global step 39325: loss = 0.1319 (0.982 sec/step)\n",
      "I0902 08:43:01.765347 139792788920128 learning.py:507] global step 39326: loss = 0.1161 (0.977 sec/step)\n",
      "I0902 08:43:02.758389 139792788920128 learning.py:507] global step 39327: loss = 0.0576 (0.991 sec/step)\n",
      "I0902 08:43:03.765652 139792788920128 learning.py:507] global step 39328: loss = 0.0831 (1.006 sec/step)\n",
      "I0902 08:43:04.773177 139792788920128 learning.py:507] global step 39329: loss = 0.1659 (1.006 sec/step)\n",
      "I0902 08:43:05.746531 139792788920128 learning.py:507] global step 39330: loss = 0.0800 (0.972 sec/step)\n",
      "I0902 08:43:07.147659 139792788920128 learning.py:507] global step 39331: loss = 0.1003 (1.399 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:43:08.109829 139792788920128 learning.py:507] global step 39332: loss = 0.0922 (0.960 sec/step)\n",
      "I0902 08:43:09.076144 139792788920128 learning.py:507] global step 39333: loss = 0.1321 (0.965 sec/step)\n",
      "I0902 08:43:10.038144 139792788920128 learning.py:507] global step 39334: loss = 0.1019 (0.960 sec/step)\n",
      "I0902 08:43:11.019701 139792788920128 learning.py:507] global step 39335: loss = 0.0944 (0.980 sec/step)\n",
      "I0902 08:43:12.001292 139792788920128 learning.py:507] global step 39336: loss = 0.0664 (0.980 sec/step)\n",
      "I0902 08:43:12.960165 139792788920128 learning.py:507] global step 39337: loss = 0.0797 (0.957 sec/step)\n",
      "I0902 08:43:13.933064 139792788920128 learning.py:507] global step 39338: loss = 0.2981 (0.971 sec/step)\n",
      "I0902 08:43:14.908689 139792788920128 learning.py:507] global step 39339: loss = 0.1587 (0.974 sec/step)\n",
      "I0902 08:43:15.871591 139792788920128 learning.py:507] global step 39340: loss = 0.2419 (0.961 sec/step)\n",
      "I0902 08:43:16.823154 139792788920128 learning.py:507] global step 39341: loss = 0.1406 (0.950 sec/step)\n",
      "I0902 08:43:17.782311 139792788920128 learning.py:507] global step 39342: loss = 0.0715 (0.957 sec/step)\n",
      "I0902 08:43:18.752190 139792788920128 learning.py:507] global step 39343: loss = 0.1654 (0.968 sec/step)\n",
      "I0902 08:43:19.706702 139792788920128 learning.py:507] global step 39344: loss = 0.0806 (0.953 sec/step)\n",
      "I0902 08:43:20.667433 139792788920128 learning.py:507] global step 39345: loss = 0.1357 (0.959 sec/step)\n",
      "I0902 08:43:21.652791 139792788920128 learning.py:507] global step 39346: loss = 0.1443 (0.984 sec/step)\n",
      "I0902 08:43:22.603988 139792788920128 learning.py:507] global step 39347: loss = 0.1849 (0.950 sec/step)\n",
      "I0902 08:43:23.606053 139792788920128 learning.py:507] global step 39348: loss = 0.0527 (1.000 sec/step)\n",
      "I0902 08:43:24.557863 139792788920128 learning.py:507] global step 39349: loss = 0.1007 (0.950 sec/step)\n",
      "I0902 08:43:25.521379 139792788920128 learning.py:507] global step 39350: loss = 0.0976 (0.962 sec/step)\n",
      "I0902 08:43:26.486971 139792788920128 learning.py:507] global step 39351: loss = 0.2104 (0.964 sec/step)\n",
      "I0902 08:43:27.450324 139792788920128 learning.py:507] global step 39352: loss = 0.0549 (0.962 sec/step)\n",
      "I0902 08:43:28.426789 139792788920128 learning.py:507] global step 39353: loss = 0.0774 (0.975 sec/step)\n",
      "I0902 08:43:29.428888 139792788920128 learning.py:507] global step 39354: loss = 0.1401 (1.000 sec/step)\n",
      "I0902 08:43:30.417712 139792788920128 learning.py:507] global step 39355: loss = 0.1243 (0.987 sec/step)\n",
      "I0902 08:43:31.405965 139792788920128 learning.py:507] global step 39356: loss = 0.1366 (0.987 sec/step)\n",
      "I0902 08:43:32.376620 139792788920128 learning.py:507] global step 39357: loss = 0.0974 (0.969 sec/step)\n",
      "I0902 08:43:33.354213 139792788920128 learning.py:507] global step 39358: loss = 0.0944 (0.976 sec/step)\n",
      "I0902 08:43:34.332036 139792788920128 learning.py:507] global step 39359: loss = 0.0920 (0.976 sec/step)\n",
      "I0902 08:43:35.307009 139792788920128 learning.py:507] global step 39360: loss = 0.1122 (0.973 sec/step)\n",
      "I0902 08:43:36.321309 139792788920128 learning.py:507] global step 39361: loss = 0.0583 (1.013 sec/step)\n",
      "I0902 08:43:37.309976 139792788920128 learning.py:507] global step 39362: loss = 0.1178 (0.987 sec/step)\n",
      "I0902 08:43:38.288538 139792788920128 learning.py:507] global step 39363: loss = 0.1981 (0.977 sec/step)\n",
      "I0902 08:43:39.258709 139792788920128 learning.py:507] global step 39364: loss = 0.0836 (0.968 sec/step)\n",
      "I0902 08:43:40.235113 139792788920128 learning.py:507] global step 39365: loss = 0.0805 (0.975 sec/step)\n",
      "I0902 08:43:41.198634 139792788920128 learning.py:507] global step 39366: loss = 0.2446 (0.962 sec/step)\n",
      "I0902 08:43:42.168722 139792788920128 learning.py:507] global step 39367: loss = 0.0687 (0.968 sec/step)\n",
      "I0902 08:43:43.124730 139792788920128 learning.py:507] global step 39368: loss = 0.2346 (0.954 sec/step)\n",
      "I0902 08:43:44.086519 139792788920128 learning.py:507] global step 39369: loss = 0.0786 (0.960 sec/step)\n",
      "I0902 08:43:45.057057 139792788920128 learning.py:507] global step 39370: loss = 0.0700 (0.969 sec/step)\n",
      "I0902 08:43:46.024496 139792788920128 learning.py:507] global step 39371: loss = 0.1022 (0.966 sec/step)\n",
      "I0902 08:43:46.973436 139792788920128 learning.py:507] global step 39372: loss = 0.3289 (0.947 sec/step)\n",
      "I0902 08:43:47.939763 139792788920128 learning.py:507] global step 39373: loss = 0.1396 (0.965 sec/step)\n",
      "I0902 08:43:48.902688 139792788920128 learning.py:507] global step 39374: loss = 0.0648 (0.961 sec/step)\n",
      "I0902 08:43:49.270360 139778953570048 supervisor.py:1117] Saving checkpoint to path data_dir/mixed_experiment/checkpoints_v2/model.ckpt\n",
      "I0902 08:43:50.321132 139792788920128 learning.py:507] global step 39375: loss = 0.0796 (1.209 sec/step)\n",
      "I0902 08:43:50.321929 139778936784640 supervisor.py:1050] Recording summary at step 39375.\n",
      "I0902 08:43:51.297426 139792788920128 learning.py:507] global step 39376: loss = 0.0994 (0.965 sec/step)\n",
      "I0902 08:43:52.268730 139792788920128 learning.py:507] global step 39377: loss = 0.1813 (0.970 sec/step)\n",
      "I0902 08:43:53.256496 139792788920128 learning.py:507] global step 39378: loss = 0.0615 (0.986 sec/step)\n",
      "I0902 08:43:54.207139 139792788920128 learning.py:507] global step 39379: loss = 0.0533 (0.949 sec/step)\n",
      "I0902 08:43:55.176235 139792788920128 learning.py:507] global step 39380: loss = 0.1837 (0.967 sec/step)\n",
      "I0902 08:43:56.134939 139792788920128 learning.py:507] global step 39381: loss = 0.0719 (0.957 sec/step)\n",
      "I0902 08:43:57.078480 139792788920128 learning.py:507] global step 39382: loss = 0.2341 (0.942 sec/step)\n",
      "I0902 08:43:58.048295 139792788920128 learning.py:507] global step 39383: loss = 0.0535 (0.968 sec/step)\n",
      "I0902 08:43:59.019038 139792788920128 learning.py:507] global step 39384: loss = 0.0990 (0.969 sec/step)\n",
      "I0902 08:43:59.983322 139792788920128 learning.py:507] global step 39385: loss = 0.2219 (0.963 sec/step)\n",
      "I0902 08:44:00.958523 139792788920128 learning.py:507] global step 39386: loss = 0.0500 (0.973 sec/step)\n",
      "I0902 08:44:01.931797 139792788920128 learning.py:507] global step 39387: loss = 0.0611 (0.972 sec/step)\n",
      "I0902 08:44:02.897801 139792788920128 learning.py:507] global step 39388: loss = 0.0786 (0.964 sec/step)\n",
      "I0902 08:44:03.861488 139792788920128 learning.py:507] global step 39389: loss = 0.0770 (0.962 sec/step)\n",
      "I0902 08:44:04.819459 139792788920128 learning.py:507] global step 39390: loss = 0.0892 (0.956 sec/step)\n",
      "I0902 08:44:05.805007 139792788920128 learning.py:507] global step 39391: loss = 0.1186 (0.984 sec/step)\n",
      "I0902 08:44:06.767823 139792788920128 learning.py:507] global step 39392: loss = 0.0828 (0.961 sec/step)\n",
      "I0902 08:44:07.747623 139792788920128 learning.py:507] global step 39393: loss = 0.1317 (0.978 sec/step)\n",
      "I0902 08:44:08.696754 139792788920128 learning.py:507] global step 39394: loss = 0.0964 (0.947 sec/step)\n",
      "I0902 08:44:09.670977 139792788920128 learning.py:507] global step 39395: loss = 0.1041 (0.973 sec/step)\n",
      "I0902 08:44:10.616734 139792788920128 learning.py:507] global step 39396: loss = 0.2178 (0.944 sec/step)\n",
      "I0902 08:44:11.573232 139792788920128 learning.py:507] global step 39397: loss = 0.1436 (0.955 sec/step)\n",
      "I0902 08:44:12.537701 139792788920128 learning.py:507] global step 39398: loss = 0.2358 (0.963 sec/step)\n",
      "I0902 08:44:13.503547 139792788920128 learning.py:507] global step 39399: loss = 0.1366 (0.964 sec/step)\n",
      "I0902 08:44:14.471304 139792788920128 learning.py:507] global step 39400: loss = 0.1397 (0.966 sec/step)\n",
      "I0902 08:44:15.439411 139792788920128 learning.py:507] global step 39401: loss = 0.0760 (0.967 sec/step)\n",
      "I0902 08:44:16.387550 139792788920128 learning.py:507] global step 39402: loss = 0.1943 (0.946 sec/step)\n",
      "I0902 08:44:17.360109 139792788920128 learning.py:507] global step 39403: loss = 0.1346 (0.971 sec/step)\n",
      "I0902 08:44:18.370349 139792788920128 learning.py:507] global step 39404: loss = 0.0920 (1.008 sec/step)\n",
      "I0902 08:44:19.369793 139792788920128 learning.py:507] global step 39405: loss = 0.0850 (0.998 sec/step)\n",
      "I0902 08:44:20.338993 139792788920128 learning.py:507] global step 39406: loss = 0.0828 (0.968 sec/step)\n",
      "I0902 08:44:21.295998 139792788920128 learning.py:507] global step 39407: loss = 0.1594 (0.955 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:44:22.271477 139792788920128 learning.py:507] global step 39408: loss = 0.1630 (0.974 sec/step)\n",
      "I0902 08:44:23.248361 139792788920128 learning.py:507] global step 39409: loss = 0.0908 (0.975 sec/step)\n",
      "I0902 08:44:24.224767 139792788920128 learning.py:507] global step 39410: loss = 0.1308 (0.975 sec/step)\n",
      "I0902 08:44:25.206707 139792788920128 learning.py:507] global step 39411: loss = 0.1957 (0.980 sec/step)\n",
      "I0902 08:44:26.168544 139792788920128 learning.py:507] global step 39412: loss = 0.1450 (0.960 sec/step)\n",
      "I0902 08:44:27.128298 139792788920128 learning.py:507] global step 39413: loss = 0.0834 (0.958 sec/step)\n",
      "I0902 08:44:28.107834 139792788920128 learning.py:507] global step 39414: loss = 0.0704 (0.978 sec/step)\n",
      "I0902 08:44:29.077160 139792788920128 learning.py:507] global step 39415: loss = 0.1285 (0.968 sec/step)\n",
      "I0902 08:44:30.026614 139792788920128 learning.py:507] global step 39416: loss = 0.0791 (0.948 sec/step)\n",
      "I0902 08:44:31.010826 139792788920128 learning.py:507] global step 39417: loss = 0.1592 (0.982 sec/step)\n",
      "I0902 08:44:31.998992 139792788920128 learning.py:507] global step 39418: loss = 0.1376 (0.987 sec/step)\n",
      "I0902 08:44:32.956421 139792788920128 learning.py:507] global step 39419: loss = 0.0955 (0.956 sec/step)\n",
      "I0902 08:44:33.913836 139792788920128 learning.py:507] global step 39420: loss = 0.0443 (0.956 sec/step)\n",
      "I0902 08:44:34.865464 139792788920128 learning.py:507] global step 39421: loss = 0.1240 (0.950 sec/step)\n",
      "I0902 08:44:35.830806 139792788920128 learning.py:507] global step 39422: loss = 0.1344 (0.964 sec/step)\n",
      "I0902 08:44:36.773209 139792788920128 learning.py:507] global step 39423: loss = 0.0800 (0.941 sec/step)\n",
      "I0902 08:44:37.736277 139792788920128 learning.py:507] global step 39424: loss = 0.0842 (0.961 sec/step)\n",
      "I0902 08:44:38.704595 139792788920128 learning.py:507] global step 39425: loss = 0.0925 (0.967 sec/step)\n",
      "I0902 08:44:39.653870 139792788920128 learning.py:507] global step 39426: loss = 0.0892 (0.948 sec/step)\n",
      "I0902 08:44:40.632264 139792788920128 learning.py:507] global step 39427: loss = 0.0666 (0.977 sec/step)\n",
      "I0902 08:44:41.609702 139792788920128 learning.py:507] global step 39428: loss = 0.2403 (0.976 sec/step)\n",
      "I0902 08:44:42.563867 139792788920128 learning.py:507] global step 39429: loss = 0.1042 (0.953 sec/step)\n",
      "I0902 08:44:43.525403 139792788920128 learning.py:507] global step 39430: loss = 0.0843 (0.960 sec/step)\n",
      "I0902 08:44:44.491811 139792788920128 learning.py:507] global step 39431: loss = 0.0763 (0.965 sec/step)\n",
      "I0902 08:44:45.480229 139792788920128 learning.py:507] global step 39432: loss = 0.1517 (0.987 sec/step)\n",
      "I0902 08:44:46.444804 139792788920128 learning.py:507] global step 39433: loss = 0.0680 (0.963 sec/step)\n",
      "I0902 08:44:47.408256 139792788920128 learning.py:507] global step 39434: loss = 0.1303 (0.962 sec/step)\n",
      "I0902 08:44:48.367362 139792788920128 learning.py:507] global step 39435: loss = 0.1217 (0.957 sec/step)\n",
      "I0902 08:44:49.326390 139792788920128 learning.py:507] global step 39436: loss = 0.0619 (0.957 sec/step)\n",
      "I0902 08:44:50.302885 139792788920128 learning.py:507] global step 39437: loss = 0.0963 (0.975 sec/step)\n",
      "I0902 08:44:51.265154 139792788920128 learning.py:507] global step 39438: loss = 0.1081 (0.961 sec/step)\n",
      "I0902 08:44:52.236614 139792788920128 learning.py:507] global step 39439: loss = 0.1111 (0.970 sec/step)\n",
      "I0902 08:44:53.234596 139792788920128 learning.py:507] global step 39440: loss = 0.1602 (0.996 sec/step)\n",
      "I0902 08:44:54.206099 139792788920128 learning.py:507] global step 39441: loss = 0.1162 (0.970 sec/step)\n",
      "I0902 08:44:55.169824 139792788920128 learning.py:507] global step 39442: loss = 0.0868 (0.962 sec/step)\n",
      "I0902 08:44:56.137695 139792788920128 learning.py:507] global step 39443: loss = 0.1249 (0.966 sec/step)\n",
      "I0902 08:44:57.095696 139792788920128 learning.py:507] global step 39444: loss = 0.0670 (0.956 sec/step)\n",
      "I0902 08:44:58.068169 139792788920128 learning.py:507] global step 39445: loss = 0.1167 (0.971 sec/step)\n",
      "I0902 08:44:59.032411 139792788920128 learning.py:507] global step 39446: loss = 0.0718 (0.963 sec/step)\n",
      "I0902 08:45:00.020638 139792788920128 learning.py:507] global step 39447: loss = 0.1103 (0.986 sec/step)\n",
      "I0902 08:45:01.002760 139792788920128 learning.py:507] global step 39448: loss = 0.4814 (0.980 sec/step)\n",
      "I0902 08:45:01.983410 139792788920128 learning.py:507] global step 39449: loss = 0.1391 (0.979 sec/step)\n",
      "I0902 08:45:02.967945 139792788920128 learning.py:507] global step 39450: loss = 0.1278 (0.983 sec/step)\n",
      "I0902 08:45:03.945919 139792788920128 learning.py:507] global step 39451: loss = 0.3061 (0.976 sec/step)\n",
      "I0902 08:45:04.905375 139792788920128 learning.py:507] global step 39452: loss = 0.0749 (0.958 sec/step)\n",
      "I0902 08:45:05.880958 139792788920128 learning.py:507] global step 39453: loss = 0.1482 (0.974 sec/step)\n",
      "I0902 08:45:06.830685 139792788920128 learning.py:507] global step 39454: loss = 0.0906 (0.948 sec/step)\n",
      "I0902 08:45:07.790646 139792788920128 learning.py:507] global step 39455: loss = 0.1353 (0.958 sec/step)\n",
      "I0902 08:45:08.752485 139792788920128 learning.py:507] global step 39456: loss = 0.1194 (0.960 sec/step)\n",
      "I0902 08:45:09.735542 139792788920128 learning.py:507] global step 39457: loss = 0.2013 (0.981 sec/step)\n",
      "I0902 08:45:10.700600 139792788920128 learning.py:507] global step 39458: loss = 0.0985 (0.963 sec/step)\n",
      "I0902 08:45:11.680463 139792788920128 learning.py:507] global step 39459: loss = 0.1409 (0.978 sec/step)\n",
      "I0902 08:45:13.103477 139792788920128 learning.py:507] global step 39460: loss = 0.1728 (1.421 sec/step)\n",
      "I0902 08:45:14.066743 139792788920128 learning.py:507] global step 39461: loss = 0.1279 (0.962 sec/step)\n",
      "I0902 08:45:15.025235 139792788920128 learning.py:507] global step 39462: loss = 0.0721 (0.957 sec/step)\n",
      "I0902 08:45:15.977231 139792788920128 learning.py:507] global step 39463: loss = 0.0956 (0.950 sec/step)\n",
      "I0902 08:45:16.961706 139792788920128 learning.py:507] global step 39464: loss = 0.0611 (0.983 sec/step)\n",
      "I0902 08:45:17.931477 139792788920128 learning.py:507] global step 39465: loss = 0.2411 (0.968 sec/step)\n",
      "I0902 08:45:18.927766 139792788920128 learning.py:507] global step 39466: loss = 0.1404 (0.995 sec/step)\n",
      "I0902 08:45:19.905207 139792788920128 learning.py:507] global step 39467: loss = 0.0810 (0.976 sec/step)\n",
      "I0902 08:45:20.892254 139792788920128 learning.py:507] global step 39468: loss = 0.0978 (0.985 sec/step)\n",
      "I0902 08:45:21.854438 139792788920128 learning.py:507] global step 39469: loss = 0.1694 (0.960 sec/step)\n",
      "I0902 08:45:22.841980 139792788920128 learning.py:507] global step 39470: loss = 0.1438 (0.986 sec/step)\n",
      "I0902 08:45:23.820832 139792788920128 learning.py:507] global step 39471: loss = 0.1388 (0.977 sec/step)\n",
      "I0902 08:45:24.800065 139792788920128 learning.py:507] global step 39472: loss = 0.0805 (0.978 sec/step)\n",
      "I0902 08:45:25.737912 139792788920128 learning.py:507] global step 39473: loss = 0.0639 (0.936 sec/step)\n",
      "I0902 08:45:26.709188 139792788920128 learning.py:507] global step 39474: loss = 0.1115 (0.970 sec/step)\n",
      "I0902 08:45:27.683464 139792788920128 learning.py:507] global step 39475: loss = 0.1264 (0.973 sec/step)\n",
      "I0902 08:45:28.644302 139792788920128 learning.py:507] global step 39476: loss = 0.1009 (0.959 sec/step)\n",
      "I0902 08:45:29.604299 139792788920128 learning.py:507] global step 39477: loss = 0.2533 (0.959 sec/step)\n",
      "I0902 08:45:30.564823 139792788920128 learning.py:507] global step 39478: loss = 0.2510 (0.959 sec/step)\n",
      "I0902 08:45:31.540359 139792788920128 learning.py:507] global step 39479: loss = 0.0617 (0.974 sec/step)\n",
      "I0902 08:45:32.525497 139792788920128 learning.py:507] global step 39480: loss = 0.1068 (0.983 sec/step)\n",
      "I0902 08:45:33.499047 139792788920128 learning.py:507] global step 39481: loss = 0.1844 (0.972 sec/step)\n",
      "I0902 08:45:34.461613 139792788920128 learning.py:507] global step 39482: loss = 0.1355 (0.961 sec/step)\n",
      "I0902 08:45:35.417569 139792788920128 learning.py:507] global step 39483: loss = 0.1416 (0.954 sec/step)\n",
      "I0902 08:45:36.388739 139792788920128 learning.py:507] global step 39484: loss = 0.0851 (0.969 sec/step)\n",
      "I0902 08:45:37.347217 139792788920128 learning.py:507] global step 39485: loss = 0.0909 (0.957 sec/step)\n",
      "I0902 08:45:38.314376 139792788920128 learning.py:507] global step 39486: loss = 0.2239 (0.966 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:45:39.308157 139792788920128 learning.py:507] global step 39487: loss = 0.0919 (0.992 sec/step)\n",
      "I0902 08:45:40.257942 139792788920128 learning.py:507] global step 39488: loss = 0.1707 (0.948 sec/step)\n",
      "I0902 08:45:41.224021 139792788920128 learning.py:507] global step 39489: loss = 0.1571 (0.964 sec/step)\n",
      "I0902 08:45:42.202538 139792788920128 learning.py:507] global step 39490: loss = 0.1275 (0.977 sec/step)\n",
      "I0902 08:45:43.189046 139792788920128 learning.py:507] global step 39491: loss = 0.0992 (0.985 sec/step)\n",
      "I0902 08:45:44.159671 139792788920128 learning.py:507] global step 39492: loss = 0.1145 (0.969 sec/step)\n",
      "I0902 08:45:45.161142 139792788920128 learning.py:507] global step 39493: loss = 0.1032 (1.000 sec/step)\n",
      "I0902 08:45:46.186144 139792788920128 learning.py:507] global step 39494: loss = 0.3582 (1.023 sec/step)\n",
      "I0902 08:45:47.165417 139792788920128 learning.py:507] global step 39495: loss = 0.0815 (0.978 sec/step)\n",
      "I0902 08:45:48.138155 139792788920128 learning.py:507] global step 39496: loss = 0.1985 (0.971 sec/step)\n",
      "I0902 08:45:49.104885 139792788920128 learning.py:507] global step 39497: loss = 0.1096 (0.965 sec/step)\n",
      "I0902 08:45:50.224662 139792788920128 learning.py:507] global step 39498: loss = 0.1768 (1.117 sec/step)\n",
      "I0902 08:45:50.518181 139778936784640 supervisor.py:1050] Recording summary at step 39498.\n",
      "I0902 08:45:51.284349 139792788920128 learning.py:507] global step 39499: loss = 0.1154 (1.057 sec/step)\n",
      "I0902 08:45:52.242803 139792788920128 learning.py:507] global step 39500: loss = 0.1366 (0.957 sec/step)\n",
      "I0902 08:45:53.216246 139792788920128 learning.py:507] global step 39501: loss = 0.1594 (0.972 sec/step)\n",
      "I0902 08:45:54.179361 139792788920128 learning.py:507] global step 39502: loss = 0.2139 (0.962 sec/step)\n",
      "I0902 08:45:55.154329 139792788920128 learning.py:507] global step 39503: loss = 0.1061 (0.973 sec/step)\n",
      "I0902 08:45:56.139236 139792788920128 learning.py:507] global step 39504: loss = 0.1615 (0.983 sec/step)\n",
      "I0902 08:45:57.107290 139792788920128 learning.py:507] global step 39505: loss = 0.1041 (0.966 sec/step)\n",
      "I0902 08:45:58.079677 139792788920128 learning.py:507] global step 39506: loss = 0.1552 (0.971 sec/step)\n",
      "I0902 08:45:59.066769 139792788920128 learning.py:507] global step 39507: loss = 0.0794 (0.985 sec/step)\n",
      "I0902 08:46:00.047491 139792788920128 learning.py:507] global step 39508: loss = 0.0741 (0.979 sec/step)\n",
      "I0902 08:46:01.007457 139792788920128 learning.py:507] global step 39509: loss = 0.3180 (0.958 sec/step)\n",
      "I0902 08:46:01.991779 139792788920128 learning.py:507] global step 39510: loss = 0.1270 (0.983 sec/step)\n",
      "I0902 08:46:02.960495 139792788920128 learning.py:507] global step 39511: loss = 0.0992 (0.967 sec/step)\n",
      "I0902 08:46:03.947448 139792788920128 learning.py:507] global step 39512: loss = 0.1225 (0.985 sec/step)\n",
      "I0902 08:46:04.912284 139792788920128 learning.py:507] global step 39513: loss = 0.1674 (0.963 sec/step)\n",
      "I0902 08:46:05.890521 139792788920128 learning.py:507] global step 39514: loss = 0.0737 (0.976 sec/step)\n",
      "I0902 08:46:06.888592 139792788920128 learning.py:507] global step 39515: loss = 0.1674 (0.996 sec/step)\n",
      "I0902 08:46:07.878037 139792788920128 learning.py:507] global step 39516: loss = 0.1024 (0.988 sec/step)\n",
      "I0902 08:46:08.872838 139792788920128 learning.py:507] global step 39517: loss = 0.0997 (0.993 sec/step)\n",
      "I0902 08:46:09.861631 139792788920128 learning.py:507] global step 39518: loss = 0.3255 (0.987 sec/step)\n",
      "I0902 08:46:10.828768 139792788920128 learning.py:507] global step 39519: loss = 0.1904 (0.966 sec/step)\n",
      "I0902 08:46:11.789403 139792788920128 learning.py:507] global step 39520: loss = 0.0879 (0.959 sec/step)\n",
      "I0902 08:46:12.750234 139792788920128 learning.py:507] global step 39521: loss = 0.0860 (0.959 sec/step)\n",
      "I0902 08:46:13.719044 139792788920128 learning.py:507] global step 39522: loss = 0.0526 (0.967 sec/step)\n",
      "I0902 08:46:14.694519 139792788920128 learning.py:507] global step 39523: loss = 0.1493 (0.974 sec/step)\n",
      "I0902 08:46:15.649970 139792788920128 learning.py:507] global step 39524: loss = 0.1260 (0.954 sec/step)\n",
      "I0902 08:46:16.638834 139792788920128 learning.py:507] global step 39525: loss = 0.1854 (0.987 sec/step)\n",
      "I0902 08:46:17.601640 139792788920128 learning.py:507] global step 39526: loss = 0.0905 (0.961 sec/step)\n",
      "I0902 08:46:18.591564 139792788920128 learning.py:507] global step 39527: loss = 0.1383 (0.988 sec/step)\n",
      "I0902 08:46:19.579485 139792788920128 learning.py:507] global step 39528: loss = 0.1186 (0.986 sec/step)\n",
      "I0902 08:46:20.565596 139792788920128 learning.py:507] global step 39529: loss = 0.1913 (0.984 sec/step)\n",
      "I0902 08:46:21.537505 139792788920128 learning.py:507] global step 39530: loss = 0.0954 (0.970 sec/step)\n",
      "I0902 08:46:22.521049 139792788920128 learning.py:507] global step 39531: loss = 0.1610 (0.982 sec/step)\n",
      "I0902 08:46:23.500521 139792788920128 learning.py:507] global step 39532: loss = 0.1275 (0.978 sec/step)\n",
      "I0902 08:46:24.473828 139792788920128 learning.py:507] global step 39533: loss = 0.1849 (0.972 sec/step)\n",
      "I0902 08:46:25.445819 139792788920128 learning.py:507] global step 39534: loss = 0.1068 (0.970 sec/step)\n",
      "I0902 08:46:26.407770 139792788920128 learning.py:507] global step 39535: loss = 0.0655 (0.960 sec/step)\n",
      "I0902 08:46:27.391691 139792788920128 learning.py:507] global step 39536: loss = 0.1310 (0.982 sec/step)\n",
      "I0902 08:46:28.366163 139792788920128 learning.py:507] global step 39537: loss = 0.1075 (0.973 sec/step)\n",
      "I0902 08:46:29.323595 139792788920128 learning.py:507] global step 39538: loss = 0.1728 (0.956 sec/step)\n",
      "I0902 08:46:30.320915 139792788920128 learning.py:507] global step 39539: loss = 0.0824 (0.996 sec/step)\n",
      "I0902 08:46:31.288364 139792788920128 learning.py:507] global step 39540: loss = 0.1548 (0.966 sec/step)\n",
      "I0902 08:46:32.250607 139792788920128 learning.py:507] global step 39541: loss = 0.1201 (0.961 sec/step)\n",
      "I0902 08:46:33.224308 139792788920128 learning.py:507] global step 39542: loss = 0.1323 (0.972 sec/step)\n",
      "I0902 08:46:34.192782 139792788920128 learning.py:507] global step 39543: loss = 0.1668 (0.967 sec/step)\n",
      "I0902 08:46:35.163135 139792788920128 learning.py:507] global step 39544: loss = 0.2367 (0.969 sec/step)\n",
      "I0902 08:46:36.155917 139792788920128 learning.py:507] global step 39545: loss = 0.1063 (0.991 sec/step)\n",
      "I0902 08:46:37.120551 139792788920128 learning.py:507] global step 39546: loss = 0.1577 (0.963 sec/step)\n",
      "I0902 08:46:38.079255 139792788920128 learning.py:507] global step 39547: loss = 0.0432 (0.957 sec/step)\n",
      "I0902 08:46:39.034097 139792788920128 learning.py:507] global step 39548: loss = 0.0856 (0.953 sec/step)\n",
      "I0902 08:46:40.002192 139792788920128 learning.py:507] global step 39549: loss = 0.0641 (0.967 sec/step)\n",
      "I0902 08:46:40.984325 139792788920128 learning.py:507] global step 39550: loss = 0.1214 (0.980 sec/step)\n",
      "I0902 08:46:41.960906 139792788920128 learning.py:507] global step 39551: loss = 0.0994 (0.975 sec/step)\n",
      "I0902 08:46:42.948552 139792788920128 learning.py:507] global step 39552: loss = 0.1220 (0.986 sec/step)\n",
      "I0902 08:46:43.943338 139792788920128 learning.py:507] global step 39553: loss = 0.2204 (0.993 sec/step)\n",
      "I0902 08:46:44.927384 139792788920128 learning.py:507] global step 39554: loss = 0.1139 (0.982 sec/step)\n",
      "I0902 08:46:45.905041 139792788920128 learning.py:507] global step 39555: loss = 0.0889 (0.976 sec/step)\n",
      "I0902 08:46:46.886526 139792788920128 learning.py:507] global step 39556: loss = 0.1679 (0.980 sec/step)\n",
      "I0902 08:46:47.851718 139792788920128 learning.py:507] global step 39557: loss = 0.1420 (0.964 sec/step)\n",
      "I0902 08:46:48.823930 139792788920128 learning.py:507] global step 39558: loss = 0.0842 (0.971 sec/step)\n",
      "I0902 08:46:49.807418 139792788920128 learning.py:507] global step 39559: loss = 0.0489 (0.982 sec/step)\n",
      "I0902 08:46:50.764760 139792788920128 learning.py:507] global step 39560: loss = 0.0826 (0.956 sec/step)\n",
      "I0902 08:46:51.764064 139792788920128 learning.py:507] global step 39561: loss = 0.2188 (0.998 sec/step)\n",
      "I0902 08:46:52.738052 139792788920128 learning.py:507] global step 39562: loss = 0.1345 (0.972 sec/step)\n",
      "I0902 08:46:53.717478 139792788920128 learning.py:507] global step 39563: loss = 0.2930 (0.978 sec/step)\n",
      "I0902 08:46:54.704918 139792788920128 learning.py:507] global step 39564: loss = 0.1386 (0.986 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:46:55.691308 139792788920128 learning.py:507] global step 39565: loss = 0.0732 (0.985 sec/step)\n",
      "I0902 08:46:56.675919 139792788920128 learning.py:507] global step 39566: loss = 0.0719 (0.983 sec/step)\n",
      "I0902 08:46:57.668508 139792788920128 learning.py:507] global step 39567: loss = 0.0873 (0.991 sec/step)\n",
      "I0902 08:46:58.639994 139792788920128 learning.py:507] global step 39568: loss = 0.1031 (0.970 sec/step)\n",
      "I0902 08:46:59.630497 139792788920128 learning.py:507] global step 39569: loss = 0.1967 (0.989 sec/step)\n",
      "I0902 08:47:00.590849 139792788920128 learning.py:507] global step 39570: loss = 0.1107 (0.959 sec/step)\n",
      "I0902 08:47:01.553205 139792788920128 learning.py:507] global step 39571: loss = 0.1053 (0.961 sec/step)\n",
      "I0902 08:47:02.506943 139792788920128 learning.py:507] global step 39572: loss = 0.1134 (0.952 sec/step)\n",
      "I0902 08:47:03.478171 139792788920128 learning.py:507] global step 39573: loss = 0.0914 (0.970 sec/step)\n",
      "I0902 08:47:04.462255 139792788920128 learning.py:507] global step 39574: loss = 0.1485 (0.983 sec/step)\n",
      "I0902 08:47:05.458477 139792788920128 learning.py:507] global step 39575: loss = 0.0846 (0.994 sec/step)\n",
      "I0902 08:47:06.456043 139792788920128 learning.py:507] global step 39576: loss = 0.1696 (0.996 sec/step)\n",
      "I0902 08:47:07.443500 139792788920128 learning.py:507] global step 39577: loss = 0.1192 (0.986 sec/step)\n",
      "I0902 08:47:08.415542 139792788920128 learning.py:507] global step 39578: loss = 0.0915 (0.970 sec/step)\n",
      "I0902 08:47:09.382145 139792788920128 learning.py:507] global step 39579: loss = 0.1242 (0.965 sec/step)\n",
      "I0902 08:47:10.384161 139792788920128 learning.py:507] global step 39580: loss = 0.0900 (1.000 sec/step)\n",
      "I0902 08:47:11.363819 139792788920128 learning.py:507] global step 39581: loss = 0.0551 (0.978 sec/step)\n",
      "I0902 08:47:12.351163 139792788920128 learning.py:507] global step 39582: loss = 0.0856 (0.986 sec/step)\n",
      "I0902 08:47:13.310063 139792788920128 learning.py:507] global step 39583: loss = 0.0644 (0.957 sec/step)\n",
      "I0902 08:47:14.278236 139792788920128 learning.py:507] global step 39584: loss = 0.0878 (0.966 sec/step)\n",
      "I0902 08:47:15.236912 139792788920128 learning.py:507] global step 39585: loss = 0.0734 (0.957 sec/step)\n",
      "I0902 08:47:16.197550 139792788920128 learning.py:507] global step 39586: loss = 0.0752 (0.959 sec/step)\n",
      "I0902 08:47:17.170922 139792788920128 learning.py:507] global step 39587: loss = 0.2175 (0.972 sec/step)\n",
      "I0902 08:47:18.169056 139792788920128 learning.py:507] global step 39588: loss = 0.2118 (0.996 sec/step)\n",
      "I0902 08:47:19.138765 139792788920128 learning.py:507] global step 39589: loss = 0.3091 (0.968 sec/step)\n",
      "I0902 08:47:20.111574 139792788920128 learning.py:507] global step 39590: loss = 0.2350 (0.971 sec/step)\n",
      "I0902 08:47:21.077239 139792788920128 learning.py:507] global step 39591: loss = 0.0589 (0.964 sec/step)\n",
      "I0902 08:47:22.053002 139792788920128 learning.py:507] global step 39592: loss = 0.1607 (0.974 sec/step)\n",
      "I0902 08:47:23.004121 139792788920128 learning.py:507] global step 39593: loss = 0.0916 (0.949 sec/step)\n",
      "I0902 08:47:23.978244 139792788920128 learning.py:507] global step 39594: loss = 0.1149 (0.972 sec/step)\n",
      "I0902 08:47:24.954975 139792788920128 learning.py:507] global step 39595: loss = 0.1527 (0.975 sec/step)\n",
      "I0902 08:47:25.940850 139792788920128 learning.py:507] global step 39596: loss = 0.2461 (0.984 sec/step)\n",
      "I0902 08:47:26.919348 139792788920128 learning.py:507] global step 39597: loss = 0.2674 (0.977 sec/step)\n",
      "I0902 08:47:27.917124 139792788920128 learning.py:507] global step 39598: loss = 0.1780 (0.996 sec/step)\n",
      "I0902 08:47:28.877924 139792788920128 learning.py:507] global step 39599: loss = 0.1831 (0.959 sec/step)\n",
      "I0902 08:47:29.855658 139792788920128 learning.py:507] global step 39600: loss = 0.0907 (0.976 sec/step)\n",
      "I0902 08:47:30.862179 139792788920128 learning.py:507] global step 39601: loss = 0.0721 (1.005 sec/step)\n",
      "I0902 08:47:31.841594 139792788920128 learning.py:507] global step 39602: loss = 0.2705 (0.978 sec/step)\n",
      "I0902 08:47:32.817954 139792788920128 learning.py:507] global step 39603: loss = 0.2002 (0.975 sec/step)\n",
      "I0902 08:47:33.801929 139792788920128 learning.py:507] global step 39604: loss = 0.1377 (0.982 sec/step)\n",
      "I0902 08:47:34.777678 139792788920128 learning.py:507] global step 39605: loss = 0.0597 (0.974 sec/step)\n",
      "I0902 08:47:35.780378 139792788920128 learning.py:507] global step 39606: loss = 0.0959 (1.001 sec/step)\n",
      "I0902 08:47:36.771812 139792788920128 learning.py:507] global step 39607: loss = 0.1028 (0.990 sec/step)\n",
      "I0902 08:47:37.747411 139792788920128 learning.py:507] global step 39608: loss = 0.1480 (0.974 sec/step)\n",
      "I0902 08:47:38.725554 139792788920128 learning.py:507] global step 39609: loss = 0.3182 (0.977 sec/step)\n",
      "I0902 08:47:39.712005 139792788920128 learning.py:507] global step 39610: loss = 0.0750 (0.985 sec/step)\n",
      "I0902 08:47:40.688975 139792788920128 learning.py:507] global step 39611: loss = 0.1614 (0.976 sec/step)\n",
      "I0902 08:47:41.665972 139792788920128 learning.py:507] global step 39612: loss = 0.1151 (0.975 sec/step)\n",
      "I0902 08:47:42.659430 139792788920128 learning.py:507] global step 39613: loss = 0.2544 (0.992 sec/step)\n",
      "I0902 08:47:43.655196 139792788920128 learning.py:507] global step 39614: loss = 0.1668 (0.994 sec/step)\n",
      "I0902 08:47:44.636825 139792788920128 learning.py:507] global step 39615: loss = 0.1196 (0.980 sec/step)\n",
      "I0902 08:47:45.586022 139792788920128 learning.py:507] global step 39616: loss = 0.1085 (0.948 sec/step)\n",
      "I0902 08:47:46.552955 139792788920128 learning.py:507] global step 39617: loss = 0.1177 (0.965 sec/step)\n",
      "I0902 08:47:47.528961 139792788920128 learning.py:507] global step 39618: loss = 0.0760 (0.974 sec/step)\n",
      "I0902 08:47:48.492387 139792788920128 learning.py:507] global step 39619: loss = 0.1661 (0.962 sec/step)\n",
      "I0902 08:47:49.462136 139792788920128 learning.py:507] global step 39620: loss = 0.0998 (0.966 sec/step)\n",
      "I0902 08:47:50.086338 139778936784640 supervisor.py:1050] Recording summary at step 39620.\n",
      "I0902 08:47:50.696563 139792788920128 learning.py:507] global step 39621: loss = 0.0844 (1.233 sec/step)\n",
      "I0902 08:47:51.655410 139792788920128 learning.py:507] global step 39622: loss = 0.0759 (0.957 sec/step)\n",
      "I0902 08:47:52.630334 139792788920128 learning.py:507] global step 39623: loss = 0.0707 (0.973 sec/step)\n",
      "I0902 08:47:53.604743 139792788920128 learning.py:507] global step 39624: loss = 0.1153 (0.973 sec/step)\n",
      "I0902 08:47:54.596462 139792788920128 learning.py:507] global step 39625: loss = 0.0902 (0.990 sec/step)\n",
      "I0902 08:47:55.599265 139792788920128 learning.py:507] global step 39626: loss = 0.1160 (1.001 sec/step)\n",
      "I0902 08:47:56.605394 139792788920128 learning.py:507] global step 39627: loss = 0.1234 (1.004 sec/step)\n",
      "I0902 08:47:57.594485 139792788920128 learning.py:507] global step 39628: loss = 0.1102 (0.988 sec/step)\n",
      "I0902 08:47:58.534746 139792788920128 learning.py:507] global step 39629: loss = 0.1034 (0.939 sec/step)\n",
      "I0902 08:47:59.518393 139792788920128 learning.py:507] global step 39630: loss = 0.0866 (0.982 sec/step)\n",
      "I0902 08:48:00.491225 139792788920128 learning.py:507] global step 39631: loss = 0.1008 (0.971 sec/step)\n",
      "I0902 08:48:01.461832 139792788920128 learning.py:507] global step 39632: loss = 0.2532 (0.969 sec/step)\n",
      "I0902 08:48:02.436236 139792788920128 learning.py:507] global step 39633: loss = 0.1558 (0.973 sec/step)\n",
      "I0902 08:48:03.404530 139792788920128 learning.py:507] global step 39634: loss = 0.0971 (0.967 sec/step)\n",
      "I0902 08:48:04.416278 139792788920128 learning.py:507] global step 39635: loss = 0.0836 (1.010 sec/step)\n",
      "I0902 08:48:05.377140 139792788920128 learning.py:507] global step 39636: loss = 0.1284 (0.959 sec/step)\n",
      "I0902 08:48:06.340480 139792788920128 learning.py:507] global step 39637: loss = 0.0814 (0.962 sec/step)\n",
      "I0902 08:48:07.311159 139792788920128 learning.py:507] global step 39638: loss = 0.1938 (0.969 sec/step)\n",
      "I0902 08:48:08.273714 139792788920128 learning.py:507] global step 39639: loss = 0.1691 (0.961 sec/step)\n",
      "I0902 08:48:09.262284 139792788920128 learning.py:507] global step 39640: loss = 0.1281 (0.987 sec/step)\n",
      "I0902 08:48:10.224070 139792788920128 learning.py:507] global step 39641: loss = 0.1526 (0.960 sec/step)\n",
      "I0902 08:48:11.206239 139792788920128 learning.py:507] global step 39642: loss = 0.1242 (0.981 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:48:12.179006 139792788920128 learning.py:507] global step 39643: loss = 0.0918 (0.971 sec/step)\n",
      "I0902 08:48:13.171110 139792788920128 learning.py:507] global step 39644: loss = 0.1408 (0.990 sec/step)\n",
      "I0902 08:48:14.129034 139792788920128 learning.py:507] global step 39645: loss = 0.1133 (0.956 sec/step)\n",
      "I0902 08:48:15.086805 139792788920128 learning.py:507] global step 39646: loss = 0.1742 (0.956 sec/step)\n",
      "I0902 08:48:16.051129 139792788920128 learning.py:507] global step 39647: loss = 0.2705 (0.963 sec/step)\n",
      "I0902 08:48:17.049438 139792788920128 learning.py:507] global step 39648: loss = 0.0746 (0.997 sec/step)\n",
      "I0902 08:48:18.017580 139792788920128 learning.py:507] global step 39649: loss = 0.1065 (0.967 sec/step)\n",
      "I0902 08:48:18.992467 139792788920128 learning.py:507] global step 39650: loss = 0.1006 (0.973 sec/step)\n",
      "I0902 08:48:19.962054 139792788920128 learning.py:507] global step 39651: loss = 0.0714 (0.968 sec/step)\n",
      "I0902 08:48:20.959851 139792788920128 learning.py:507] global step 39652: loss = 0.1223 (0.996 sec/step)\n",
      "I0902 08:48:21.938334 139792788920128 learning.py:507] global step 39653: loss = 0.1944 (0.977 sec/step)\n",
      "I0902 08:48:22.901298 139792788920128 learning.py:507] global step 39654: loss = 0.1766 (0.961 sec/step)\n",
      "I0902 08:48:23.863155 139792788920128 learning.py:507] global step 39655: loss = 0.1691 (0.960 sec/step)\n",
      "I0902 08:48:24.821701 139792788920128 learning.py:507] global step 39656: loss = 0.1336 (0.957 sec/step)\n",
      "I0902 08:48:25.782769 139792788920128 learning.py:507] global step 39657: loss = 0.1101 (0.960 sec/step)\n",
      "I0902 08:48:26.779813 139792788920128 learning.py:507] global step 39658: loss = 0.1320 (0.996 sec/step)\n",
      "I0902 08:48:27.807900 139792788920128 learning.py:507] global step 39659: loss = 0.0716 (1.027 sec/step)\n",
      "I0902 08:48:28.788474 139792788920128 learning.py:507] global step 39660: loss = 0.0776 (0.979 sec/step)\n",
      "I0902 08:48:29.759141 139792788920128 learning.py:507] global step 39661: loss = 0.0999 (0.970 sec/step)\n",
      "I0902 08:48:30.737792 139792788920128 learning.py:507] global step 39662: loss = 0.1186 (0.977 sec/step)\n",
      "I0902 08:48:31.725863 139792788920128 learning.py:507] global step 39663: loss = 0.1474 (0.987 sec/step)\n",
      "I0902 08:48:32.731818 139792788920128 learning.py:507] global step 39664: loss = 0.1083 (1.004 sec/step)\n",
      "I0902 08:48:33.719161 139792788920128 learning.py:507] global step 39665: loss = 0.0980 (0.986 sec/step)\n",
      "I0902 08:48:34.713600 139792788920128 learning.py:507] global step 39666: loss = 0.1761 (0.993 sec/step)\n",
      "I0902 08:48:35.668355 139792788920128 learning.py:507] global step 39667: loss = 0.0641 (0.953 sec/step)\n",
      "I0902 08:48:36.646210 139792788920128 learning.py:507] global step 39668: loss = 0.2223 (0.976 sec/step)\n",
      "I0902 08:48:37.615454 139792788920128 learning.py:507] global step 39669: loss = 0.1219 (0.968 sec/step)\n",
      "I0902 08:48:38.584153 139792788920128 learning.py:507] global step 39670: loss = 0.0691 (0.967 sec/step)\n",
      "I0902 08:48:39.554534 139792788920128 learning.py:507] global step 39671: loss = 0.1262 (0.969 sec/step)\n",
      "I0902 08:48:40.512655 139792788920128 learning.py:507] global step 39672: loss = 0.1365 (0.956 sec/step)\n",
      "I0902 08:48:41.487211 139792788920128 learning.py:507] global step 39673: loss = 0.1739 (0.973 sec/step)\n",
      "I0902 08:48:42.470751 139792788920128 learning.py:507] global step 39674: loss = 0.0814 (0.982 sec/step)\n",
      "I0902 08:48:43.439100 139792788920128 learning.py:507] global step 39675: loss = 0.1698 (0.967 sec/step)\n",
      "I0902 08:48:44.413764 139792788920128 learning.py:507] global step 39676: loss = 0.2445 (0.973 sec/step)\n",
      "I0902 08:48:45.375083 139792788920128 learning.py:507] global step 39677: loss = 0.0723 (0.960 sec/step)\n",
      "I0902 08:48:46.342797 139792788920128 learning.py:507] global step 39678: loss = 0.1368 (0.966 sec/step)\n",
      "I0902 08:48:47.310580 139792788920128 learning.py:507] global step 39679: loss = 0.0804 (0.966 sec/step)\n",
      "I0902 08:48:48.274467 139792788920128 learning.py:507] global step 39680: loss = 0.0967 (0.962 sec/step)\n",
      "I0902 08:48:49.270196 139792788920128 learning.py:507] global step 39681: loss = 0.0971 (0.994 sec/step)\n",
      "I0902 08:48:50.227890 139792788920128 learning.py:507] global step 39682: loss = 0.1084 (0.956 sec/step)\n",
      "I0902 08:48:51.192154 139792788920128 learning.py:507] global step 39683: loss = 0.0683 (0.962 sec/step)\n",
      "I0902 08:48:52.152770 139792788920128 learning.py:507] global step 39684: loss = 0.1783 (0.959 sec/step)\n",
      "I0902 08:48:53.120380 139792788920128 learning.py:507] global step 39685: loss = 0.1097 (0.966 sec/step)\n",
      "I0902 08:48:54.094364 139792788920128 learning.py:507] global step 39686: loss = 0.0695 (0.972 sec/step)\n",
      "I0902 08:48:55.054116 139792788920128 learning.py:507] global step 39687: loss = 0.1747 (0.958 sec/step)\n",
      "I0902 08:48:56.027155 139792788920128 learning.py:507] global step 39688: loss = 0.0541 (0.971 sec/step)\n",
      "I0902 08:48:56.992771 139792788920128 learning.py:507] global step 39689: loss = 0.1305 (0.964 sec/step)\n",
      "I0902 08:48:57.978477 139792788920128 learning.py:507] global step 39690: loss = 0.1239 (0.984 sec/step)\n",
      "I0902 08:48:58.953884 139792788920128 learning.py:507] global step 39691: loss = 0.0737 (0.974 sec/step)\n",
      "I0902 08:48:59.932381 139792788920128 learning.py:507] global step 39692: loss = 0.1176 (0.977 sec/step)\n",
      "I0902 08:49:00.889000 139792788920128 learning.py:507] global step 39693: loss = 0.0942 (0.955 sec/step)\n",
      "I0902 08:49:01.878673 139792788920128 learning.py:507] global step 39694: loss = 0.1082 (0.988 sec/step)\n",
      "I0902 08:49:02.849453 139792788920128 learning.py:507] global step 39695: loss = 0.1011 (0.969 sec/step)\n",
      "I0902 08:49:03.820051 139792788920128 learning.py:507] global step 39696: loss = 0.0813 (0.969 sec/step)\n",
      "I0902 08:49:04.809806 139792788920128 learning.py:507] global step 39697: loss = 0.1099 (0.988 sec/step)\n",
      "I0902 08:49:05.782805 139792788920128 learning.py:507] global step 39698: loss = 0.1067 (0.971 sec/step)\n",
      "I0902 08:49:06.735506 139792788920128 learning.py:507] global step 39699: loss = 0.1290 (0.951 sec/step)\n",
      "I0902 08:49:07.700674 139792788920128 learning.py:507] global step 39700: loss = 0.0688 (0.964 sec/step)\n",
      "I0902 08:49:08.688873 139792788920128 learning.py:507] global step 39701: loss = 0.1206 (0.986 sec/step)\n",
      "I0902 08:49:09.658409 139792788920128 learning.py:507] global step 39702: loss = 0.0768 (0.968 sec/step)\n",
      "I0902 08:49:10.622946 139792788920128 learning.py:507] global step 39703: loss = 0.0741 (0.963 sec/step)\n",
      "I0902 08:49:11.594686 139792788920128 learning.py:507] global step 39704: loss = 0.1315 (0.970 sec/step)\n",
      "I0902 08:49:12.576220 139792788920128 learning.py:507] global step 39705: loss = 0.1970 (0.980 sec/step)\n",
      "I0902 08:49:13.540355 139792788920128 learning.py:507] global step 39706: loss = 0.2483 (0.962 sec/step)\n",
      "I0902 08:49:14.502482 139792788920128 learning.py:507] global step 39707: loss = 0.1177 (0.960 sec/step)\n",
      "I0902 08:49:15.480367 139792788920128 learning.py:507] global step 39708: loss = 0.1745 (0.976 sec/step)\n",
      "I0902 08:49:16.463774 139792788920128 learning.py:507] global step 39709: loss = 0.1790 (0.982 sec/step)\n",
      "I0902 08:49:17.433128 139792788920128 learning.py:507] global step 39710: loss = 0.1442 (0.967 sec/step)\n",
      "I0902 08:49:18.415000 139792788920128 learning.py:507] global step 39711: loss = 0.0789 (0.980 sec/step)\n",
      "I0902 08:49:19.372158 139792788920128 learning.py:507] global step 39712: loss = 0.0736 (0.956 sec/step)\n",
      "I0902 08:49:20.352309 139792788920128 learning.py:507] global step 39713: loss = 0.0932 (0.979 sec/step)\n",
      "I0902 08:49:21.320647 139792788920128 learning.py:507] global step 39714: loss = 0.1516 (0.967 sec/step)\n",
      "I0902 08:49:22.269548 139792788920128 learning.py:507] global step 39715: loss = 0.0862 (0.947 sec/step)\n",
      "I0902 08:49:23.243950 139792788920128 learning.py:507] global step 39716: loss = 0.0831 (0.973 sec/step)\n",
      "I0902 08:49:24.240016 139792788920128 learning.py:507] global step 39717: loss = 0.0761 (0.995 sec/step)\n",
      "I0902 08:49:25.392772 139792788920128 learning.py:507] global step 39718: loss = 0.1628 (1.151 sec/step)\n",
      "I0902 08:49:26.355479 139792788920128 learning.py:507] global step 39719: loss = 0.1984 (0.961 sec/step)\n",
      "I0902 08:49:27.334067 139792788920128 learning.py:507] global step 39720: loss = 0.1449 (0.977 sec/step)\n",
      "I0902 08:49:28.299054 139792788920128 learning.py:507] global step 39721: loss = 0.1238 (0.963 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:49:29.260600 139792788920128 learning.py:507] global step 39722: loss = 0.1111 (0.960 sec/step)\n",
      "I0902 08:49:30.226165 139792788920128 learning.py:507] global step 39723: loss = 0.0542 (0.964 sec/step)\n",
      "I0902 08:49:31.199560 139792788920128 learning.py:507] global step 39724: loss = 0.0714 (0.972 sec/step)\n",
      "I0902 08:49:32.170661 139792788920128 learning.py:507] global step 39725: loss = 0.0855 (0.969 sec/step)\n",
      "I0902 08:49:33.133118 139792788920128 learning.py:507] global step 39726: loss = 0.1521 (0.961 sec/step)\n",
      "I0902 08:49:34.106012 139792788920128 learning.py:507] global step 39727: loss = 0.1560 (0.971 sec/step)\n",
      "I0902 08:49:35.079149 139792788920128 learning.py:507] global step 39728: loss = 0.1006 (0.971 sec/step)\n",
      "I0902 08:49:36.068504 139792788920128 learning.py:507] global step 39729: loss = 0.0796 (0.988 sec/step)\n",
      "I0902 08:49:37.037041 139792788920128 learning.py:507] global step 39730: loss = 0.0884 (0.967 sec/step)\n",
      "I0902 08:49:38.015673 139792788920128 learning.py:507] global step 39731: loss = 0.0791 (0.977 sec/step)\n",
      "I0902 08:49:38.985629 139792788920128 learning.py:507] global step 39732: loss = 0.1743 (0.968 sec/step)\n",
      "I0902 08:49:39.955540 139792788920128 learning.py:507] global step 39733: loss = 0.1111 (0.968 sec/step)\n",
      "I0902 08:49:40.910919 139792788920128 learning.py:507] global step 39734: loss = 0.1348 (0.954 sec/step)\n",
      "I0902 08:49:41.866029 139792788920128 learning.py:507] global step 39735: loss = 0.2207 (0.953 sec/step)\n",
      "I0902 08:49:42.827531 139792788920128 learning.py:507] global step 39736: loss = 0.0778 (0.960 sec/step)\n",
      "I0902 08:49:43.781931 139792788920128 learning.py:507] global step 39737: loss = 0.1104 (0.953 sec/step)\n",
      "I0902 08:49:44.747714 139792788920128 learning.py:507] global step 39738: loss = 0.0925 (0.964 sec/step)\n",
      "I0902 08:49:45.703316 139792788920128 learning.py:507] global step 39739: loss = 0.0940 (0.954 sec/step)\n",
      "I0902 08:49:46.670567 139792788920128 learning.py:507] global step 39740: loss = 0.1171 (0.966 sec/step)\n",
      "I0902 08:49:47.619333 139792788920128 learning.py:507] global step 39741: loss = 0.1227 (0.947 sec/step)\n",
      "I0902 08:49:48.592232 139792788920128 learning.py:507] global step 39742: loss = 0.1424 (0.971 sec/step)\n",
      "I0902 08:49:49.593007 139792788920128 learning.py:507] global step 39743: loss = 0.1964 (0.992 sec/step)\n",
      "I0902 08:49:50.241090 139778936784640 supervisor.py:1050] Recording summary at step 39743.\n",
      "I0902 08:49:50.836883 139792788920128 learning.py:507] global step 39744: loss = 0.0739 (1.241 sec/step)\n",
      "I0902 08:49:51.807685 139792788920128 learning.py:507] global step 39745: loss = 0.0854 (0.969 sec/step)\n",
      "I0902 08:49:52.766149 139792788920128 learning.py:507] global step 39746: loss = 0.0997 (0.957 sec/step)\n",
      "I0902 08:49:53.726269 139792788920128 learning.py:507] global step 39747: loss = 0.0752 (0.958 sec/step)\n",
      "I0902 08:49:54.703946 139792788920128 learning.py:507] global step 39748: loss = 0.1078 (0.976 sec/step)\n",
      "I0902 08:49:55.681272 139792788920128 learning.py:507] global step 39749: loss = 0.0851 (0.976 sec/step)\n",
      "I0902 08:49:56.645267 139792788920128 learning.py:507] global step 39750: loss = 0.0852 (0.962 sec/step)\n",
      "I0902 08:49:57.610720 139792788920128 learning.py:507] global step 39751: loss = 0.1179 (0.964 sec/step)\n",
      "I0902 08:49:58.579456 139792788920128 learning.py:507] global step 39752: loss = 0.1033 (0.967 sec/step)\n",
      "I0902 08:49:59.537787 139792788920128 learning.py:507] global step 39753: loss = 0.2357 (0.957 sec/step)\n",
      "I0902 08:50:00.504717 139792788920128 learning.py:507] global step 39754: loss = 0.1085 (0.965 sec/step)\n",
      "I0902 08:50:01.489288 139792788920128 learning.py:507] global step 39755: loss = 0.0891 (0.983 sec/step)\n",
      "I0902 08:50:02.452909 139792788920128 learning.py:507] global step 39756: loss = 0.3427 (0.962 sec/step)\n",
      "I0902 08:50:03.432725 139792788920128 learning.py:507] global step 39757: loss = 0.1071 (0.978 sec/step)\n",
      "I0902 08:50:04.390549 139792788920128 learning.py:507] global step 39758: loss = 0.1023 (0.956 sec/step)\n",
      "I0902 08:50:05.364973 139792788920128 learning.py:507] global step 39759: loss = 0.1073 (0.973 sec/step)\n",
      "I0902 08:50:06.329500 139792788920128 learning.py:507] global step 39760: loss = 0.0941 (0.963 sec/step)\n",
      "I0902 08:50:07.303525 139792788920128 learning.py:507] global step 39761: loss = 0.1418 (0.972 sec/step)\n",
      "I0902 08:50:08.261452 139792788920128 learning.py:507] global step 39762: loss = 0.0943 (0.956 sec/step)\n",
      "I0902 08:50:09.234424 139792788920128 learning.py:507] global step 39763: loss = 0.0914 (0.971 sec/step)\n",
      "I0902 08:50:10.206003 139792788920128 learning.py:507] global step 39764: loss = 0.1076 (0.970 sec/step)\n",
      "I0902 08:50:11.181315 139792788920128 learning.py:507] global step 39765: loss = 0.0613 (0.974 sec/step)\n",
      "I0902 08:50:12.141665 139792788920128 learning.py:507] global step 39766: loss = 0.1261 (0.959 sec/step)\n",
      "I0902 08:50:13.115200 139792788920128 learning.py:507] global step 39767: loss = 0.0651 (0.972 sec/step)\n",
      "I0902 08:50:14.083114 139792788920128 learning.py:507] global step 39768: loss = 0.0810 (0.966 sec/step)\n",
      "I0902 08:50:15.071879 139792788920128 learning.py:507] global step 39769: loss = 0.1475 (0.987 sec/step)\n",
      "I0902 08:50:16.025502 139792788920128 learning.py:507] global step 39770: loss = 0.0888 (0.952 sec/step)\n",
      "I0902 08:50:16.981381 139792788920128 learning.py:507] global step 39771: loss = 0.1755 (0.954 sec/step)\n",
      "I0902 08:50:17.950141 139792788920128 learning.py:507] global step 39772: loss = 0.3233 (0.967 sec/step)\n",
      "I0902 08:50:18.917737 139792788920128 learning.py:507] global step 39773: loss = 0.1783 (0.966 sec/step)\n",
      "I0902 08:50:19.885205 139792788920128 learning.py:507] global step 39774: loss = 0.1147 (0.966 sec/step)\n",
      "I0902 08:50:20.862113 139792788920128 learning.py:507] global step 39775: loss = 0.1148 (0.975 sec/step)\n",
      "I0902 08:50:21.831815 139792788920128 learning.py:507] global step 39776: loss = 0.1508 (0.968 sec/step)\n",
      "I0902 08:50:22.806015 139792788920128 learning.py:507] global step 39777: loss = 0.1014 (0.972 sec/step)\n",
      "I0902 08:50:23.766282 139792788920128 learning.py:507] global step 39778: loss = 0.2006 (0.959 sec/step)\n",
      "I0902 08:50:24.736793 139792788920128 learning.py:507] global step 39779: loss = 0.1154 (0.969 sec/step)\n",
      "I0902 08:50:25.711298 139792788920128 learning.py:507] global step 39780: loss = 0.0709 (0.973 sec/step)\n",
      "I0902 08:50:26.678753 139792788920128 learning.py:507] global step 39781: loss = 0.0780 (0.966 sec/step)\n",
      "I0902 08:50:27.636241 139792788920128 learning.py:507] global step 39782: loss = 0.0687 (0.956 sec/step)\n",
      "I0902 08:50:28.601926 139792788920128 learning.py:507] global step 39783: loss = 0.1243 (0.964 sec/step)\n",
      "I0902 08:50:29.550157 139792788920128 learning.py:507] global step 39784: loss = 0.0965 (0.947 sec/step)\n",
      "I0902 08:50:30.509129 139792788920128 learning.py:507] global step 39785: loss = 0.0765 (0.957 sec/step)\n",
      "I0902 08:50:31.463829 139792788920128 learning.py:507] global step 39786: loss = 0.1001 (0.953 sec/step)\n",
      "I0902 08:50:32.432280 139792788920128 learning.py:507] global step 39787: loss = 0.1043 (0.967 sec/step)\n",
      "I0902 08:50:33.406065 139792788920128 learning.py:507] global step 39788: loss = 0.1591 (0.972 sec/step)\n",
      "I0902 08:50:34.374926 139792788920128 learning.py:507] global step 39789: loss = 0.0708 (0.967 sec/step)\n",
      "I0902 08:50:35.359348 139792788920128 learning.py:507] global step 39790: loss = 0.0921 (0.983 sec/step)\n",
      "I0902 08:50:36.314556 139792788920128 learning.py:507] global step 39791: loss = 0.1296 (0.954 sec/step)\n",
      "I0902 08:50:37.289383 139792788920128 learning.py:507] global step 39792: loss = 0.1321 (0.973 sec/step)\n",
      "I0902 08:50:38.280781 139792788920128 learning.py:507] global step 39793: loss = 0.1182 (0.990 sec/step)\n",
      "I0902 08:50:39.250505 139792788920128 learning.py:507] global step 39794: loss = 0.1479 (0.968 sec/step)\n",
      "I0902 08:50:40.217908 139792788920128 learning.py:507] global step 39795: loss = 0.1018 (0.966 sec/step)\n",
      "I0902 08:50:41.195821 139792788920128 learning.py:507] global step 39796: loss = 0.0874 (0.976 sec/step)\n",
      "I0902 08:50:42.156411 139792788920128 learning.py:507] global step 39797: loss = 0.0515 (0.959 sec/step)\n",
      "I0902 08:50:43.115040 139792788920128 learning.py:507] global step 39798: loss = 0.2415 (0.957 sec/step)\n",
      "I0902 08:50:44.087802 139792788920128 learning.py:507] global step 39799: loss = 0.1871 (0.971 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:50:45.049906 139792788920128 learning.py:507] global step 39800: loss = 0.1746 (0.960 sec/step)\n",
      "I0902 08:50:46.012555 139792788920128 learning.py:507] global step 39801: loss = 0.0977 (0.961 sec/step)\n",
      "I0902 08:50:46.979607 139792788920128 learning.py:507] global step 39802: loss = 0.1012 (0.966 sec/step)\n",
      "I0902 08:50:47.959385 139792788920128 learning.py:507] global step 39803: loss = 0.2336 (0.978 sec/step)\n",
      "I0902 08:50:48.906665 139792788920128 learning.py:507] global step 39804: loss = 0.1022 (0.946 sec/step)\n",
      "I0902 08:50:49.881370 139792788920128 learning.py:507] global step 39805: loss = 0.1354 (0.973 sec/step)\n",
      "I0902 08:50:50.841400 139792788920128 learning.py:507] global step 39806: loss = 0.0523 (0.958 sec/step)\n",
      "I0902 08:50:51.827435 139792788920128 learning.py:507] global step 39807: loss = 0.0390 (0.984 sec/step)\n",
      "I0902 08:50:52.785336 139792788920128 learning.py:507] global step 39808: loss = 0.0926 (0.956 sec/step)\n",
      "I0902 08:50:53.770813 139792788920128 learning.py:507] global step 39809: loss = 0.1295 (0.984 sec/step)\n",
      "I0902 08:50:54.732339 139792788920128 learning.py:507] global step 39810: loss = 0.2143 (0.960 sec/step)\n",
      "I0902 08:50:55.702596 139792788920128 learning.py:507] global step 39811: loss = 0.0489 (0.969 sec/step)\n",
      "I0902 08:50:56.667254 139792788920128 learning.py:507] global step 39812: loss = 0.1085 (0.963 sec/step)\n",
      "I0902 08:50:57.650845 139792788920128 learning.py:507] global step 39813: loss = 0.0780 (0.982 sec/step)\n",
      "I0902 08:50:58.627573 139792788920128 learning.py:507] global step 39814: loss = 0.1346 (0.975 sec/step)\n",
      "I0902 08:50:59.609291 139792788920128 learning.py:507] global step 39815: loss = 0.0967 (0.980 sec/step)\n",
      "I0902 08:51:00.599950 139792788920128 learning.py:507] global step 39816: loss = 0.3982 (0.989 sec/step)\n",
      "I0902 08:51:01.577108 139792788920128 learning.py:507] global step 39817: loss = 0.0650 (0.975 sec/step)\n",
      "I0902 08:51:02.547540 139792788920128 learning.py:507] global step 39818: loss = 0.0731 (0.969 sec/step)\n",
      "I0902 08:51:03.517905 139792788920128 learning.py:507] global step 39819: loss = 0.1134 (0.969 sec/step)\n",
      "I0902 08:51:04.481517 139792788920128 learning.py:507] global step 39820: loss = 0.1318 (0.962 sec/step)\n",
      "I0902 08:51:05.445756 139792788920128 learning.py:507] global step 39821: loss = 0.0848 (0.963 sec/step)\n",
      "I0902 08:51:06.405427 139792788920128 learning.py:507] global step 39822: loss = 0.1231 (0.958 sec/step)\n",
      "I0902 08:51:07.375557 139792788920128 learning.py:507] global step 39823: loss = 0.1768 (0.969 sec/step)\n",
      "I0902 08:51:08.343457 139792788920128 learning.py:507] global step 39824: loss = 0.1159 (0.966 sec/step)\n",
      "I0902 08:51:09.307237 139792788920128 learning.py:507] global step 39825: loss = 0.1128 (0.962 sec/step)\n",
      "I0902 08:51:10.292664 139792788920128 learning.py:507] global step 39826: loss = 0.1783 (0.984 sec/step)\n",
      "I0902 08:51:11.264698 139792788920128 learning.py:507] global step 39827: loss = 0.0679 (0.970 sec/step)\n",
      "I0902 08:51:12.240706 139792788920128 learning.py:507] global step 39828: loss = 0.0719 (0.974 sec/step)\n",
      "I0902 08:51:13.212167 139792788920128 learning.py:507] global step 39829: loss = 0.1445 (0.970 sec/step)\n",
      "I0902 08:51:14.164852 139792788920128 learning.py:507] global step 39830: loss = 0.0826 (0.951 sec/step)\n",
      "I0902 08:51:15.153367 139792788920128 learning.py:507] global step 39831: loss = 0.0975 (0.987 sec/step)\n",
      "I0902 08:51:16.134682 139792788920128 learning.py:507] global step 39832: loss = 0.0817 (0.980 sec/step)\n",
      "I0902 08:51:17.109384 139792788920128 learning.py:507] global step 39833: loss = 0.1769 (0.973 sec/step)\n",
      "I0902 08:51:18.066202 139792788920128 learning.py:507] global step 39834: loss = 0.1062 (0.955 sec/step)\n",
      "I0902 08:51:19.029944 139792788920128 learning.py:507] global step 39835: loss = 0.0437 (0.962 sec/step)\n",
      "I0902 08:51:20.007854 139792788920128 learning.py:507] global step 39836: loss = 0.0791 (0.976 sec/step)\n",
      "I0902 08:51:20.991075 139792788920128 learning.py:507] global step 39837: loss = 0.1442 (0.981 sec/step)\n",
      "I0902 08:51:21.949871 139792788920128 learning.py:507] global step 39838: loss = 0.1179 (0.957 sec/step)\n",
      "I0902 08:51:22.920252 139792788920128 learning.py:507] global step 39839: loss = 0.1342 (0.969 sec/step)\n",
      "I0902 08:51:23.914216 139792788920128 learning.py:507] global step 39840: loss = 0.1320 (0.992 sec/step)\n",
      "I0902 08:51:24.872547 139792788920128 learning.py:507] global step 39841: loss = 0.1167 (0.957 sec/step)\n",
      "I0902 08:51:25.842141 139792788920128 learning.py:507] global step 39842: loss = 0.1555 (0.968 sec/step)\n",
      "I0902 08:51:26.812072 139792788920128 learning.py:507] global step 39843: loss = 0.2180 (0.968 sec/step)\n",
      "I0902 08:51:27.792247 139792788920128 learning.py:507] global step 39844: loss = 0.0983 (0.979 sec/step)\n",
      "I0902 08:51:28.759469 139792788920128 learning.py:507] global step 39845: loss = 0.2458 (0.966 sec/step)\n",
      "I0902 08:51:29.740378 139792788920128 learning.py:507] global step 39846: loss = 0.0857 (0.979 sec/step)\n",
      "I0902 08:51:30.710656 139792788920128 learning.py:507] global step 39847: loss = 0.0573 (0.969 sec/step)\n",
      "I0902 08:51:31.713413 139792788920128 learning.py:507] global step 39848: loss = 0.0945 (1.001 sec/step)\n",
      "I0902 08:51:32.699627 139792788920128 learning.py:507] global step 39849: loss = 0.1948 (0.985 sec/step)\n",
      "I0902 08:51:33.673872 139792788920128 learning.py:507] global step 39850: loss = 0.0648 (0.973 sec/step)\n",
      "I0902 08:51:34.649794 139792788920128 learning.py:507] global step 39851: loss = 0.1708 (0.974 sec/step)\n",
      "I0902 08:51:35.636724 139792788920128 learning.py:507] global step 39852: loss = 0.1323 (0.985 sec/step)\n",
      "I0902 08:51:36.617232 139792788920128 learning.py:507] global step 39853: loss = 0.0872 (0.979 sec/step)\n",
      "I0902 08:51:37.596992 139792788920128 learning.py:507] global step 39854: loss = 0.1501 (0.978 sec/step)\n",
      "I0902 08:51:38.585036 139792788920128 learning.py:507] global step 39855: loss = 0.0932 (0.986 sec/step)\n",
      "I0902 08:51:39.545255 139792788920128 learning.py:507] global step 39856: loss = 0.1438 (0.959 sec/step)\n",
      "I0902 08:51:40.522086 139792788920128 learning.py:507] global step 39857: loss = 0.0511 (0.975 sec/step)\n",
      "I0902 08:51:41.477612 139792788920128 learning.py:507] global step 39858: loss = 0.1785 (0.954 sec/step)\n",
      "I0902 08:51:42.447574 139792788920128 learning.py:507] global step 39859: loss = 0.0763 (0.968 sec/step)\n",
      "I0902 08:51:43.419502 139792788920128 learning.py:507] global step 39860: loss = 0.0777 (0.970 sec/step)\n",
      "I0902 08:51:44.376457 139792788920128 learning.py:507] global step 39861: loss = 0.0879 (0.955 sec/step)\n",
      "I0902 08:51:45.343496 139792788920128 learning.py:507] global step 39862: loss = 0.1483 (0.966 sec/step)\n",
      "I0902 08:51:46.334609 139792788920128 learning.py:507] global step 39863: loss = 0.1344 (0.990 sec/step)\n",
      "I0902 08:51:47.313389 139792788920128 learning.py:507] global step 39864: loss = 0.3032 (0.977 sec/step)\n",
      "I0902 08:51:48.290210 139792788920128 learning.py:507] global step 39865: loss = 0.1762 (0.975 sec/step)\n",
      "I0902 08:51:49.251934 139792788920128 learning.py:507] global step 39866: loss = 0.1388 (0.960 sec/step)\n",
      "I0902 08:51:49.894652 139778936784640 supervisor.py:1050] Recording summary at step 39866.\n",
      "I0902 08:51:50.505362 139792788920128 learning.py:507] global step 39867: loss = 0.1393 (1.252 sec/step)\n",
      "I0902 08:51:51.480298 139792788920128 learning.py:507] global step 39868: loss = 0.0689 (0.973 sec/step)\n",
      "I0902 08:51:52.443775 139792788920128 learning.py:507] global step 39869: loss = 0.1092 (0.962 sec/step)\n",
      "I0902 08:51:53.427012 139792788920128 learning.py:507] global step 39870: loss = 0.0904 (0.981 sec/step)\n",
      "I0902 08:51:54.389146 139792788920128 learning.py:507] global step 39871: loss = 0.0945 (0.961 sec/step)\n",
      "I0902 08:51:55.338165 139792788920128 learning.py:507] global step 39872: loss = 0.0814 (0.947 sec/step)\n",
      "I0902 08:51:56.292370 139792788920128 learning.py:507] global step 39873: loss = 0.1398 (0.953 sec/step)\n",
      "I0902 08:51:57.266915 139792788920128 learning.py:507] global step 39874: loss = 0.1931 (0.973 sec/step)\n",
      "I0902 08:51:58.212399 139792788920128 learning.py:507] global step 39875: loss = 0.0497 (0.944 sec/step)\n",
      "I0902 08:51:59.169691 139792788920128 learning.py:507] global step 39876: loss = 0.3960 (0.956 sec/step)\n",
      "I0902 08:52:00.168587 139792788920128 learning.py:507] global step 39877: loss = 0.1036 (0.997 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:52:01.145137 139792788920128 learning.py:507] global step 39878: loss = 0.1048 (0.975 sec/step)\n",
      "I0902 08:52:02.106641 139792788920128 learning.py:507] global step 39879: loss = 0.1690 (0.960 sec/step)\n",
      "I0902 08:52:03.070688 139792788920128 learning.py:507] global step 39880: loss = 0.0998 (0.963 sec/step)\n",
      "I0902 08:52:04.045207 139792788920128 learning.py:507] global step 39881: loss = 0.1185 (0.973 sec/step)\n",
      "I0902 08:52:05.008790 139792788920128 learning.py:507] global step 39882: loss = 0.1683 (0.962 sec/step)\n",
      "I0902 08:52:05.989576 139792788920128 learning.py:507] global step 39883: loss = 0.1053 (0.979 sec/step)\n",
      "I0902 08:52:06.948523 139792788920128 learning.py:507] global step 39884: loss = 0.0559 (0.957 sec/step)\n",
      "I0902 08:52:07.913598 139792788920128 learning.py:507] global step 39885: loss = 0.1721 (0.963 sec/step)\n",
      "I0902 08:52:08.886840 139792788920128 learning.py:507] global step 39886: loss = 0.0581 (0.972 sec/step)\n",
      "I0902 08:52:09.849204 139792788920128 learning.py:507] global step 39887: loss = 0.0773 (0.961 sec/step)\n",
      "I0902 08:52:10.821978 139792788920128 learning.py:507] global step 39888: loss = 0.0726 (0.971 sec/step)\n",
      "I0902 08:52:11.796750 139792788920128 learning.py:507] global step 39889: loss = 0.1647 (0.973 sec/step)\n",
      "I0902 08:52:12.765881 139792788920128 learning.py:507] global step 39890: loss = 0.1519 (0.968 sec/step)\n",
      "I0902 08:52:13.735123 139792788920128 learning.py:507] global step 39891: loss = 0.1640 (0.968 sec/step)\n",
      "I0902 08:52:14.689623 139792788920128 learning.py:507] global step 39892: loss = 0.0801 (0.953 sec/step)\n",
      "I0902 08:52:15.639698 139792788920128 learning.py:507] global step 39893: loss = 0.0866 (0.949 sec/step)\n",
      "I0902 08:52:16.609446 139792788920128 learning.py:507] global step 39894: loss = 0.1529 (0.968 sec/step)\n",
      "I0902 08:52:17.568167 139792788920128 learning.py:507] global step 39895: loss = 0.1007 (0.957 sec/step)\n",
      "I0902 08:52:18.544595 139792788920128 learning.py:507] global step 39896: loss = 0.1168 (0.975 sec/step)\n",
      "I0902 08:52:19.510973 139792788920128 learning.py:507] global step 39897: loss = 0.1412 (0.965 sec/step)\n",
      "I0902 08:52:20.482625 139792788920128 learning.py:507] global step 39898: loss = 0.0907 (0.970 sec/step)\n",
      "I0902 08:52:21.442464 139792788920128 learning.py:507] global step 39899: loss = 0.1343 (0.958 sec/step)\n",
      "I0902 08:52:22.394220 139792788920128 learning.py:507] global step 39900: loss = 0.1096 (0.950 sec/step)\n",
      "I0902 08:52:23.369103 139792788920128 learning.py:507] global step 39901: loss = 0.1170 (0.973 sec/step)\n",
      "I0902 08:52:24.316288 139792788920128 learning.py:507] global step 39902: loss = 0.0634 (0.946 sec/step)\n",
      "I0902 08:52:25.278755 139792788920128 learning.py:507] global step 39903: loss = 0.1278 (0.961 sec/step)\n",
      "I0902 08:52:26.244328 139792788920128 learning.py:507] global step 39904: loss = 0.2187 (0.964 sec/step)\n",
      "I0902 08:52:27.210866 139792788920128 learning.py:507] global step 39905: loss = 0.0813 (0.965 sec/step)\n",
      "I0902 08:52:28.176278 139792788920128 learning.py:507] global step 39906: loss = 0.2183 (0.964 sec/step)\n",
      "I0902 08:52:29.147554 139792788920128 learning.py:507] global step 39907: loss = 0.1214 (0.970 sec/step)\n",
      "I0902 08:52:30.125393 139792788920128 learning.py:507] global step 39908: loss = 0.0884 (0.976 sec/step)\n",
      "I0902 08:52:31.077598 139792788920128 learning.py:507] global step 39909: loss = 0.0625 (0.951 sec/step)\n",
      "I0902 08:52:32.053459 139792788920128 learning.py:507] global step 39910: loss = 0.1614 (0.974 sec/step)\n",
      "I0902 08:52:33.037849 139792788920128 learning.py:507] global step 39911: loss = 0.1225 (0.983 sec/step)\n",
      "I0902 08:52:34.003789 139792788920128 learning.py:507] global step 39912: loss = 0.0922 (0.964 sec/step)\n",
      "I0902 08:52:34.948576 139792788920128 learning.py:507] global step 39913: loss = 0.1240 (0.943 sec/step)\n",
      "I0902 08:52:35.925582 139792788920128 learning.py:507] global step 39914: loss = 0.0776 (0.975 sec/step)\n",
      "I0902 08:52:36.882170 139792788920128 learning.py:507] global step 39915: loss = 0.3903 (0.955 sec/step)\n",
      "I0902 08:52:37.845254 139792788920128 learning.py:507] global step 39916: loss = 0.2012 (0.961 sec/step)\n",
      "I0902 08:52:38.829774 139792788920128 learning.py:507] global step 39917: loss = 0.1366 (0.983 sec/step)\n",
      "I0902 08:52:39.796416 139792788920128 learning.py:507] global step 39918: loss = 0.0909 (0.965 sec/step)\n",
      "I0902 08:52:40.756086 139792788920128 learning.py:507] global step 39919: loss = 0.1323 (0.958 sec/step)\n",
      "I0902 08:52:41.716596 139792788920128 learning.py:507] global step 39920: loss = 0.0812 (0.958 sec/step)\n",
      "I0902 08:52:42.696526 139792788920128 learning.py:507] global step 39921: loss = 0.3860 (0.978 sec/step)\n",
      "I0902 08:52:43.667270 139792788920128 learning.py:507] global step 39922: loss = 0.0673 (0.969 sec/step)\n",
      "I0902 08:52:44.634590 139792788920128 learning.py:507] global step 39923: loss = 0.1799 (0.966 sec/step)\n",
      "I0902 08:52:45.591754 139792788920128 learning.py:507] global step 39924: loss = 0.1793 (0.956 sec/step)\n",
      "I0902 08:52:46.557419 139792788920128 learning.py:507] global step 39925: loss = 0.1196 (0.964 sec/step)\n",
      "I0902 08:52:47.518449 139792788920128 learning.py:507] global step 39926: loss = 0.1378 (0.959 sec/step)\n",
      "I0902 08:52:48.479726 139792788920128 learning.py:507] global step 39927: loss = 0.0658 (0.960 sec/step)\n",
      "I0902 08:52:49.451340 139792788920128 learning.py:507] global step 39928: loss = 0.1776 (0.970 sec/step)\n",
      "I0902 08:52:50.421470 139792788920128 learning.py:507] global step 39929: loss = 0.1306 (0.968 sec/step)\n",
      "I0902 08:52:51.393192 139792788920128 learning.py:507] global step 39930: loss = 0.1481 (0.970 sec/step)\n",
      "I0902 08:52:52.366521 139792788920128 learning.py:507] global step 39931: loss = 0.1244 (0.972 sec/step)\n",
      "I0902 08:52:53.336532 139792788920128 learning.py:507] global step 39932: loss = 0.1170 (0.968 sec/step)\n",
      "I0902 08:52:54.292849 139792788920128 learning.py:507] global step 39933: loss = 0.1381 (0.955 sec/step)\n",
      "I0902 08:52:55.287665 139792788920128 learning.py:507] global step 39934: loss = 0.1458 (0.993 sec/step)\n",
      "I0902 08:52:56.253024 139792788920128 learning.py:507] global step 39935: loss = 0.0995 (0.964 sec/step)\n",
      "I0902 08:52:57.203613 139792788920128 learning.py:507] global step 39936: loss = 0.0857 (0.949 sec/step)\n",
      "I0902 08:52:58.151722 139792788920128 learning.py:507] global step 39937: loss = 0.1051 (0.947 sec/step)\n",
      "I0902 08:52:59.118127 139792788920128 learning.py:507] global step 39938: loss = 0.1967 (0.965 sec/step)\n",
      "I0902 08:53:00.089011 139792788920128 learning.py:507] global step 39939: loss = 0.1334 (0.969 sec/step)\n",
      "I0902 08:53:01.054590 139792788920128 learning.py:507] global step 39940: loss = 0.1260 (0.964 sec/step)\n",
      "I0902 08:53:02.023640 139792788920128 learning.py:507] global step 39941: loss = 0.1263 (0.968 sec/step)\n",
      "I0902 08:53:02.992383 139792788920128 learning.py:507] global step 39942: loss = 0.1977 (0.967 sec/step)\n",
      "I0902 08:53:03.961703 139792788920128 learning.py:507] global step 39943: loss = 0.0826 (0.968 sec/step)\n",
      "I0902 08:53:04.946600 139792788920128 learning.py:507] global step 39944: loss = 0.2730 (0.983 sec/step)\n",
      "I0902 08:53:05.918114 139792788920128 learning.py:507] global step 39945: loss = 0.1245 (0.970 sec/step)\n",
      "I0902 08:53:06.909060 139792788920128 learning.py:507] global step 39946: loss = 0.0889 (0.989 sec/step)\n",
      "I0902 08:53:07.865063 139792788920128 learning.py:507] global step 39947: loss = 0.1053 (0.954 sec/step)\n",
      "I0902 08:53:08.826643 139792788920128 learning.py:507] global step 39948: loss = 0.0899 (0.960 sec/step)\n",
      "I0902 08:53:09.788118 139792788920128 learning.py:507] global step 39949: loss = 0.0823 (0.960 sec/step)\n",
      "I0902 08:53:10.779877 139792788920128 learning.py:507] global step 39950: loss = 0.1027 (0.990 sec/step)\n",
      "I0902 08:53:11.734789 139792788920128 learning.py:507] global step 39951: loss = 0.1143 (0.953 sec/step)\n",
      "I0902 08:53:12.712226 139792788920128 learning.py:507] global step 39952: loss = 0.2465 (0.976 sec/step)\n",
      "I0902 08:53:13.685743 139792788920128 learning.py:507] global step 39953: loss = 0.1730 (0.972 sec/step)\n",
      "I0902 08:53:14.666866 139792788920128 learning.py:507] global step 39954: loss = 0.0591 (0.980 sec/step)\n",
      "I0902 08:53:15.638523 139792788920128 learning.py:507] global step 39955: loss = 0.0559 (0.970 sec/step)\n",
      "I0902 08:53:16.605482 139792788920128 learning.py:507] global step 39956: loss = 0.2215 (0.965 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:53:17.568729 139792788920128 learning.py:507] global step 39957: loss = 0.1553 (0.961 sec/step)\n",
      "I0902 08:53:18.541341 139792788920128 learning.py:507] global step 39958: loss = 0.1324 (0.971 sec/step)\n",
      "I0902 08:53:19.501883 139792788920128 learning.py:507] global step 39959: loss = 0.0764 (0.959 sec/step)\n",
      "I0902 08:53:20.468647 139792788920128 learning.py:507] global step 39960: loss = 0.1000 (0.965 sec/step)\n",
      "I0902 08:53:21.442009 139792788920128 learning.py:507] global step 39961: loss = 0.0800 (0.972 sec/step)\n",
      "I0902 08:53:22.401472 139792788920128 learning.py:507] global step 39962: loss = 0.0721 (0.958 sec/step)\n",
      "I0902 08:53:23.365654 139792788920128 learning.py:507] global step 39963: loss = 0.0817 (0.962 sec/step)\n",
      "I0902 08:53:24.337588 139792788920128 learning.py:507] global step 39964: loss = 0.0827 (0.970 sec/step)\n",
      "I0902 08:53:25.306628 139792788920128 learning.py:507] global step 39965: loss = 0.2004 (0.967 sec/step)\n",
      "I0902 08:53:26.287937 139792788920128 learning.py:507] global step 39966: loss = 0.2853 (0.980 sec/step)\n",
      "I0902 08:53:27.226198 139792788920128 learning.py:507] global step 39967: loss = 0.0703 (0.937 sec/step)\n",
      "I0902 08:53:28.198307 139792788920128 learning.py:507] global step 39968: loss = 0.1405 (0.970 sec/step)\n",
      "I0902 08:53:29.167731 139792788920128 learning.py:507] global step 39969: loss = 0.1718 (0.968 sec/step)\n",
      "I0902 08:53:30.127272 139792788920128 learning.py:507] global step 39970: loss = 0.1046 (0.958 sec/step)\n",
      "I0902 08:53:31.100234 139792788920128 learning.py:507] global step 39971: loss = 0.1050 (0.971 sec/step)\n",
      "I0902 08:53:32.070760 139792788920128 learning.py:507] global step 39972: loss = 0.2250 (0.969 sec/step)\n",
      "I0902 08:53:33.040105 139792788920128 learning.py:507] global step 39973: loss = 0.0733 (0.968 sec/step)\n",
      "I0902 08:53:34.009532 139792788920128 learning.py:507] global step 39974: loss = 0.1006 (0.968 sec/step)\n",
      "I0902 08:53:34.980062 139792788920128 learning.py:507] global step 39975: loss = 0.1301 (0.969 sec/step)\n",
      "I0902 08:53:35.959149 139792788920128 learning.py:507] global step 39976: loss = 0.0623 (0.977 sec/step)\n",
      "I0902 08:53:36.913039 139792788920128 learning.py:507] global step 39977: loss = 0.1790 (0.953 sec/step)\n",
      "I0902 08:53:37.878740 139792788920128 learning.py:507] global step 39978: loss = 0.2490 (0.964 sec/step)\n",
      "I0902 08:53:38.850974 139792788920128 learning.py:507] global step 39979: loss = 0.1434 (0.971 sec/step)\n",
      "I0902 08:53:39.824673 139792788920128 learning.py:507] global step 39980: loss = 0.1146 (0.972 sec/step)\n",
      "I0902 08:53:40.802340 139792788920128 learning.py:507] global step 39981: loss = 0.1821 (0.976 sec/step)\n",
      "I0902 08:53:41.776705 139792788920128 learning.py:507] global step 39982: loss = 0.0578 (0.973 sec/step)\n",
      "I0902 08:53:42.757853 139792788920128 learning.py:507] global step 39983: loss = 0.2466 (0.980 sec/step)\n",
      "I0902 08:53:43.730688 139792788920128 learning.py:507] global step 39984: loss = 0.1133 (0.971 sec/step)\n",
      "I0902 08:53:44.695268 139792788920128 learning.py:507] global step 39985: loss = 0.0791 (0.963 sec/step)\n",
      "I0902 08:53:45.673584 139792788920128 learning.py:507] global step 39986: loss = 0.0940 (0.977 sec/step)\n",
      "I0902 08:53:46.671666 139792788920128 learning.py:507] global step 39987: loss = 0.1076 (0.997 sec/step)\n",
      "I0902 08:53:47.636858 139792788920128 learning.py:507] global step 39988: loss = 0.0523 (0.963 sec/step)\n",
      "I0902 08:53:48.593474 139792788920128 learning.py:507] global step 39989: loss = 0.0877 (0.955 sec/step)\n",
      "I0902 08:53:49.270353 139778953570048 supervisor.py:1117] Saving checkpoint to path data_dir/mixed_experiment/checkpoints_v2/model.ckpt\n",
      "I0902 08:53:49.554642 139792788920128 learning.py:507] global step 39990: loss = 0.2042 (0.947 sec/step)\n",
      "I0902 08:53:50.181757 139778936784640 supervisor.py:1050] Recording summary at step 39990.\n",
      "I0902 08:53:50.781341 139792788920128 learning.py:507] global step 39991: loss = 0.1685 (1.224 sec/step)\n",
      "I0902 08:53:51.748688 139792788920128 learning.py:507] global step 39992: loss = 0.1222 (0.966 sec/step)\n",
      "I0902 08:53:52.741787 139792788920128 learning.py:507] global step 39993: loss = 0.0676 (0.992 sec/step)\n",
      "I0902 08:53:53.701267 139792788920128 learning.py:507] global step 39994: loss = 0.1541 (0.958 sec/step)\n",
      "I0902 08:53:54.687553 139792788920128 learning.py:507] global step 39995: loss = 0.1154 (0.985 sec/step)\n",
      "I0902 08:53:55.666676 139792788920128 learning.py:507] global step 39996: loss = 0.0568 (0.977 sec/step)\n",
      "I0902 08:53:56.620510 139792788920128 learning.py:507] global step 39997: loss = 0.1326 (0.952 sec/step)\n",
      "I0902 08:53:57.581905 139792788920128 learning.py:507] global step 39998: loss = 0.0955 (0.960 sec/step)\n",
      "I0902 08:53:58.538323 139792788920128 learning.py:507] global step 39999: loss = 0.1804 (0.955 sec/step)\n",
      "I0902 08:53:59.507156 139792788920128 learning.py:507] global step 40000: loss = 0.0779 (0.967 sec/step)\n",
      "I0902 08:54:00.488933 139792788920128 learning.py:507] global step 40001: loss = 0.1487 (0.980 sec/step)\n",
      "I0902 08:54:01.463264 139792788920128 learning.py:507] global step 40002: loss = 0.2227 (0.973 sec/step)\n",
      "I0902 08:54:02.420975 139792788920128 learning.py:507] global step 40003: loss = 0.1054 (0.956 sec/step)\n",
      "I0902 08:54:03.384345 139792788920128 learning.py:507] global step 40004: loss = 0.1027 (0.962 sec/step)\n",
      "I0902 08:54:04.371473 139792788920128 learning.py:507] global step 40005: loss = 0.0747 (0.985 sec/step)\n",
      "I0902 08:54:05.349276 139792788920128 learning.py:507] global step 40006: loss = 0.1031 (0.976 sec/step)\n",
      "I0902 08:54:06.315523 139792788920128 learning.py:507] global step 40007: loss = 0.0757 (0.965 sec/step)\n",
      "I0902 08:54:07.283800 139792788920128 learning.py:507] global step 40008: loss = 0.1859 (0.967 sec/step)\n",
      "I0902 08:54:08.264047 139792788920128 learning.py:507] global step 40009: loss = 0.0924 (0.979 sec/step)\n",
      "I0902 08:54:09.239887 139792788920128 learning.py:507] global step 40010: loss = 0.1278 (0.975 sec/step)\n",
      "I0902 08:54:10.200609 139792788920128 learning.py:507] global step 40011: loss = 0.1417 (0.960 sec/step)\n",
      "I0902 08:54:11.162953 139792788920128 learning.py:507] global step 40012: loss = 0.1318 (0.961 sec/step)\n",
      "I0902 08:54:12.152597 139792788920128 learning.py:507] global step 40013: loss = 0.0902 (0.988 sec/step)\n",
      "I0902 08:54:13.120617 139792788920128 learning.py:507] global step 40014: loss = 0.1379 (0.967 sec/step)\n",
      "I0902 08:54:14.100040 139792788920128 learning.py:507] global step 40015: loss = 0.0893 (0.978 sec/step)\n",
      "I0902 08:54:15.053578 139792788920128 learning.py:507] global step 40016: loss = 0.1290 (0.952 sec/step)\n",
      "I0902 08:54:16.033114 139792788920128 learning.py:507] global step 40017: loss = 0.1601 (0.978 sec/step)\n",
      "I0902 08:54:17.004268 139792788920128 learning.py:507] global step 40018: loss = 0.1760 (0.970 sec/step)\n",
      "I0902 08:54:17.983155 139792788920128 learning.py:507] global step 40019: loss = 0.2849 (0.977 sec/step)\n",
      "I0902 08:54:18.943392 139792788920128 learning.py:507] global step 40020: loss = 0.0828 (0.959 sec/step)\n",
      "I0902 08:54:19.900491 139792788920128 learning.py:507] global step 40021: loss = 0.0940 (0.955 sec/step)\n",
      "I0902 08:54:20.880577 139792788920128 learning.py:507] global step 40022: loss = 0.1469 (0.978 sec/step)\n",
      "I0902 08:54:21.831224 139792788920128 learning.py:507] global step 40023: loss = 0.0953 (0.949 sec/step)\n",
      "I0902 08:54:22.801836 139792788920128 learning.py:507] global step 40024: loss = 0.0593 (0.969 sec/step)\n",
      "I0902 08:54:23.773954 139792788920128 learning.py:507] global step 40025: loss = 0.0782 (0.971 sec/step)\n",
      "I0902 08:54:24.754822 139792788920128 learning.py:507] global step 40026: loss = 0.1239 (0.979 sec/step)\n",
      "I0902 08:54:25.726734 139792788920128 learning.py:507] global step 40027: loss = 0.2007 (0.970 sec/step)\n",
      "I0902 08:54:26.695230 139792788920128 learning.py:507] global step 40028: loss = 0.0782 (0.967 sec/step)\n",
      "I0902 08:54:27.663432 139792788920128 learning.py:507] global step 40029: loss = 0.0765 (0.967 sec/step)\n",
      "I0902 08:54:28.641048 139792788920128 learning.py:507] global step 40030: loss = 0.0674 (0.976 sec/step)\n",
      "I0902 08:54:29.613942 139792788920128 learning.py:507] global step 40031: loss = 0.2316 (0.971 sec/step)\n",
      "I0902 08:54:30.566032 139792788920128 learning.py:507] global step 40032: loss = 0.0960 (0.950 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:54:31.523163 139792788920128 learning.py:507] global step 40033: loss = 0.0979 (0.956 sec/step)\n",
      "I0902 08:54:32.498724 139792788920128 learning.py:507] global step 40034: loss = 0.0941 (0.974 sec/step)\n",
      "I0902 08:54:33.473978 139792788920128 learning.py:507] global step 40035: loss = 0.0922 (0.974 sec/step)\n",
      "I0902 08:54:34.439893 139792788920128 learning.py:507] global step 40036: loss = 0.1190 (0.964 sec/step)\n",
      "I0902 08:54:35.426347 139792788920128 learning.py:507] global step 40037: loss = 0.0691 (0.985 sec/step)\n",
      "I0902 08:54:36.396707 139792788920128 learning.py:507] global step 40038: loss = 0.1241 (0.969 sec/step)\n",
      "I0902 08:54:37.362309 139792788920128 learning.py:507] global step 40039: loss = 0.0565 (0.964 sec/step)\n",
      "I0902 08:54:38.315361 139792788920128 learning.py:507] global step 40040: loss = 0.0586 (0.951 sec/step)\n",
      "I0902 08:54:39.275058 139792788920128 learning.py:507] global step 40041: loss = 0.2237 (0.958 sec/step)\n",
      "I0902 08:54:40.244363 139792788920128 learning.py:507] global step 40042: loss = 0.0765 (0.968 sec/step)\n",
      "I0902 08:54:41.217126 139792788920128 learning.py:507] global step 40043: loss = 0.1616 (0.971 sec/step)\n",
      "I0902 08:54:42.186651 139792788920128 learning.py:507] global step 40044: loss = 0.1021 (0.968 sec/step)\n",
      "I0902 08:54:43.162883 139792788920128 learning.py:507] global step 40045: loss = 0.0681 (0.975 sec/step)\n",
      "I0902 08:54:44.145463 139792788920128 learning.py:507] global step 40046: loss = 0.2042 (0.981 sec/step)\n",
      "I0902 08:54:45.118066 139792788920128 learning.py:507] global step 40047: loss = 0.3324 (0.971 sec/step)\n",
      "I0902 08:54:46.058186 139792788920128 learning.py:507] global step 40048: loss = 0.1365 (0.939 sec/step)\n",
      "I0902 08:54:47.039725 139792788920128 learning.py:507] global step 40049: loss = 0.1131 (0.980 sec/step)\n",
      "I0902 08:54:48.028504 139792788920128 learning.py:507] global step 40050: loss = 0.0393 (0.987 sec/step)\n",
      "I0902 08:54:49.003432 139792788920128 learning.py:507] global step 40051: loss = 0.0893 (0.973 sec/step)\n",
      "I0902 08:54:49.962094 139792788920128 learning.py:507] global step 40052: loss = 0.1566 (0.957 sec/step)\n",
      "I0902 08:54:50.921171 139792788920128 learning.py:507] global step 40053: loss = 0.1731 (0.957 sec/step)\n",
      "I0902 08:54:51.889147 139792788920128 learning.py:507] global step 40054: loss = 0.1194 (0.966 sec/step)\n",
      "I0902 08:54:52.859649 139792788920128 learning.py:507] global step 40055: loss = 0.4330 (0.969 sec/step)\n",
      "I0902 08:54:53.826027 139792788920128 learning.py:507] global step 40056: loss = 0.1076 (0.965 sec/step)\n",
      "I0902 08:54:54.783030 139792788920128 learning.py:507] global step 40057: loss = 0.1080 (0.955 sec/step)\n",
      "I0902 08:54:55.746338 139792788920128 learning.py:507] global step 40058: loss = 0.1245 (0.962 sec/step)\n",
      "I0902 08:54:56.709839 139792788920128 learning.py:507] global step 40059: loss = 0.0937 (0.962 sec/step)\n",
      "I0902 08:54:57.676894 139792788920128 learning.py:507] global step 40060: loss = 0.1861 (0.965 sec/step)\n",
      "I0902 08:54:58.646591 139792788920128 learning.py:507] global step 40061: loss = 0.1144 (0.968 sec/step)\n",
      "I0902 08:54:59.617303 139792788920128 learning.py:507] global step 40062: loss = 0.2550 (0.969 sec/step)\n",
      "I0902 08:55:00.593210 139792788920128 learning.py:507] global step 40063: loss = 0.1641 (0.974 sec/step)\n",
      "I0902 08:55:01.560526 139792788920128 learning.py:507] global step 40064: loss = 0.0883 (0.966 sec/step)\n",
      "I0902 08:55:02.511172 139792788920128 learning.py:507] global step 40065: loss = 0.0909 (0.949 sec/step)\n",
      "I0902 08:55:03.483057 139792788920128 learning.py:507] global step 40066: loss = 0.0908 (0.971 sec/step)\n",
      "I0902 08:55:04.465832 139792788920128 learning.py:507] global step 40067: loss = 0.0842 (0.981 sec/step)\n",
      "I0902 08:55:05.441597 139792788920128 learning.py:507] global step 40068: loss = 0.0791 (0.974 sec/step)\n",
      "I0902 08:55:06.399086 139792788920128 learning.py:507] global step 40069: loss = 0.0854 (0.956 sec/step)\n",
      "I0902 08:55:07.384533 139792788920128 learning.py:507] global step 40070: loss = 0.0915 (0.984 sec/step)\n",
      "I0902 08:55:08.361566 139792788920128 learning.py:507] global step 40071: loss = 0.0699 (0.976 sec/step)\n",
      "I0902 08:55:09.334077 139792788920128 learning.py:507] global step 40072: loss = 0.1167 (0.971 sec/step)\n",
      "I0902 08:55:10.297978 139792788920128 learning.py:507] global step 40073: loss = 0.1070 (0.962 sec/step)\n",
      "I0902 08:55:11.252647 139792788920128 learning.py:507] global step 40074: loss = 0.1538 (0.953 sec/step)\n",
      "I0902 08:55:12.208269 139792788920128 learning.py:507] global step 40075: loss = 0.2921 (0.954 sec/step)\n",
      "I0902 08:55:13.161789 139792788920128 learning.py:507] global step 40076: loss = 0.4989 (0.951 sec/step)\n",
      "I0902 08:55:14.138294 139792788920128 learning.py:507] global step 40077: loss = 0.1120 (0.975 sec/step)\n",
      "I0902 08:55:15.109961 139792788920128 learning.py:507] global step 40078: loss = 0.0926 (0.970 sec/step)\n",
      "I0902 08:55:16.083769 139792788920128 learning.py:507] global step 40079: loss = 0.2225 (0.972 sec/step)\n",
      "I0902 08:55:17.069194 139792788920128 learning.py:507] global step 40080: loss = 0.0841 (0.984 sec/step)\n",
      "I0902 08:55:18.047106 139792788920128 learning.py:507] global step 40081: loss = 0.3661 (0.976 sec/step)\n",
      "I0902 08:55:19.017206 139792788920128 learning.py:507] global step 40082: loss = 0.1604 (0.969 sec/step)\n",
      "I0902 08:55:19.968360 139792788920128 learning.py:507] global step 40083: loss = 0.0781 (0.950 sec/step)\n",
      "I0902 08:55:20.949554 139792788920128 learning.py:507] global step 40084: loss = 0.1099 (0.979 sec/step)\n",
      "I0902 08:55:21.921779 139792788920128 learning.py:507] global step 40085: loss = 0.1397 (0.971 sec/step)\n",
      "I0902 08:55:22.899096 139792788920128 learning.py:507] global step 40086: loss = 0.0952 (0.976 sec/step)\n",
      "I0902 08:55:23.887097 139792788920128 learning.py:507] global step 40087: loss = 0.1579 (0.987 sec/step)\n",
      "I0902 08:55:24.851324 139792788920128 learning.py:507] global step 40088: loss = 0.0857 (0.963 sec/step)\n",
      "I0902 08:55:25.798444 139792788920128 learning.py:507] global step 40089: loss = 0.0857 (0.946 sec/step)\n",
      "I0902 08:55:26.776694 139792788920128 learning.py:507] global step 40090: loss = 0.1226 (0.977 sec/step)\n",
      "I0902 08:55:27.741336 139792788920128 learning.py:507] global step 40091: loss = 0.0920 (0.963 sec/step)\n",
      "I0902 08:55:28.710855 139792788920128 learning.py:507] global step 40092: loss = 0.1907 (0.968 sec/step)\n",
      "I0902 08:55:29.682362 139792788920128 learning.py:507] global step 40093: loss = 0.1610 (0.970 sec/step)\n",
      "I0902 08:55:30.650302 139792788920128 learning.py:507] global step 40094: loss = 0.1884 (0.967 sec/step)\n",
      "I0902 08:55:31.588638 139792788920128 learning.py:507] global step 40095: loss = 0.2639 (0.937 sec/step)\n",
      "I0902 08:55:32.566042 139792788920128 learning.py:507] global step 40096: loss = 0.0808 (0.976 sec/step)\n",
      "I0902 08:55:33.533865 139792788920128 learning.py:507] global step 40097: loss = 0.0835 (0.966 sec/step)\n",
      "I0902 08:55:34.520563 139792788920128 learning.py:507] global step 40098: loss = 0.1235 (0.985 sec/step)\n",
      "I0902 08:55:35.492160 139792788920128 learning.py:507] global step 40099: loss = 0.1529 (0.970 sec/step)\n",
      "I0902 08:55:36.461130 139792788920128 learning.py:507] global step 40100: loss = 0.0784 (0.967 sec/step)\n",
      "I0902 08:55:37.436709 139792788920128 learning.py:507] global step 40101: loss = 0.1236 (0.974 sec/step)\n",
      "I0902 08:55:38.400726 139792788920128 learning.py:507] global step 40102: loss = 0.0704 (0.962 sec/step)\n",
      "I0902 08:55:39.375065 139792788920128 learning.py:507] global step 40103: loss = 0.1072 (0.973 sec/step)\n",
      "I0902 08:55:40.345569 139792788920128 learning.py:507] global step 40104: loss = 0.1727 (0.969 sec/step)\n",
      "I0902 08:55:41.293664 139792788920128 learning.py:507] global step 40105: loss = 0.0985 (0.947 sec/step)\n",
      "I0902 08:55:42.247752 139792788920128 learning.py:507] global step 40106: loss = 0.1317 (0.953 sec/step)\n",
      "I0902 08:55:43.212357 139792788920128 learning.py:507] global step 40107: loss = 0.1040 (0.963 sec/step)\n",
      "I0902 08:55:44.192301 139792788920128 learning.py:507] global step 40108: loss = 0.0655 (0.978 sec/step)\n",
      "I0902 08:55:45.155628 139792788920128 learning.py:507] global step 40109: loss = 0.1083 (0.962 sec/step)\n",
      "I0902 08:55:46.114162 139792788920128 learning.py:507] global step 40110: loss = 0.1844 (0.957 sec/step)\n",
      "I0902 08:55:47.066323 139792788920128 learning.py:507] global step 40111: loss = 0.1903 (0.951 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:55:48.046166 139792788920128 learning.py:507] global step 40112: loss = 0.0957 (0.978 sec/step)\n",
      "I0902 08:55:49.010947 139792788920128 learning.py:507] global step 40113: loss = 0.1142 (0.964 sec/step)\n",
      "I0902 08:55:50.129149 139792788920128 learning.py:507] global step 40114: loss = 0.2573 (1.114 sec/step)\n",
      "I0902 08:55:50.459465 139778936784640 supervisor.py:1050] Recording summary at step 40114.\n",
      "I0902 08:55:51.226943 139792788920128 learning.py:507] global step 40115: loss = 0.1250 (1.087 sec/step)\n",
      "I0902 08:55:52.190385 139792788920128 learning.py:507] global step 40116: loss = 0.0899 (0.962 sec/step)\n",
      "I0902 08:55:53.146703 139792788920128 learning.py:507] global step 40117: loss = 0.1944 (0.955 sec/step)\n",
      "I0902 08:55:54.125234 139792788920128 learning.py:507] global step 40118: loss = 0.0814 (0.977 sec/step)\n",
      "I0902 08:55:55.087413 139792788920128 learning.py:507] global step 40119: loss = 0.1191 (0.961 sec/step)\n",
      "I0902 08:55:56.055048 139792788920128 learning.py:507] global step 40120: loss = 0.1053 (0.966 sec/step)\n",
      "I0902 08:55:57.021390 139792788920128 learning.py:507] global step 40121: loss = 0.3660 (0.965 sec/step)\n",
      "I0902 08:55:58.010057 139792788920128 learning.py:507] global step 40122: loss = 0.0827 (0.987 sec/step)\n",
      "I0902 08:55:58.988658 139792788920128 learning.py:507] global step 40123: loss = 0.1139 (0.977 sec/step)\n",
      "I0902 08:55:59.957977 139792788920128 learning.py:507] global step 40124: loss = 0.0776 (0.968 sec/step)\n",
      "I0902 08:56:00.923712 139792788920128 learning.py:507] global step 40125: loss = 0.1167 (0.964 sec/step)\n",
      "I0902 08:56:01.897339 139792788920128 learning.py:507] global step 40126: loss = 0.0873 (0.972 sec/step)\n",
      "I0902 08:56:02.866016 139792788920128 learning.py:507] global step 40127: loss = 0.1200 (0.967 sec/step)\n",
      "I0902 08:56:03.835897 139792788920128 learning.py:507] global step 40128: loss = 0.0682 (0.968 sec/step)\n",
      "I0902 08:56:04.794209 139792788920128 learning.py:507] global step 40129: loss = 0.1241 (0.956 sec/step)\n",
      "I0902 08:56:05.753390 139792788920128 learning.py:507] global step 40130: loss = 0.0987 (0.958 sec/step)\n",
      "I0902 08:56:06.729218 139792788920128 learning.py:507] global step 40131: loss = 0.1724 (0.974 sec/step)\n",
      "I0902 08:56:07.709723 139792788920128 learning.py:507] global step 40132: loss = 0.2339 (0.979 sec/step)\n",
      "I0902 08:56:08.680941 139792788920128 learning.py:507] global step 40133: loss = 0.2136 (0.970 sec/step)\n",
      "I0902 08:56:09.663224 139792788920128 learning.py:507] global step 40134: loss = 0.1227 (0.981 sec/step)\n",
      "I0902 08:56:10.647485 139792788920128 learning.py:507] global step 40135: loss = 0.0912 (0.983 sec/step)\n",
      "I0902 08:56:11.641233 139792788920128 learning.py:507] global step 40136: loss = 0.0948 (0.992 sec/step)\n",
      "I0902 08:56:12.613890 139792788920128 learning.py:507] global step 40137: loss = 0.1613 (0.971 sec/step)\n",
      "I0902 08:56:13.567344 139792788920128 learning.py:507] global step 40138: loss = 0.0944 (0.952 sec/step)\n",
      "I0902 08:56:14.546014 139792788920128 learning.py:507] global step 40139: loss = 0.1052 (0.977 sec/step)\n",
      "I0902 08:56:15.534127 139792788920128 learning.py:507] global step 40140: loss = 0.1656 (0.986 sec/step)\n",
      "I0902 08:56:16.495252 139792788920128 learning.py:507] global step 40141: loss = 0.0951 (0.959 sec/step)\n",
      "I0902 08:56:17.463646 139792788920128 learning.py:507] global step 40142: loss = 0.1021 (0.967 sec/step)\n",
      "I0902 08:56:18.483915 139792788920128 learning.py:507] global step 40143: loss = 0.1259 (1.019 sec/step)\n",
      "I0902 08:56:19.467135 139792788920128 learning.py:507] global step 40144: loss = 0.1640 (0.981 sec/step)\n",
      "I0902 08:56:20.439076 139792788920128 learning.py:507] global step 40145: loss = 0.1353 (0.970 sec/step)\n",
      "I0902 08:56:21.409868 139792788920128 learning.py:507] global step 40146: loss = 0.0803 (0.969 sec/step)\n",
      "I0902 08:56:22.382098 139792788920128 learning.py:507] global step 40147: loss = 0.1612 (0.971 sec/step)\n",
      "I0902 08:56:23.336033 139792788920128 learning.py:507] global step 40148: loss = 0.1441 (0.952 sec/step)\n",
      "I0902 08:56:24.307910 139792788920128 learning.py:507] global step 40149: loss = 0.0838 (0.970 sec/step)\n",
      "I0902 08:56:25.282755 139792788920128 learning.py:507] global step 40150: loss = 0.1154 (0.973 sec/step)\n",
      "I0902 08:56:26.283842 139792788920128 learning.py:507] global step 40151: loss = 0.0747 (1.000 sec/step)\n",
      "I0902 08:56:27.271697 139792788920128 learning.py:507] global step 40152: loss = 0.1213 (0.986 sec/step)\n",
      "I0902 08:56:28.246740 139792788920128 learning.py:507] global step 40153: loss = 0.2082 (0.973 sec/step)\n",
      "I0902 08:56:29.225944 139792788920128 learning.py:507] global step 40154: loss = 0.1161 (0.978 sec/step)\n",
      "I0902 08:56:30.193823 139792788920128 learning.py:507] global step 40155: loss = 0.2637 (0.966 sec/step)\n",
      "I0902 08:56:31.177395 139792788920128 learning.py:507] global step 40156: loss = 0.1035 (0.982 sec/step)\n",
      "I0902 08:56:32.165486 139792788920128 learning.py:507] global step 40157: loss = 0.0778 (0.986 sec/step)\n",
      "I0902 08:56:33.166633 139792788920128 learning.py:507] global step 40158: loss = 0.0955 (0.999 sec/step)\n",
      "I0902 08:56:34.136923 139792788920128 learning.py:507] global step 40159: loss = 0.1387 (0.969 sec/step)\n",
      "I0902 08:56:35.119738 139792788920128 learning.py:507] global step 40160: loss = 0.0749 (0.981 sec/step)\n",
      "I0902 08:56:36.076337 139792788920128 learning.py:507] global step 40161: loss = 0.1549 (0.955 sec/step)\n",
      "I0902 08:56:37.045175 139792788920128 learning.py:507] global step 40162: loss = 0.1125 (0.967 sec/step)\n",
      "I0902 08:56:38.010563 139792788920128 learning.py:507] global step 40163: loss = 0.1082 (0.964 sec/step)\n",
      "I0902 08:56:38.979867 139792788920128 learning.py:507] global step 40164: loss = 0.0626 (0.968 sec/step)\n",
      "I0902 08:56:39.965004 139792788920128 learning.py:507] global step 40165: loss = 0.1029 (0.983 sec/step)\n",
      "I0902 08:56:40.933743 139792788920128 learning.py:507] global step 40166: loss = 0.1379 (0.967 sec/step)\n",
      "I0902 08:56:41.925717 139792788920128 learning.py:507] global step 40167: loss = 0.1076 (0.990 sec/step)\n",
      "I0902 08:56:42.897169 139792788920128 learning.py:507] global step 40168: loss = 0.1566 (0.970 sec/step)\n",
      "I0902 08:56:43.889261 139792788920128 learning.py:507] global step 40169: loss = 0.0712 (0.990 sec/step)\n",
      "I0902 08:56:44.841228 139792788920128 learning.py:507] global step 40170: loss = 0.0794 (0.950 sec/step)\n",
      "I0902 08:56:45.837788 139792788920128 learning.py:507] global step 40171: loss = 0.2934 (0.995 sec/step)\n",
      "I0902 08:56:46.815742 139792788920128 learning.py:507] global step 40172: loss = 0.0855 (0.976 sec/step)\n",
      "I0902 08:56:47.783092 139792788920128 learning.py:507] global step 40173: loss = 0.0503 (0.966 sec/step)\n",
      "I0902 08:56:48.752903 139792788920128 learning.py:507] global step 40174: loss = 0.0511 (0.968 sec/step)\n",
      "I0902 08:56:49.727756 139792788920128 learning.py:507] global step 40175: loss = 0.1397 (0.973 sec/step)\n",
      "I0902 08:56:50.710168 139792788920128 learning.py:507] global step 40176: loss = 0.0879 (0.981 sec/step)\n",
      "I0902 08:56:51.691192 139792788920128 learning.py:507] global step 40177: loss = 0.0966 (0.979 sec/step)\n",
      "I0902 08:56:52.678498 139792788920128 learning.py:507] global step 40178: loss = 0.1620 (0.986 sec/step)\n",
      "I0902 08:56:53.672960 139792788920128 learning.py:507] global step 40179: loss = 0.2411 (0.993 sec/step)\n",
      "I0902 08:56:54.638444 139792788920128 learning.py:507] global step 40180: loss = 0.0864 (0.964 sec/step)\n",
      "I0902 08:56:55.601709 139792788920128 learning.py:507] global step 40181: loss = 0.1260 (0.962 sec/step)\n",
      "I0902 08:56:56.575422 139792788920128 learning.py:507] global step 40182: loss = 0.0474 (0.972 sec/step)\n",
      "I0902 08:56:57.567607 139792788920128 learning.py:507] global step 40183: loss = 0.1830 (0.990 sec/step)\n",
      "I0902 08:56:58.546579 139792788920128 learning.py:507] global step 40184: loss = 0.0635 (0.977 sec/step)\n",
      "I0902 08:56:59.524528 139792788920128 learning.py:507] global step 40185: loss = 0.1762 (0.976 sec/step)\n",
      "I0902 08:57:00.500471 139792788920128 learning.py:507] global step 40186: loss = 0.1141 (0.974 sec/step)\n",
      "I0902 08:57:01.480289 139792788920128 learning.py:507] global step 40187: loss = 0.1592 (0.978 sec/step)\n",
      "I0902 08:57:02.459047 139792788920128 learning.py:507] global step 40188: loss = 0.3446 (0.977 sec/step)\n",
      "I0902 08:57:03.432916 139792788920128 learning.py:507] global step 40189: loss = 0.0770 (0.972 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:57:04.398581 139792788920128 learning.py:507] global step 40190: loss = 0.2184 (0.964 sec/step)\n",
      "I0902 08:57:05.363015 139792788920128 learning.py:507] global step 40191: loss = 0.1291 (0.963 sec/step)\n",
      "I0902 08:57:06.349124 139792788920128 learning.py:507] global step 40192: loss = 0.1330 (0.984 sec/step)\n",
      "I0902 08:57:07.342579 139792788920128 learning.py:507] global step 40193: loss = 0.1402 (0.992 sec/step)\n",
      "I0902 08:57:08.296997 139792788920128 learning.py:507] global step 40194: loss = 0.1171 (0.953 sec/step)\n",
      "I0902 08:57:09.279509 139792788920128 learning.py:507] global step 40195: loss = 0.1253 (0.981 sec/step)\n",
      "I0902 08:57:10.264208 139792788920128 learning.py:507] global step 40196: loss = 0.1477 (0.983 sec/step)\n",
      "I0902 08:57:11.243124 139792788920128 learning.py:507] global step 40197: loss = 0.1028 (0.977 sec/step)\n",
      "I0902 08:57:12.221062 139792788920128 learning.py:507] global step 40198: loss = 0.1465 (0.976 sec/step)\n",
      "I0902 08:57:13.210475 139792788920128 learning.py:507] global step 40199: loss = 0.1010 (0.988 sec/step)\n",
      "I0902 08:57:14.174161 139792788920128 learning.py:507] global step 40200: loss = 0.1716 (0.962 sec/step)\n",
      "I0902 08:57:15.173401 139792788920128 learning.py:507] global step 40201: loss = 0.1088 (0.998 sec/step)\n",
      "I0902 08:57:16.145406 139792788920128 learning.py:507] global step 40202: loss = 0.1868 (0.970 sec/step)\n",
      "I0902 08:57:17.108601 139792788920128 learning.py:507] global step 40203: loss = 0.1861 (0.962 sec/step)\n",
      "I0902 08:57:18.100328 139792788920128 learning.py:507] global step 40204: loss = 0.1157 (0.990 sec/step)\n",
      "I0902 08:57:19.079352 139792788920128 learning.py:507] global step 40205: loss = 0.0839 (0.977 sec/step)\n",
      "I0902 08:57:20.081749 139792788920128 learning.py:507] global step 40206: loss = 0.0946 (1.001 sec/step)\n",
      "I0902 08:57:21.071302 139792788920128 learning.py:507] global step 40207: loss = 0.0860 (0.988 sec/step)\n",
      "I0902 08:57:22.041424 139792788920128 learning.py:507] global step 40208: loss = 0.0932 (0.969 sec/step)\n",
      "I0902 08:57:23.024005 139792788920128 learning.py:507] global step 40209: loss = 0.3118 (0.981 sec/step)\n",
      "I0902 08:57:23.999313 139792788920128 learning.py:507] global step 40210: loss = 0.2203 (0.974 sec/step)\n",
      "I0902 08:57:24.968021 139792788920128 learning.py:507] global step 40211: loss = 0.0786 (0.967 sec/step)\n",
      "I0902 08:57:25.932332 139792788920128 learning.py:507] global step 40212: loss = 0.0924 (0.963 sec/step)\n",
      "I0902 08:57:26.898386 139792788920128 learning.py:507] global step 40213: loss = 0.0633 (0.964 sec/step)\n",
      "I0902 08:57:27.894304 139792788920128 learning.py:507] global step 40214: loss = 0.1302 (0.994 sec/step)\n",
      "I0902 08:57:28.855245 139792788920128 learning.py:507] global step 40215: loss = 0.1986 (0.959 sec/step)\n",
      "I0902 08:57:29.831612 139792788920128 learning.py:507] global step 40216: loss = 0.3606 (0.975 sec/step)\n",
      "I0902 08:57:30.788238 139792788920128 learning.py:507] global step 40217: loss = 0.0643 (0.955 sec/step)\n",
      "I0902 08:57:31.783605 139792788920128 learning.py:507] global step 40218: loss = 0.0672 (0.994 sec/step)\n",
      "I0902 08:57:32.785918 139792788920128 learning.py:507] global step 40219: loss = 0.1153 (1.001 sec/step)\n",
      "I0902 08:57:33.766782 139792788920128 learning.py:507] global step 40220: loss = 0.0736 (0.979 sec/step)\n",
      "I0902 08:57:34.771258 139792788920128 learning.py:507] global step 40221: loss = 0.2299 (1.003 sec/step)\n",
      "I0902 08:57:35.744076 139792788920128 learning.py:507] global step 40222: loss = 0.1298 (0.971 sec/step)\n",
      "I0902 08:57:36.703934 139792788920128 learning.py:507] global step 40223: loss = 0.1758 (0.958 sec/step)\n",
      "I0902 08:57:37.678863 139792788920128 learning.py:507] global step 40224: loss = 0.1039 (0.973 sec/step)\n",
      "I0902 08:57:38.687719 139792788920128 learning.py:507] global step 40225: loss = 0.1303 (1.007 sec/step)\n",
      "I0902 08:57:39.676823 139792788920128 learning.py:507] global step 40226: loss = 0.1045 (0.987 sec/step)\n",
      "I0902 08:57:40.655784 139792788920128 learning.py:507] global step 40227: loss = 0.0865 (0.977 sec/step)\n",
      "I0902 08:57:41.628648 139792788920128 learning.py:507] global step 40228: loss = 0.1005 (0.971 sec/step)\n",
      "I0902 08:57:42.593771 139792788920128 learning.py:507] global step 40229: loss = 0.1139 (0.963 sec/step)\n",
      "I0902 08:57:43.586038 139792788920128 learning.py:507] global step 40230: loss = 0.2373 (0.991 sec/step)\n",
      "I0902 08:57:44.556106 139792788920128 learning.py:507] global step 40231: loss = 0.0854 (0.968 sec/step)\n",
      "I0902 08:57:45.547054 139792788920128 learning.py:507] global step 40232: loss = 0.1057 (0.989 sec/step)\n",
      "I0902 08:57:46.543134 139792788920128 learning.py:507] global step 40233: loss = 0.0928 (0.995 sec/step)\n",
      "I0902 08:57:47.485244 139792788920128 learning.py:507] global step 40234: loss = 0.0566 (0.940 sec/step)\n",
      "I0902 08:57:48.463679 139792788920128 learning.py:507] global step 40235: loss = 0.2107 (0.977 sec/step)\n",
      "I0902 08:57:49.459845 139792788920128 learning.py:507] global step 40236: loss = 0.1939 (0.991 sec/step)\n",
      "I0902 08:57:50.110676 139778936784640 supervisor.py:1050] Recording summary at step 40236.\n",
      "I0902 08:57:50.753472 139792788920128 learning.py:507] global step 40237: loss = 0.0455 (1.292 sec/step)\n",
      "I0902 08:57:51.734703 139792788920128 learning.py:507] global step 40238: loss = 0.0583 (0.980 sec/step)\n",
      "I0902 08:57:52.729169 139792788920128 learning.py:507] global step 40239: loss = 0.2233 (0.993 sec/step)\n",
      "I0902 08:57:53.740538 139792788920128 learning.py:507] global step 40240: loss = 0.1058 (1.010 sec/step)\n",
      "I0902 08:57:54.722001 139792788920128 learning.py:507] global step 40241: loss = 0.0780 (0.980 sec/step)\n",
      "I0902 08:57:55.699602 139792788920128 learning.py:507] global step 40242: loss = 0.1374 (0.976 sec/step)\n",
      "I0902 08:57:56.714944 139792788920128 learning.py:507] global step 40243: loss = 0.0772 (1.014 sec/step)\n",
      "I0902 08:57:57.682574 139792788920128 learning.py:507] global step 40244: loss = 0.1211 (0.966 sec/step)\n",
      "I0902 08:57:58.674101 139792788920128 learning.py:507] global step 40245: loss = 0.1296 (0.990 sec/step)\n",
      "I0902 08:57:59.645901 139792788920128 learning.py:507] global step 40246: loss = 0.0705 (0.970 sec/step)\n",
      "I0902 08:58:00.643659 139792788920128 learning.py:507] global step 40247: loss = 0.2125 (0.996 sec/step)\n",
      "I0902 08:58:01.629443 139792788920128 learning.py:507] global step 40248: loss = 0.1125 (0.984 sec/step)\n",
      "I0902 08:58:02.609675 139792788920128 learning.py:507] global step 40249: loss = 0.1686 (0.979 sec/step)\n",
      "I0902 08:58:03.587665 139792788920128 learning.py:507] global step 40250: loss = 0.0984 (0.976 sec/step)\n",
      "I0902 08:58:04.576537 139792788920128 learning.py:507] global step 40251: loss = 0.1571 (0.987 sec/step)\n",
      "I0902 08:58:05.564229 139792788920128 learning.py:507] global step 40252: loss = 0.1440 (0.986 sec/step)\n",
      "I0902 08:58:06.538289 139792788920128 learning.py:507] global step 40253: loss = 0.1186 (0.972 sec/step)\n",
      "I0902 08:58:07.513714 139792788920128 learning.py:507] global step 40254: loss = 0.1154 (0.974 sec/step)\n",
      "I0902 08:58:08.489289 139792788920128 learning.py:507] global step 40255: loss = 0.3374 (0.974 sec/step)\n",
      "I0902 08:58:09.461815 139792788920128 learning.py:507] global step 40256: loss = 0.1330 (0.971 sec/step)\n",
      "I0902 08:58:10.444267 139792788920128 learning.py:507] global step 40257: loss = 0.1033 (0.981 sec/step)\n",
      "I0902 08:58:11.412732 139792788920128 learning.py:507] global step 40258: loss = 0.1271 (0.967 sec/step)\n",
      "I0902 08:58:12.363096 139792788920128 learning.py:507] global step 40259: loss = 0.1100 (0.949 sec/step)\n",
      "I0902 08:58:13.338603 139792788920128 learning.py:507] global step 40260: loss = 0.1079 (0.974 sec/step)\n",
      "I0902 08:58:14.328584 139792788920128 learning.py:507] global step 40261: loss = 0.1215 (0.989 sec/step)\n",
      "I0902 08:58:15.297032 139792788920128 learning.py:507] global step 40262: loss = 0.2343 (0.966 sec/step)\n",
      "I0902 08:58:16.264789 139792788920128 learning.py:507] global step 40263: loss = 0.0838 (0.966 sec/step)\n",
      "I0902 08:58:17.230267 139792788920128 learning.py:507] global step 40264: loss = 0.0903 (0.964 sec/step)\n",
      "I0902 08:58:18.218909 139792788920128 learning.py:507] global step 40265: loss = 0.0771 (0.987 sec/step)\n",
      "I0902 08:58:19.203153 139792788920128 learning.py:507] global step 40266: loss = 0.0884 (0.983 sec/step)\n",
      "I0902 08:58:20.175611 139792788920128 learning.py:507] global step 40267: loss = 0.2347 (0.971 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:58:21.145614 139792788920128 learning.py:507] global step 40268: loss = 0.0700 (0.969 sec/step)\n",
      "I0902 08:58:22.116121 139792788920128 learning.py:507] global step 40269: loss = 0.0939 (0.969 sec/step)\n",
      "I0902 08:58:23.089815 139792788920128 learning.py:507] global step 40270: loss = 0.1059 (0.972 sec/step)\n",
      "I0902 08:58:24.068820 139792788920128 learning.py:507] global step 40271: loss = 0.0760 (0.978 sec/step)\n",
      "I0902 08:58:25.035668 139792788920128 learning.py:507] global step 40272: loss = 0.2618 (0.965 sec/step)\n",
      "I0902 08:58:26.002169 139792788920128 learning.py:507] global step 40273: loss = 0.4115 (0.965 sec/step)\n",
      "I0902 08:58:26.979990 139792788920128 learning.py:507] global step 40274: loss = 0.2561 (0.976 sec/step)\n",
      "I0902 08:58:27.948025 139792788920128 learning.py:507] global step 40275: loss = 0.4322 (0.966 sec/step)\n",
      "I0902 08:58:28.910224 139792788920128 learning.py:507] global step 40276: loss = 0.0632 (0.960 sec/step)\n",
      "I0902 08:58:29.881592 139792788920128 learning.py:507] global step 40277: loss = 0.1456 (0.970 sec/step)\n",
      "I0902 08:58:30.872154 139792788920128 learning.py:507] global step 40278: loss = 0.0953 (0.989 sec/step)\n",
      "I0902 08:58:31.836483 139792788920128 learning.py:507] global step 40279: loss = 0.1149 (0.963 sec/step)\n",
      "I0902 08:58:32.822100 139792788920128 learning.py:507] global step 40280: loss = 0.1811 (0.984 sec/step)\n",
      "I0902 08:58:33.775075 139792788920128 learning.py:507] global step 40281: loss = 0.1325 (0.951 sec/step)\n",
      "I0902 08:58:34.746130 139792788920128 learning.py:507] global step 40282: loss = 0.0657 (0.970 sec/step)\n",
      "I0902 08:58:35.706639 139792788920128 learning.py:507] global step 40283: loss = 0.0702 (0.959 sec/step)\n",
      "I0902 08:58:36.687701 139792788920128 learning.py:507] global step 40284: loss = 0.0913 (0.979 sec/step)\n",
      "I0902 08:58:37.646234 139792788920128 learning.py:507] global step 40285: loss = 0.1982 (0.957 sec/step)\n",
      "I0902 08:58:38.628018 139792788920128 learning.py:507] global step 40286: loss = 0.2951 (0.980 sec/step)\n",
      "I0902 08:58:39.610924 139792788920128 learning.py:507] global step 40287: loss = 0.1120 (0.981 sec/step)\n",
      "I0902 08:58:40.573459 139792788920128 learning.py:507] global step 40288: loss = 0.1051 (0.961 sec/step)\n",
      "I0902 08:58:41.558821 139792788920128 learning.py:507] global step 40289: loss = 0.0845 (0.984 sec/step)\n",
      "I0902 08:58:42.557424 139792788920128 learning.py:507] global step 40290: loss = 0.0879 (0.997 sec/step)\n",
      "I0902 08:58:43.513983 139792788920128 learning.py:507] global step 40291: loss = 0.1576 (0.955 sec/step)\n",
      "I0902 08:58:44.483817 139792788920128 learning.py:507] global step 40292: loss = 0.1285 (0.968 sec/step)\n",
      "I0902 08:58:45.454899 139792788920128 learning.py:507] global step 40293: loss = 0.1309 (0.970 sec/step)\n",
      "I0902 08:58:46.435386 139792788920128 learning.py:507] global step 40294: loss = 0.1726 (0.979 sec/step)\n",
      "I0902 08:58:47.413183 139792788920128 learning.py:507] global step 40295: loss = 0.1557 (0.976 sec/step)\n",
      "I0902 08:58:48.387333 139792788920128 learning.py:507] global step 40296: loss = 0.1444 (0.972 sec/step)\n",
      "I0902 08:58:49.373860 139792788920128 learning.py:507] global step 40297: loss = 0.1065 (0.985 sec/step)\n",
      "I0902 08:58:50.354335 139792788920128 learning.py:507] global step 40298: loss = 0.0555 (0.979 sec/step)\n",
      "I0902 08:58:51.312447 139792788920128 learning.py:507] global step 40299: loss = 0.0892 (0.956 sec/step)\n",
      "I0902 08:58:52.274386 139792788920128 learning.py:507] global step 40300: loss = 0.1064 (0.960 sec/step)\n",
      "I0902 08:58:53.251558 139792788920128 learning.py:507] global step 40301: loss = 0.1184 (0.975 sec/step)\n",
      "I0902 08:58:54.218808 139792788920128 learning.py:507] global step 40302: loss = 0.1365 (0.965 sec/step)\n",
      "I0902 08:58:55.180383 139792788920128 learning.py:507] global step 40303: loss = 0.1974 (0.960 sec/step)\n",
      "I0902 08:58:56.156543 139792788920128 learning.py:507] global step 40304: loss = 0.1608 (0.975 sec/step)\n",
      "I0902 08:58:57.140959 139792788920128 learning.py:507] global step 40305: loss = 0.0570 (0.983 sec/step)\n",
      "I0902 08:58:58.131297 139792788920128 learning.py:507] global step 40306: loss = 0.1128 (0.989 sec/step)\n",
      "I0902 08:58:59.100613 139792788920128 learning.py:507] global step 40307: loss = 0.1604 (0.968 sec/step)\n",
      "I0902 08:59:00.058329 139792788920128 learning.py:507] global step 40308: loss = 0.1228 (0.956 sec/step)\n",
      "I0902 08:59:01.036655 139792788920128 learning.py:507] global step 40309: loss = 0.0970 (0.977 sec/step)\n",
      "I0902 08:59:02.007411 139792788920128 learning.py:507] global step 40310: loss = 0.2432 (0.969 sec/step)\n",
      "I0902 08:59:02.978232 139792788920128 learning.py:507] global step 40311: loss = 0.0977 (0.969 sec/step)\n",
      "I0902 08:59:03.942766 139792788920128 learning.py:507] global step 40312: loss = 0.1244 (0.963 sec/step)\n",
      "I0902 08:59:04.917184 139792788920128 learning.py:507] global step 40313: loss = 0.1782 (0.973 sec/step)\n",
      "I0902 08:59:05.900392 139792788920128 learning.py:507] global step 40314: loss = 0.0705 (0.982 sec/step)\n",
      "I0902 08:59:06.859681 139792788920128 learning.py:507] global step 40315: loss = 0.0644 (0.957 sec/step)\n",
      "I0902 08:59:07.826070 139792788920128 learning.py:507] global step 40316: loss = 0.4094 (0.965 sec/step)\n",
      "I0902 08:59:08.801330 139792788920128 learning.py:507] global step 40317: loss = 0.0749 (0.974 sec/step)\n",
      "I0902 08:59:09.792200 139792788920128 learning.py:507] global step 40318: loss = 0.0919 (0.989 sec/step)\n",
      "I0902 08:59:10.773335 139792788920128 learning.py:507] global step 40319: loss = 0.2406 (0.979 sec/step)\n",
      "I0902 08:59:11.750101 139792788920128 learning.py:507] global step 40320: loss = 0.0753 (0.975 sec/step)\n",
      "I0902 08:59:12.738324 139792788920128 learning.py:507] global step 40321: loss = 0.0724 (0.987 sec/step)\n",
      "I0902 08:59:13.704958 139792788920128 learning.py:507] global step 40322: loss = 0.0904 (0.965 sec/step)\n",
      "I0902 08:59:14.729148 139792788920128 learning.py:507] global step 40323: loss = 0.1473 (1.022 sec/step)\n",
      "I0902 08:59:15.723587 139792788920128 learning.py:507] global step 40324: loss = 0.1493 (0.993 sec/step)\n",
      "I0902 08:59:16.698099 139792788920128 learning.py:507] global step 40325: loss = 0.1224 (0.973 sec/step)\n",
      "I0902 08:59:17.660784 139792788920128 learning.py:507] global step 40326: loss = 0.0733 (0.961 sec/step)\n",
      "I0902 08:59:18.641644 139792788920128 learning.py:507] global step 40327: loss = 0.0856 (0.979 sec/step)\n",
      "I0902 08:59:19.596046 139792788920128 learning.py:507] global step 40328: loss = 0.0946 (0.953 sec/step)\n",
      "I0902 08:59:20.573972 139792788920128 learning.py:507] global step 40329: loss = 0.2256 (0.976 sec/step)\n",
      "I0902 08:59:21.572806 139792788920128 learning.py:507] global step 40330: loss = 0.2248 (0.997 sec/step)\n",
      "I0902 08:59:22.560180 139792788920128 learning.py:507] global step 40331: loss = 0.1317 (0.986 sec/step)\n",
      "I0902 08:59:23.530911 139792788920128 learning.py:507] global step 40332: loss = 0.1261 (0.969 sec/step)\n",
      "I0902 08:59:24.505730 139792788920128 learning.py:507] global step 40333: loss = 0.0665 (0.973 sec/step)\n",
      "I0902 08:59:25.479973 139792788920128 learning.py:507] global step 40334: loss = 0.1048 (0.973 sec/step)\n",
      "I0902 08:59:26.444172 139792788920128 learning.py:507] global step 40335: loss = 0.1761 (0.962 sec/step)\n",
      "I0902 08:59:27.443833 139792788920128 learning.py:507] global step 40336: loss = 0.0986 (0.998 sec/step)\n",
      "I0902 08:59:28.434830 139792788920128 learning.py:507] global step 40337: loss = 0.0539 (0.989 sec/step)\n",
      "I0902 08:59:29.407976 139792788920128 learning.py:507] global step 40338: loss = 0.1273 (0.972 sec/step)\n",
      "I0902 08:59:30.400770 139792788920128 learning.py:507] global step 40339: loss = 0.2184 (0.991 sec/step)\n",
      "I0902 08:59:31.392587 139792788920128 learning.py:507] global step 40340: loss = 0.1516 (0.990 sec/step)\n",
      "I0902 08:59:32.391085 139792788920128 learning.py:507] global step 40341: loss = 0.1220 (0.997 sec/step)\n",
      "I0902 08:59:33.377676 139792788920128 learning.py:507] global step 40342: loss = 0.2908 (0.985 sec/step)\n",
      "I0902 08:59:34.344675 139792788920128 learning.py:507] global step 40343: loss = 0.1035 (0.965 sec/step)\n",
      "I0902 08:59:35.336328 139792788920128 learning.py:507] global step 40344: loss = 0.1538 (0.990 sec/step)\n",
      "I0902 08:59:36.327941 139792788920128 learning.py:507] global step 40345: loss = 0.5855 (0.990 sec/step)\n",
      "I0902 08:59:37.299669 139792788920128 learning.py:507] global step 40346: loss = 0.1207 (0.970 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 08:59:38.278869 139792788920128 learning.py:507] global step 40347: loss = 0.0790 (0.978 sec/step)\n",
      "I0902 08:59:39.247920 139792788920128 learning.py:507] global step 40348: loss = 0.1213 (0.967 sec/step)\n",
      "I0902 08:59:40.209772 139792788920128 learning.py:507] global step 40349: loss = 0.1276 (0.960 sec/step)\n",
      "I0902 08:59:41.192221 139792788920128 learning.py:507] global step 40350: loss = 0.1429 (0.981 sec/step)\n",
      "I0902 08:59:42.176557 139792788920128 learning.py:507] global step 40351: loss = 0.1314 (0.983 sec/step)\n",
      "I0902 08:59:43.147687 139792788920128 learning.py:507] global step 40352: loss = 0.4270 (0.969 sec/step)\n",
      "I0902 08:59:44.125660 139792788920128 learning.py:507] global step 40353: loss = 0.1708 (0.976 sec/step)\n",
      "I0902 08:59:45.106485 139792788920128 learning.py:507] global step 40354: loss = 0.1393 (0.979 sec/step)\n",
      "I0902 08:59:46.073516 139792788920128 learning.py:507] global step 40355: loss = 0.1046 (0.965 sec/step)\n",
      "I0902 08:59:47.029523 139792788920128 learning.py:507] global step 40356: loss = 0.0637 (0.955 sec/step)\n",
      "I0902 08:59:47.993666 139792788920128 learning.py:507] global step 40357: loss = 0.1445 (0.962 sec/step)\n",
      "I0902 08:59:48.990569 139792788920128 learning.py:507] global step 40358: loss = 0.1110 (0.995 sec/step)\n",
      "I0902 08:59:50.112410 139792788920128 learning.py:507] global step 40359: loss = 0.1200 (1.116 sec/step)\n",
      "I0902 08:59:50.431276 139778936784640 supervisor.py:1050] Recording summary at step 40359.\n",
      "I0902 08:59:51.210068 139792788920128 learning.py:507] global step 40360: loss = 0.0612 (1.095 sec/step)\n",
      "I0902 08:59:52.189522 139792788920128 learning.py:507] global step 40361: loss = 0.0845 (0.978 sec/step)\n",
      "I0902 08:59:53.156245 139792788920128 learning.py:507] global step 40362: loss = 0.1429 (0.965 sec/step)\n",
      "I0902 08:59:54.122635 139792788920128 learning.py:507] global step 40363: loss = 0.0829 (0.965 sec/step)\n",
      "I0902 08:59:55.084921 139792788920128 learning.py:507] global step 40364: loss = 0.2003 (0.961 sec/step)\n",
      "I0902 08:59:56.055740 139792788920128 learning.py:507] global step 40365: loss = 0.1423 (0.969 sec/step)\n",
      "I0902 08:59:57.055702 139792788920128 learning.py:507] global step 40366: loss = 0.0938 (0.999 sec/step)\n",
      "I0902 08:59:58.025447 139792788920128 learning.py:507] global step 40367: loss = 0.1237 (0.968 sec/step)\n",
      "I0902 08:59:59.002748 139792788920128 learning.py:507] global step 40368: loss = 0.0471 (0.976 sec/step)\n",
      "I0902 08:59:59.970362 139792788920128 learning.py:507] global step 40369: loss = 0.1223 (0.966 sec/step)\n",
      "I0902 09:00:00.965527 139792788920128 learning.py:507] global step 40370: loss = 0.1389 (0.994 sec/step)\n",
      "I0902 09:00:01.932687 139792788920128 learning.py:507] global step 40371: loss = 0.2295 (0.966 sec/step)\n",
      "I0902 09:00:02.916166 139792788920128 learning.py:507] global step 40372: loss = 0.1226 (0.982 sec/step)\n",
      "I0902 09:00:03.904263 139792788920128 learning.py:507] global step 40373: loss = 0.1108 (0.986 sec/step)\n",
      "I0902 09:00:04.871515 139792788920128 learning.py:507] global step 40374: loss = 0.1218 (0.966 sec/step)\n",
      "I0902 09:00:05.849528 139792788920128 learning.py:507] global step 40375: loss = 0.1676 (0.976 sec/step)\n",
      "I0902 09:00:06.848365 139792788920128 learning.py:507] global step 40376: loss = 0.2589 (0.997 sec/step)\n",
      "I0902 09:00:07.823061 139792788920128 learning.py:507] global step 40377: loss = 0.0802 (0.973 sec/step)\n",
      "I0902 09:00:08.807746 139792788920128 learning.py:507] global step 40378: loss = 0.0573 (0.983 sec/step)\n",
      "I0902 09:00:09.778177 139792788920128 learning.py:507] global step 40379: loss = 0.1475 (0.969 sec/step)\n",
      "I0902 09:00:10.757364 139792788920128 learning.py:507] global step 40380: loss = 0.1742 (0.977 sec/step)\n",
      "I0902 09:00:11.757683 139792788920128 learning.py:507] global step 40381: loss = 0.1554 (0.999 sec/step)\n",
      "I0902 09:00:12.754910 139792788920128 learning.py:507] global step 40382: loss = 0.0734 (0.996 sec/step)\n",
      "I0902 09:00:13.734641 139792788920128 learning.py:507] global step 40383: loss = 0.0900 (0.978 sec/step)\n",
      "I0902 09:00:14.711645 139792788920128 learning.py:507] global step 40384: loss = 0.1614 (0.975 sec/step)\n",
      "I0902 09:00:15.669259 139792788920128 learning.py:507] global step 40385: loss = 0.2088 (0.956 sec/step)\n",
      "I0902 09:00:16.647180 139792788920128 learning.py:507] global step 40386: loss = 0.1440 (0.976 sec/step)\n",
      "I0902 09:00:17.625457 139792788920128 learning.py:507] global step 40387: loss = 0.1415 (0.977 sec/step)\n",
      "I0902 09:00:18.600215 139792788920128 learning.py:507] global step 40388: loss = 0.0867 (0.973 sec/step)\n",
      "I0902 09:00:19.584824 139792788920128 learning.py:507] global step 40389: loss = 0.1423 (0.983 sec/step)\n",
      "I0902 09:00:20.574824 139792788920128 learning.py:507] global step 40390: loss = 0.1335 (0.988 sec/step)\n",
      "I0902 09:00:21.547668 139792788920128 learning.py:507] global step 40391: loss = 0.0759 (0.971 sec/step)\n",
      "I0902 09:00:22.507236 139792788920128 learning.py:507] global step 40392: loss = 0.1056 (0.958 sec/step)\n",
      "I0902 09:00:23.495867 139792788920128 learning.py:507] global step 40393: loss = 0.1432 (0.987 sec/step)\n",
      "I0902 09:00:24.446982 139792788920128 learning.py:507] global step 40394: loss = 0.1819 (0.949 sec/step)\n",
      "I0902 09:00:25.403777 139792788920128 learning.py:507] global step 40395: loss = 0.0931 (0.955 sec/step)\n",
      "I0902 09:00:26.392023 139792788920128 learning.py:507] global step 40396: loss = 0.1501 (0.986 sec/step)\n",
      "I0902 09:00:27.338962 139792788920128 learning.py:507] global step 40397: loss = 0.0995 (0.945 sec/step)\n",
      "I0902 09:00:28.324330 139792788920128 learning.py:507] global step 40398: loss = 0.1396 (0.984 sec/step)\n",
      "I0902 09:00:29.292529 139792788920128 learning.py:507] global step 40399: loss = 0.0669 (0.967 sec/step)\n",
      "I0902 09:00:30.253769 139792788920128 learning.py:507] global step 40400: loss = 0.1381 (0.960 sec/step)\n",
      "I0902 09:00:31.262878 139792788920128 learning.py:507] global step 40401: loss = 0.2808 (1.008 sec/step)\n",
      "I0902 09:00:32.250865 139792788920128 learning.py:507] global step 40402: loss = 0.0961 (0.986 sec/step)\n",
      "I0902 09:00:33.239991 139792788920128 learning.py:507] global step 40403: loss = 0.1115 (0.987 sec/step)\n",
      "I0902 09:00:34.224741 139792788920128 learning.py:507] global step 40404: loss = 0.1297 (0.983 sec/step)\n",
      "I0902 09:00:35.211973 139792788920128 learning.py:507] global step 40405: loss = 0.1267 (0.986 sec/step)\n",
      "I0902 09:00:36.202769 139792788920128 learning.py:507] global step 40406: loss = 0.0747 (0.989 sec/step)\n",
      "I0902 09:00:37.177918 139792788920128 learning.py:507] global step 40407: loss = 0.0878 (0.974 sec/step)\n",
      "I0902 09:00:38.160376 139792788920128 learning.py:507] global step 40408: loss = 0.0876 (0.981 sec/step)\n",
      "I0902 09:00:39.133316 139792788920128 learning.py:507] global step 40409: loss = 0.1258 (0.971 sec/step)\n",
      "I0902 09:00:40.093226 139792788920128 learning.py:507] global step 40410: loss = 0.1146 (0.958 sec/step)\n",
      "I0902 09:00:41.050921 139792788920128 learning.py:507] global step 40411: loss = 0.0893 (0.956 sec/step)\n",
      "I0902 09:00:42.031830 139792788920128 learning.py:507] global step 40412: loss = 0.1954 (0.979 sec/step)\n",
      "I0902 09:00:43.005383 139792788920128 learning.py:507] global step 40413: loss = 0.1443 (0.972 sec/step)\n",
      "I0902 09:00:43.997747 139792788920128 learning.py:507] global step 40414: loss = 0.0916 (0.991 sec/step)\n",
      "I0902 09:00:45.013038 139792788920128 learning.py:507] global step 40415: loss = 0.1114 (1.014 sec/step)\n",
      "I0902 09:00:46.002127 139792788920128 learning.py:507] global step 40416: loss = 0.1072 (0.987 sec/step)\n",
      "I0902 09:00:46.993751 139792788920128 learning.py:507] global step 40417: loss = 0.1185 (0.990 sec/step)\n",
      "I0902 09:00:48.010445 139792788920128 learning.py:507] global step 40418: loss = 0.1005 (1.015 sec/step)\n",
      "I0902 09:00:48.992026 139792788920128 learning.py:507] global step 40419: loss = 0.3294 (0.980 sec/step)\n",
      "I0902 09:00:49.973938 139792788920128 learning.py:507] global step 40420: loss = 0.1799 (0.980 sec/step)\n",
      "I0902 09:00:50.945876 139792788920128 learning.py:507] global step 40421: loss = 0.1100 (0.970 sec/step)\n",
      "I0902 09:00:51.921627 139792788920128 learning.py:507] global step 40422: loss = 0.1123 (0.974 sec/step)\n",
      "I0902 09:00:52.909832 139792788920128 learning.py:507] global step 40423: loss = 0.1724 (0.986 sec/step)\n",
      "I0902 09:00:53.884309 139792788920128 learning.py:507] global step 40424: loss = 0.2503 (0.973 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:00:54.884140 139792788920128 learning.py:507] global step 40425: loss = 0.0700 (0.998 sec/step)\n",
      "I0902 09:00:55.902693 139792788920128 learning.py:507] global step 40426: loss = 0.1213 (1.017 sec/step)\n",
      "I0902 09:00:56.884737 139792788920128 learning.py:507] global step 40427: loss = 0.1569 (0.980 sec/step)\n",
      "I0902 09:00:57.862030 139792788920128 learning.py:507] global step 40428: loss = 0.1403 (0.976 sec/step)\n",
      "I0902 09:00:58.830122 139792788920128 learning.py:507] global step 40429: loss = 0.2206 (0.967 sec/step)\n",
      "I0902 09:00:59.814032 139792788920128 learning.py:507] global step 40430: loss = 0.3274 (0.982 sec/step)\n",
      "I0902 09:01:00.815544 139792788920128 learning.py:507] global step 40431: loss = 0.0819 (1.000 sec/step)\n",
      "I0902 09:01:01.793327 139792788920128 learning.py:507] global step 40432: loss = 0.1309 (0.976 sec/step)\n",
      "I0902 09:01:02.783433 139792788920128 learning.py:507] global step 40433: loss = 0.1541 (0.988 sec/step)\n",
      "I0902 09:01:03.784255 139792788920128 learning.py:507] global step 40434: loss = 0.1093 (0.999 sec/step)\n",
      "I0902 09:01:04.762898 139792788920128 learning.py:507] global step 40435: loss = 0.1130 (0.977 sec/step)\n",
      "I0902 09:01:05.748624 139792788920128 learning.py:507] global step 40436: loss = 0.1239 (0.984 sec/step)\n",
      "I0902 09:01:06.734184 139792788920128 learning.py:507] global step 40437: loss = 0.1727 (0.984 sec/step)\n",
      "I0902 09:01:07.719045 139792788920128 learning.py:507] global step 40438: loss = 0.0660 (0.983 sec/step)\n",
      "I0902 09:01:08.702718 139792788920128 learning.py:507] global step 40439: loss = 0.1456 (0.982 sec/step)\n",
      "I0902 09:01:09.669340 139792788920128 learning.py:507] global step 40440: loss = 0.1455 (0.965 sec/step)\n",
      "I0902 09:01:10.639321 139792788920128 learning.py:507] global step 40441: loss = 0.1122 (0.969 sec/step)\n",
      "I0902 09:01:11.613439 139792788920128 learning.py:507] global step 40442: loss = 0.1428 (0.973 sec/step)\n",
      "I0902 09:01:12.575288 139792788920128 learning.py:507] global step 40443: loss = 0.1959 (0.960 sec/step)\n",
      "I0902 09:01:13.557253 139792788920128 learning.py:507] global step 40444: loss = 0.1391 (0.980 sec/step)\n",
      "I0902 09:01:14.546165 139792788920128 learning.py:507] global step 40445: loss = 0.3247 (0.987 sec/step)\n",
      "I0902 09:01:15.515982 139792788920128 learning.py:507] global step 40446: loss = 0.1210 (0.968 sec/step)\n",
      "I0902 09:01:16.503575 139792788920128 learning.py:507] global step 40447: loss = 0.0784 (0.986 sec/step)\n",
      "I0902 09:01:17.498849 139792788920128 learning.py:507] global step 40448: loss = 0.1942 (0.994 sec/step)\n",
      "I0902 09:01:18.499682 139792788920128 learning.py:507] global step 40449: loss = 0.0904 (0.999 sec/step)\n",
      "I0902 09:01:19.453915 139792788920128 learning.py:507] global step 40450: loss = 0.0874 (0.953 sec/step)\n",
      "I0902 09:01:20.421521 139792788920128 learning.py:507] global step 40451: loss = 0.0624 (0.966 sec/step)\n",
      "I0902 09:01:21.398283 139792788920128 learning.py:507] global step 40452: loss = 0.1641 (0.975 sec/step)\n",
      "I0902 09:01:22.398448 139792788920128 learning.py:507] global step 40453: loss = 0.1021 (0.999 sec/step)\n",
      "I0902 09:01:23.378887 139792788920128 learning.py:507] global step 40454: loss = 0.0752 (0.979 sec/step)\n",
      "I0902 09:01:24.361234 139792788920128 learning.py:507] global step 40455: loss = 0.1182 (0.981 sec/step)\n",
      "I0902 09:01:25.344762 139792788920128 learning.py:507] global step 40456: loss = 0.1738 (0.982 sec/step)\n",
      "I0902 09:01:26.320823 139792788920128 learning.py:507] global step 40457: loss = 0.1966 (0.974 sec/step)\n",
      "I0902 09:01:27.299076 139792788920128 learning.py:507] global step 40458: loss = 0.0631 (0.977 sec/step)\n",
      "I0902 09:01:28.273321 139792788920128 learning.py:507] global step 40459: loss = 0.1164 (0.973 sec/step)\n",
      "I0902 09:01:29.235134 139792788920128 learning.py:507] global step 40460: loss = 0.0485 (0.960 sec/step)\n",
      "I0902 09:01:30.188548 139792788920128 learning.py:507] global step 40461: loss = 0.1206 (0.952 sec/step)\n",
      "I0902 09:01:31.161838 139792788920128 learning.py:507] global step 40462: loss = 0.0665 (0.972 sec/step)\n",
      "I0902 09:01:32.141061 139792788920128 learning.py:507] global step 40463: loss = 0.1465 (0.978 sec/step)\n",
      "I0902 09:01:33.116688 139792788920128 learning.py:507] global step 40464: loss = 0.1049 (0.974 sec/step)\n",
      "I0902 09:01:34.080897 139792788920128 learning.py:507] global step 40465: loss = 0.0897 (0.962 sec/step)\n",
      "I0902 09:01:35.080283 139792788920128 learning.py:507] global step 40466: loss = 0.0470 (0.998 sec/step)\n",
      "I0902 09:01:36.064882 139792788920128 learning.py:507] global step 40467: loss = 0.1607 (0.983 sec/step)\n",
      "I0902 09:01:37.042392 139792788920128 learning.py:507] global step 40468: loss = 0.1075 (0.976 sec/step)\n",
      "I0902 09:01:38.038621 139792788920128 learning.py:507] global step 40469: loss = 0.1967 (0.995 sec/step)\n",
      "I0902 09:01:39.024065 139792788920128 learning.py:507] global step 40470: loss = 0.0830 (0.984 sec/step)\n",
      "I0902 09:01:40.007730 139792788920128 learning.py:507] global step 40471: loss = 0.2064 (0.982 sec/step)\n",
      "I0902 09:01:40.977081 139792788920128 learning.py:507] global step 40472: loss = 0.1303 (0.968 sec/step)\n",
      "I0902 09:01:41.955780 139792788920128 learning.py:507] global step 40473: loss = 0.0729 (0.977 sec/step)\n",
      "I0902 09:01:42.934012 139792788920128 learning.py:507] global step 40474: loss = 0.1416 (0.977 sec/step)\n",
      "I0902 09:01:43.898938 139792788920128 learning.py:507] global step 40475: loss = 0.0611 (0.963 sec/step)\n",
      "I0902 09:01:44.866778 139792788920128 learning.py:507] global step 40476: loss = 0.2629 (0.966 sec/step)\n",
      "I0902 09:01:45.848831 139792788920128 learning.py:507] global step 40477: loss = 0.1553 (0.980 sec/step)\n",
      "I0902 09:01:46.851765 139792788920128 learning.py:507] global step 40478: loss = 0.1606 (1.001 sec/step)\n",
      "I0902 09:01:47.838145 139792788920128 learning.py:507] global step 40479: loss = 0.0503 (0.985 sec/step)\n",
      "I0902 09:01:48.806102 139792788920128 learning.py:507] global step 40480: loss = 0.0692 (0.966 sec/step)\n",
      "I0902 09:01:49.937093 139792788920128 learning.py:507] global step 40481: loss = 0.1223 (1.126 sec/step)\n",
      "I0902 09:01:50.255204 139778936784640 supervisor.py:1050] Recording summary at step 40481.\n",
      "I0902 09:01:51.039012 139792788920128 learning.py:507] global step 40482: loss = 0.1647 (1.097 sec/step)\n",
      "I0902 09:01:52.004169 139792788920128 learning.py:507] global step 40483: loss = 0.0933 (0.964 sec/step)\n",
      "I0902 09:01:52.972754 139792788920128 learning.py:507] global step 40484: loss = 0.1155 (0.967 sec/step)\n",
      "I0902 09:01:53.945144 139792788920128 learning.py:507] global step 40485: loss = 0.1867 (0.971 sec/step)\n",
      "I0902 09:01:54.922004 139792788920128 learning.py:507] global step 40486: loss = 0.0512 (0.975 sec/step)\n",
      "I0902 09:01:55.906115 139792788920128 learning.py:507] global step 40487: loss = 0.4307 (0.982 sec/step)\n",
      "I0902 09:01:56.882742 139792788920128 learning.py:507] global step 40488: loss = 0.0521 (0.975 sec/step)\n",
      "I0902 09:01:57.878516 139792788920128 learning.py:507] global step 40489: loss = 0.3139 (0.994 sec/step)\n",
      "I0902 09:01:58.861177 139792788920128 learning.py:507] global step 40490: loss = 0.1491 (0.981 sec/step)\n",
      "I0902 09:01:59.839080 139792788920128 learning.py:507] global step 40491: loss = 0.0957 (0.976 sec/step)\n",
      "I0902 09:02:00.818686 139792788920128 learning.py:507] global step 40492: loss = 0.1694 (0.978 sec/step)\n",
      "I0902 09:02:01.788009 139792788920128 learning.py:507] global step 40493: loss = 0.1290 (0.968 sec/step)\n",
      "I0902 09:02:02.756001 139792788920128 learning.py:507] global step 40494: loss = 0.1000 (0.966 sec/step)\n",
      "I0902 09:02:03.744768 139792788920128 learning.py:507] global step 40495: loss = 0.1074 (0.987 sec/step)\n",
      "I0902 09:02:04.722023 139792788920128 learning.py:507] global step 40496: loss = 0.1089 (0.976 sec/step)\n",
      "I0902 09:02:05.690591 139792788920128 learning.py:507] global step 40497: loss = 0.1521 (0.967 sec/step)\n",
      "I0902 09:02:06.697894 139792788920128 learning.py:507] global step 40498: loss = 0.1142 (1.006 sec/step)\n",
      "I0902 09:02:07.665501 139792788920128 learning.py:507] global step 40499: loss = 0.1681 (0.966 sec/step)\n",
      "I0902 09:02:08.634633 139792788920128 learning.py:507] global step 40500: loss = 0.1335 (0.967 sec/step)\n",
      "I0902 09:02:09.605461 139792788920128 learning.py:507] global step 40501: loss = 0.0488 (0.969 sec/step)\n",
      "I0902 09:02:10.602622 139792788920128 learning.py:507] global step 40502: loss = 0.2864 (0.995 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:02:11.588790 139792788920128 learning.py:507] global step 40503: loss = 0.1680 (0.984 sec/step)\n",
      "I0902 09:02:12.559998 139792788920128 learning.py:507] global step 40504: loss = 0.0877 (0.969 sec/step)\n",
      "I0902 09:02:13.556079 139792788920128 learning.py:507] global step 40505: loss = 0.2334 (0.994 sec/step)\n",
      "I0902 09:02:14.549470 139792788920128 learning.py:507] global step 40506: loss = 0.2301 (0.992 sec/step)\n",
      "I0902 09:02:15.536757 139792788920128 learning.py:507] global step 40507: loss = 0.0641 (0.986 sec/step)\n",
      "I0902 09:02:16.529885 139792788920128 learning.py:507] global step 40508: loss = 0.1053 (0.991 sec/step)\n",
      "I0902 09:02:17.502131 139792788920128 learning.py:507] global step 40509: loss = 0.0526 (0.971 sec/step)\n",
      "I0902 09:02:18.490866 139792788920128 learning.py:507] global step 40510: loss = 0.1578 (0.987 sec/step)\n",
      "I0902 09:02:19.471650 139792788920128 learning.py:507] global step 40511: loss = 0.1237 (0.979 sec/step)\n",
      "I0902 09:02:20.461911 139792788920128 learning.py:507] global step 40512: loss = 0.2563 (0.989 sec/step)\n",
      "I0902 09:02:21.443328 139792788920128 learning.py:507] global step 40513: loss = 0.0711 (0.980 sec/step)\n",
      "I0902 09:02:22.439314 139792788920128 learning.py:507] global step 40514: loss = 0.1293 (0.994 sec/step)\n",
      "I0902 09:02:23.411178 139792788920128 learning.py:507] global step 40515: loss = 0.0772 (0.970 sec/step)\n",
      "I0902 09:02:24.403512 139792788920128 learning.py:507] global step 40516: loss = 0.1393 (0.991 sec/step)\n",
      "I0902 09:02:25.369576 139792788920128 learning.py:507] global step 40517: loss = 0.0902 (0.964 sec/step)\n",
      "I0902 09:02:26.341731 139792788920128 learning.py:507] global step 40518: loss = 0.1326 (0.971 sec/step)\n",
      "I0902 09:02:27.298117 139792788920128 learning.py:507] global step 40519: loss = 0.0947 (0.955 sec/step)\n",
      "I0902 09:02:28.277986 139792788920128 learning.py:507] global step 40520: loss = 0.1169 (0.978 sec/step)\n",
      "I0902 09:02:29.238101 139792788920128 learning.py:507] global step 40521: loss = 0.2093 (0.958 sec/step)\n",
      "I0902 09:02:30.217334 139792788920128 learning.py:507] global step 40522: loss = 0.1380 (0.978 sec/step)\n",
      "I0902 09:02:31.184301 139792788920128 learning.py:507] global step 40523: loss = 0.1061 (0.965 sec/step)\n",
      "I0902 09:02:32.161402 139792788920128 learning.py:507] global step 40524: loss = 0.2264 (0.975 sec/step)\n",
      "I0902 09:02:33.116913 139792788920128 learning.py:507] global step 40525: loss = 0.1083 (0.954 sec/step)\n",
      "I0902 09:02:34.098415 139792788920128 learning.py:507] global step 40526: loss = 0.1238 (0.980 sec/step)\n",
      "I0902 09:02:35.088625 139792788920128 learning.py:507] global step 40527: loss = 0.0799 (0.989 sec/step)\n",
      "I0902 09:02:36.068046 139792788920128 learning.py:507] global step 40528: loss = 0.1252 (0.978 sec/step)\n",
      "I0902 09:02:37.023656 139792788920128 learning.py:507] global step 40529: loss = 0.0966 (0.954 sec/step)\n",
      "I0902 09:02:37.987892 139792788920128 learning.py:507] global step 40530: loss = 0.0677 (0.963 sec/step)\n",
      "I0902 09:02:38.982535 139792788920128 learning.py:507] global step 40531: loss = 0.0435 (0.993 sec/step)\n",
      "I0902 09:02:39.948365 139792788920128 learning.py:507] global step 40532: loss = 0.1008 (0.964 sec/step)\n",
      "I0902 09:02:40.923994 139792788920128 learning.py:507] global step 40533: loss = 0.1243 (0.974 sec/step)\n",
      "I0902 09:02:41.899787 139792788920128 learning.py:507] global step 40534: loss = 0.0870 (0.974 sec/step)\n",
      "I0902 09:02:42.874228 139792788920128 learning.py:507] global step 40535: loss = 0.1055 (0.973 sec/step)\n",
      "I0902 09:02:43.848465 139792788920128 learning.py:507] global step 40536: loss = 0.1177 (0.973 sec/step)\n",
      "I0902 09:02:44.843360 139792788920128 learning.py:507] global step 40537: loss = 0.2436 (0.993 sec/step)\n",
      "I0902 09:02:45.820544 139792788920128 learning.py:507] global step 40538: loss = 0.0875 (0.975 sec/step)\n",
      "I0902 09:02:46.806852 139792788920128 learning.py:507] global step 40539: loss = 0.1850 (0.985 sec/step)\n",
      "I0902 09:02:47.775832 139792788920128 learning.py:507] global step 40540: loss = 0.1165 (0.967 sec/step)\n",
      "I0902 09:02:48.756095 139792788920128 learning.py:507] global step 40541: loss = 0.2855 (0.978 sec/step)\n",
      "I0902 09:02:49.741740 139792788920128 learning.py:507] global step 40542: loss = 0.0736 (0.984 sec/step)\n",
      "I0902 09:02:50.729696 139792788920128 learning.py:507] global step 40543: loss = 0.1593 (0.986 sec/step)\n",
      "I0902 09:02:51.700592 139792788920128 learning.py:507] global step 40544: loss = 0.1593 (0.969 sec/step)\n",
      "I0902 09:02:52.686576 139792788920128 learning.py:507] global step 40545: loss = 0.1460 (0.984 sec/step)\n",
      "I0902 09:02:53.650300 139792788920128 learning.py:507] global step 40546: loss = 0.2860 (0.962 sec/step)\n",
      "I0902 09:02:54.625136 139792788920128 learning.py:507] global step 40547: loss = 0.1595 (0.973 sec/step)\n",
      "I0902 09:02:55.594999 139792788920128 learning.py:507] global step 40548: loss = 0.2462 (0.968 sec/step)\n",
      "I0902 09:02:56.583621 139792788920128 learning.py:507] global step 40549: loss = 0.0852 (0.987 sec/step)\n",
      "I0902 09:02:57.584174 139792788920128 learning.py:507] global step 40550: loss = 0.1595 (0.999 sec/step)\n",
      "I0902 09:02:58.560791 139792788920128 learning.py:507] global step 40551: loss = 0.1022 (0.975 sec/step)\n",
      "I0902 09:02:59.542998 139792788920128 learning.py:507] global step 40552: loss = 0.1665 (0.981 sec/step)\n",
      "I0902 09:03:00.512001 139792788920128 learning.py:507] global step 40553: loss = 0.1919 (0.967 sec/step)\n",
      "I0902 09:03:01.488643 139792788920128 learning.py:507] global step 40554: loss = 0.0910 (0.974 sec/step)\n",
      "I0902 09:03:02.464801 139792788920128 learning.py:507] global step 40555: loss = 0.1255 (0.975 sec/step)\n",
      "I0902 09:03:03.432083 139792788920128 learning.py:507] global step 40556: loss = 0.0503 (0.966 sec/step)\n",
      "I0902 09:03:04.384791 139792788920128 learning.py:507] global step 40557: loss = 0.0573 (0.951 sec/step)\n",
      "I0902 09:03:05.368245 139792788920128 learning.py:507] global step 40558: loss = 0.1248 (0.982 sec/step)\n",
      "I0902 09:03:06.362586 139792788920128 learning.py:507] global step 40559: loss = 0.1207 (0.993 sec/step)\n",
      "I0902 09:03:07.348920 139792788920128 learning.py:507] global step 40560: loss = 0.1372 (0.984 sec/step)\n",
      "I0902 09:03:08.327212 139792788920128 learning.py:507] global step 40561: loss = 0.0916 (0.976 sec/step)\n",
      "I0902 09:03:09.301159 139792788920128 learning.py:507] global step 40562: loss = 0.0973 (0.972 sec/step)\n",
      "I0902 09:03:10.283883 139792788920128 learning.py:507] global step 40563: loss = 0.1124 (0.981 sec/step)\n",
      "I0902 09:03:11.259484 139792788920128 learning.py:507] global step 40564: loss = 0.0797 (0.974 sec/step)\n",
      "I0902 09:03:12.256541 139792788920128 learning.py:507] global step 40565: loss = 0.1170 (0.995 sec/step)\n",
      "I0902 09:03:13.250144 139792788920128 learning.py:507] global step 40566: loss = 0.4176 (0.992 sec/step)\n",
      "I0902 09:03:14.257132 139792788920128 learning.py:507] global step 40567: loss = 0.1320 (1.005 sec/step)\n",
      "I0902 09:03:15.227058 139792788920128 learning.py:507] global step 40568: loss = 0.1024 (0.969 sec/step)\n",
      "I0902 09:03:16.202858 139792788920128 learning.py:507] global step 40569: loss = 0.0882 (0.974 sec/step)\n",
      "I0902 09:03:17.172107 139792788920128 learning.py:507] global step 40570: loss = 0.0931 (0.968 sec/step)\n",
      "I0902 09:03:18.130097 139792788920128 learning.py:507] global step 40571: loss = 0.1767 (0.956 sec/step)\n",
      "I0902 09:03:19.095343 139792788920128 learning.py:507] global step 40572: loss = 0.0992 (0.963 sec/step)\n",
      "I0902 09:03:20.068271 139792788920128 learning.py:507] global step 40573: loss = 0.1171 (0.971 sec/step)\n",
      "I0902 09:03:21.047531 139792788920128 learning.py:507] global step 40574: loss = 0.0811 (0.978 sec/step)\n",
      "I0902 09:03:22.024988 139792788920128 learning.py:507] global step 40575: loss = 0.0753 (0.976 sec/step)\n",
      "I0902 09:03:22.998224 139792788920128 learning.py:507] global step 40576: loss = 0.1734 (0.972 sec/step)\n",
      "I0902 09:03:23.990088 139792788920128 learning.py:507] global step 40577: loss = 0.1380 (0.990 sec/step)\n",
      "I0902 09:03:24.969028 139792788920128 learning.py:507] global step 40578: loss = 0.1408 (0.977 sec/step)\n",
      "I0902 09:03:25.953041 139792788920128 learning.py:507] global step 40579: loss = 0.1231 (0.982 sec/step)\n",
      "I0902 09:03:26.931158 139792788920128 learning.py:507] global step 40580: loss = 0.1843 (0.976 sec/step)\n",
      "I0902 09:03:27.911705 139792788920128 learning.py:507] global step 40581: loss = 0.0872 (0.979 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:03:28.883318 139792788920128 learning.py:507] global step 40582: loss = 0.1680 (0.970 sec/step)\n",
      "I0902 09:03:29.867255 139792788920128 learning.py:507] global step 40583: loss = 0.0957 (0.983 sec/step)\n",
      "I0902 09:03:30.847985 139792788920128 learning.py:507] global step 40584: loss = 0.0809 (0.979 sec/step)\n",
      "I0902 09:03:31.836958 139792788920128 learning.py:507] global step 40585: loss = 0.0850 (0.987 sec/step)\n",
      "I0902 09:03:32.801702 139792788920128 learning.py:507] global step 40586: loss = 0.0967 (0.963 sec/step)\n",
      "I0902 09:03:33.784799 139792788920128 learning.py:507] global step 40587: loss = 0.1432 (0.981 sec/step)\n",
      "I0902 09:03:34.776408 139792788920128 learning.py:507] global step 40588: loss = 0.1157 (0.990 sec/step)\n",
      "I0902 09:03:35.748235 139792788920128 learning.py:507] global step 40589: loss = 0.3779 (0.970 sec/step)\n",
      "I0902 09:03:36.720859 139792788920128 learning.py:507] global step 40590: loss = 0.1760 (0.971 sec/step)\n",
      "I0902 09:03:37.686424 139792788920128 learning.py:507] global step 40591: loss = 0.1624 (0.964 sec/step)\n",
      "I0902 09:03:38.687009 139792788920128 learning.py:507] global step 40592: loss = 0.0780 (0.999 sec/step)\n",
      "I0902 09:03:39.662126 139792788920128 learning.py:507] global step 40593: loss = 0.1085 (0.973 sec/step)\n",
      "I0902 09:03:40.640794 139792788920128 learning.py:507] global step 40594: loss = 0.2510 (0.977 sec/step)\n",
      "I0902 09:03:41.614586 139792788920128 learning.py:507] global step 40595: loss = 0.1897 (0.972 sec/step)\n",
      "I0902 09:03:42.606204 139792788920128 learning.py:507] global step 40596: loss = 0.0762 (0.990 sec/step)\n",
      "I0902 09:03:43.599465 139792788920128 learning.py:507] global step 40597: loss = 0.1162 (0.992 sec/step)\n",
      "I0902 09:03:44.587911 139792788920128 learning.py:507] global step 40598: loss = 0.0555 (0.987 sec/step)\n",
      "I0902 09:03:45.603039 139792788920128 learning.py:507] global step 40599: loss = 0.1463 (1.013 sec/step)\n",
      "I0902 09:03:46.570030 139792788920128 learning.py:507] global step 40600: loss = 0.3172 (0.965 sec/step)\n",
      "I0902 09:03:47.562601 139792788920128 learning.py:507] global step 40601: loss = 0.1160 (0.991 sec/step)\n",
      "I0902 09:03:48.561022 139792788920128 learning.py:507] global step 40602: loss = 0.0966 (0.997 sec/step)\n",
      "I0902 09:03:49.270345 139778953570048 supervisor.py:1117] Saving checkpoint to path data_dir/mixed_experiment/checkpoints_v2/model.ckpt\n",
      "I0902 09:03:49.555338 139792788920128 learning.py:507] global step 40603: loss = 0.1622 (0.981 sec/step)\n",
      "I0902 09:03:50.173414 139778936784640 supervisor.py:1050] Recording summary at step 40603.\n",
      "I0902 09:03:50.786305 139792788920128 learning.py:507] global step 40604: loss = 0.1560 (1.228 sec/step)\n",
      "I0902 09:03:51.779483 139792788920128 learning.py:507] global step 40605: loss = 0.1292 (0.992 sec/step)\n",
      "I0902 09:03:52.752243 139792788920128 learning.py:507] global step 40606: loss = 0.1653 (0.971 sec/step)\n",
      "I0902 09:03:53.715711 139792788920128 learning.py:507] global step 40607: loss = 0.0768 (0.962 sec/step)\n",
      "I0902 09:03:54.680028 139792788920128 learning.py:507] global step 40608: loss = 0.0582 (0.963 sec/step)\n",
      "I0902 09:03:55.654168 139792788920128 learning.py:507] global step 40609: loss = 0.0771 (0.972 sec/step)\n",
      "I0902 09:03:56.623082 139792788920128 learning.py:507] global step 40610: loss = 0.1744 (0.967 sec/step)\n",
      "I0902 09:03:57.590846 139792788920128 learning.py:507] global step 40611: loss = 0.1846 (0.966 sec/step)\n",
      "I0902 09:03:58.547521 139792788920128 learning.py:507] global step 40612: loss = 0.1403 (0.955 sec/step)\n",
      "I0902 09:03:59.515081 139792788920128 learning.py:507] global step 40613: loss = 0.1983 (0.966 sec/step)\n",
      "I0902 09:04:00.495667 139792788920128 learning.py:507] global step 40614: loss = 0.0997 (0.979 sec/step)\n",
      "I0902 09:04:01.498483 139792788920128 learning.py:507] global step 40615: loss = 0.1850 (1.002 sec/step)\n",
      "I0902 09:04:02.477317 139792788920128 learning.py:507] global step 40616: loss = 0.0643 (0.978 sec/step)\n",
      "I0902 09:04:03.445270 139792788920128 learning.py:507] global step 40617: loss = 0.1675 (0.967 sec/step)\n",
      "I0902 09:04:04.430122 139792788920128 learning.py:507] global step 40618: loss = 0.2001 (0.984 sec/step)\n",
      "I0902 09:04:05.405023 139792788920128 learning.py:507] global step 40619: loss = 0.0851 (0.973 sec/step)\n",
      "I0902 09:04:06.389712 139792788920128 learning.py:507] global step 40620: loss = 0.0771 (0.983 sec/step)\n",
      "I0902 09:04:07.377644 139792788920128 learning.py:507] global step 40621: loss = 0.0939 (0.987 sec/step)\n",
      "I0902 09:04:08.342059 139792788920128 learning.py:507] global step 40622: loss = 0.1040 (0.963 sec/step)\n",
      "I0902 09:04:09.324857 139792788920128 learning.py:507] global step 40623: loss = 0.0588 (0.981 sec/step)\n",
      "I0902 09:04:10.290197 139792788920128 learning.py:507] global step 40624: loss = 0.1459 (0.964 sec/step)\n",
      "I0902 09:04:11.251137 139792788920128 learning.py:507] global step 40625: loss = 0.1315 (0.960 sec/step)\n",
      "I0902 09:04:12.208693 139792788920128 learning.py:507] global step 40626: loss = 0.2127 (0.956 sec/step)\n",
      "I0902 09:04:13.191575 139792788920128 learning.py:507] global step 40627: loss = 0.0838 (0.981 sec/step)\n",
      "I0902 09:04:14.155638 139792788920128 learning.py:507] global step 40628: loss = 0.1257 (0.962 sec/step)\n",
      "I0902 09:04:15.126775 139792788920128 learning.py:507] global step 40629: loss = 0.1084 (0.970 sec/step)\n",
      "I0902 09:04:16.083020 139792788920128 learning.py:507] global step 40630: loss = 0.1039 (0.955 sec/step)\n",
      "I0902 09:04:17.067312 139792788920128 learning.py:507] global step 40631: loss = 0.1466 (0.983 sec/step)\n",
      "I0902 09:04:18.055658 139792788920128 learning.py:507] global step 40632: loss = 0.1095 (0.987 sec/step)\n",
      "I0902 09:04:19.029703 139792788920128 learning.py:507] global step 40633: loss = 0.0535 (0.973 sec/step)\n",
      "I0902 09:04:19.982111 139792788920128 learning.py:507] global step 40634: loss = 0.1139 (0.951 sec/step)\n",
      "I0902 09:04:20.936216 139792788920128 learning.py:507] global step 40635: loss = 0.3439 (0.953 sec/step)\n",
      "I0902 09:04:21.918614 139792788920128 learning.py:507] global step 40636: loss = 0.1415 (0.981 sec/step)\n",
      "I0902 09:04:22.906445 139792788920128 learning.py:507] global step 40637: loss = 0.0859 (0.986 sec/step)\n",
      "I0902 09:04:23.905767 139792788920128 learning.py:507] global step 40638: loss = 0.1259 (0.998 sec/step)\n",
      "I0902 09:04:24.878320 139792788920128 learning.py:507] global step 40639: loss = 0.4243 (0.971 sec/step)\n",
      "I0902 09:04:25.853556 139792788920128 learning.py:507] global step 40640: loss = 0.0674 (0.974 sec/step)\n",
      "I0902 09:04:26.844855 139792788920128 learning.py:507] global step 40641: loss = 0.2161 (0.990 sec/step)\n",
      "I0902 09:04:27.827748 139792788920128 learning.py:507] global step 40642: loss = 0.1897 (0.982 sec/step)\n",
      "I0902 09:04:28.800572 139792788920128 learning.py:507] global step 40643: loss = 0.1862 (0.971 sec/step)\n",
      "I0902 09:04:29.787553 139792788920128 learning.py:507] global step 40644: loss = 0.0715 (0.985 sec/step)\n",
      "I0902 09:04:30.768094 139792788920128 learning.py:507] global step 40645: loss = 0.1664 (0.979 sec/step)\n",
      "I0902 09:04:31.740554 139792788920128 learning.py:507] global step 40646: loss = 0.1406 (0.971 sec/step)\n",
      "I0902 09:04:32.711986 139792788920128 learning.py:507] global step 40647: loss = 0.1228 (0.970 sec/step)\n",
      "I0902 09:04:33.673350 139792788920128 learning.py:507] global step 40648: loss = 0.3019 (0.960 sec/step)\n",
      "I0902 09:04:34.648512 139792788920128 learning.py:507] global step 40649: loss = 0.0821 (0.973 sec/step)\n",
      "I0902 09:04:35.619029 139792788920128 learning.py:507] global step 40650: loss = 0.1121 (0.969 sec/step)\n",
      "I0902 09:04:36.607298 139792788920128 learning.py:507] global step 40651: loss = 0.1620 (0.987 sec/step)\n",
      "I0902 09:04:37.587457 139792788920128 learning.py:507] global step 40652: loss = 0.0643 (0.979 sec/step)\n",
      "I0902 09:04:38.570879 139792788920128 learning.py:507] global step 40653: loss = 0.0923 (0.982 sec/step)\n",
      "I0902 09:04:39.555002 139792788920128 learning.py:507] global step 40654: loss = 0.1067 (0.982 sec/step)\n",
      "I0902 09:04:40.535968 139792788920128 learning.py:507] global step 40655: loss = 0.2394 (0.979 sec/step)\n",
      "I0902 09:04:41.505395 139792788920128 learning.py:507] global step 40656: loss = 0.2055 (0.968 sec/step)\n",
      "I0902 09:04:42.493342 139792788920128 learning.py:507] global step 40657: loss = 0.1014 (0.986 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:04:43.478777 139792788920128 learning.py:507] global step 40658: loss = 0.0918 (0.984 sec/step)\n",
      "I0902 09:04:44.458394 139792788920128 learning.py:507] global step 40659: loss = 0.0896 (0.978 sec/step)\n",
      "I0902 09:04:45.429300 139792788920128 learning.py:507] global step 40660: loss = 0.0986 (0.969 sec/step)\n",
      "I0902 09:04:46.397680 139792788920128 learning.py:507] global step 40661: loss = 0.1179 (0.967 sec/step)\n",
      "I0902 09:04:47.391551 139792788920128 learning.py:507] global step 40662: loss = 0.1218 (0.992 sec/step)\n",
      "I0902 09:04:48.401784 139792788920128 learning.py:507] global step 40663: loss = 0.2435 (1.009 sec/step)\n",
      "I0902 09:04:49.366552 139792788920128 learning.py:507] global step 40664: loss = 0.0662 (0.963 sec/step)\n",
      "I0902 09:04:50.342495 139792788920128 learning.py:507] global step 40665: loss = 0.0457 (0.974 sec/step)\n",
      "I0902 09:04:51.301203 139792788920128 learning.py:507] global step 40666: loss = 0.1212 (0.957 sec/step)\n",
      "I0902 09:04:52.251621 139792788920128 learning.py:507] global step 40667: loss = 0.1767 (0.949 sec/step)\n",
      "I0902 09:04:53.240372 139792788920128 learning.py:507] global step 40668: loss = 0.0954 (0.987 sec/step)\n",
      "I0902 09:04:54.229584 139792788920128 learning.py:507] global step 40669: loss = 0.1147 (0.987 sec/step)\n",
      "I0902 09:04:55.208586 139792788920128 learning.py:507] global step 40670: loss = 0.1185 (0.977 sec/step)\n",
      "I0902 09:04:56.177320 139792788920128 learning.py:507] global step 40671: loss = 0.1223 (0.967 sec/step)\n",
      "I0902 09:04:57.153723 139792788920128 learning.py:507] global step 40672: loss = 0.1604 (0.975 sec/step)\n",
      "I0902 09:04:58.131669 139792788920128 learning.py:507] global step 40673: loss = 0.1005 (0.976 sec/step)\n",
      "I0902 09:04:59.097513 139792788920128 learning.py:507] global step 40674: loss = 0.2514 (0.964 sec/step)\n",
      "I0902 09:05:00.088262 139792788920128 learning.py:507] global step 40675: loss = 0.1128 (0.989 sec/step)\n",
      "I0902 09:05:01.060255 139792788920128 learning.py:507] global step 40676: loss = 0.0685 (0.970 sec/step)\n",
      "I0902 09:05:02.029054 139792788920128 learning.py:507] global step 40677: loss = 0.0577 (0.967 sec/step)\n",
      "I0902 09:05:02.975198 139792788920128 learning.py:507] global step 40678: loss = 0.0910 (0.945 sec/step)\n",
      "I0902 09:05:03.959355 139792788920128 learning.py:507] global step 40679: loss = 0.1604 (0.982 sec/step)\n",
      "I0902 09:05:04.913738 139792788920128 learning.py:507] global step 40680: loss = 0.2599 (0.953 sec/step)\n",
      "I0902 09:05:05.877154 139792788920128 learning.py:507] global step 40681: loss = 0.1631 (0.962 sec/step)\n",
      "I0902 09:05:06.860838 139792788920128 learning.py:507] global step 40682: loss = 0.0520 (0.982 sec/step)\n",
      "I0902 09:05:07.847030 139792788920128 learning.py:507] global step 40683: loss = 0.0981 (0.985 sec/step)\n",
      "I0902 09:05:08.836046 139792788920128 learning.py:507] global step 40684: loss = 0.0829 (0.987 sec/step)\n",
      "I0902 09:05:09.807456 139792788920128 learning.py:507] global step 40685: loss = 0.0691 (0.970 sec/step)\n",
      "I0902 09:05:10.768331 139792788920128 learning.py:507] global step 40686: loss = 0.1603 (0.959 sec/step)\n",
      "I0902 09:05:11.735861 139792788920128 learning.py:507] global step 40687: loss = 0.1434 (0.966 sec/step)\n",
      "I0902 09:05:12.696133 139792788920128 learning.py:507] global step 40688: loss = 0.1678 (0.959 sec/step)\n",
      "I0902 09:05:13.659244 139792788920128 learning.py:507] global step 40689: loss = 0.0676 (0.961 sec/step)\n",
      "I0902 09:05:14.639409 139792788920128 learning.py:507] global step 40690: loss = 0.0896 (0.979 sec/step)\n",
      "I0902 09:05:15.632937 139792788920128 learning.py:507] global step 40691: loss = 0.1270 (0.992 sec/step)\n",
      "I0902 09:05:16.636834 139792788920128 learning.py:507] global step 40692: loss = 0.0714 (1.002 sec/step)\n",
      "I0902 09:05:17.623970 139792788920128 learning.py:507] global step 40693: loss = 0.2720 (0.985 sec/step)\n",
      "I0902 09:05:18.593762 139792788920128 learning.py:507] global step 40694: loss = 0.1889 (0.968 sec/step)\n",
      "I0902 09:05:19.567726 139792788920128 learning.py:507] global step 40695: loss = 0.0873 (0.972 sec/step)\n",
      "I0902 09:05:20.572520 139792788920128 learning.py:507] global step 40696: loss = 0.0908 (1.003 sec/step)\n",
      "I0902 09:05:21.554478 139792788920128 learning.py:507] global step 40697: loss = 0.0634 (0.980 sec/step)\n",
      "I0902 09:05:22.527884 139792788920128 learning.py:507] global step 40698: loss = 0.1723 (0.972 sec/step)\n",
      "I0902 09:05:23.502363 139792788920128 learning.py:507] global step 40699: loss = 0.1398 (0.973 sec/step)\n",
      "I0902 09:05:24.469309 139792788920128 learning.py:507] global step 40700: loss = 0.1054 (0.965 sec/step)\n",
      "I0902 09:05:25.464084 139792788920128 learning.py:507] global step 40701: loss = 0.1706 (0.993 sec/step)\n",
      "I0902 09:05:26.425384 139792788920128 learning.py:507] global step 40702: loss = 0.0617 (0.960 sec/step)\n",
      "I0902 09:05:27.413328 139792788920128 learning.py:507] global step 40703: loss = 0.1117 (0.986 sec/step)\n",
      "I0902 09:05:28.390135 139792788920128 learning.py:507] global step 40704: loss = 0.1482 (0.975 sec/step)\n",
      "I0902 09:05:29.354871 139792788920128 learning.py:507] global step 40705: loss = 0.0742 (0.963 sec/step)\n",
      "I0902 09:05:30.337711 139792788920128 learning.py:507] global step 40706: loss = 0.1738 (0.981 sec/step)\n",
      "I0902 09:05:31.299559 139792788920128 learning.py:507] global step 40707: loss = 0.1099 (0.960 sec/step)\n",
      "I0902 09:05:32.270147 139792788920128 learning.py:507] global step 40708: loss = 0.1874 (0.969 sec/step)\n",
      "I0902 09:05:33.258136 139792788920128 learning.py:507] global step 40709: loss = 0.0595 (0.986 sec/step)\n",
      "I0902 09:05:34.242363 139792788920128 learning.py:507] global step 40710: loss = 0.1060 (0.982 sec/step)\n",
      "I0902 09:05:35.237862 139792788920128 learning.py:507] global step 40711: loss = 0.1470 (0.994 sec/step)\n",
      "I0902 09:05:36.212856 139792788920128 learning.py:507] global step 40712: loss = 0.2495 (0.973 sec/step)\n",
      "I0902 09:05:37.198077 139792788920128 learning.py:507] global step 40713: loss = 0.0815 (0.983 sec/step)\n",
      "I0902 09:05:38.177142 139792788920128 learning.py:507] global step 40714: loss = 0.1806 (0.977 sec/step)\n",
      "I0902 09:05:39.158262 139792788920128 learning.py:507] global step 40715: loss = 0.1078 (0.980 sec/step)\n",
      "I0902 09:05:40.120414 139792788920128 learning.py:507] global step 40716: loss = 0.1681 (0.960 sec/step)\n",
      "I0902 09:05:41.083140 139792788920128 learning.py:507] global step 40717: loss = 0.1362 (0.961 sec/step)\n",
      "I0902 09:05:42.076739 139792788920128 learning.py:507] global step 40718: loss = 0.1530 (0.992 sec/step)\n",
      "I0902 09:05:43.053482 139792788920128 learning.py:507] global step 40719: loss = 0.2095 (0.975 sec/step)\n",
      "I0902 09:05:44.012466 139792788920128 learning.py:507] global step 40720: loss = 0.1104 (0.957 sec/step)\n",
      "I0902 09:05:45.004301 139792788920128 learning.py:507] global step 40721: loss = 0.0675 (0.990 sec/step)\n",
      "I0902 09:05:46.018387 139792788920128 learning.py:507] global step 40722: loss = 0.2466 (1.012 sec/step)\n",
      "I0902 09:05:46.999009 139792788920128 learning.py:507] global step 40723: loss = 0.5200 (0.979 sec/step)\n",
      "I0902 09:05:47.956404 139792788920128 learning.py:507] global step 40724: loss = 0.1065 (0.956 sec/step)\n",
      "I0902 09:05:48.917618 139792788920128 learning.py:507] global step 40725: loss = 0.3357 (0.960 sec/step)\n",
      "I0902 09:05:50.066441 139792788920128 learning.py:507] global step 40726: loss = 0.1131 (1.145 sec/step)\n",
      "I0902 09:05:50.243199 139778936784640 supervisor.py:1050] Recording summary at step 40726.\n",
      "I0902 09:05:51.176756 139792788920128 learning.py:507] global step 40727: loss = 0.2319 (1.108 sec/step)\n",
      "I0902 09:05:52.147926 139792788920128 learning.py:507] global step 40728: loss = 0.0758 (0.970 sec/step)\n",
      "I0902 09:05:53.129287 139792788920128 learning.py:507] global step 40729: loss = 0.1806 (0.980 sec/step)\n",
      "I0902 09:05:54.109253 139792788920128 learning.py:507] global step 40730: loss = 0.0952 (0.978 sec/step)\n",
      "I0902 09:05:55.090357 139792788920128 learning.py:507] global step 40731: loss = 0.1334 (0.979 sec/step)\n",
      "I0902 09:05:56.066220 139792788920128 learning.py:507] global step 40732: loss = 0.1022 (0.974 sec/step)\n",
      "I0902 09:05:57.056270 139792788920128 learning.py:507] global step 40733: loss = 0.1746 (0.988 sec/step)\n",
      "I0902 09:05:58.046365 139792788920128 learning.py:507] global step 40734: loss = 0.1513 (0.989 sec/step)\n",
      "I0902 09:05:59.041906 139792788920128 learning.py:507] global step 40735: loss = 0.1809 (0.994 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:05:59.998290 139792788920128 learning.py:507] global step 40736: loss = 0.2732 (0.955 sec/step)\n",
      "I0902 09:06:00.988184 139792788920128 learning.py:507] global step 40737: loss = 0.0837 (0.988 sec/step)\n",
      "I0902 09:06:01.953572 139792788920128 learning.py:507] global step 40738: loss = 0.0763 (0.964 sec/step)\n",
      "I0902 09:06:02.936304 139792788920128 learning.py:507] global step 40739: loss = 0.0909 (0.981 sec/step)\n",
      "I0902 09:06:03.943740 139792788920128 learning.py:507] global step 40740: loss = 0.2289 (1.006 sec/step)\n",
      "I0902 09:06:04.922742 139792788920128 learning.py:507] global step 40741: loss = 0.0711 (0.977 sec/step)\n",
      "I0902 09:06:05.892760 139792788920128 learning.py:507] global step 40742: loss = 0.1180 (0.968 sec/step)\n",
      "I0902 09:06:06.869979 139792788920128 learning.py:507] global step 40743: loss = 0.1200 (0.976 sec/step)\n",
      "I0902 09:06:07.830899 139792788920128 learning.py:507] global step 40744: loss = 0.1964 (0.959 sec/step)\n",
      "I0902 09:06:08.789491 139792788920128 learning.py:507] global step 40745: loss = 0.0690 (0.957 sec/step)\n",
      "I0902 09:06:09.762796 139792788920128 learning.py:507] global step 40746: loss = 0.0655 (0.972 sec/step)\n",
      "I0902 09:06:10.727465 139792788920128 learning.py:507] global step 40747: loss = 0.1128 (0.963 sec/step)\n",
      "I0902 09:06:11.690838 139792788920128 learning.py:507] global step 40748: loss = 0.1008 (0.962 sec/step)\n",
      "I0902 09:06:12.658836 139792788920128 learning.py:507] global step 40749: loss = 0.0694 (0.966 sec/step)\n",
      "I0902 09:06:13.630706 139792788920128 learning.py:507] global step 40750: loss = 0.1517 (0.970 sec/step)\n",
      "I0902 09:06:14.612320 139792788920128 learning.py:507] global step 40751: loss = 0.1041 (0.980 sec/step)\n",
      "I0902 09:06:15.574500 139792788920128 learning.py:507] global step 40752: loss = 0.1310 (0.960 sec/step)\n",
      "I0902 09:06:16.536913 139792788920128 learning.py:507] global step 40753: loss = 0.0979 (0.961 sec/step)\n",
      "I0902 09:06:17.518510 139792788920128 learning.py:507] global step 40754: loss = 0.0975 (0.980 sec/step)\n",
      "I0902 09:06:18.481223 139792788920128 learning.py:507] global step 40755: loss = 0.0994 (0.961 sec/step)\n",
      "I0902 09:06:19.437702 139792788920128 learning.py:507] global step 40756: loss = 0.1620 (0.955 sec/step)\n",
      "I0902 09:06:20.416526 139792788920128 learning.py:507] global step 40757: loss = 0.0901 (0.977 sec/step)\n",
      "I0902 09:06:21.392506 139792788920128 learning.py:507] global step 40758: loss = 0.1365 (0.974 sec/step)\n",
      "I0902 09:06:22.358589 139792788920128 learning.py:507] global step 40759: loss = 0.1588 (0.965 sec/step)\n",
      "I0902 09:06:23.324481 139792788920128 learning.py:507] global step 40760: loss = 0.0766 (0.965 sec/step)\n",
      "I0902 09:06:24.291612 139792788920128 learning.py:507] global step 40761: loss = 0.1420 (0.966 sec/step)\n",
      "I0902 09:06:25.285346 139792788920128 learning.py:507] global step 40762: loss = 0.3004 (0.992 sec/step)\n",
      "I0902 09:06:26.260250 139792788920128 learning.py:507] global step 40763: loss = 0.1939 (0.973 sec/step)\n",
      "I0902 09:06:27.245428 139792788920128 learning.py:507] global step 40764: loss = 0.1786 (0.984 sec/step)\n",
      "I0902 09:06:28.240475 139792788920128 learning.py:507] global step 40765: loss = 0.1061 (0.993 sec/step)\n",
      "I0902 09:06:29.205579 139792788920128 learning.py:507] global step 40766: loss = 0.0697 (0.964 sec/step)\n",
      "I0902 09:06:30.195098 139792788920128 learning.py:507] global step 40767: loss = 0.1166 (0.988 sec/step)\n",
      "I0902 09:06:31.176516 139792788920128 learning.py:507] global step 40768: loss = 0.1698 (0.980 sec/step)\n",
      "I0902 09:06:32.149534 139792788920128 learning.py:507] global step 40769: loss = 0.0990 (0.971 sec/step)\n",
      "I0902 09:06:33.118872 139792788920128 learning.py:507] global step 40770: loss = 0.1584 (0.968 sec/step)\n",
      "I0902 09:06:34.102864 139792788920128 learning.py:507] global step 40771: loss = 0.1258 (0.982 sec/step)\n",
      "I0902 09:06:35.088846 139792788920128 learning.py:507] global step 40772: loss = 0.0868 (0.984 sec/step)\n",
      "I0902 09:06:36.088620 139792788920128 learning.py:507] global step 40773: loss = 0.1026 (0.998 sec/step)\n",
      "I0902 09:06:37.077251 139792788920128 learning.py:507] global step 40774: loss = 0.1078 (0.987 sec/step)\n",
      "I0902 09:06:38.070865 139792788920128 learning.py:507] global step 40775: loss = 0.1258 (0.992 sec/step)\n",
      "I0902 09:06:39.064232 139792788920128 learning.py:507] global step 40776: loss = 0.0564 (0.992 sec/step)\n",
      "I0902 09:06:40.041618 139792788920128 learning.py:507] global step 40777: loss = 0.1121 (0.976 sec/step)\n",
      "I0902 09:06:41.029235 139792788920128 learning.py:507] global step 40778: loss = 0.0508 (0.986 sec/step)\n",
      "I0902 09:06:42.015963 139792788920128 learning.py:507] global step 40779: loss = 0.1854 (0.985 sec/step)\n",
      "I0902 09:06:42.989687 139792788920128 learning.py:507] global step 40780: loss = 0.2576 (0.972 sec/step)\n",
      "I0902 09:06:43.950542 139792788920128 learning.py:507] global step 40781: loss = 0.0583 (0.959 sec/step)\n",
      "I0902 09:06:44.931578 139792788920128 learning.py:507] global step 40782: loss = 0.1671 (0.979 sec/step)\n",
      "I0902 09:06:45.898642 139792788920128 learning.py:507] global step 40783: loss = 0.0440 (0.965 sec/step)\n",
      "I0902 09:06:46.860040 139792788920128 learning.py:507] global step 40784: loss = 0.1020 (0.960 sec/step)\n",
      "I0902 09:06:47.830919 139792788920128 learning.py:507] global step 40785: loss = 0.0890 (0.970 sec/step)\n",
      "I0902 09:06:48.804824 139792788920128 learning.py:507] global step 40786: loss = 0.0500 (0.972 sec/step)\n",
      "I0902 09:06:49.782721 139792788920128 learning.py:507] global step 40787: loss = 0.1047 (0.976 sec/step)\n",
      "I0902 09:06:50.739397 139792788920128 learning.py:507] global step 40788: loss = 0.1483 (0.955 sec/step)\n",
      "I0902 09:06:51.713155 139792788920128 learning.py:507] global step 40789: loss = 0.0931 (0.972 sec/step)\n",
      "I0902 09:06:52.681840 139792788920128 learning.py:507] global step 40790: loss = 0.0890 (0.967 sec/step)\n",
      "I0902 09:06:53.639319 139792788920128 learning.py:507] global step 40791: loss = 0.1518 (0.956 sec/step)\n",
      "I0902 09:06:54.598425 139792788920128 learning.py:507] global step 40792: loss = 0.0891 (0.958 sec/step)\n",
      "I0902 09:06:55.566064 139792788920128 learning.py:507] global step 40793: loss = 0.1427 (0.966 sec/step)\n",
      "I0902 09:06:56.533648 139792788920128 learning.py:507] global step 40794: loss = 0.1429 (0.966 sec/step)\n",
      "I0902 09:06:57.487693 139792788920128 learning.py:507] global step 40795: loss = 0.2767 (0.952 sec/step)\n",
      "I0902 09:06:58.447980 139792788920128 learning.py:507] global step 40796: loss = 0.1338 (0.959 sec/step)\n",
      "I0902 09:06:59.425383 139792788920128 learning.py:507] global step 40797: loss = 0.1227 (0.976 sec/step)\n",
      "I0902 09:07:00.379986 139792788920128 learning.py:507] global step 40798: loss = 0.1047 (0.953 sec/step)\n",
      "I0902 09:07:01.360951 139792788920128 learning.py:507] global step 40799: loss = 0.2322 (0.979 sec/step)\n",
      "I0902 09:07:02.342729 139792788920128 learning.py:507] global step 40800: loss = 0.0842 (0.980 sec/step)\n",
      "I0902 09:07:03.308517 139792788920128 learning.py:507] global step 40801: loss = 0.3570 (0.964 sec/step)\n",
      "I0902 09:07:04.293331 139792788920128 learning.py:507] global step 40802: loss = 0.0845 (0.983 sec/step)\n",
      "I0902 09:07:05.239620 139792788920128 learning.py:507] global step 40803: loss = 0.2094 (0.945 sec/step)\n",
      "I0902 09:07:06.211513 139792788920128 learning.py:507] global step 40804: loss = 0.1266 (0.971 sec/step)\n",
      "I0902 09:07:07.183399 139792788920128 learning.py:507] global step 40805: loss = 0.1045 (0.971 sec/step)\n",
      "I0902 09:07:08.152227 139792788920128 learning.py:507] global step 40806: loss = 0.1719 (0.968 sec/step)\n",
      "I0902 09:07:09.117079 139792788920128 learning.py:507] global step 40807: loss = 0.0595 (0.963 sec/step)\n",
      "I0902 09:07:10.079557 139792788920128 learning.py:507] global step 40808: loss = 0.0888 (0.961 sec/step)\n",
      "I0902 09:07:11.065550 139792788920128 learning.py:507] global step 40809: loss = 0.1137 (0.984 sec/step)\n",
      "I0902 09:07:12.024184 139792788920128 learning.py:507] global step 40810: loss = 0.1267 (0.957 sec/step)\n",
      "I0902 09:07:12.982881 139792788920128 learning.py:507] global step 40811: loss = 0.1399 (0.957 sec/step)\n",
      "I0902 09:07:13.997607 139792788920128 learning.py:507] global step 40812: loss = 0.0537 (1.014 sec/step)\n",
      "I0902 09:07:14.984620 139792788920128 learning.py:507] global step 40813: loss = 0.1130 (0.986 sec/step)\n",
      "I0902 09:07:15.946618 139792788920128 learning.py:507] global step 40814: loss = 0.0507 (0.961 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:07:16.923855 139792788920128 learning.py:507] global step 40815: loss = 0.1765 (0.976 sec/step)\n",
      "I0902 09:07:17.910305 139792788920128 learning.py:507] global step 40816: loss = 0.1615 (0.985 sec/step)\n",
      "I0902 09:07:18.869670 139792788920128 learning.py:507] global step 40817: loss = 0.1358 (0.958 sec/step)\n",
      "I0902 09:07:19.851982 139792788920128 learning.py:507] global step 40818: loss = 0.1370 (0.981 sec/step)\n",
      "I0902 09:07:20.826336 139792788920128 learning.py:507] global step 40819: loss = 0.1785 (0.973 sec/step)\n",
      "I0902 09:07:21.787560 139792788920128 learning.py:507] global step 40820: loss = 0.1544 (0.960 sec/step)\n",
      "I0902 09:07:22.745557 139792788920128 learning.py:507] global step 40821: loss = 0.1329 (0.957 sec/step)\n",
      "I0902 09:07:23.718605 139792788920128 learning.py:507] global step 40822: loss = 0.0724 (0.972 sec/step)\n",
      "I0902 09:07:24.709053 139792788920128 learning.py:507] global step 40823: loss = 0.0840 (0.989 sec/step)\n",
      "I0902 09:07:25.677952 139792788920128 learning.py:507] global step 40824: loss = 0.1410 (0.967 sec/step)\n",
      "I0902 09:07:26.664710 139792788920128 learning.py:507] global step 40825: loss = 0.2064 (0.985 sec/step)\n",
      "I0902 09:07:27.638614 139792788920128 learning.py:507] global step 40826: loss = 0.1216 (0.973 sec/step)\n",
      "I0902 09:07:28.632562 139792788920128 learning.py:507] global step 40827: loss = 0.0724 (0.993 sec/step)\n",
      "I0902 09:07:29.617794 139792788920128 learning.py:507] global step 40828: loss = 0.3084 (0.984 sec/step)\n",
      "I0902 09:07:30.602150 139792788920128 learning.py:507] global step 40829: loss = 0.1117 (0.983 sec/step)\n",
      "I0902 09:07:31.569574 139792788920128 learning.py:507] global step 40830: loss = 0.1128 (0.966 sec/step)\n",
      "I0902 09:07:32.547958 139792788920128 learning.py:507] global step 40831: loss = 0.1289 (0.977 sec/step)\n",
      "I0902 09:07:33.502299 139792788920128 learning.py:507] global step 40832: loss = 0.0546 (0.952 sec/step)\n",
      "I0902 09:07:34.488994 139792788920128 learning.py:507] global step 40833: loss = 0.0550 (0.985 sec/step)\n",
      "I0902 09:07:35.484565 139792788920128 learning.py:507] global step 40834: loss = 0.1551 (0.994 sec/step)\n",
      "I0902 09:07:36.447549 139792788920128 learning.py:507] global step 40835: loss = 0.0865 (0.961 sec/step)\n",
      "I0902 09:07:37.424164 139792788920128 learning.py:507] global step 40836: loss = 0.1352 (0.975 sec/step)\n",
      "I0902 09:07:38.404320 139792788920128 learning.py:507] global step 40837: loss = 0.0783 (0.979 sec/step)\n",
      "I0902 09:07:39.395414 139792788920128 learning.py:507] global step 40838: loss = 0.1735 (0.989 sec/step)\n",
      "I0902 09:07:40.364202 139792788920128 learning.py:507] global step 40839: loss = 0.0714 (0.967 sec/step)\n",
      "I0902 09:07:41.334639 139792788920128 learning.py:507] global step 40840: loss = 0.1130 (0.969 sec/step)\n",
      "I0902 09:07:42.320693 139792788920128 learning.py:507] global step 40841: loss = 0.1352 (0.985 sec/step)\n",
      "I0902 09:07:43.309055 139792788920128 learning.py:507] global step 40842: loss = 0.3043 (0.987 sec/step)\n",
      "I0902 09:07:44.277525 139792788920128 learning.py:507] global step 40843: loss = 0.2386 (0.967 sec/step)\n",
      "I0902 09:07:45.257382 139792788920128 learning.py:507] global step 40844: loss = 0.1321 (0.978 sec/step)\n",
      "I0902 09:07:46.220968 139792788920128 learning.py:507] global step 40845: loss = 0.1642 (0.962 sec/step)\n",
      "I0902 09:07:47.179288 139792788920128 learning.py:507] global step 40846: loss = 0.1506 (0.957 sec/step)\n",
      "I0902 09:07:48.146122 139792788920128 learning.py:507] global step 40847: loss = 0.0981 (0.965 sec/step)\n",
      "I0902 09:07:49.109481 139792788920128 learning.py:507] global step 40848: loss = 0.0719 (0.962 sec/step)\n",
      "I0902 09:07:50.242746 139792788920128 learning.py:507] global step 40849: loss = 0.1458 (1.131 sec/step)\n",
      "I0902 09:07:50.375598 139778936784640 supervisor.py:1050] Recording summary at step 40849.\n",
      "I0902 09:07:51.299072 139792788920128 learning.py:507] global step 40850: loss = 0.1818 (1.054 sec/step)\n",
      "I0902 09:07:52.254902 139792788920128 learning.py:507] global step 40851: loss = 0.0548 (0.954 sec/step)\n",
      "I0902 09:07:53.238924 139792788920128 learning.py:507] global step 40852: loss = 0.1488 (0.983 sec/step)\n",
      "I0902 09:07:54.206457 139792788920128 learning.py:507] global step 40853: loss = 0.1419 (0.966 sec/step)\n",
      "I0902 09:07:55.165980 139792788920128 learning.py:507] global step 40854: loss = 0.1687 (0.958 sec/step)\n",
      "I0902 09:07:56.124165 139792788920128 learning.py:507] global step 40855: loss = 0.0793 (0.957 sec/step)\n",
      "I0902 09:07:57.091206 139792788920128 learning.py:507] global step 40856: loss = 0.1860 (0.965 sec/step)\n",
      "I0902 09:07:58.076200 139792788920128 learning.py:507] global step 40857: loss = 0.2519 (0.983 sec/step)\n",
      "I0902 09:07:59.049382 139792788920128 learning.py:507] global step 40858: loss = 0.1748 (0.972 sec/step)\n",
      "I0902 09:08:00.019112 139792788920128 learning.py:507] global step 40859: loss = 0.1153 (0.968 sec/step)\n",
      "I0902 09:08:00.992971 139792788920128 learning.py:507] global step 40860: loss = 0.1936 (0.972 sec/step)\n",
      "I0902 09:08:01.964002 139792788920128 learning.py:507] global step 40861: loss = 0.2170 (0.969 sec/step)\n",
      "I0902 09:08:02.943173 139792788920128 learning.py:507] global step 40862: loss = 0.1716 (0.978 sec/step)\n",
      "I0902 09:08:03.910156 139792788920128 learning.py:507] global step 40863: loss = 0.1211 (0.966 sec/step)\n",
      "I0902 09:08:04.871397 139792788920128 learning.py:507] global step 40864: loss = 0.2139 (0.960 sec/step)\n",
      "I0902 09:08:05.835024 139792788920128 learning.py:507] global step 40865: loss = 0.1230 (0.962 sec/step)\n",
      "I0902 09:08:06.807033 139792788920128 learning.py:507] global step 40866: loss = 0.1126 (0.970 sec/step)\n",
      "I0902 09:08:07.773278 139792788920128 learning.py:507] global step 40867: loss = 0.1131 (0.964 sec/step)\n",
      "I0902 09:08:08.721438 139792788920128 learning.py:507] global step 40868: loss = 0.1629 (0.947 sec/step)\n",
      "I0902 09:08:09.687534 139792788920128 learning.py:507] global step 40869: loss = 0.0684 (0.964 sec/step)\n",
      "I0902 09:08:10.651476 139792788920128 learning.py:507] global step 40870: loss = 0.1873 (0.962 sec/step)\n",
      "I0902 09:08:11.618177 139792788920128 learning.py:507] global step 40871: loss = 0.1482 (0.965 sec/step)\n",
      "I0902 09:08:12.592382 139792788920128 learning.py:507] global step 40872: loss = 0.2010 (0.972 sec/step)\n",
      "I0902 09:08:13.538908 139792788920128 learning.py:507] global step 40873: loss = 0.1540 (0.945 sec/step)\n",
      "I0902 09:08:14.506643 139792788920128 learning.py:507] global step 40874: loss = 0.0813 (0.966 sec/step)\n",
      "I0902 09:08:15.478375 139792788920128 learning.py:507] global step 40875: loss = 0.1318 (0.970 sec/step)\n",
      "I0902 09:08:16.418071 139792788920128 learning.py:507] global step 40876: loss = 0.1022 (0.938 sec/step)\n",
      "I0902 09:08:17.386935 139792788920128 learning.py:507] global step 40877: loss = 0.1603 (0.967 sec/step)\n",
      "I0902 09:08:18.344640 139792788920128 learning.py:507] global step 40878: loss = 0.1568 (0.956 sec/step)\n",
      "I0902 09:08:19.304737 139792788920128 learning.py:507] global step 40879: loss = 0.0664 (0.958 sec/step)\n",
      "I0902 09:08:20.256741 139792788920128 learning.py:507] global step 40880: loss = 0.1508 (0.950 sec/step)\n",
      "I0902 09:08:21.216866 139792788920128 learning.py:507] global step 40881: loss = 0.0933 (0.958 sec/step)\n",
      "I0902 09:08:22.170264 139792788920128 learning.py:507] global step 40882: loss = 0.1372 (0.952 sec/step)\n",
      "I0902 09:08:23.148908 139792788920128 learning.py:507] global step 40883: loss = 0.5741 (0.977 sec/step)\n",
      "I0902 09:08:24.121183 139792788920128 learning.py:507] global step 40884: loss = 0.1312 (0.971 sec/step)\n",
      "I0902 09:08:25.105038 139792788920128 learning.py:507] global step 40885: loss = 0.0528 (0.982 sec/step)\n",
      "I0902 09:08:26.061467 139792788920128 learning.py:507] global step 40886: loss = 0.0393 (0.955 sec/step)\n",
      "I0902 09:08:27.016806 139792788920128 learning.py:507] global step 40887: loss = 0.1152 (0.954 sec/step)\n",
      "I0902 09:08:27.969929 139792788920128 learning.py:507] global step 40888: loss = 0.0974 (0.952 sec/step)\n",
      "I0902 09:08:28.919388 139792788920128 learning.py:507] global step 40889: loss = 0.1710 (0.948 sec/step)\n",
      "I0902 09:08:29.876679 139792788920128 learning.py:507] global step 40890: loss = 0.1380 (0.956 sec/step)\n",
      "I0902 09:08:30.845873 139792788920128 learning.py:507] global step 40891: loss = 0.2347 (0.967 sec/step)\n",
      "I0902 09:08:31.828305 139792788920128 learning.py:507] global step 40892: loss = 0.1438 (0.981 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:08:32.796215 139792788920128 learning.py:507] global step 40893: loss = 0.1600 (0.966 sec/step)\n",
      "I0902 09:08:33.773383 139792788920128 learning.py:507] global step 40894: loss = 0.2667 (0.976 sec/step)\n",
      "I0902 09:08:34.737095 139792788920128 learning.py:507] global step 40895: loss = 0.1396 (0.962 sec/step)\n",
      "I0902 09:08:35.705396 139792788920128 learning.py:507] global step 40896: loss = 0.2863 (0.967 sec/step)\n",
      "I0902 09:08:36.664327 139792788920128 learning.py:507] global step 40897: loss = 0.1530 (0.958 sec/step)\n",
      "I0902 09:08:37.631748 139792788920128 learning.py:507] global step 40898: loss = 0.0950 (0.966 sec/step)\n",
      "I0902 09:08:38.593134 139792788920128 learning.py:507] global step 40899: loss = 0.2213 (0.960 sec/step)\n",
      "I0902 09:08:39.552630 139792788920128 learning.py:507] global step 40900: loss = 0.0644 (0.958 sec/step)\n",
      "I0902 09:08:40.529916 139792788920128 learning.py:507] global step 40901: loss = 0.2671 (0.976 sec/step)\n",
      "I0902 09:08:41.498572 139792788920128 learning.py:507] global step 40902: loss = 0.0934 (0.967 sec/step)\n",
      "I0902 09:08:42.475793 139792788920128 learning.py:507] global step 40903: loss = 0.1141 (0.975 sec/step)\n",
      "I0902 09:08:43.463112 139792788920128 learning.py:507] global step 40904: loss = 0.1245 (0.986 sec/step)\n",
      "I0902 09:08:44.441459 139792788920128 learning.py:507] global step 40905: loss = 0.1544 (0.977 sec/step)\n",
      "I0902 09:08:45.415302 139792788920128 learning.py:507] global step 40906: loss = 0.2189 (0.972 sec/step)\n",
      "I0902 09:08:46.399336 139792788920128 learning.py:507] global step 40907: loss = 0.3329 (0.983 sec/step)\n",
      "I0902 09:08:47.370535 139792788920128 learning.py:507] global step 40908: loss = 0.2184 (0.970 sec/step)\n",
      "I0902 09:08:48.347062 139792788920128 learning.py:507] global step 40909: loss = 0.0663 (0.975 sec/step)\n",
      "I0902 09:08:49.312016 139792788920128 learning.py:507] global step 40910: loss = 0.1785 (0.963 sec/step)\n",
      "I0902 09:08:50.282154 139792788920128 learning.py:507] global step 40911: loss = 0.0538 (0.968 sec/step)\n",
      "I0902 09:08:51.261971 139792788920128 learning.py:507] global step 40912: loss = 0.0619 (0.978 sec/step)\n",
      "I0902 09:08:52.248930 139792788920128 learning.py:507] global step 40913: loss = 0.1077 (0.985 sec/step)\n",
      "I0902 09:08:53.219372 139792788920128 learning.py:507] global step 40914: loss = 0.1638 (0.969 sec/step)\n",
      "I0902 09:08:54.191256 139792788920128 learning.py:507] global step 40915: loss = 0.2049 (0.970 sec/step)\n",
      "I0902 09:08:55.163660 139792788920128 learning.py:507] global step 40916: loss = 0.1577 (0.971 sec/step)\n",
      "I0902 09:08:56.143902 139792788920128 learning.py:507] global step 40917: loss = 0.1107 (0.979 sec/step)\n",
      "I0902 09:08:57.115926 139792788920128 learning.py:507] global step 40918: loss = 0.0754 (0.970 sec/step)\n",
      "I0902 09:08:58.092068 139792788920128 learning.py:507] global step 40919: loss = 0.2679 (0.975 sec/step)\n",
      "I0902 09:08:59.054521 139792788920128 learning.py:507] global step 40920: loss = 0.0951 (0.961 sec/step)\n",
      "I0902 09:09:00.001219 139792788920128 learning.py:507] global step 40921: loss = 0.1231 (0.945 sec/step)\n",
      "I0902 09:09:00.969116 139792788920128 learning.py:507] global step 40922: loss = 0.1397 (0.966 sec/step)\n",
      "I0902 09:09:01.944797 139792788920128 learning.py:507] global step 40923: loss = 0.1265 (0.974 sec/step)\n",
      "I0902 09:09:02.924468 139792788920128 learning.py:507] global step 40924: loss = 0.0915 (0.978 sec/step)\n",
      "I0902 09:09:03.904903 139792788920128 learning.py:507] global step 40925: loss = 0.1324 (0.979 sec/step)\n",
      "I0902 09:09:04.873307 139792788920128 learning.py:507] global step 40926: loss = 0.1655 (0.967 sec/step)\n",
      "I0902 09:09:05.845740 139792788920128 learning.py:507] global step 40927: loss = 0.1416 (0.971 sec/step)\n",
      "I0902 09:09:06.806487 139792788920128 learning.py:507] global step 40928: loss = 0.1063 (0.959 sec/step)\n",
      "I0902 09:09:07.771241 139792788920128 learning.py:507] global step 40929: loss = 0.1531 (0.963 sec/step)\n",
      "I0902 09:09:08.742458 139792788920128 learning.py:507] global step 40930: loss = 0.0965 (0.970 sec/step)\n",
      "I0902 09:09:09.699069 139792788920128 learning.py:507] global step 40931: loss = 0.2060 (0.955 sec/step)\n",
      "I0902 09:09:10.683999 139792788920128 learning.py:507] global step 40932: loss = 0.0984 (0.983 sec/step)\n",
      "I0902 09:09:11.647256 139792788920128 learning.py:507] global step 40933: loss = 0.2014 (0.961 sec/step)\n",
      "I0902 09:09:12.618639 139792788920128 learning.py:507] global step 40934: loss = 0.0837 (0.970 sec/step)\n",
      "I0902 09:09:13.581741 139792788920128 learning.py:507] global step 40935: loss = 0.1259 (0.961 sec/step)\n",
      "I0902 09:09:14.541186 139792788920128 learning.py:507] global step 40936: loss = 0.1431 (0.958 sec/step)\n",
      "I0902 09:09:15.504390 139792788920128 learning.py:507] global step 40937: loss = 0.2656 (0.962 sec/step)\n",
      "I0902 09:09:16.481207 139792788920128 learning.py:507] global step 40938: loss = 0.2505 (0.975 sec/step)\n",
      "I0902 09:09:17.448161 139792788920128 learning.py:507] global step 40939: loss = 0.1816 (0.965 sec/step)\n",
      "I0902 09:09:18.403394 139792788920128 learning.py:507] global step 40940: loss = 0.1319 (0.954 sec/step)\n",
      "I0902 09:09:19.383900 139792788920128 learning.py:507] global step 40941: loss = 0.0919 (0.979 sec/step)\n",
      "I0902 09:09:20.363686 139792788920128 learning.py:507] global step 40942: loss = 0.0979 (0.978 sec/step)\n",
      "I0902 09:09:21.313616 139792788920128 learning.py:507] global step 40943: loss = 0.1224 (0.949 sec/step)\n",
      "I0902 09:09:22.273072 139792788920128 learning.py:507] global step 40944: loss = 0.1429 (0.958 sec/step)\n",
      "I0902 09:09:23.224683 139792788920128 learning.py:507] global step 40945: loss = 0.1044 (0.950 sec/step)\n",
      "I0902 09:09:24.201038 139792788920128 learning.py:507] global step 40946: loss = 0.1827 (0.975 sec/step)\n",
      "I0902 09:09:25.182631 139792788920128 learning.py:507] global step 40947: loss = 0.1552 (0.980 sec/step)\n",
      "I0902 09:09:26.148710 139792788920128 learning.py:507] global step 40948: loss = 0.0783 (0.964 sec/step)\n",
      "I0902 09:09:27.107824 139792788920128 learning.py:507] global step 40949: loss = 0.1040 (0.958 sec/step)\n",
      "I0902 09:09:28.064969 139792788920128 learning.py:507] global step 40950: loss = 0.3001 (0.956 sec/step)\n",
      "I0902 09:09:29.019876 139792788920128 learning.py:507] global step 40951: loss = 0.1433 (0.953 sec/step)\n",
      "I0902 09:09:29.992816 139792788920128 learning.py:507] global step 40952: loss = 0.1461 (0.971 sec/step)\n",
      "I0902 09:09:30.945467 139792788920128 learning.py:507] global step 40953: loss = 0.0935 (0.951 sec/step)\n",
      "I0902 09:09:31.908338 139792788920128 learning.py:507] global step 40954: loss = 0.0570 (0.961 sec/step)\n",
      "I0902 09:09:32.880493 139792788920128 learning.py:507] global step 40955: loss = 0.1039 (0.970 sec/step)\n",
      "I0902 09:09:33.853551 139792788920128 learning.py:507] global step 40956: loss = 0.1381 (0.971 sec/step)\n",
      "I0902 09:09:34.805161 139792788920128 learning.py:507] global step 40957: loss = 0.2204 (0.950 sec/step)\n",
      "I0902 09:09:35.774034 139792788920128 learning.py:507] global step 40958: loss = 0.1553 (0.967 sec/step)\n",
      "I0902 09:09:36.733274 139792788920128 learning.py:507] global step 40959: loss = 0.0788 (0.957 sec/step)\n",
      "I0902 09:09:37.682541 139792788920128 learning.py:507] global step 40960: loss = 0.1484 (0.948 sec/step)\n",
      "I0902 09:09:38.656888 139792788920128 learning.py:507] global step 40961: loss = 0.1593 (0.973 sec/step)\n",
      "I0902 09:09:39.633096 139792788920128 learning.py:507] global step 40962: loss = 0.2997 (0.974 sec/step)\n",
      "I0902 09:09:40.594544 139792788920128 learning.py:507] global step 40963: loss = 0.0988 (0.960 sec/step)\n",
      "I0902 09:09:41.576926 139792788920128 learning.py:507] global step 40964: loss = 0.1768 (0.981 sec/step)\n",
      "I0902 09:09:42.555736 139792788920128 learning.py:507] global step 40965: loss = 0.0757 (0.977 sec/step)\n",
      "I0902 09:09:43.544128 139792788920128 learning.py:507] global step 40966: loss = 0.1423 (0.986 sec/step)\n",
      "I0902 09:09:44.505751 139792788920128 learning.py:507] global step 40967: loss = 0.1043 (0.960 sec/step)\n",
      "I0902 09:09:45.460701 139792788920128 learning.py:507] global step 40968: loss = 0.0761 (0.954 sec/step)\n",
      "I0902 09:09:46.423389 139792788920128 learning.py:507] global step 40969: loss = 0.2295 (0.961 sec/step)\n",
      "I0902 09:09:47.402602 139792788920128 learning.py:507] global step 40970: loss = 0.1698 (0.978 sec/step)\n",
      "I0902 09:09:48.365626 139792788920128 learning.py:507] global step 40971: loss = 0.0456 (0.961 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:09:49.349266 139792788920128 learning.py:507] global step 40972: loss = 0.0517 (0.972 sec/step)\n",
      "I0902 09:09:49.975291 139778936784640 supervisor.py:1050] Recording summary at step 40972.\n",
      "I0902 09:09:50.592773 139792788920128 learning.py:507] global step 40973: loss = 0.0831 (1.240 sec/step)\n",
      "I0902 09:09:51.547549 139792788920128 learning.py:507] global step 40974: loss = 0.2079 (0.953 sec/step)\n",
      "I0902 09:09:52.522123 139792788920128 learning.py:507] global step 40975: loss = 0.0630 (0.973 sec/step)\n",
      "I0902 09:09:53.478788 139792788920128 learning.py:507] global step 40976: loss = 0.0669 (0.955 sec/step)\n",
      "I0902 09:09:54.427605 139792788920128 learning.py:507] global step 40977: loss = 0.0861 (0.947 sec/step)\n",
      "I0902 09:09:55.399365 139792788920128 learning.py:507] global step 40978: loss = 0.1873 (0.970 sec/step)\n",
      "I0902 09:09:56.379313 139792788920128 learning.py:507] global step 40979: loss = 0.0559 (0.978 sec/step)\n",
      "I0902 09:09:57.347802 139792788920128 learning.py:507] global step 40980: loss = 0.1113 (0.967 sec/step)\n",
      "I0902 09:09:58.309813 139792788920128 learning.py:507] global step 40981: loss = 0.0807 (0.960 sec/step)\n",
      "I0902 09:09:59.303602 139792788920128 learning.py:507] global step 40982: loss = 0.1241 (0.992 sec/step)\n",
      "I0902 09:10:00.258004 139792788920128 learning.py:507] global step 40983: loss = 0.1277 (0.953 sec/step)\n",
      "I0902 09:10:01.218496 139792788920128 learning.py:507] global step 40984: loss = 0.1090 (0.959 sec/step)\n",
      "I0902 09:10:02.174422 139792788920128 learning.py:507] global step 40985: loss = 0.1303 (0.954 sec/step)\n",
      "I0902 09:10:03.153446 139792788920128 learning.py:507] global step 40986: loss = 0.1063 (0.977 sec/step)\n",
      "I0902 09:10:04.141502 139792788920128 learning.py:507] global step 40987: loss = 0.0659 (0.986 sec/step)\n",
      "I0902 09:10:05.099109 139792788920128 learning.py:507] global step 40988: loss = 0.0934 (0.956 sec/step)\n",
      "I0902 09:10:06.080720 139792788920128 learning.py:507] global step 40989: loss = 0.1875 (0.980 sec/step)\n",
      "I0902 09:10:07.038299 139792788920128 learning.py:507] global step 40990: loss = 0.1201 (0.956 sec/step)\n",
      "I0902 09:10:08.030674 139792788920128 learning.py:507] global step 40991: loss = 0.1002 (0.991 sec/step)\n",
      "I0902 09:10:08.974027 139792788920128 learning.py:507] global step 40992: loss = 0.0804 (0.942 sec/step)\n",
      "I0902 09:10:09.946485 139792788920128 learning.py:507] global step 40993: loss = 0.1094 (0.971 sec/step)\n",
      "I0902 09:10:10.917851 139792788920128 learning.py:507] global step 40994: loss = 0.0970 (0.970 sec/step)\n",
      "I0902 09:10:11.885586 139792788920128 learning.py:507] global step 40995: loss = 0.1668 (0.966 sec/step)\n",
      "I0902 09:10:12.851849 139792788920128 learning.py:507] global step 40996: loss = 0.1772 (0.965 sec/step)\n",
      "I0902 09:10:13.847071 139792788920128 learning.py:507] global step 40997: loss = 0.1210 (0.994 sec/step)\n",
      "I0902 09:10:14.830418 139792788920128 learning.py:507] global step 40998: loss = 0.3035 (0.982 sec/step)\n",
      "I0902 09:10:15.793496 139792788920128 learning.py:507] global step 40999: loss = 0.0977 (0.961 sec/step)\n",
      "I0902 09:10:16.784870 139792788920128 learning.py:507] global step 41000: loss = 0.0817 (0.989 sec/step)\n",
      "I0902 09:10:17.752070 139792788920128 learning.py:507] global step 41001: loss = 0.3057 (0.966 sec/step)\n",
      "I0902 09:10:18.718701 139792788920128 learning.py:507] global step 41002: loss = 0.1587 (0.965 sec/step)\n",
      "I0902 09:10:19.717811 139792788920128 learning.py:507] global step 41003: loss = 0.0634 (0.997 sec/step)\n",
      "I0902 09:10:20.673925 139792788920128 learning.py:507] global step 41004: loss = 0.0555 (0.955 sec/step)\n",
      "I0902 09:10:21.653846 139792788920128 learning.py:507] global step 41005: loss = 0.1654 (0.978 sec/step)\n",
      "I0902 09:10:22.609841 139792788920128 learning.py:507] global step 41006: loss = 0.1994 (0.954 sec/step)\n",
      "I0902 09:10:23.579834 139792788920128 learning.py:507] global step 41007: loss = 0.0787 (0.968 sec/step)\n",
      "I0902 09:10:24.540029 139792788920128 learning.py:507] global step 41008: loss = 0.0792 (0.958 sec/step)\n",
      "I0902 09:10:25.516179 139792788920128 learning.py:507] global step 41009: loss = 0.0991 (0.974 sec/step)\n",
      "I0902 09:10:26.471490 139792788920128 learning.py:507] global step 41010: loss = 0.1827 (0.954 sec/step)\n",
      "I0902 09:10:27.431796 139792788920128 learning.py:507] global step 41011: loss = 0.0703 (0.959 sec/step)\n",
      "I0902 09:10:28.384508 139792788920128 learning.py:507] global step 41012: loss = 0.1613 (0.951 sec/step)\n",
      "I0902 09:10:29.333826 139792788920128 learning.py:507] global step 41013: loss = 0.1725 (0.948 sec/step)\n",
      "I0902 09:10:30.306452 139792788920128 learning.py:507] global step 41014: loss = 0.1709 (0.971 sec/step)\n",
      "I0902 09:10:31.267538 139792788920128 learning.py:507] global step 41015: loss = 0.1132 (0.960 sec/step)\n",
      "I0902 09:10:32.239344 139792788920128 learning.py:507] global step 41016: loss = 0.1562 (0.971 sec/step)\n",
      "I0902 09:10:33.218358 139792788920128 learning.py:507] global step 41017: loss = 0.1469 (0.977 sec/step)\n",
      "I0902 09:10:34.192067 139792788920128 learning.py:507] global step 41018: loss = 0.1113 (0.972 sec/step)\n",
      "I0902 09:10:35.186320 139792788920128 learning.py:507] global step 41019: loss = 0.2271 (0.992 sec/step)\n",
      "I0902 09:10:36.159652 139792788920128 learning.py:507] global step 41020: loss = 0.1021 (0.972 sec/step)\n",
      "I0902 09:10:37.147531 139792788920128 learning.py:507] global step 41021: loss = 0.2175 (0.986 sec/step)\n",
      "I0902 09:10:38.111170 139792788920128 learning.py:507] global step 41022: loss = 0.1236 (0.962 sec/step)\n",
      "I0902 09:10:39.069390 139792788920128 learning.py:507] global step 41023: loss = 0.1439 (0.957 sec/step)\n",
      "I0902 09:10:40.045185 139792788920128 learning.py:507] global step 41024: loss = 0.0909 (0.974 sec/step)\n",
      "I0902 09:10:41.005332 139792788920128 learning.py:507] global step 41025: loss = 0.0969 (0.958 sec/step)\n",
      "I0902 09:10:41.979669 139792788920128 learning.py:507] global step 41026: loss = 0.0959 (0.973 sec/step)\n",
      "I0902 09:10:42.961208 139792788920128 learning.py:507] global step 41027: loss = 0.0780 (0.980 sec/step)\n",
      "I0902 09:10:43.938550 139792788920128 learning.py:507] global step 41028: loss = 0.1347 (0.976 sec/step)\n",
      "I0902 09:10:44.908551 139792788920128 learning.py:507] global step 41029: loss = 0.0801 (0.968 sec/step)\n",
      "I0902 09:10:45.886369 139792788920128 learning.py:507] global step 41030: loss = 0.0690 (0.976 sec/step)\n",
      "I0902 09:10:46.850522 139792788920128 learning.py:507] global step 41031: loss = 0.1109 (0.963 sec/step)\n",
      "I0902 09:10:47.815444 139792788920128 learning.py:507] global step 41032: loss = 0.1410 (0.963 sec/step)\n",
      "I0902 09:10:48.763630 139792788920128 learning.py:507] global step 41033: loss = 0.1195 (0.947 sec/step)\n",
      "I0902 09:10:49.737314 139792788920128 learning.py:507] global step 41034: loss = 0.2709 (0.972 sec/step)\n",
      "I0902 09:10:50.706691 139792788920128 learning.py:507] global step 41035: loss = 0.1274 (0.968 sec/step)\n",
      "I0902 09:10:51.672105 139792788920128 learning.py:507] global step 41036: loss = 0.0737 (0.964 sec/step)\n",
      "I0902 09:10:52.656561 139792788920128 learning.py:507] global step 41037: loss = 0.1214 (0.983 sec/step)\n",
      "I0902 09:10:53.616371 139792788920128 learning.py:507] global step 41038: loss = 0.1182 (0.958 sec/step)\n",
      "I0902 09:10:54.612415 139792788920128 learning.py:507] global step 41039: loss = 0.2242 (0.994 sec/step)\n",
      "I0902 09:10:55.567834 139792788920128 learning.py:507] global step 41040: loss = 0.1400 (0.954 sec/step)\n",
      "I0902 09:10:56.526827 139792788920128 learning.py:507] global step 41041: loss = 0.1893 (0.958 sec/step)\n",
      "I0902 09:10:57.531791 139792788920128 learning.py:507] global step 41042: loss = 0.1365 (1.003 sec/step)\n",
      "I0902 09:10:58.509817 139792788920128 learning.py:507] global step 41043: loss = 0.1067 (0.976 sec/step)\n",
      "I0902 09:10:59.497382 139792788920128 learning.py:507] global step 41044: loss = 0.1467 (0.986 sec/step)\n",
      "I0902 09:11:00.478190 139792788920128 learning.py:507] global step 41045: loss = 0.1449 (0.979 sec/step)\n",
      "I0902 09:11:01.453265 139792788920128 learning.py:507] global step 41046: loss = 0.0667 (0.973 sec/step)\n",
      "I0902 09:11:02.417086 139792788920128 learning.py:507] global step 41047: loss = 0.0912 (0.962 sec/step)\n",
      "I0902 09:11:03.383603 139792788920128 learning.py:507] global step 41048: loss = 0.0816 (0.965 sec/step)\n",
      "I0902 09:11:04.341823 139792788920128 learning.py:507] global step 41049: loss = 0.3039 (0.957 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:11:05.305490 139792788920128 learning.py:507] global step 41050: loss = 0.0938 (0.962 sec/step)\n",
      "I0902 09:11:06.265342 139792788920128 learning.py:507] global step 41051: loss = 0.1674 (0.958 sec/step)\n",
      "I0902 09:11:07.262830 139792788920128 learning.py:507] global step 41052: loss = 0.0538 (0.996 sec/step)\n",
      "I0902 09:11:08.228969 139792788920128 learning.py:507] global step 41053: loss = 0.1568 (0.965 sec/step)\n",
      "I0902 09:11:09.193511 139792788920128 learning.py:507] global step 41054: loss = 0.0632 (0.963 sec/step)\n",
      "I0902 09:11:10.169657 139792788920128 learning.py:507] global step 41055: loss = 0.1604 (0.974 sec/step)\n",
      "I0902 09:11:11.136655 139792788920128 learning.py:507] global step 41056: loss = 0.1390 (0.965 sec/step)\n",
      "I0902 09:11:12.109662 139792788920128 learning.py:507] global step 41057: loss = 0.1383 (0.972 sec/step)\n",
      "I0902 09:11:13.075270 139792788920128 learning.py:507] global step 41058: loss = 0.1533 (0.964 sec/step)\n",
      "I0902 09:11:14.096067 139792788920128 learning.py:507] global step 41059: loss = 0.1052 (1.019 sec/step)\n",
      "I0902 09:11:15.076484 139792788920128 learning.py:507] global step 41060: loss = 0.1717 (0.979 sec/step)\n",
      "I0902 09:11:16.036765 139792788920128 learning.py:507] global step 41061: loss = 0.0514 (0.959 sec/step)\n",
      "I0902 09:11:16.995264 139792788920128 learning.py:507] global step 41062: loss = 0.0484 (0.957 sec/step)\n",
      "I0902 09:11:17.972629 139792788920128 learning.py:507] global step 41063: loss = 0.1885 (0.976 sec/step)\n",
      "I0902 09:11:18.963079 139792788920128 learning.py:507] global step 41064: loss = 0.1349 (0.989 sec/step)\n",
      "I0902 09:11:19.928885 139792788920128 learning.py:507] global step 41065: loss = 0.1281 (0.965 sec/step)\n",
      "I0902 09:11:20.908487 139792788920128 learning.py:507] global step 41066: loss = 0.2035 (0.978 sec/step)\n",
      "I0902 09:11:21.907417 139792788920128 learning.py:507] global step 41067: loss = 0.1122 (0.997 sec/step)\n",
      "I0902 09:11:22.879830 139792788920128 learning.py:507] global step 41068: loss = 0.2751 (0.971 sec/step)\n",
      "I0902 09:11:23.856565 139792788920128 learning.py:507] global step 41069: loss = 0.1303 (0.975 sec/step)\n",
      "I0902 09:11:24.842961 139792788920128 learning.py:507] global step 41070: loss = 0.1334 (0.985 sec/step)\n",
      "I0902 09:11:25.789585 139792788920128 learning.py:507] global step 41071: loss = 0.0981 (0.946 sec/step)\n",
      "I0902 09:11:26.766334 139792788920128 learning.py:507] global step 41072: loss = 0.1111 (0.975 sec/step)\n",
      "I0902 09:11:27.763127 139792788920128 learning.py:507] global step 41073: loss = 0.0880 (0.995 sec/step)\n",
      "I0902 09:11:28.773011 139792788920128 learning.py:507] global step 41074: loss = 0.1279 (1.009 sec/step)\n",
      "I0902 09:11:29.742696 139792788920128 learning.py:507] global step 41075: loss = 0.1538 (0.969 sec/step)\n",
      "I0902 09:11:30.720344 139792788920128 learning.py:507] global step 41076: loss = 0.0796 (0.976 sec/step)\n",
      "I0902 09:11:31.689854 139792788920128 learning.py:507] global step 41077: loss = 0.0910 (0.968 sec/step)\n",
      "I0902 09:11:32.679328 139792788920128 learning.py:507] global step 41078: loss = 0.3591 (0.988 sec/step)\n",
      "I0902 09:11:33.687832 139792788920128 learning.py:507] global step 41079: loss = 0.1475 (1.007 sec/step)\n",
      "I0902 09:11:34.664366 139792788920128 learning.py:507] global step 41080: loss = 0.1009 (0.975 sec/step)\n",
      "I0902 09:11:35.637049 139792788920128 learning.py:507] global step 41081: loss = 0.0995 (0.971 sec/step)\n",
      "I0902 09:11:36.616769 139792788920128 learning.py:507] global step 41082: loss = 0.0785 (0.978 sec/step)\n",
      "I0902 09:11:37.596699 139792788920128 learning.py:507] global step 41083: loss = 0.1182 (0.978 sec/step)\n",
      "I0902 09:11:38.581505 139792788920128 learning.py:507] global step 41084: loss = 0.1259 (0.983 sec/step)\n",
      "I0902 09:11:39.555516 139792788920128 learning.py:507] global step 41085: loss = 0.1282 (0.972 sec/step)\n",
      "I0902 09:11:40.539337 139792788920128 learning.py:507] global step 41086: loss = 0.2199 (0.982 sec/step)\n",
      "I0902 09:11:41.493815 139792788920128 learning.py:507] global step 41087: loss = 0.1105 (0.953 sec/step)\n",
      "I0902 09:11:42.457016 139792788920128 learning.py:507] global step 41088: loss = 0.1329 (0.962 sec/step)\n",
      "I0902 09:11:43.412266 139792788920128 learning.py:507] global step 41089: loss = 0.1825 (0.953 sec/step)\n",
      "I0902 09:11:44.368191 139792788920128 learning.py:507] global step 41090: loss = 0.1532 (0.954 sec/step)\n",
      "I0902 09:11:45.324831 139792788920128 learning.py:507] global step 41091: loss = 0.1455 (0.955 sec/step)\n",
      "I0902 09:11:46.289206 139792788920128 learning.py:507] global step 41092: loss = 0.1613 (0.963 sec/step)\n",
      "I0902 09:11:47.264476 139792788920128 learning.py:507] global step 41093: loss = 0.2909 (0.974 sec/step)\n",
      "I0902 09:11:48.218251 139792788920128 learning.py:507] global step 41094: loss = 0.0449 (0.952 sec/step)\n",
      "I0902 09:11:49.196621 139792788920128 learning.py:507] global step 41095: loss = 0.1493 (0.977 sec/step)\n",
      "I0902 09:11:50.319807 139792788920128 learning.py:507] global step 41096: loss = 0.1290 (1.120 sec/step)\n",
      "I0902 09:11:50.473347 139778936784640 supervisor.py:1050] Recording summary at step 41096.\n",
      "I0902 09:11:51.392372 139792788920128 learning.py:507] global step 41097: loss = 0.0965 (1.071 sec/step)\n",
      "I0902 09:11:52.356628 139792788920128 learning.py:507] global step 41098: loss = 0.1212 (0.962 sec/step)\n",
      "I0902 09:11:53.340894 139792788920128 learning.py:507] global step 41099: loss = 0.1048 (0.983 sec/step)\n",
      "I0902 09:11:54.297165 139792788920128 learning.py:507] global step 41100: loss = 0.1804 (0.954 sec/step)\n",
      "I0902 09:11:55.276704 139792788920128 learning.py:507] global step 41101: loss = 0.1517 (0.978 sec/step)\n",
      "I0902 09:11:56.244257 139792788920128 learning.py:507] global step 41102: loss = 0.1155 (0.966 sec/step)\n",
      "I0902 09:11:57.232695 139792788920128 learning.py:507] global step 41103: loss = 0.0920 (0.987 sec/step)\n",
      "I0902 09:11:58.186740 139792788920128 learning.py:507] global step 41104: loss = 0.0718 (0.952 sec/step)\n",
      "I0902 09:11:59.138382 139792788920128 learning.py:507] global step 41105: loss = 0.2408 (0.950 sec/step)\n",
      "I0902 09:12:00.117535 139792788920128 learning.py:507] global step 41106: loss = 0.0608 (0.977 sec/step)\n",
      "I0902 09:12:01.085984 139792788920128 learning.py:507] global step 41107: loss = 0.1057 (0.967 sec/step)\n",
      "I0902 09:12:02.045369 139792788920128 learning.py:507] global step 41108: loss = 0.1535 (0.958 sec/step)\n",
      "I0902 09:12:03.015003 139792788920128 learning.py:507] global step 41109: loss = 0.1009 (0.968 sec/step)\n",
      "I0902 09:12:03.992739 139792788920128 learning.py:507] global step 41110: loss = 0.1305 (0.976 sec/step)\n",
      "I0902 09:12:04.964384 139792788920128 learning.py:507] global step 41111: loss = 0.0742 (0.970 sec/step)\n",
      "I0902 09:12:05.927689 139792788920128 learning.py:507] global step 41112: loss = 0.0699 (0.961 sec/step)\n",
      "I0902 09:12:06.912283 139792788920128 learning.py:507] global step 41113: loss = 0.0758 (0.983 sec/step)\n",
      "I0902 09:12:07.888360 139792788920128 learning.py:507] global step 41114: loss = 0.1017 (0.974 sec/step)\n",
      "I0902 09:12:08.851213 139792788920128 learning.py:507] global step 41115: loss = 0.1160 (0.961 sec/step)\n",
      "I0902 09:12:09.810679 139792788920128 learning.py:507] global step 41116: loss = 0.1323 (0.958 sec/step)\n",
      "I0902 09:12:10.765489 139792788920128 learning.py:507] global step 41117: loss = 0.0912 (0.953 sec/step)\n",
      "I0902 09:12:11.722882 139792788920128 learning.py:507] global step 41118: loss = 0.1359 (0.956 sec/step)\n",
      "I0902 09:12:12.675282 139792788920128 learning.py:507] global step 41119: loss = 0.1242 (0.951 sec/step)\n",
      "I0902 09:12:13.639589 139792788920128 learning.py:507] global step 41120: loss = 0.2285 (0.963 sec/step)\n",
      "I0902 09:12:14.590375 139792788920128 learning.py:507] global step 41121: loss = 0.2604 (0.949 sec/step)\n",
      "I0902 09:12:15.553611 139792788920128 learning.py:507] global step 41122: loss = 0.0940 (0.962 sec/step)\n",
      "I0902 09:12:16.524376 139792788920128 learning.py:507] global step 41123: loss = 0.1060 (0.969 sec/step)\n",
      "I0902 09:12:17.498286 139792788920128 learning.py:507] global step 41124: loss = 0.0659 (0.972 sec/step)\n",
      "I0902 09:12:18.457442 139792788920128 learning.py:507] global step 41125: loss = 0.1753 (0.957 sec/step)\n",
      "I0902 09:12:19.425396 139792788920128 learning.py:507] global step 41126: loss = 0.0818 (0.966 sec/step)\n",
      "I0902 09:12:20.386309 139792788920128 learning.py:507] global step 41127: loss = 0.1949 (0.959 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:12:21.367713 139792788920128 learning.py:507] global step 41128: loss = 0.1698 (0.980 sec/step)\n",
      "I0902 09:12:22.340693 139792788920128 learning.py:507] global step 41129: loss = 0.0946 (0.971 sec/step)\n",
      "I0902 09:12:23.312721 139792788920128 learning.py:507] global step 41130: loss = 0.1555 (0.970 sec/step)\n",
      "I0902 09:12:24.269536 139792788920128 learning.py:507] global step 41131: loss = 0.1443 (0.955 sec/step)\n",
      "I0902 09:12:25.231276 139792788920128 learning.py:507] global step 41132: loss = 0.0944 (0.960 sec/step)\n",
      "I0902 09:12:26.187103 139792788920128 learning.py:507] global step 41133: loss = 0.1068 (0.954 sec/step)\n",
      "I0902 09:12:27.151783 139792788920128 learning.py:507] global step 41134: loss = 0.1280 (0.963 sec/step)\n",
      "I0902 09:12:28.101892 139792788920128 learning.py:507] global step 41135: loss = 0.2031 (0.949 sec/step)\n",
      "I0902 09:12:29.057794 139792788920128 learning.py:507] global step 41136: loss = 0.1333 (0.955 sec/step)\n",
      "I0902 09:12:30.029873 139792788920128 learning.py:507] global step 41137: loss = 0.0935 (0.970 sec/step)\n",
      "I0902 09:12:31.007546 139792788920128 learning.py:507] global step 41138: loss = 0.0897 (0.976 sec/step)\n",
      "I0902 09:12:31.969815 139792788920128 learning.py:507] global step 41139: loss = 0.0778 (0.961 sec/step)\n",
      "I0902 09:12:32.947045 139792788920128 learning.py:507] global step 41140: loss = 0.0807 (0.976 sec/step)\n",
      "I0902 09:12:33.916218 139792788920128 learning.py:507] global step 41141: loss = 0.0879 (0.968 sec/step)\n",
      "I0902 09:12:34.865345 139792788920128 learning.py:507] global step 41142: loss = 0.0883 (0.947 sec/step)\n",
      "I0902 09:12:35.829077 139792788920128 learning.py:507] global step 41143: loss = 0.0832 (0.962 sec/step)\n",
      "I0902 09:12:36.788360 139792788920128 learning.py:507] global step 41144: loss = 0.0854 (0.958 sec/step)\n",
      "I0902 09:12:37.744997 139792788920128 learning.py:507] global step 41145: loss = 0.0924 (0.955 sec/step)\n",
      "I0902 09:12:38.722227 139792788920128 learning.py:507] global step 41146: loss = 0.0838 (0.976 sec/step)\n",
      "I0902 09:12:39.708197 139792788920128 learning.py:507] global step 41147: loss = 0.0599 (0.984 sec/step)\n",
      "I0902 09:12:40.678096 139792788920128 learning.py:507] global step 41148: loss = 0.0972 (0.968 sec/step)\n",
      "I0902 09:12:41.655596 139792788920128 learning.py:507] global step 41149: loss = 0.0927 (0.976 sec/step)\n",
      "I0902 09:12:42.641545 139792788920128 learning.py:507] global step 41150: loss = 0.1142 (0.984 sec/step)\n",
      "I0902 09:12:43.600928 139792788920128 learning.py:507] global step 41151: loss = 0.0807 (0.958 sec/step)\n",
      "I0902 09:12:44.555618 139792788920128 learning.py:507] global step 41152: loss = 0.1790 (0.953 sec/step)\n",
      "I0902 09:12:45.546098 139792788920128 learning.py:507] global step 41153: loss = 0.1141 (0.989 sec/step)\n",
      "I0902 09:12:46.524133 139792788920128 learning.py:507] global step 41154: loss = 0.0827 (0.976 sec/step)\n",
      "I0902 09:12:47.483486 139792788920128 learning.py:507] global step 41155: loss = 0.0410 (0.958 sec/step)\n",
      "I0902 09:12:48.469744 139792788920128 learning.py:507] global step 41156: loss = 0.2094 (0.985 sec/step)\n",
      "I0902 09:12:49.422264 139792788920128 learning.py:507] global step 41157: loss = 0.1696 (0.951 sec/step)\n",
      "I0902 09:12:50.376355 139792788920128 learning.py:507] global step 41158: loss = 0.1218 (0.953 sec/step)\n",
      "I0902 09:12:51.348123 139792788920128 learning.py:507] global step 41159: loss = 0.1023 (0.970 sec/step)\n",
      "I0902 09:12:52.321192 139792788920128 learning.py:507] global step 41160: loss = 0.0531 (0.971 sec/step)\n",
      "I0902 09:12:53.288907 139792788920128 learning.py:507] global step 41161: loss = 0.0959 (0.966 sec/step)\n",
      "I0902 09:12:54.252081 139792788920128 learning.py:507] global step 41162: loss = 0.2047 (0.962 sec/step)\n",
      "I0902 09:12:55.215178 139792788920128 learning.py:507] global step 41163: loss = 0.1394 (0.961 sec/step)\n",
      "I0902 09:12:56.182542 139792788920128 learning.py:507] global step 41164: loss = 0.1742 (0.966 sec/step)\n",
      "I0902 09:12:57.148846 139792788920128 learning.py:507] global step 41165: loss = 0.1210 (0.965 sec/step)\n",
      "I0902 09:12:58.113854 139792788920128 learning.py:507] global step 41166: loss = 0.1174 (0.963 sec/step)\n",
      "I0902 09:12:59.076186 139792788920128 learning.py:507] global step 41167: loss = 0.0502 (0.961 sec/step)\n",
      "I0902 09:13:00.018049 139792788920128 learning.py:507] global step 41168: loss = 0.1285 (0.940 sec/step)\n",
      "I0902 09:13:00.982106 139792788920128 learning.py:507] global step 41169: loss = 0.2026 (0.962 sec/step)\n",
      "I0902 09:13:01.963772 139792788920128 learning.py:507] global step 41170: loss = 0.1743 (0.980 sec/step)\n",
      "I0902 09:13:02.953210 139792788920128 learning.py:507] global step 41171: loss = 0.1391 (0.988 sec/step)\n",
      "I0902 09:13:03.910517 139792788920128 learning.py:507] global step 41172: loss = 0.1247 (0.956 sec/step)\n",
      "I0902 09:13:04.904174 139792788920128 learning.py:507] global step 41173: loss = 0.2012 (0.992 sec/step)\n",
      "I0902 09:13:05.881973 139792788920128 learning.py:507] global step 41174: loss = 0.1158 (0.976 sec/step)\n",
      "I0902 09:13:06.861086 139792788920128 learning.py:507] global step 41175: loss = 0.2736 (0.977 sec/step)\n",
      "I0902 09:13:07.818527 139792788920128 learning.py:507] global step 41176: loss = 0.1817 (0.956 sec/step)\n",
      "I0902 09:13:08.780650 139792788920128 learning.py:507] global step 41177: loss = 0.0773 (0.961 sec/step)\n",
      "I0902 09:13:09.767597 139792788920128 learning.py:507] global step 41178: loss = 0.0635 (0.985 sec/step)\n",
      "I0902 09:13:10.768570 139792788920128 learning.py:507] global step 41179: loss = 0.0317 (1.000 sec/step)\n",
      "I0902 09:13:11.748334 139792788920128 learning.py:507] global step 41180: loss = 0.2564 (0.978 sec/step)\n",
      "I0902 09:13:12.716396 139792788920128 learning.py:507] global step 41181: loss = 0.1329 (0.966 sec/step)\n",
      "I0902 09:13:13.670751 139792788920128 learning.py:507] global step 41182: loss = 0.1657 (0.953 sec/step)\n",
      "I0902 09:13:14.632042 139792788920128 learning.py:507] global step 41183: loss = 0.2233 (0.960 sec/step)\n",
      "I0902 09:13:15.598762 139792788920128 learning.py:507] global step 41184: loss = 0.0978 (0.965 sec/step)\n",
      "I0902 09:13:16.568405 139792788920128 learning.py:507] global step 41185: loss = 0.0691 (0.968 sec/step)\n",
      "I0902 09:13:17.559116 139792788920128 learning.py:507] global step 41186: loss = 0.1530 (0.989 sec/step)\n",
      "I0902 09:13:18.570773 139792788920128 learning.py:507] global step 41187: loss = 0.1491 (1.010 sec/step)\n",
      "I0902 09:13:19.528263 139792788920128 learning.py:507] global step 41188: loss = 0.1429 (0.956 sec/step)\n",
      "I0902 09:13:20.500682 139792788920128 learning.py:507] global step 41189: loss = 0.1292 (0.971 sec/step)\n",
      "I0902 09:13:21.498337 139792788920128 learning.py:507] global step 41190: loss = 0.0602 (0.996 sec/step)\n",
      "I0902 09:13:22.469496 139792788920128 learning.py:507] global step 41191: loss = 0.0654 (0.970 sec/step)\n",
      "I0902 09:13:23.458119 139792788920128 learning.py:507] global step 41192: loss = 0.1242 (0.987 sec/step)\n",
      "I0902 09:13:24.435971 139792788920128 learning.py:507] global step 41193: loss = 0.1292 (0.976 sec/step)\n",
      "I0902 09:13:25.412845 139792788920128 learning.py:507] global step 41194: loss = 0.1961 (0.975 sec/step)\n",
      "I0902 09:13:26.383199 139792788920128 learning.py:507] global step 41195: loss = 0.1597 (0.969 sec/step)\n",
      "I0902 09:13:27.344748 139792788920128 learning.py:507] global step 41196: loss = 0.1493 (0.960 sec/step)\n",
      "I0902 09:13:28.297024 139792788920128 learning.py:507] global step 41197: loss = 0.1502 (0.951 sec/step)\n",
      "I0902 09:13:29.274403 139792788920128 learning.py:507] global step 41198: loss = 0.1117 (0.976 sec/step)\n",
      "I0902 09:13:30.233097 139792788920128 learning.py:507] global step 41199: loss = 0.0543 (0.957 sec/step)\n",
      "I0902 09:13:31.188929 139792788920128 learning.py:507] global step 41200: loss = 0.1521 (0.954 sec/step)\n",
      "I0902 09:13:32.164404 139792788920128 learning.py:507] global step 41201: loss = 0.1048 (0.974 sec/step)\n",
      "I0902 09:13:33.125968 139792788920128 learning.py:507] global step 41202: loss = 0.0799 (0.960 sec/step)\n",
      "I0902 09:13:34.080134 139792788920128 learning.py:507] global step 41203: loss = 0.0717 (0.952 sec/step)\n",
      "I0902 09:13:35.034286 139792788920128 learning.py:507] global step 41204: loss = 0.0659 (0.953 sec/step)\n",
      "I0902 09:13:36.018394 139792788920128 learning.py:507] global step 41205: loss = 0.2459 (0.983 sec/step)\n",
      "I0902 09:13:37.006381 139792788920128 learning.py:507] global step 41206: loss = 0.1441 (0.986 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:13:37.986100 139792788920128 learning.py:507] global step 41207: loss = 0.1474 (0.978 sec/step)\n",
      "I0902 09:13:38.947880 139792788920128 learning.py:507] global step 41208: loss = 0.1592 (0.960 sec/step)\n",
      "I0902 09:13:39.929188 139792788920128 learning.py:507] global step 41209: loss = 0.0709 (0.980 sec/step)\n",
      "I0902 09:13:40.903804 139792788920128 learning.py:507] global step 41210: loss = 0.0970 (0.973 sec/step)\n",
      "I0902 09:13:41.884771 139792788920128 learning.py:507] global step 41211: loss = 0.1243 (0.979 sec/step)\n",
      "I0902 09:13:42.851656 139792788920128 learning.py:507] global step 41212: loss = 0.0768 (0.965 sec/step)\n",
      "I0902 09:13:43.828198 139792788920128 learning.py:507] global step 41213: loss = 0.1061 (0.975 sec/step)\n",
      "I0902 09:13:44.824285 139792788920128 learning.py:507] global step 41214: loss = 0.1469 (0.994 sec/step)\n",
      "I0902 09:13:45.814881 139792788920128 learning.py:507] global step 41215: loss = 0.2735 (0.989 sec/step)\n",
      "I0902 09:13:46.790333 139792788920128 learning.py:507] global step 41216: loss = 0.0706 (0.974 sec/step)\n",
      "I0902 09:13:47.770767 139792788920128 learning.py:507] global step 41217: loss = 0.1008 (0.979 sec/step)\n",
      "I0902 09:13:48.752970 139792788920128 learning.py:507] global step 41218: loss = 0.1611 (0.981 sec/step)\n",
      "I0902 09:13:49.270476 139778953570048 supervisor.py:1117] Saving checkpoint to path data_dir/mixed_experiment/checkpoints_v2/model.ckpt\n",
      "I0902 09:13:49.847621 139792788920128 learning.py:507] global step 41219: loss = 0.3449 (1.088 sec/step)\n",
      "I0902 09:13:50.042808 139778936784640 supervisor.py:1050] Recording summary at step 41219.\n",
      "I0902 09:13:50.931216 139792788920128 learning.py:507] global step 41220: loss = 0.0721 (1.073 sec/step)\n",
      "I0902 09:13:51.922066 139792788920128 learning.py:507] global step 41221: loss = 0.0944 (0.989 sec/step)\n",
      "I0902 09:13:52.885851 139792788920128 learning.py:507] global step 41222: loss = 0.2106 (0.962 sec/step)\n",
      "I0902 09:13:53.849415 139792788920128 learning.py:507] global step 41223: loss = 0.0526 (0.962 sec/step)\n",
      "I0902 09:13:54.824706 139792788920128 learning.py:507] global step 41224: loss = 0.1273 (0.974 sec/step)\n",
      "I0902 09:13:55.807822 139792788920128 learning.py:507] global step 41225: loss = 0.0708 (0.981 sec/step)\n",
      "I0902 09:13:56.801258 139792788920128 learning.py:507] global step 41226: loss = 0.1637 (0.992 sec/step)\n",
      "I0902 09:13:57.778983 139792788920128 learning.py:507] global step 41227: loss = 0.0879 (0.976 sec/step)\n",
      "I0902 09:13:58.742153 139792788920128 learning.py:507] global step 41228: loss = 0.1994 (0.962 sec/step)\n",
      "I0902 09:13:59.707421 139792788920128 learning.py:507] global step 41229: loss = 0.0504 (0.964 sec/step)\n",
      "I0902 09:14:00.682178 139792788920128 learning.py:507] global step 41230: loss = 0.0906 (0.973 sec/step)\n",
      "I0902 09:14:01.682162 139792788920128 learning.py:507] global step 41231: loss = 0.0916 (0.998 sec/step)\n",
      "I0902 09:14:02.671865 139792788920128 learning.py:507] global step 41232: loss = 0.0802 (0.988 sec/step)\n",
      "I0902 09:14:03.656706 139792788920128 learning.py:507] global step 41233: loss = 0.1053 (0.983 sec/step)\n",
      "I0902 09:14:04.635787 139792788920128 learning.py:507] global step 41234: loss = 0.1496 (0.977 sec/step)\n",
      "I0902 09:14:05.641646 139792788920128 learning.py:507] global step 41235: loss = 0.1356 (1.004 sec/step)\n",
      "I0902 09:14:06.621150 139792788920128 learning.py:507] global step 41236: loss = 0.2996 (0.978 sec/step)\n",
      "I0902 09:14:07.583329 139792788920128 learning.py:507] global step 41237: loss = 0.1215 (0.961 sec/step)\n",
      "I0902 09:14:08.561630 139792788920128 learning.py:507] global step 41238: loss = 0.1116 (0.977 sec/step)\n",
      "I0902 09:14:09.534809 139792788920128 learning.py:507] global step 41239: loss = 0.0868 (0.972 sec/step)\n",
      "I0902 09:14:10.497110 139792788920128 learning.py:507] global step 41240: loss = 0.0861 (0.961 sec/step)\n",
      "I0902 09:14:11.471417 139792788920128 learning.py:507] global step 41241: loss = 0.2470 (0.973 sec/step)\n",
      "I0902 09:14:12.461142 139792788920128 learning.py:507] global step 41242: loss = 0.0792 (0.988 sec/step)\n",
      "I0902 09:14:13.421185 139792788920128 learning.py:507] global step 41243: loss = 0.2079 (0.958 sec/step)\n",
      "I0902 09:14:14.390280 139792788920128 learning.py:507] global step 41244: loss = 0.1845 (0.968 sec/step)\n",
      "I0902 09:14:15.354685 139792788920128 learning.py:507] global step 41245: loss = 0.1004 (0.963 sec/step)\n",
      "I0902 09:14:16.319019 139792788920128 learning.py:507] global step 41246: loss = 0.1077 (0.963 sec/step)\n",
      "I0902 09:14:17.296380 139792788920128 learning.py:507] global step 41247: loss = 0.1226 (0.976 sec/step)\n",
      "I0902 09:14:18.256153 139792788920128 learning.py:507] global step 41248: loss = 0.1561 (0.958 sec/step)\n",
      "I0902 09:14:19.229476 139792788920128 learning.py:507] global step 41249: loss = 0.1101 (0.972 sec/step)\n",
      "I0902 09:14:20.214918 139792788920128 learning.py:507] global step 41250: loss = 0.0802 (0.984 sec/step)\n",
      "I0902 09:14:21.162189 139792788920128 learning.py:507] global step 41251: loss = 0.2326 (0.946 sec/step)\n",
      "I0902 09:14:22.132584 139792788920128 learning.py:507] global step 41252: loss = 0.0772 (0.969 sec/step)\n",
      "I0902 09:14:23.098296 139792788920128 learning.py:507] global step 41253: loss = 0.0646 (0.964 sec/step)\n",
      "I0902 09:14:24.060620 139792788920128 learning.py:507] global step 41254: loss = 0.1064 (0.961 sec/step)\n",
      "I0902 09:14:25.037224 139792788920128 learning.py:507] global step 41255: loss = 0.1531 (0.975 sec/step)\n",
      "I0902 09:14:25.993295 139792788920128 learning.py:507] global step 41256: loss = 0.0832 (0.955 sec/step)\n",
      "I0902 09:14:26.985566 139792788920128 learning.py:507] global step 41257: loss = 0.1283 (0.991 sec/step)\n",
      "I0902 09:14:27.985338 139792788920128 learning.py:507] global step 41258: loss = 0.1499 (0.998 sec/step)\n",
      "I0902 09:14:28.973659 139792788920128 learning.py:507] global step 41259: loss = 0.0789 (0.987 sec/step)\n",
      "I0902 09:14:29.926854 139792788920128 learning.py:507] global step 41260: loss = 0.1055 (0.952 sec/step)\n",
      "I0902 09:14:30.914778 139792788920128 learning.py:507] global step 41261: loss = 0.2658 (0.986 sec/step)\n",
      "I0902 09:14:31.860455 139792788920128 learning.py:507] global step 41262: loss = 0.0774 (0.944 sec/step)\n",
      "I0902 09:14:32.843413 139792788920128 learning.py:507] global step 41263: loss = 0.1781 (0.981 sec/step)\n",
      "I0902 09:14:33.824211 139792788920128 learning.py:507] global step 41264: loss = 0.1878 (0.979 sec/step)\n",
      "I0902 09:14:34.792926 139792788920128 learning.py:507] global step 41265: loss = 0.1027 (0.967 sec/step)\n",
      "I0902 09:14:35.768881 139792788920128 learning.py:507] global step 41266: loss = 0.1738 (0.974 sec/step)\n",
      "I0902 09:14:36.722870 139792788920128 learning.py:507] global step 41267: loss = 0.0619 (0.952 sec/step)\n",
      "I0902 09:14:37.702030 139792788920128 learning.py:507] global step 41268: loss = 0.1204 (0.978 sec/step)\n",
      "I0902 09:14:38.680895 139792788920128 learning.py:507] global step 41269: loss = 0.1440 (0.977 sec/step)\n",
      "I0902 09:14:39.642280 139792788920128 learning.py:507] global step 41270: loss = 0.0872 (0.960 sec/step)\n",
      "I0902 09:14:40.602524 139792788920128 learning.py:507] global step 41271: loss = 0.0930 (0.959 sec/step)\n",
      "I0902 09:14:41.569082 139792788920128 learning.py:507] global step 41272: loss = 0.0518 (0.965 sec/step)\n",
      "I0902 09:14:42.526987 139792788920128 learning.py:507] global step 41273: loss = 0.1391 (0.956 sec/step)\n",
      "I0902 09:14:43.497195 139792788920128 learning.py:507] global step 41274: loss = 0.1486 (0.969 sec/step)\n",
      "I0902 09:14:44.481202 139792788920128 learning.py:507] global step 41275: loss = 0.1042 (0.982 sec/step)\n",
      "I0902 09:14:45.438628 139792788920128 learning.py:507] global step 41276: loss = 0.1559 (0.956 sec/step)\n",
      "I0902 09:14:46.410708 139792788920128 learning.py:507] global step 41277: loss = 0.2330 (0.970 sec/step)\n",
      "I0902 09:14:47.382718 139792788920128 learning.py:507] global step 41278: loss = 0.1340 (0.970 sec/step)\n",
      "I0902 09:14:48.377712 139792788920128 learning.py:507] global step 41279: loss = 0.0899 (0.993 sec/step)\n",
      "I0902 09:14:49.351392 139792788920128 learning.py:507] global step 41280: loss = 0.4925 (0.972 sec/step)\n",
      "I0902 09:14:50.335640 139792788920128 learning.py:507] global step 41281: loss = 0.0872 (0.983 sec/step)\n",
      "I0902 09:14:51.297098 139792788920128 learning.py:507] global step 41282: loss = 0.0721 (0.960 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:14:52.255008 139792788920128 learning.py:507] global step 41283: loss = 0.0875 (0.956 sec/step)\n",
      "I0902 09:14:53.225114 139792788920128 learning.py:507] global step 41284: loss = 0.1297 (0.968 sec/step)\n",
      "I0902 09:14:54.188232 139792788920128 learning.py:507] global step 41285: loss = 0.0563 (0.961 sec/step)\n",
      "I0902 09:14:55.155766 139792788920128 learning.py:507] global step 41286: loss = 0.1348 (0.966 sec/step)\n",
      "I0902 09:14:56.112812 139792788920128 learning.py:507] global step 41287: loss = 0.1309 (0.955 sec/step)\n",
      "I0902 09:14:57.082766 139792788920128 learning.py:507] global step 41288: loss = 0.0753 (0.968 sec/step)\n",
      "I0902 09:14:58.057362 139792788920128 learning.py:507] global step 41289: loss = 0.0945 (0.973 sec/step)\n",
      "I0902 09:14:59.028269 139792788920128 learning.py:507] global step 41290: loss = 0.0870 (0.969 sec/step)\n",
      "I0902 09:14:59.997025 139792788920128 learning.py:507] global step 41291: loss = 0.1103 (0.967 sec/step)\n",
      "I0902 09:15:00.977564 139792788920128 learning.py:507] global step 41292: loss = 0.1850 (0.979 sec/step)\n",
      "I0902 09:15:01.932419 139792788920128 learning.py:507] global step 41293: loss = 0.1048 (0.953 sec/step)\n",
      "I0902 09:15:02.912158 139792788920128 learning.py:507] global step 41294: loss = 0.1173 (0.978 sec/step)\n",
      "I0902 09:15:03.890087 139792788920128 learning.py:507] global step 41295: loss = 0.0902 (0.976 sec/step)\n",
      "I0902 09:15:04.850159 139792788920128 learning.py:507] global step 41296: loss = 0.1112 (0.958 sec/step)\n",
      "I0902 09:15:05.815113 139792788920128 learning.py:507] global step 41297: loss = 0.1547 (0.963 sec/step)\n",
      "I0902 09:15:06.777246 139792788920128 learning.py:507] global step 41298: loss = 0.1850 (0.960 sec/step)\n",
      "I0902 09:15:07.759806 139792788920128 learning.py:507] global step 41299: loss = 0.1092 (0.981 sec/step)\n",
      "I0902 09:15:08.729792 139792788920128 learning.py:507] global step 41300: loss = 0.2812 (0.968 sec/step)\n",
      "I0902 09:15:09.678418 139792788920128 learning.py:507] global step 41301: loss = 0.0913 (0.947 sec/step)\n",
      "I0902 09:15:10.650388 139792788920128 learning.py:507] global step 41302: loss = 0.2010 (0.970 sec/step)\n",
      "I0902 09:15:11.628555 139792788920128 learning.py:507] global step 41303: loss = 0.1219 (0.976 sec/step)\n",
      "I0902 09:15:12.589522 139792788920128 learning.py:507] global step 41304: loss = 0.0895 (0.959 sec/step)\n",
      "I0902 09:15:13.541633 139792788920128 learning.py:507] global step 41305: loss = 0.1516 (0.951 sec/step)\n",
      "I0902 09:15:14.516748 139792788920128 learning.py:507] global step 41306: loss = 0.0796 (0.973 sec/step)\n",
      "I0902 09:15:15.488235 139792788920128 learning.py:507] global step 41307: loss = 0.2985 (0.970 sec/step)\n",
      "I0902 09:15:16.444803 139792788920128 learning.py:507] global step 41308: loss = 0.1039 (0.955 sec/step)\n",
      "I0902 09:15:17.424939 139792788920128 learning.py:507] global step 41309: loss = 0.1623 (0.978 sec/step)\n",
      "I0902 09:15:18.411479 139792788920128 learning.py:507] global step 41310: loss = 0.1226 (0.985 sec/step)\n",
      "I0902 09:15:19.377955 139792788920128 learning.py:507] global step 41311: loss = 0.1044 (0.965 sec/step)\n",
      "I0902 09:15:20.338848 139792788920128 learning.py:507] global step 41312: loss = 0.1350 (0.959 sec/step)\n",
      "I0902 09:15:21.298271 139792788920128 learning.py:507] global step 41313: loss = 0.1214 (0.958 sec/step)\n",
      "I0902 09:15:22.243459 139792788920128 learning.py:507] global step 41314: loss = 0.1732 (0.944 sec/step)\n",
      "I0902 09:15:23.209376 139792788920128 learning.py:507] global step 41315: loss = 0.1540 (0.964 sec/step)\n",
      "I0902 09:15:24.169322 139792788920128 learning.py:507] global step 41316: loss = 0.1388 (0.958 sec/step)\n",
      "I0902 09:15:25.137135 139792788920128 learning.py:507] global step 41317: loss = 0.0876 (0.966 sec/step)\n",
      "I0902 09:15:26.109993 139792788920128 learning.py:507] global step 41318: loss = 0.0986 (0.971 sec/step)\n",
      "I0902 09:15:27.087496 139792788920128 learning.py:507] global step 41319: loss = 0.1266 (0.976 sec/step)\n",
      "I0902 09:15:28.057200 139792788920128 learning.py:507] global step 41320: loss = 0.1316 (0.968 sec/step)\n",
      "I0902 09:15:29.022309 139792788920128 learning.py:507] global step 41321: loss = 0.0937 (0.963 sec/step)\n",
      "I0902 09:15:29.987110 139792788920128 learning.py:507] global step 41322: loss = 0.1205 (0.963 sec/step)\n",
      "I0902 09:15:30.951678 139792788920128 learning.py:507] global step 41323: loss = 0.1821 (0.963 sec/step)\n",
      "I0902 09:15:31.907520 139792788920128 learning.py:507] global step 41324: loss = 0.0878 (0.954 sec/step)\n",
      "I0902 09:15:32.889971 139792788920128 learning.py:507] global step 41325: loss = 0.0954 (0.981 sec/step)\n",
      "I0902 09:15:33.847245 139792788920128 learning.py:507] global step 41326: loss = 0.0865 (0.956 sec/step)\n",
      "I0902 09:15:34.824541 139792788920128 learning.py:507] global step 41327: loss = 0.0837 (0.976 sec/step)\n",
      "I0902 09:15:35.790788 139792788920128 learning.py:507] global step 41328: loss = 0.3797 (0.965 sec/step)\n",
      "I0902 09:15:36.773986 139792788920128 learning.py:507] global step 41329: loss = 0.0869 (0.982 sec/step)\n",
      "I0902 09:15:37.761193 139792788920128 learning.py:507] global step 41330: loss = 0.0827 (0.986 sec/step)\n",
      "I0902 09:15:38.743300 139792788920128 learning.py:507] global step 41331: loss = 0.1549 (0.980 sec/step)\n",
      "I0902 09:15:39.696894 139792788920128 learning.py:507] global step 41332: loss = 0.0814 (0.952 sec/step)\n",
      "I0902 09:15:40.660685 139792788920128 learning.py:507] global step 41333: loss = 0.3224 (0.962 sec/step)\n",
      "I0902 09:15:41.646575 139792788920128 learning.py:507] global step 41334: loss = 0.0822 (0.984 sec/step)\n",
      "I0902 09:15:42.612320 139792788920128 learning.py:507] global step 41335: loss = 0.1052 (0.964 sec/step)\n",
      "I0902 09:15:43.569840 139792788920128 learning.py:507] global step 41336: loss = 0.0677 (0.956 sec/step)\n",
      "I0902 09:15:44.521962 139792788920128 learning.py:507] global step 41337: loss = 0.3201 (0.950 sec/step)\n",
      "I0902 09:15:45.489728 139792788920128 learning.py:507] global step 41338: loss = 0.0879 (0.966 sec/step)\n",
      "I0902 09:15:46.449726 139792788920128 learning.py:507] global step 41339: loss = 0.0792 (0.958 sec/step)\n",
      "I0902 09:15:47.427317 139792788920128 learning.py:507] global step 41340: loss = 0.1249 (0.976 sec/step)\n",
      "I0902 09:15:48.395200 139792788920128 learning.py:507] global step 41341: loss = 0.0944 (0.966 sec/step)\n",
      "I0902 09:15:49.366098 139792788920128 learning.py:507] global step 41342: loss = 0.2054 (0.967 sec/step)\n",
      "I0902 09:15:49.970479 139778936784640 supervisor.py:1050] Recording summary at step 41342.\n",
      "I0902 09:15:50.585510 139792788920128 learning.py:507] global step 41343: loss = 0.1463 (1.217 sec/step)\n",
      "I0902 09:15:51.555788 139792788920128 learning.py:507] global step 41344: loss = 0.0884 (0.969 sec/step)\n",
      "I0902 09:15:52.538587 139792788920128 learning.py:507] global step 41345: loss = 0.1061 (0.981 sec/step)\n",
      "I0902 09:15:53.501576 139792788920128 learning.py:507] global step 41346: loss = 0.1993 (0.961 sec/step)\n",
      "I0902 09:15:54.476842 139792788920128 learning.py:507] global step 41347: loss = 0.0907 (0.974 sec/step)\n",
      "I0902 09:15:55.445274 139792788920128 learning.py:507] global step 41348: loss = 0.1482 (0.967 sec/step)\n",
      "I0902 09:15:56.420531 139792788920128 learning.py:507] global step 41349: loss = 0.1593 (0.974 sec/step)\n",
      "I0902 09:15:57.385184 139792788920128 learning.py:507] global step 41350: loss = 0.1035 (0.963 sec/step)\n",
      "I0902 09:15:58.345624 139792788920128 learning.py:507] global step 41351: loss = 0.0981 (0.959 sec/step)\n",
      "I0902 09:15:59.324730 139792788920128 learning.py:507] global step 41352: loss = 0.1127 (0.978 sec/step)\n",
      "I0902 09:16:00.301928 139792788920128 learning.py:507] global step 41353: loss = 0.0937 (0.976 sec/step)\n",
      "I0902 09:16:01.261936 139792788920128 learning.py:507] global step 41354: loss = 0.0829 (0.958 sec/step)\n",
      "I0902 09:16:02.231266 139792788920128 learning.py:507] global step 41355: loss = 0.0334 (0.968 sec/step)\n",
      "I0902 09:16:03.206666 139792788920128 learning.py:507] global step 41356: loss = 0.1332 (0.974 sec/step)\n",
      "I0902 09:16:04.182183 139792788920128 learning.py:507] global step 41357: loss = 0.0795 (0.974 sec/step)\n",
      "I0902 09:16:05.143555 139792788920128 learning.py:507] global step 41358: loss = 0.0665 (0.960 sec/step)\n",
      "I0902 09:16:06.122738 139792788920128 learning.py:507] global step 41359: loss = 0.1021 (0.978 sec/step)\n",
      "I0902 09:16:07.080550 139792788920128 learning.py:507] global step 41360: loss = 0.0487 (0.956 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:16:08.059439 139792788920128 learning.py:507] global step 41361: loss = 0.1444 (0.977 sec/step)\n",
      "I0902 09:16:09.023741 139792788920128 learning.py:507] global step 41362: loss = 0.2441 (0.963 sec/step)\n",
      "I0902 09:16:10.011583 139792788920128 learning.py:507] global step 41363: loss = 0.1063 (0.986 sec/step)\n",
      "I0902 09:16:10.956113 139792788920128 learning.py:507] global step 41364: loss = 0.1315 (0.943 sec/step)\n",
      "I0902 09:16:11.920664 139792788920128 learning.py:507] global step 41365: loss = 0.0709 (0.963 sec/step)\n",
      "I0902 09:16:12.892746 139792788920128 learning.py:507] global step 41366: loss = 0.2015 (0.971 sec/step)\n",
      "I0902 09:16:13.883761 139792788920128 learning.py:507] global step 41367: loss = 0.1378 (0.989 sec/step)\n",
      "I0902 09:16:14.855385 139792788920128 learning.py:507] global step 41368: loss = 0.1057 (0.970 sec/step)\n",
      "I0902 09:16:15.817494 139792788920128 learning.py:507] global step 41369: loss = 0.1215 (0.961 sec/step)\n",
      "I0902 09:16:16.804258 139792788920128 learning.py:507] global step 41370: loss = 0.1130 (0.985 sec/step)\n",
      "I0902 09:16:17.771543 139792788920128 learning.py:507] global step 41371: loss = 0.3835 (0.966 sec/step)\n",
      "I0902 09:16:18.726211 139792788920128 learning.py:507] global step 41372: loss = 0.1282 (0.953 sec/step)\n",
      "I0902 09:16:19.684067 139792788920128 learning.py:507] global step 41373: loss = 0.0675 (0.956 sec/step)\n",
      "I0902 09:16:20.672070 139792788920128 learning.py:507] global step 41374: loss = 0.1656 (0.986 sec/step)\n",
      "I0902 09:16:21.639658 139792788920128 learning.py:507] global step 41375: loss = 0.1918 (0.966 sec/step)\n",
      "I0902 09:16:22.601769 139792788920128 learning.py:507] global step 41376: loss = 0.1308 (0.961 sec/step)\n",
      "I0902 09:16:23.571407 139792788920128 learning.py:507] global step 41377: loss = 0.0521 (0.968 sec/step)\n",
      "I0902 09:16:24.555139 139792788920128 learning.py:507] global step 41378: loss = 0.1960 (0.982 sec/step)\n",
      "I0902 09:16:25.513878 139792788920128 learning.py:507] global step 41379: loss = 0.1003 (0.957 sec/step)\n",
      "I0902 09:16:26.480962 139792788920128 learning.py:507] global step 41380: loss = 0.2056 (0.965 sec/step)\n",
      "I0902 09:16:27.449304 139792788920128 learning.py:507] global step 41381: loss = 0.0687 (0.967 sec/step)\n",
      "I0902 09:16:28.427339 139792788920128 learning.py:507] global step 41382: loss = 0.0840 (0.976 sec/step)\n",
      "I0902 09:16:29.403594 139792788920128 learning.py:507] global step 41383: loss = 0.1024 (0.974 sec/step)\n",
      "I0902 09:16:30.377332 139792788920128 learning.py:507] global step 41384: loss = 0.1716 (0.972 sec/step)\n",
      "I0902 09:16:31.350669 139792788920128 learning.py:507] global step 41385: loss = 0.1077 (0.972 sec/step)\n",
      "I0902 09:16:32.325072 139792788920128 learning.py:507] global step 41386: loss = 0.1731 (0.973 sec/step)\n",
      "I0902 09:16:33.311301 139792788920128 learning.py:507] global step 41387: loss = 0.1443 (0.985 sec/step)\n",
      "I0902 09:16:34.282541 139792788920128 learning.py:507] global step 41388: loss = 0.0616 (0.970 sec/step)\n",
      "I0902 09:16:35.230015 139792788920128 learning.py:507] global step 41389: loss = 0.2193 (0.946 sec/step)\n",
      "I0902 09:16:36.206336 139792788920128 learning.py:507] global step 41390: loss = 0.0779 (0.975 sec/step)\n",
      "I0902 09:16:37.191979 139792788920128 learning.py:507] global step 41391: loss = 0.1655 (0.984 sec/step)\n",
      "I0902 09:16:38.157618 139792788920128 learning.py:507] global step 41392: loss = 0.1394 (0.964 sec/step)\n",
      "I0902 09:16:39.118195 139792788920128 learning.py:507] global step 41393: loss = 0.0956 (0.959 sec/step)\n",
      "I0902 09:16:40.078297 139792788920128 learning.py:507] global step 41394: loss = 0.1060 (0.958 sec/step)\n",
      "I0902 09:16:41.031342 139792788920128 learning.py:507] global step 41395: loss = 0.0730 (0.951 sec/step)\n",
      "I0902 09:16:41.997349 139792788920128 learning.py:507] global step 41396: loss = 0.1342 (0.964 sec/step)\n",
      "I0902 09:16:42.943413 139792788920128 learning.py:507] global step 41397: loss = 0.1143 (0.944 sec/step)\n",
      "I0902 09:16:43.919538 139792788920128 learning.py:507] global step 41398: loss = 0.1457 (0.974 sec/step)\n",
      "I0902 09:16:44.884537 139792788920128 learning.py:507] global step 41399: loss = 0.1105 (0.963 sec/step)\n",
      "I0902 09:16:45.874152 139792788920128 learning.py:507] global step 41400: loss = 0.1469 (0.988 sec/step)\n",
      "I0902 09:16:46.843089 139792788920128 learning.py:507] global step 41401: loss = 0.1049 (0.967 sec/step)\n",
      "I0902 09:16:47.803311 139792788920128 learning.py:507] global step 41402: loss = 0.0816 (0.959 sec/step)\n",
      "I0902 09:16:48.766236 139792788920128 learning.py:507] global step 41403: loss = 0.1500 (0.961 sec/step)\n",
      "I0902 09:16:49.756638 139792788920128 learning.py:507] global step 41404: loss = 0.1093 (0.989 sec/step)\n",
      "I0902 09:16:50.723620 139792788920128 learning.py:507] global step 41405: loss = 0.1163 (0.965 sec/step)\n",
      "I0902 09:16:51.689753 139792788920128 learning.py:507] global step 41406: loss = 0.2714 (0.965 sec/step)\n",
      "I0902 09:16:52.669332 139792788920128 learning.py:507] global step 41407: loss = 0.1232 (0.978 sec/step)\n",
      "I0902 09:16:53.646594 139792788920128 learning.py:507] global step 41408: loss = 0.1289 (0.976 sec/step)\n",
      "I0902 09:16:54.615391 139792788920128 learning.py:507] global step 41409: loss = 0.1936 (0.967 sec/step)\n",
      "I0902 09:16:55.575840 139792788920128 learning.py:507] global step 41410: loss = 0.0660 (0.959 sec/step)\n",
      "I0902 09:16:56.533643 139792788920128 learning.py:507] global step 41411: loss = 0.1504 (0.956 sec/step)\n",
      "I0902 09:16:57.517727 139792788920128 learning.py:507] global step 41412: loss = 0.3375 (0.983 sec/step)\n",
      "I0902 09:16:58.493339 139792788920128 learning.py:507] global step 41413: loss = 0.0886 (0.974 sec/step)\n",
      "I0902 09:16:59.449725 139792788920128 learning.py:507] global step 41414: loss = 0.0945 (0.955 sec/step)\n",
      "I0902 09:17:00.401913 139792788920128 learning.py:507] global step 41415: loss = 0.0643 (0.951 sec/step)\n",
      "I0902 09:17:01.384030 139792788920128 learning.py:507] global step 41416: loss = 0.2193 (0.981 sec/step)\n",
      "I0902 09:17:02.349001 139792788920128 learning.py:507] global step 41417: loss = 0.2007 (0.963 sec/step)\n",
      "I0902 09:17:03.308536 139792788920128 learning.py:507] global step 41418: loss = 0.1181 (0.958 sec/step)\n",
      "I0902 09:17:04.258635 139792788920128 learning.py:507] global step 41419: loss = 0.4869 (0.949 sec/step)\n",
      "I0902 09:17:05.219705 139792788920128 learning.py:507] global step 41420: loss = 0.0911 (0.960 sec/step)\n",
      "I0902 09:17:06.180513 139792788920128 learning.py:507] global step 41421: loss = 0.1348 (0.959 sec/step)\n",
      "I0902 09:17:07.137358 139792788920128 learning.py:507] global step 41422: loss = 0.1433 (0.956 sec/step)\n",
      "I0902 09:17:08.108809 139792788920128 learning.py:507] global step 41423: loss = 0.1201 (0.970 sec/step)\n",
      "I0902 09:17:09.088026 139792788920128 learning.py:507] global step 41424: loss = 0.1426 (0.978 sec/step)\n",
      "I0902 09:17:10.045581 139792788920128 learning.py:507] global step 41425: loss = 0.1185 (0.956 sec/step)\n",
      "I0902 09:17:11.016617 139792788920128 learning.py:507] global step 41426: loss = 0.0808 (0.970 sec/step)\n",
      "I0902 09:17:11.988184 139792788920128 learning.py:507] global step 41427: loss = 0.1291 (0.970 sec/step)\n",
      "I0902 09:17:12.947149 139792788920128 learning.py:507] global step 41428: loss = 0.1486 (0.958 sec/step)\n",
      "I0902 09:17:13.899106 139792788920128 learning.py:507] global step 41429: loss = 0.1966 (0.951 sec/step)\n",
      "I0902 09:17:14.859428 139792788920128 learning.py:507] global step 41430: loss = 0.1028 (0.959 sec/step)\n",
      "I0902 09:17:15.813705 139792788920128 learning.py:507] global step 41431: loss = 0.1662 (0.953 sec/step)\n",
      "I0902 09:17:16.781159 139792788920128 learning.py:507] global step 41432: loss = 0.1248 (0.966 sec/step)\n",
      "I0902 09:17:17.753816 139792788920128 learning.py:507] global step 41433: loss = 0.0549 (0.971 sec/step)\n",
      "I0902 09:17:18.720321 139792788920128 learning.py:507] global step 41434: loss = 0.0757 (0.965 sec/step)\n",
      "I0902 09:17:19.672454 139792788920128 learning.py:507] global step 41435: loss = 0.1323 (0.951 sec/step)\n",
      "I0902 09:17:20.661493 139792788920128 learning.py:507] global step 41436: loss = 0.1345 (0.988 sec/step)\n",
      "I0902 09:17:21.627819 139792788920128 learning.py:507] global step 41437: loss = 0.0670 (0.965 sec/step)\n",
      "I0902 09:17:22.604016 139792788920128 learning.py:507] global step 41438: loss = 0.0863 (0.975 sec/step)\n",
      "I0902 09:17:23.592108 139792788920128 learning.py:507] global step 41439: loss = 0.1758 (0.985 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:17:24.566879 139792788920128 learning.py:507] global step 41440: loss = 0.0873 (0.973 sec/step)\n",
      "I0902 09:17:25.520266 139792788920128 learning.py:507] global step 41441: loss = 0.1412 (0.952 sec/step)\n",
      "I0902 09:17:26.471588 139792788920128 learning.py:507] global step 41442: loss = 0.0915 (0.950 sec/step)\n",
      "I0902 09:17:27.429711 139792788920128 learning.py:507] global step 41443: loss = 0.0841 (0.957 sec/step)\n",
      "I0902 09:17:28.388806 139792788920128 learning.py:507] global step 41444: loss = 0.0548 (0.957 sec/step)\n",
      "I0902 09:17:29.363737 139792788920128 learning.py:507] global step 41445: loss = 0.0563 (0.973 sec/step)\n",
      "I0902 09:17:30.326603 139792788920128 learning.py:507] global step 41446: loss = 0.1504 (0.961 sec/step)\n",
      "I0902 09:17:31.285356 139792788920128 learning.py:507] global step 41447: loss = 0.0831 (0.957 sec/step)\n",
      "I0902 09:17:32.258180 139792788920128 learning.py:507] global step 41448: loss = 0.0864 (0.971 sec/step)\n",
      "I0902 09:17:33.220134 139792788920128 learning.py:507] global step 41449: loss = 0.1099 (0.960 sec/step)\n",
      "I0902 09:17:34.183754 139792788920128 learning.py:507] global step 41450: loss = 0.1161 (0.962 sec/step)\n",
      "I0902 09:17:35.144814 139792788920128 learning.py:507] global step 41451: loss = 0.1089 (0.959 sec/step)\n",
      "I0902 09:17:36.118685 139792788920128 learning.py:507] global step 41452: loss = 0.1529 (0.972 sec/step)\n",
      "I0902 09:17:37.078661 139792788920128 learning.py:507] global step 41453: loss = 0.1282 (0.958 sec/step)\n",
      "I0902 09:17:38.080873 139792788920128 learning.py:507] global step 41454: loss = 0.0669 (1.001 sec/step)\n",
      "I0902 09:17:39.052192 139792788920128 learning.py:507] global step 41455: loss = 0.1494 (0.970 sec/step)\n",
      "I0902 09:17:40.036985 139792788920128 learning.py:507] global step 41456: loss = 0.0824 (0.983 sec/step)\n",
      "I0902 09:17:41.003759 139792788920128 learning.py:507] global step 41457: loss = 0.2573 (0.965 sec/step)\n",
      "I0902 09:17:41.978565 139792788920128 learning.py:507] global step 41458: loss = 0.1162 (0.973 sec/step)\n",
      "I0902 09:17:42.942382 139792788920128 learning.py:507] global step 41459: loss = 0.1983 (0.962 sec/step)\n",
      "I0902 09:17:43.909981 139792788920128 learning.py:507] global step 41460: loss = 0.1716 (0.966 sec/step)\n",
      "I0902 09:17:44.882143 139792788920128 learning.py:507] global step 41461: loss = 0.1714 (0.970 sec/step)\n",
      "I0902 09:17:45.866014 139792788920128 learning.py:507] global step 41462: loss = 0.1275 (0.982 sec/step)\n",
      "I0902 09:17:46.834832 139792788920128 learning.py:507] global step 41463: loss = 0.1129 (0.967 sec/step)\n",
      "I0902 09:17:47.807089 139792788920128 learning.py:507] global step 41464: loss = 0.1710 (0.971 sec/step)\n",
      "I0902 09:17:48.760696 139792788920128 learning.py:507] global step 41465: loss = 0.0714 (0.952 sec/step)\n",
      "I0902 09:17:49.868669 139792788920128 learning.py:507] global step 41466: loss = 0.0693 (1.103 sec/step)\n",
      "I0902 09:17:50.172882 139778936784640 supervisor.py:1050] Recording summary at step 41466.\n",
      "I0902 09:17:50.958159 139792788920128 learning.py:507] global step 41467: loss = 0.3980 (1.083 sec/step)\n",
      "I0902 09:17:51.912348 139792788920128 learning.py:507] global step 41468: loss = 0.1189 (0.952 sec/step)\n",
      "I0902 09:17:52.868820 139792788920128 learning.py:507] global step 41469: loss = 0.0476 (0.955 sec/step)\n",
      "I0902 09:17:53.835761 139792788920128 learning.py:507] global step 41470: loss = 0.1321 (0.965 sec/step)\n",
      "I0902 09:17:54.828801 139792788920128 learning.py:507] global step 41471: loss = 0.2271 (0.992 sec/step)\n",
      "I0902 09:17:55.813768 139792788920128 learning.py:507] global step 41472: loss = 0.0976 (0.983 sec/step)\n",
      "I0902 09:17:56.787519 139792788920128 learning.py:507] global step 41473: loss = 0.0815 (0.972 sec/step)\n",
      "I0902 09:17:57.757802 139792788920128 learning.py:507] global step 41474: loss = 0.0931 (0.969 sec/step)\n",
      "I0902 09:17:58.717802 139792788920128 learning.py:507] global step 41475: loss = 0.1466 (0.958 sec/step)\n",
      "I0902 09:17:59.674552 139792788920128 learning.py:507] global step 41476: loss = 0.1066 (0.955 sec/step)\n",
      "I0902 09:18:00.641244 139792788920128 learning.py:507] global step 41477: loss = 0.1279 (0.965 sec/step)\n",
      "I0902 09:18:01.609853 139792788920128 learning.py:507] global step 41478: loss = 0.1325 (0.967 sec/step)\n",
      "I0902 09:18:02.579637 139792788920128 learning.py:507] global step 41479: loss = 0.1392 (0.968 sec/step)\n",
      "I0902 09:18:03.539402 139792788920128 learning.py:507] global step 41480: loss = 0.0510 (0.958 sec/step)\n",
      "I0902 09:18:04.508181 139792788920128 learning.py:507] global step 41481: loss = 0.2000 (0.967 sec/step)\n",
      "I0902 09:18:05.481710 139792788920128 learning.py:507] global step 41482: loss = 0.1553 (0.972 sec/step)\n",
      "I0902 09:18:06.445057 139792788920128 learning.py:507] global step 41483: loss = 0.1320 (0.962 sec/step)\n",
      "I0902 09:18:07.411156 139792788920128 learning.py:507] global step 41484: loss = 0.1370 (0.964 sec/step)\n",
      "I0902 09:18:08.376079 139792788920128 learning.py:507] global step 41485: loss = 0.1640 (0.963 sec/step)\n",
      "I0902 09:18:09.343058 139792788920128 learning.py:507] global step 41486: loss = 0.0978 (0.965 sec/step)\n",
      "I0902 09:18:10.304887 139792788920128 learning.py:507] global step 41487: loss = 0.1067 (0.960 sec/step)\n",
      "I0902 09:18:11.267933 139792788920128 learning.py:507] global step 41488: loss = 0.0693 (0.961 sec/step)\n",
      "I0902 09:18:12.226125 139792788920128 learning.py:507] global step 41489: loss = 0.0917 (0.956 sec/step)\n",
      "I0902 09:18:13.186959 139792788920128 learning.py:507] global step 41490: loss = 0.1114 (0.959 sec/step)\n",
      "I0902 09:18:14.148665 139792788920128 learning.py:507] global step 41491: loss = 0.0851 (0.960 sec/step)\n",
      "I0902 09:18:15.121388 139792788920128 learning.py:507] global step 41492: loss = 0.1705 (0.971 sec/step)\n",
      "I0902 09:18:16.099308 139792788920128 learning.py:507] global step 41493: loss = 0.1336 (0.976 sec/step)\n",
      "I0902 09:18:17.072812 139792788920128 learning.py:507] global step 41494: loss = 0.0827 (0.972 sec/step)\n",
      "I0902 09:18:18.046786 139792788920128 learning.py:507] global step 41495: loss = 0.1700 (0.972 sec/step)\n",
      "I0902 09:18:19.004966 139792788920128 learning.py:507] global step 41496: loss = 0.0654 (0.956 sec/step)\n",
      "I0902 09:18:19.970113 139792788920128 learning.py:507] global step 41497: loss = 0.0999 (0.964 sec/step)\n",
      "I0902 09:18:20.924038 139792788920128 learning.py:507] global step 41498: loss = 0.0700 (0.952 sec/step)\n",
      "I0902 09:18:21.886860 139792788920128 learning.py:507] global step 41499: loss = 0.0942 (0.961 sec/step)\n",
      "I0902 09:18:22.867462 139792788920128 learning.py:507] global step 41500: loss = 0.0703 (0.979 sec/step)\n",
      "I0902 09:18:23.840463 139792788920128 learning.py:507] global step 41501: loss = 0.1306 (0.971 sec/step)\n",
      "I0902 09:18:24.826042 139792788920128 learning.py:507] global step 41502: loss = 0.1234 (0.984 sec/step)\n",
      "I0902 09:18:25.780832 139792788920128 learning.py:507] global step 41503: loss = 0.1621 (0.953 sec/step)\n",
      "I0902 09:18:26.756140 139792788920128 learning.py:507] global step 41504: loss = 0.2346 (0.974 sec/step)\n",
      "I0902 09:18:27.726880 139792788920128 learning.py:507] global step 41505: loss = 0.1303 (0.969 sec/step)\n",
      "I0902 09:18:28.694450 139792788920128 learning.py:507] global step 41506: loss = 0.1634 (0.966 sec/step)\n",
      "I0902 09:18:29.658025 139792788920128 learning.py:507] global step 41507: loss = 0.1342 (0.962 sec/step)\n",
      "I0902 09:18:30.607849 139792788920128 learning.py:507] global step 41508: loss = 0.0672 (0.948 sec/step)\n",
      "I0902 09:18:31.577129 139792788920128 learning.py:507] global step 41509: loss = 0.0634 (0.967 sec/step)\n",
      "I0902 09:18:32.557663 139792788920128 learning.py:507] global step 41510: loss = 0.1773 (0.979 sec/step)\n",
      "I0902 09:18:33.527703 139792788920128 learning.py:507] global step 41511: loss = 0.1057 (0.968 sec/step)\n",
      "I0902 09:18:34.493359 139792788920128 learning.py:507] global step 41512: loss = 0.1037 (0.964 sec/step)\n",
      "I0902 09:18:35.467272 139792788920128 learning.py:507] global step 41513: loss = 0.0832 (0.972 sec/step)\n",
      "I0902 09:18:36.432095 139792788920128 learning.py:507] global step 41514: loss = 0.0889 (0.963 sec/step)\n",
      "I0902 09:18:37.401313 139792788920128 learning.py:507] global step 41515: loss = 0.0690 (0.967 sec/step)\n",
      "I0902 09:18:38.370563 139792788920128 learning.py:507] global step 41516: loss = 0.0602 (0.968 sec/step)\n",
      "I0902 09:18:39.331449 139792788920128 learning.py:507] global step 41517: loss = 0.1371 (0.959 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:18:40.310847 139792788920128 learning.py:507] global step 41518: loss = 0.1821 (0.978 sec/step)\n",
      "I0902 09:18:41.320407 139792788920128 learning.py:507] global step 41519: loss = 0.2725 (1.008 sec/step)\n",
      "I0902 09:18:42.317909 139792788920128 learning.py:507] global step 41520: loss = 0.0879 (0.996 sec/step)\n",
      "I0902 09:18:43.291128 139792788920128 learning.py:507] global step 41521: loss = 0.0484 (0.972 sec/step)\n",
      "I0902 09:18:44.283888 139792788920128 learning.py:507] global step 41522: loss = 0.0966 (0.991 sec/step)\n",
      "I0902 09:18:45.257405 139792788920128 learning.py:507] global step 41523: loss = 0.1049 (0.972 sec/step)\n",
      "I0902 09:18:46.224380 139792788920128 learning.py:507] global step 41524: loss = 0.0995 (0.965 sec/step)\n",
      "I0902 09:18:47.195931 139792788920128 learning.py:507] global step 41525: loss = 0.0638 (0.970 sec/step)\n",
      "I0902 09:18:48.162611 139792788920128 learning.py:507] global step 41526: loss = 0.1708 (0.965 sec/step)\n",
      "I0902 09:18:49.125085 139792788920128 learning.py:507] global step 41527: loss = 0.2528 (0.961 sec/step)\n",
      "I0902 09:18:50.097097 139792788920128 learning.py:507] global step 41528: loss = 0.0531 (0.970 sec/step)\n",
      "I0902 09:18:51.061925 139792788920128 learning.py:507] global step 41529: loss = 0.1801 (0.963 sec/step)\n",
      "I0902 09:18:52.014910 139792788920128 learning.py:507] global step 41530: loss = 0.2068 (0.951 sec/step)\n",
      "I0902 09:18:52.981278 139792788920128 learning.py:507] global step 41531: loss = 0.0823 (0.965 sec/step)\n",
      "I0902 09:18:53.942862 139792788920128 learning.py:507] global step 41532: loss = 0.0906 (0.960 sec/step)\n",
      "I0902 09:18:54.895964 139792788920128 learning.py:507] global step 41533: loss = 0.1139 (0.951 sec/step)\n",
      "I0902 09:18:55.858772 139792788920128 learning.py:507] global step 41534: loss = 0.2261 (0.961 sec/step)\n",
      "I0902 09:18:56.837899 139792788920128 learning.py:507] global step 41535: loss = 0.0812 (0.977 sec/step)\n",
      "I0902 09:18:57.811159 139792788920128 learning.py:507] global step 41536: loss = 0.0752 (0.972 sec/step)\n",
      "I0902 09:18:58.778946 139792788920128 learning.py:507] global step 41537: loss = 0.1089 (0.966 sec/step)\n",
      "I0902 09:18:59.738169 139792788920128 learning.py:507] global step 41538: loss = 0.1612 (0.958 sec/step)\n",
      "I0902 09:19:00.711587 139792788920128 learning.py:507] global step 41539: loss = 0.1383 (0.972 sec/step)\n",
      "I0902 09:19:01.680097 139792788920128 learning.py:507] global step 41540: loss = 0.0821 (0.967 sec/step)\n",
      "I0902 09:19:02.637207 139792788920128 learning.py:507] global step 41541: loss = 0.1455 (0.955 sec/step)\n",
      "I0902 09:19:03.598494 139792788920128 learning.py:507] global step 41542: loss = 0.1718 (0.960 sec/step)\n",
      "I0902 09:19:04.562448 139792788920128 learning.py:507] global step 41543: loss = 0.0849 (0.962 sec/step)\n",
      "I0902 09:19:05.519745 139792788920128 learning.py:507] global step 41544: loss = 0.0619 (0.955 sec/step)\n",
      "I0902 09:19:06.492227 139792788920128 learning.py:507] global step 41545: loss = 0.0901 (0.971 sec/step)\n",
      "I0902 09:19:07.475806 139792788920128 learning.py:507] global step 41546: loss = 0.2067 (0.982 sec/step)\n",
      "I0902 09:19:08.458642 139792788920128 learning.py:507] global step 41547: loss = 0.1086 (0.981 sec/step)\n",
      "I0902 09:19:09.431720 139792788920128 learning.py:507] global step 41548: loss = 0.1678 (0.971 sec/step)\n",
      "I0902 09:19:10.389010 139792788920128 learning.py:507] global step 41549: loss = 0.1104 (0.955 sec/step)\n",
      "I0902 09:19:11.343133 139792788920128 learning.py:507] global step 41550: loss = 0.1394 (0.952 sec/step)\n",
      "I0902 09:19:12.303048 139792788920128 learning.py:507] global step 41551: loss = 0.0966 (0.959 sec/step)\n",
      "I0902 09:19:13.283659 139792788920128 learning.py:507] global step 41552: loss = 0.2092 (0.979 sec/step)\n",
      "I0902 09:19:14.247098 139792788920128 learning.py:507] global step 41553: loss = 0.2348 (0.962 sec/step)\n",
      "I0902 09:19:15.211520 139792788920128 learning.py:507] global step 41554: loss = 0.1217 (0.963 sec/step)\n",
      "I0902 09:19:16.174910 139792788920128 learning.py:507] global step 41555: loss = 0.2399 (0.962 sec/step)\n",
      "I0902 09:19:17.140304 139792788920128 learning.py:507] global step 41556: loss = 0.1054 (0.964 sec/step)\n",
      "I0902 09:19:18.119846 139792788920128 learning.py:507] global step 41557: loss = 0.1228 (0.978 sec/step)\n",
      "I0902 09:19:19.077702 139792788920128 learning.py:507] global step 41558: loss = 0.0914 (0.956 sec/step)\n",
      "I0902 09:19:20.032378 139792788920128 learning.py:507] global step 41559: loss = 0.1065 (0.953 sec/step)\n",
      "I0902 09:19:20.987311 139792788920128 learning.py:507] global step 41560: loss = 0.3238 (0.953 sec/step)\n",
      "I0902 09:19:21.957038 139792788920128 learning.py:507] global step 41561: loss = 0.0835 (0.968 sec/step)\n",
      "I0902 09:19:22.933262 139792788920128 learning.py:507] global step 41562: loss = 0.0625 (0.975 sec/step)\n",
      "I0902 09:19:23.901675 139792788920128 learning.py:507] global step 41563: loss = 0.1950 (0.967 sec/step)\n",
      "I0902 09:19:24.864048 139792788920128 learning.py:507] global step 41564: loss = 0.1036 (0.961 sec/step)\n",
      "I0902 09:19:25.814024 139792788920128 learning.py:507] global step 41565: loss = 0.2469 (0.948 sec/step)\n",
      "I0902 09:19:26.768083 139792788920128 learning.py:507] global step 41566: loss = 0.1051 (0.952 sec/step)\n",
      "I0902 09:19:27.749860 139792788920128 learning.py:507] global step 41567: loss = 0.1968 (0.980 sec/step)\n",
      "I0902 09:19:28.721819 139792788920128 learning.py:507] global step 41568: loss = 0.1282 (0.970 sec/step)\n",
      "I0902 09:19:29.687266 139792788920128 learning.py:507] global step 41569: loss = 0.0816 (0.964 sec/step)\n",
      "I0902 09:19:30.656720 139792788920128 learning.py:507] global step 41570: loss = 0.1286 (0.968 sec/step)\n",
      "I0902 09:19:31.604028 139792788920128 learning.py:507] global step 41571: loss = 0.1293 (0.946 sec/step)\n",
      "I0902 09:19:32.558605 139792788920128 learning.py:507] global step 41572: loss = 0.1324 (0.953 sec/step)\n",
      "I0902 09:19:33.546788 139792788920128 learning.py:507] global step 41573: loss = 0.1303 (0.987 sec/step)\n",
      "I0902 09:19:34.514493 139792788920128 learning.py:507] global step 41574: loss = 0.1215 (0.966 sec/step)\n",
      "I0902 09:19:35.479101 139792788920128 learning.py:507] global step 41575: loss = 0.1163 (0.963 sec/step)\n",
      "I0902 09:19:36.445501 139792788920128 learning.py:507] global step 41576: loss = 0.1271 (0.965 sec/step)\n",
      "I0902 09:19:37.402821 139792788920128 learning.py:507] global step 41577: loss = 0.0923 (0.956 sec/step)\n",
      "I0902 09:19:38.380755 139792788920128 learning.py:507] global step 41578: loss = 0.1410 (0.976 sec/step)\n",
      "I0902 09:19:39.353132 139792788920128 learning.py:507] global step 41579: loss = 0.0810 (0.971 sec/step)\n",
      "I0902 09:19:40.370014 139792788920128 learning.py:507] global step 41580: loss = 0.0736 (1.015 sec/step)\n",
      "I0902 09:19:41.386395 139792788920128 learning.py:507] global step 41581: loss = 0.0603 (1.015 sec/step)\n",
      "I0902 09:19:42.370756 139792788920128 learning.py:507] global step 41582: loss = 0.2450 (0.983 sec/step)\n",
      "I0902 09:19:43.353121 139792788920128 learning.py:507] global step 41583: loss = 0.0984 (0.981 sec/step)\n",
      "I0902 09:19:44.326035 139792788920128 learning.py:507] global step 41584: loss = 0.0774 (0.971 sec/step)\n",
      "I0902 09:19:45.285587 139792788920128 learning.py:507] global step 41585: loss = 0.0753 (0.958 sec/step)\n",
      "I0902 09:19:46.275725 139792788920128 learning.py:507] global step 41586: loss = 0.1111 (0.989 sec/step)\n",
      "I0902 09:19:47.241057 139792788920128 learning.py:507] global step 41587: loss = 0.0968 (0.964 sec/step)\n",
      "I0902 09:19:48.223038 139792788920128 learning.py:507] global step 41588: loss = 0.0985 (0.980 sec/step)\n",
      "I0902 09:19:49.182374 139792788920128 learning.py:507] global step 41589: loss = 0.0647 (0.958 sec/step)\n",
      "I0902 09:19:50.318948 139792788920128 learning.py:507] global step 41590: loss = 0.0765 (1.133 sec/step)\n",
      "I0902 09:19:50.615408 139778936784640 supervisor.py:1050] Recording summary at step 41590.\n",
      "I0902 09:19:51.375699 139792788920128 learning.py:507] global step 41591: loss = 0.0821 (1.054 sec/step)\n",
      "I0902 09:19:52.346123 139792788920128 learning.py:507] global step 41592: loss = 0.1075 (0.969 sec/step)\n",
      "I0902 09:19:53.292958 139792788920128 learning.py:507] global step 41593: loss = 0.1292 (0.945 sec/step)\n",
      "I0902 09:19:54.271644 139792788920128 learning.py:507] global step 41594: loss = 0.1169 (0.977 sec/step)\n",
      "I0902 09:19:55.230371 139792788920128 learning.py:507] global step 41595: loss = 0.0884 (0.957 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:19:56.185484 139792788920128 learning.py:507] global step 41596: loss = 0.2087 (0.953 sec/step)\n",
      "I0902 09:19:57.192009 139792788920128 learning.py:507] global step 41597: loss = 0.0669 (1.005 sec/step)\n",
      "I0902 09:19:58.153152 139792788920128 learning.py:507] global step 41598: loss = 0.1085 (0.960 sec/step)\n",
      "I0902 09:19:59.116510 139792788920128 learning.py:507] global step 41599: loss = 0.0850 (0.962 sec/step)\n",
      "I0902 09:20:00.095582 139792788920128 learning.py:507] global step 41600: loss = 0.0930 (0.977 sec/step)\n",
      "I0902 09:20:01.073436 139792788920128 learning.py:507] global step 41601: loss = 0.1619 (0.976 sec/step)\n",
      "I0902 09:20:02.016090 139792788920128 learning.py:507] global step 41602: loss = 0.2570 (0.941 sec/step)\n",
      "I0902 09:20:02.976148 139792788920128 learning.py:507] global step 41603: loss = 0.2282 (0.958 sec/step)\n",
      "I0902 09:20:03.930997 139792788920128 learning.py:507] global step 41604: loss = 0.1716 (0.953 sec/step)\n",
      "I0902 09:20:04.915992 139792788920128 learning.py:507] global step 41605: loss = 0.0466 (0.983 sec/step)\n",
      "I0902 09:20:05.884257 139792788920128 learning.py:507] global step 41606: loss = 0.1208 (0.967 sec/step)\n",
      "I0902 09:20:06.856415 139792788920128 learning.py:507] global step 41607: loss = 0.1629 (0.971 sec/step)\n",
      "I0902 09:20:07.818633 139792788920128 learning.py:507] global step 41608: loss = 0.1378 (0.960 sec/step)\n",
      "I0902 09:20:08.777045 139792788920128 learning.py:507] global step 41609: loss = 0.1162 (0.957 sec/step)\n",
      "I0902 09:20:09.744896 139792788920128 learning.py:507] global step 41610: loss = 0.0811 (0.966 sec/step)\n",
      "I0902 09:20:10.705419 139792788920128 learning.py:507] global step 41611: loss = 0.0541 (0.959 sec/step)\n",
      "I0902 09:20:11.683396 139792788920128 learning.py:507] global step 41612: loss = 0.0983 (0.976 sec/step)\n",
      "I0902 09:20:12.657794 139792788920128 learning.py:507] global step 41613: loss = 0.1410 (0.973 sec/step)\n",
      "I0902 09:20:13.617843 139792788920128 learning.py:507] global step 41614: loss = 0.0917 (0.958 sec/step)\n",
      "I0902 09:20:14.579205 139792788920128 learning.py:507] global step 41615: loss = 0.3195 (0.960 sec/step)\n",
      "I0902 09:20:15.556106 139792788920128 learning.py:507] global step 41616: loss = 0.0765 (0.975 sec/step)\n",
      "I0902 09:20:16.521507 139792788920128 learning.py:507] global step 41617: loss = 0.1348 (0.964 sec/step)\n",
      "I0902 09:20:17.477906 139792788920128 learning.py:507] global step 41618: loss = 0.0734 (0.955 sec/step)\n",
      "I0902 09:20:18.448361 139792788920128 learning.py:507] global step 41619: loss = 0.1058 (0.969 sec/step)\n",
      "I0902 09:20:19.408602 139792788920128 learning.py:507] global step 41620: loss = 0.2135 (0.958 sec/step)\n",
      "I0902 09:20:20.366539 139792788920128 learning.py:507] global step 41621: loss = 0.1074 (0.956 sec/step)\n",
      "I0902 09:20:21.328326 139792788920128 learning.py:507] global step 41622: loss = 0.1234 (0.960 sec/step)\n",
      "I0902 09:20:22.291059 139792788920128 learning.py:507] global step 41623: loss = 0.1806 (0.961 sec/step)\n",
      "I0902 09:20:23.257494 139792788920128 learning.py:507] global step 41624: loss = 0.1565 (0.965 sec/step)\n",
      "I0902 09:20:24.222377 139792788920128 learning.py:507] global step 41625: loss = 0.1802 (0.963 sec/step)\n",
      "I0902 09:20:25.203864 139792788920128 learning.py:507] global step 41626: loss = 0.1169 (0.980 sec/step)\n",
      "I0902 09:20:26.177148 139792788920128 learning.py:507] global step 41627: loss = 0.1184 (0.972 sec/step)\n",
      "I0902 09:20:27.136492 139792788920128 learning.py:507] global step 41628: loss = 0.0552 (0.958 sec/step)\n",
      "I0902 09:20:28.105380 139792788920128 learning.py:507] global step 41629: loss = 0.1487 (0.967 sec/step)\n",
      "I0902 09:20:29.103843 139792788920128 learning.py:507] global step 41630: loss = 0.0606 (0.997 sec/step)\n",
      "I0902 09:20:30.085789 139792788920128 learning.py:507] global step 41631: loss = 0.1341 (0.980 sec/step)\n",
      "I0902 09:20:31.048985 139792788920128 learning.py:507] global step 41632: loss = 0.0850 (0.961 sec/step)\n",
      "I0902 09:20:32.046522 139792788920128 learning.py:507] global step 41633: loss = 0.0681 (0.996 sec/step)\n",
      "I0902 09:20:32.992739 139792788920128 learning.py:507] global step 41634: loss = 0.2157 (0.944 sec/step)\n",
      "I0902 09:20:33.958910 139792788920128 learning.py:507] global step 41635: loss = 0.1316 (0.964 sec/step)\n",
      "I0902 09:20:34.909926 139792788920128 learning.py:507] global step 41636: loss = 0.1358 (0.949 sec/step)\n",
      "I0902 09:20:35.874947 139792788920128 learning.py:507] global step 41637: loss = 0.1136 (0.964 sec/step)\n",
      "I0902 09:20:36.830070 139792788920128 learning.py:507] global step 41638: loss = 0.1693 (0.953 sec/step)\n",
      "I0902 09:20:37.789602 139792788920128 learning.py:507] global step 41639: loss = 0.2204 (0.958 sec/step)\n",
      "I0902 09:20:38.763980 139792788920128 learning.py:507] global step 41640: loss = 0.1656 (0.973 sec/step)\n",
      "I0902 09:20:39.729394 139792788920128 learning.py:507] global step 41641: loss = 0.1128 (0.964 sec/step)\n",
      "I0902 09:20:40.705031 139792788920128 learning.py:507] global step 41642: loss = 0.3563 (0.974 sec/step)\n",
      "I0902 09:20:41.676805 139792788920128 learning.py:507] global step 41643: loss = 0.1730 (0.970 sec/step)\n",
      "I0902 09:20:42.659786 139792788920128 learning.py:507] global step 41644: loss = 0.1265 (0.981 sec/step)\n",
      "I0902 09:20:43.621526 139792788920128 learning.py:507] global step 41645: loss = 0.0667 (0.960 sec/step)\n",
      "I0902 09:20:44.583215 139792788920128 learning.py:507] global step 41646: loss = 0.0944 (0.960 sec/step)\n",
      "I0902 09:20:45.553396 139792788920128 learning.py:507] global step 41647: loss = 0.1204 (0.969 sec/step)\n",
      "I0902 09:20:46.532826 139792788920128 learning.py:507] global step 41648: loss = 0.3157 (0.978 sec/step)\n",
      "I0902 09:20:47.503168 139792788920128 learning.py:507] global step 41649: loss = 0.1739 (0.969 sec/step)\n",
      "I0902 09:20:48.464573 139792788920128 learning.py:507] global step 41650: loss = 0.0552 (0.960 sec/step)\n",
      "I0902 09:20:49.423238 139792788920128 learning.py:507] global step 41651: loss = 0.1414 (0.957 sec/step)\n",
      "I0902 09:20:50.381957 139792788920128 learning.py:507] global step 41652: loss = 0.0503 (0.957 sec/step)\n",
      "I0902 09:20:51.387170 139792788920128 learning.py:507] global step 41653: loss = 0.0519 (1.004 sec/step)\n",
      "I0902 09:20:52.387622 139792788920128 learning.py:507] global step 41654: loss = 0.1835 (0.999 sec/step)\n",
      "I0902 09:20:53.344200 139792788920128 learning.py:507] global step 41655: loss = 0.0803 (0.955 sec/step)\n",
      "I0902 09:20:54.322954 139792788920128 learning.py:507] global step 41656: loss = 0.2813 (0.977 sec/step)\n",
      "I0902 09:20:55.279260 139792788920128 learning.py:507] global step 41657: loss = 0.1224 (0.955 sec/step)\n",
      "I0902 09:20:56.236900 139792788920128 learning.py:507] global step 41658: loss = 0.0802 (0.956 sec/step)\n",
      "I0902 09:20:57.210441 139792788920128 learning.py:507] global step 41659: loss = 0.0909 (0.972 sec/step)\n",
      "I0902 09:20:58.184285 139792788920128 learning.py:507] global step 41660: loss = 0.0912 (0.972 sec/step)\n",
      "I0902 09:20:59.159033 139792788920128 learning.py:507] global step 41661: loss = 0.2226 (0.973 sec/step)\n",
      "I0902 09:21:00.113415 139792788920128 learning.py:507] global step 41662: loss = 0.0851 (0.953 sec/step)\n",
      "I0902 09:21:01.081859 139792788920128 learning.py:507] global step 41663: loss = 0.1321 (0.967 sec/step)\n",
      "I0902 09:21:02.037465 139792788920128 learning.py:507] global step 41664: loss = 0.1680 (0.954 sec/step)\n",
      "I0902 09:21:03.014493 139792788920128 learning.py:507] global step 41665: loss = 0.0706 (0.975 sec/step)\n",
      "I0902 09:21:03.969699 139792788920128 learning.py:507] global step 41666: loss = 0.0805 (0.954 sec/step)\n",
      "I0902 09:21:04.951647 139792788920128 learning.py:507] global step 41667: loss = 0.1804 (0.980 sec/step)\n",
      "I0902 09:21:05.937805 139792788920128 learning.py:507] global step 41668: loss = 0.1087 (0.985 sec/step)\n",
      "I0902 09:21:06.911097 139792788920128 learning.py:507] global step 41669: loss = 0.0974 (0.972 sec/step)\n",
      "I0902 09:21:07.897996 139792788920128 learning.py:507] global step 41670: loss = 0.1448 (0.985 sec/step)\n",
      "I0902 09:21:08.891198 139792788920128 learning.py:507] global step 41671: loss = 0.1702 (0.991 sec/step)\n",
      "I0902 09:21:09.862576 139792788920128 learning.py:507] global step 41672: loss = 0.0693 (0.970 sec/step)\n",
      "I0902 09:21:10.839142 139792788920128 learning.py:507] global step 41673: loss = 0.0889 (0.975 sec/step)\n",
      "I0902 09:21:11.819898 139792788920128 learning.py:507] global step 41674: loss = 0.1769 (0.979 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:21:12.796301 139792788920128 learning.py:507] global step 41675: loss = 0.1333 (0.975 sec/step)\n",
      "I0902 09:21:13.765892 139792788920128 learning.py:507] global step 41676: loss = 0.1776 (0.968 sec/step)\n",
      "I0902 09:21:14.749220 139792788920128 learning.py:507] global step 41677: loss = 0.1823 (0.982 sec/step)\n",
      "I0902 09:21:15.718167 139792788920128 learning.py:507] global step 41678: loss = 0.1271 (0.967 sec/step)\n",
      "I0902 09:21:16.687187 139792788920128 learning.py:507] global step 41679: loss = 0.1284 (0.967 sec/step)\n",
      "I0902 09:21:17.662645 139792788920128 learning.py:507] global step 41680: loss = 0.0765 (0.974 sec/step)\n",
      "I0902 09:21:18.639190 139792788920128 learning.py:507] global step 41681: loss = 0.1576 (0.975 sec/step)\n",
      "I0902 09:21:19.606527 139792788920128 learning.py:507] global step 41682: loss = 0.2621 (0.966 sec/step)\n",
      "I0902 09:21:20.569583 139792788920128 learning.py:507] global step 41683: loss = 0.5801 (0.962 sec/step)\n",
      "I0902 09:21:21.541601 139792788920128 learning.py:507] global step 41684: loss = 0.0738 (0.970 sec/step)\n",
      "I0902 09:21:22.509090 139792788920128 learning.py:507] global step 41685: loss = 0.1053 (0.966 sec/step)\n",
      "I0902 09:21:23.471226 139792788920128 learning.py:507] global step 41686: loss = 0.1334 (0.960 sec/step)\n",
      "I0902 09:21:24.434005 139792788920128 learning.py:507] global step 41687: loss = 0.0650 (0.961 sec/step)\n",
      "I0902 09:21:25.407569 139792788920128 learning.py:507] global step 41688: loss = 0.1901 (0.972 sec/step)\n",
      "I0902 09:21:26.401241 139792788920128 learning.py:507] global step 41689: loss = 0.1706 (0.992 sec/step)\n",
      "I0902 09:21:27.360979 139792788920128 learning.py:507] global step 41690: loss = 0.1138 (0.958 sec/step)\n",
      "I0902 09:21:28.345387 139792788920128 learning.py:507] global step 41691: loss = 0.2559 (0.983 sec/step)\n",
      "I0902 09:21:29.314978 139792788920128 learning.py:507] global step 41692: loss = 0.1334 (0.968 sec/step)\n",
      "I0902 09:21:30.294043 139792788920128 learning.py:507] global step 41693: loss = 0.0845 (0.978 sec/step)\n",
      "I0902 09:21:31.257365 139792788920128 learning.py:507] global step 41694: loss = 0.0612 (0.962 sec/step)\n",
      "I0902 09:21:32.242343 139792788920128 learning.py:507] global step 41695: loss = 0.1444 (0.983 sec/step)\n",
      "I0902 09:21:33.213306 139792788920128 learning.py:507] global step 41696: loss = 0.0580 (0.969 sec/step)\n",
      "I0902 09:21:34.212221 139792788920128 learning.py:507] global step 41697: loss = 0.1135 (0.997 sec/step)\n",
      "I0902 09:21:35.199868 139792788920128 learning.py:507] global step 41698: loss = 0.0643 (0.986 sec/step)\n",
      "I0902 09:21:36.151217 139792788920128 learning.py:507] global step 41699: loss = 0.1272 (0.950 sec/step)\n",
      "I0902 09:21:37.132592 139792788920128 learning.py:507] global step 41700: loss = 0.1131 (0.980 sec/step)\n",
      "I0902 09:21:38.095383 139792788920128 learning.py:507] global step 41701: loss = 0.0771 (0.961 sec/step)\n",
      "I0902 09:21:39.056766 139792788920128 learning.py:507] global step 41702: loss = 0.1645 (0.960 sec/step)\n",
      "I0902 09:21:40.022134 139792788920128 learning.py:507] global step 41703: loss = 0.0862 (0.964 sec/step)\n",
      "I0902 09:21:41.005849 139792788920128 learning.py:507] global step 41704: loss = 0.0564 (0.982 sec/step)\n",
      "I0902 09:21:41.967765 139792788920128 learning.py:507] global step 41705: loss = 0.1454 (0.960 sec/step)\n",
      "I0902 09:21:42.931913 139792788920128 learning.py:507] global step 41706: loss = 0.0686 (0.962 sec/step)\n",
      "I0902 09:21:43.903870 139792788920128 learning.py:507] global step 41707: loss = 0.1611 (0.970 sec/step)\n",
      "I0902 09:21:44.876536 139792788920128 learning.py:507] global step 41708: loss = 0.1466 (0.971 sec/step)\n",
      "I0902 09:21:45.838031 139792788920128 learning.py:507] global step 41709: loss = 0.1032 (0.960 sec/step)\n",
      "I0902 09:21:46.792232 139792788920128 learning.py:507] global step 41710: loss = 0.1507 (0.952 sec/step)\n",
      "I0902 09:21:47.771098 139792788920128 learning.py:507] global step 41711: loss = 0.0992 (0.977 sec/step)\n",
      "I0902 09:21:48.747409 139792788920128 learning.py:507] global step 41712: loss = 0.1558 (0.975 sec/step)\n",
      "I0902 09:21:49.858418 139792788920128 learning.py:507] global step 41713: loss = 0.0925 (1.106 sec/step)\n",
      "I0902 09:21:50.166583 139778936784640 supervisor.py:1050] Recording summary at step 41713.\n",
      "I0902 09:21:50.946489 139792788920128 learning.py:507] global step 41714: loss = 0.1018 (1.083 sec/step)\n",
      "I0902 09:21:51.918583 139792788920128 learning.py:507] global step 41715: loss = 0.1477 (0.971 sec/step)\n",
      "I0902 09:21:52.887774 139792788920128 learning.py:507] global step 41716: loss = 0.0980 (0.967 sec/step)\n",
      "I0902 09:21:53.857828 139792788920128 learning.py:507] global step 41717: loss = 0.1865 (0.968 sec/step)\n",
      "I0902 09:21:54.818384 139792788920128 learning.py:507] global step 41718: loss = 0.1375 (0.959 sec/step)\n",
      "I0902 09:21:55.794541 139792788920128 learning.py:507] global step 41719: loss = 0.1340 (0.975 sec/step)\n",
      "I0902 09:21:56.765455 139792788920128 learning.py:507] global step 41720: loss = 0.1375 (0.969 sec/step)\n",
      "I0902 09:21:57.738701 139792788920128 learning.py:507] global step 41721: loss = 0.1991 (0.972 sec/step)\n",
      "I0902 09:21:58.697574 139792788920128 learning.py:507] global step 41722: loss = 0.1806 (0.957 sec/step)\n",
      "I0902 09:21:59.667623 139792788920128 learning.py:507] global step 41723: loss = 0.1403 (0.968 sec/step)\n",
      "I0902 09:22:00.626646 139792788920128 learning.py:507] global step 41724: loss = 0.1482 (0.957 sec/step)\n",
      "I0902 09:22:01.593458 139792788920128 learning.py:507] global step 41725: loss = 0.0546 (0.965 sec/step)\n",
      "I0902 09:22:02.552381 139792788920128 learning.py:507] global step 41726: loss = 0.1400 (0.957 sec/step)\n",
      "I0902 09:22:03.523946 139792788920128 learning.py:507] global step 41727: loss = 0.1055 (0.970 sec/step)\n",
      "I0902 09:22:04.496670 139792788920128 learning.py:507] global step 41728: loss = 0.0860 (0.971 sec/step)\n",
      "I0902 09:22:05.455533 139792788920128 learning.py:507] global step 41729: loss = 0.4806 (0.957 sec/step)\n",
      "I0902 09:22:06.404444 139792788920128 learning.py:507] global step 41730: loss = 0.1355 (0.947 sec/step)\n",
      "I0902 09:22:07.377411 139792788920128 learning.py:507] global step 41731: loss = 0.1007 (0.971 sec/step)\n",
      "I0902 09:22:08.357437 139792788920128 learning.py:507] global step 41732: loss = 0.1582 (0.979 sec/step)\n",
      "I0902 09:22:09.320660 139792788920128 learning.py:507] global step 41733: loss = 0.4594 (0.962 sec/step)\n",
      "I0902 09:22:10.303619 139792788920128 learning.py:507] global step 41734: loss = 0.1193 (0.981 sec/step)\n",
      "I0902 09:22:11.277834 139792788920128 learning.py:507] global step 41735: loss = 0.0727 (0.973 sec/step)\n",
      "I0902 09:22:12.255345 139792788920128 learning.py:507] global step 41736: loss = 0.0902 (0.976 sec/step)\n",
      "I0902 09:22:13.205527 139792788920128 learning.py:507] global step 41737: loss = 0.1605 (0.949 sec/step)\n",
      "I0902 09:22:14.158315 139792788920128 learning.py:507] global step 41738: loss = 0.0825 (0.951 sec/step)\n",
      "I0902 09:22:15.121584 139792788920128 learning.py:507] global step 41739: loss = 0.2881 (0.962 sec/step)\n",
      "I0902 09:22:16.073264 139792788920128 learning.py:507] global step 41740: loss = 0.0782 (0.950 sec/step)\n",
      "I0902 09:22:17.059139 139792788920128 learning.py:507] global step 41741: loss = 0.0953 (0.984 sec/step)\n",
      "I0902 09:22:18.030884 139792788920128 learning.py:507] global step 41742: loss = 0.1487 (0.970 sec/step)\n",
      "I0902 09:22:18.996288 139792788920128 learning.py:507] global step 41743: loss = 0.0574 (0.964 sec/step)\n",
      "I0902 09:22:19.969079 139792788920128 learning.py:507] global step 41744: loss = 0.1620 (0.971 sec/step)\n",
      "I0902 09:22:20.970382 139792788920128 learning.py:507] global step 41745: loss = 0.2338 (1.000 sec/step)\n",
      "I0902 09:22:21.955297 139792788920128 learning.py:507] global step 41746: loss = 0.2178 (0.983 sec/step)\n",
      "I0902 09:22:22.962111 139792788920128 learning.py:507] global step 41747: loss = 0.1574 (1.005 sec/step)\n",
      "I0902 09:22:23.968894 139792788920128 learning.py:507] global step 41748: loss = 0.0743 (1.005 sec/step)\n",
      "I0902 09:22:24.947917 139792788920128 learning.py:507] global step 41749: loss = 0.1261 (0.977 sec/step)\n",
      "I0902 09:22:25.922840 139792788920128 learning.py:507] global step 41750: loss = 0.0698 (0.973 sec/step)\n",
      "I0902 09:22:26.907649 139792788920128 learning.py:507] global step 41751: loss = 0.0902 (0.983 sec/step)\n",
      "I0902 09:22:27.870120 139792788920128 learning.py:507] global step 41752: loss = 0.0966 (0.961 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:22:28.844326 139792788920128 learning.py:507] global step 41753: loss = 0.1155 (0.972 sec/step)\n",
      "I0902 09:22:29.820036 139792788920128 learning.py:507] global step 41754: loss = 0.1512 (0.974 sec/step)\n",
      "I0902 09:22:30.782019 139792788920128 learning.py:507] global step 41755: loss = 0.0943 (0.960 sec/step)\n",
      "I0902 09:22:31.749310 139792788920128 learning.py:507] global step 41756: loss = 0.1696 (0.966 sec/step)\n",
      "I0902 09:22:32.717236 139792788920128 learning.py:507] global step 41757: loss = 0.0660 (0.966 sec/step)\n",
      "I0902 09:22:33.680546 139792788920128 learning.py:507] global step 41758: loss = 0.0920 (0.962 sec/step)\n",
      "I0902 09:22:34.629386 139792788920128 learning.py:507] global step 41759: loss = 0.0917 (0.947 sec/step)\n",
      "I0902 09:22:35.611035 139792788920128 learning.py:507] global step 41760: loss = 0.0891 (0.980 sec/step)\n",
      "I0902 09:22:36.584281 139792788920128 learning.py:507] global step 41761: loss = 0.0530 (0.972 sec/step)\n",
      "I0902 09:22:37.548199 139792788920128 learning.py:507] global step 41762: loss = 0.1066 (0.962 sec/step)\n",
      "I0902 09:22:38.513622 139792788920128 learning.py:507] global step 41763: loss = 0.1814 (0.964 sec/step)\n",
      "I0902 09:22:39.481000 139792788920128 learning.py:507] global step 41764: loss = 0.1400 (0.966 sec/step)\n",
      "I0902 09:22:40.451125 139792788920128 learning.py:507] global step 41765: loss = 0.1544 (0.969 sec/step)\n",
      "I0902 09:22:41.438443 139792788920128 learning.py:507] global step 41766: loss = 0.1241 (0.986 sec/step)\n",
      "I0902 09:22:42.394146 139792788920128 learning.py:507] global step 41767: loss = 0.0494 (0.954 sec/step)\n",
      "I0902 09:22:43.351960 139792788920128 learning.py:507] global step 41768: loss = 0.1811 (0.956 sec/step)\n",
      "I0902 09:22:44.312489 139792788920128 learning.py:507] global step 41769: loss = 0.1312 (0.959 sec/step)\n",
      "I0902 09:22:45.281468 139792788920128 learning.py:507] global step 41770: loss = 0.1063 (0.968 sec/step)\n",
      "I0902 09:22:46.238412 139792788920128 learning.py:507] global step 41771: loss = 0.0930 (0.955 sec/step)\n",
      "I0902 09:22:47.205871 139792788920128 learning.py:507] global step 41772: loss = 0.0499 (0.966 sec/step)\n",
      "I0902 09:22:48.167112 139792788920128 learning.py:507] global step 41773: loss = 0.2002 (0.960 sec/step)\n",
      "I0902 09:22:49.136714 139792788920128 learning.py:507] global step 41774: loss = 0.1667 (0.968 sec/step)\n",
      "I0902 09:22:50.118890 139792788920128 learning.py:507] global step 41775: loss = 0.1586 (0.980 sec/step)\n",
      "I0902 09:22:51.077370 139792788920128 learning.py:507] global step 41776: loss = 0.0624 (0.957 sec/step)\n",
      "I0902 09:22:52.045099 139792788920128 learning.py:507] global step 41777: loss = 0.0355 (0.966 sec/step)\n",
      "I0902 09:22:52.998107 139792788920128 learning.py:507] global step 41778: loss = 0.1154 (0.951 sec/step)\n",
      "I0902 09:22:53.985201 139792788920128 learning.py:507] global step 41779: loss = 0.0621 (0.985 sec/step)\n",
      "I0902 09:22:54.951053 139792788920128 learning.py:507] global step 41780: loss = 0.1039 (0.964 sec/step)\n",
      "I0902 09:22:55.947669 139792788920128 learning.py:507] global step 41781: loss = 0.0542 (0.995 sec/step)\n",
      "I0902 09:22:56.928271 139792788920128 learning.py:507] global step 41782: loss = 0.0973 (0.979 sec/step)\n",
      "I0902 09:22:57.885365 139792788920128 learning.py:507] global step 41783: loss = 0.0762 (0.955 sec/step)\n",
      "I0902 09:22:58.851183 139792788920128 learning.py:507] global step 41784: loss = 0.1251 (0.964 sec/step)\n",
      "I0902 09:22:59.831271 139792788920128 learning.py:507] global step 41785: loss = 0.2743 (0.978 sec/step)\n",
      "I0902 09:23:00.816830 139792788920128 learning.py:507] global step 41786: loss = 0.1239 (0.984 sec/step)\n",
      "I0902 09:23:01.784281 139792788920128 learning.py:507] global step 41787: loss = 0.1549 (0.966 sec/step)\n",
      "I0902 09:23:02.758922 139792788920128 learning.py:507] global step 41788: loss = 0.1408 (0.973 sec/step)\n",
      "I0902 09:23:03.755582 139792788920128 learning.py:507] global step 41789: loss = 0.0801 (0.995 sec/step)\n",
      "I0902 09:23:04.739441 139792788920128 learning.py:507] global step 41790: loss = 0.1112 (0.982 sec/step)\n",
      "I0902 09:23:05.707978 139792788920128 learning.py:507] global step 41791: loss = 0.1514 (0.967 sec/step)\n",
      "I0902 09:23:06.697913 139792788920128 learning.py:507] global step 41792: loss = 0.1527 (0.988 sec/step)\n",
      "I0902 09:23:07.687591 139792788920128 learning.py:507] global step 41793: loss = 0.1908 (0.988 sec/step)\n",
      "I0902 09:23:08.659597 139792788920128 learning.py:507] global step 41794: loss = 0.1700 (0.970 sec/step)\n",
      "I0902 09:23:09.643515 139792788920128 learning.py:507] global step 41795: loss = 0.1127 (0.982 sec/step)\n",
      "I0902 09:23:10.632952 139792788920128 learning.py:507] global step 41796: loss = 0.1248 (0.988 sec/step)\n",
      "I0902 09:23:11.601578 139792788920128 learning.py:507] global step 41797: loss = 0.0912 (0.967 sec/step)\n",
      "I0902 09:23:12.594603 139792788920128 learning.py:507] global step 41798: loss = 0.0863 (0.991 sec/step)\n",
      "I0902 09:23:13.581193 139792788920128 learning.py:507] global step 41799: loss = 0.1404 (0.985 sec/step)\n",
      "I0902 09:23:14.541394 139792788920128 learning.py:507] global step 41800: loss = 0.0815 (0.959 sec/step)\n",
      "I0902 09:23:15.531963 139792788920128 learning.py:507] global step 41801: loss = 0.1211 (0.989 sec/step)\n",
      "I0902 09:23:16.521978 139792788920128 learning.py:507] global step 41802: loss = 0.1439 (0.988 sec/step)\n",
      "I0902 09:23:17.485648 139792788920128 learning.py:507] global step 41803: loss = 0.0846 (0.962 sec/step)\n",
      "I0902 09:23:18.456986 139792788920128 learning.py:507] global step 41804: loss = 0.2259 (0.970 sec/step)\n",
      "I0902 09:23:19.460306 139792788920128 learning.py:507] global step 41805: loss = 0.0535 (1.002 sec/step)\n",
      "I0902 09:23:20.473793 139792788920128 learning.py:507] global step 41806: loss = 0.1099 (1.012 sec/step)\n",
      "I0902 09:23:21.471779 139792788920128 learning.py:507] global step 41807: loss = 0.1257 (0.996 sec/step)\n",
      "I0902 09:23:22.448708 139792788920128 learning.py:507] global step 41808: loss = 0.0650 (0.975 sec/step)\n",
      "I0902 09:23:23.432777 139792788920128 learning.py:507] global step 41809: loss = 0.2321 (0.982 sec/step)\n",
      "I0902 09:23:24.409531 139792788920128 learning.py:507] global step 41810: loss = 0.1159 (0.975 sec/step)\n",
      "I0902 09:23:25.409448 139792788920128 learning.py:507] global step 41811: loss = 0.1207 (0.998 sec/step)\n",
      "I0902 09:23:26.387835 139792788920128 learning.py:507] global step 41812: loss = 0.1457 (0.977 sec/step)\n",
      "I0902 09:23:27.357897 139792788920128 learning.py:507] global step 41813: loss = 0.1283 (0.968 sec/step)\n",
      "I0902 09:23:28.337126 139792788920128 learning.py:507] global step 41814: loss = 0.0759 (0.978 sec/step)\n",
      "I0902 09:23:29.298105 139792788920128 learning.py:507] global step 41815: loss = 0.0958 (0.959 sec/step)\n",
      "I0902 09:23:30.272850 139792788920128 learning.py:507] global step 41816: loss = 0.1059 (0.973 sec/step)\n",
      "I0902 09:23:31.230011 139792788920128 learning.py:507] global step 41817: loss = 0.2789 (0.956 sec/step)\n",
      "I0902 09:23:32.204100 139792788920128 learning.py:507] global step 41818: loss = 0.0917 (0.972 sec/step)\n",
      "I0902 09:23:33.186639 139792788920128 learning.py:507] global step 41819: loss = 0.0951 (0.981 sec/step)\n",
      "I0902 09:23:34.250651 139792788920128 learning.py:507] global step 41820: loss = 0.1414 (1.062 sec/step)\n",
      "I0902 09:23:35.246987 139792788920128 learning.py:507] global step 41821: loss = 0.0864 (0.995 sec/step)\n",
      "I0902 09:23:36.233965 139792788920128 learning.py:507] global step 41822: loss = 0.0448 (0.985 sec/step)\n",
      "I0902 09:23:37.221908 139792788920128 learning.py:507] global step 41823: loss = 0.1487 (0.986 sec/step)\n",
      "I0902 09:23:38.182124 139792788920128 learning.py:507] global step 41824: loss = 0.1976 (0.959 sec/step)\n",
      "I0902 09:23:39.174520 139792788920128 learning.py:507] global step 41825: loss = 0.0808 (0.991 sec/step)\n",
      "I0902 09:23:40.165576 139792788920128 learning.py:507] global step 41826: loss = 0.0521 (0.989 sec/step)\n",
      "I0902 09:23:41.131527 139792788920128 learning.py:507] global step 41827: loss = 0.1623 (0.964 sec/step)\n",
      "I0902 09:23:42.138851 139792788920128 learning.py:507] global step 41828: loss = 0.0600 (1.006 sec/step)\n",
      "I0902 09:23:43.146167 139792788920128 learning.py:507] global step 41829: loss = 0.0705 (1.006 sec/step)\n",
      "I0902 09:23:44.127925 139792788920128 learning.py:507] global step 41830: loss = 0.0703 (0.980 sec/step)\n",
      "I0902 09:23:45.090021 139792788920128 learning.py:507] global step 41831: loss = 0.0817 (0.960 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:23:46.053912 139792788920128 learning.py:507] global step 41832: loss = 0.0803 (0.962 sec/step)\n",
      "I0902 09:23:47.033826 139792788920128 learning.py:507] global step 41833: loss = 0.1626 (0.978 sec/step)\n",
      "I0902 09:23:48.012869 139792788920128 learning.py:507] global step 41834: loss = 0.4276 (0.977 sec/step)\n",
      "I0902 09:23:48.995324 139792788920128 learning.py:507] global step 41835: loss = 0.1377 (0.981 sec/step)\n",
      "I0902 09:23:49.270365 139778953570048 supervisor.py:1117] Saving checkpoint to path data_dir/mixed_experiment/checkpoints_v2/model.ckpt\n",
      "I0902 09:23:50.310379 139778936784640 supervisor.py:1050] Recording summary at step 41836.\n",
      "I0902 09:23:50.416193 139792788920128 learning.py:507] global step 41836: loss = 0.4112 (1.314 sec/step)\n",
      "I0902 09:23:51.458680 139792788920128 learning.py:507] global step 41837: loss = 0.1003 (0.961 sec/step)\n",
      "I0902 09:23:52.434226 139792788920128 learning.py:507] global step 41838: loss = 0.0719 (0.974 sec/step)\n",
      "I0902 09:23:53.402578 139792788920128 learning.py:507] global step 41839: loss = 0.0601 (0.967 sec/step)\n",
      "I0902 09:23:54.363216 139792788920128 learning.py:507] global step 41840: loss = 0.1160 (0.959 sec/step)\n",
      "I0902 09:23:55.323780 139792788920128 learning.py:507] global step 41841: loss = 0.0901 (0.959 sec/step)\n",
      "I0902 09:23:56.323247 139792788920128 learning.py:507] global step 41842: loss = 0.0603 (0.998 sec/step)\n",
      "I0902 09:23:57.291427 139792788920128 learning.py:507] global step 41843: loss = 0.1301 (0.966 sec/step)\n",
      "I0902 09:23:58.256034 139792788920128 learning.py:507] global step 41844: loss = 0.0688 (0.963 sec/step)\n",
      "I0902 09:23:59.228369 139792788920128 learning.py:507] global step 41845: loss = 0.1550 (0.971 sec/step)\n",
      "I0902 09:24:00.215143 139792788920128 learning.py:507] global step 41846: loss = 0.0844 (0.985 sec/step)\n",
      "I0902 09:24:01.184311 139792788920128 learning.py:507] global step 41847: loss = 0.1109 (0.968 sec/step)\n",
      "I0902 09:24:02.166673 139792788920128 learning.py:507] global step 41848: loss = 0.0551 (0.981 sec/step)\n",
      "I0902 09:24:03.154987 139792788920128 learning.py:507] global step 41849: loss = 0.0570 (0.987 sec/step)\n",
      "I0902 09:24:04.144359 139792788920128 learning.py:507] global step 41850: loss = 0.1093 (0.988 sec/step)\n",
      "I0902 09:24:05.112565 139792788920128 learning.py:507] global step 41851: loss = 0.0763 (0.966 sec/step)\n",
      "I0902 09:24:06.084318 139792788920128 learning.py:507] global step 41852: loss = 0.1626 (0.970 sec/step)\n",
      "I0902 09:24:07.052701 139792788920128 learning.py:507] global step 41853: loss = 0.0659 (0.967 sec/step)\n",
      "I0902 09:24:08.022080 139792788920128 learning.py:507] global step 41854: loss = 0.1242 (0.968 sec/step)\n",
      "I0902 09:24:08.990381 139792788920128 learning.py:507] global step 41855: loss = 0.0646 (0.967 sec/step)\n",
      "I0902 09:24:09.961996 139792788920128 learning.py:507] global step 41856: loss = 0.1045 (0.970 sec/step)\n",
      "I0902 09:24:10.940900 139792788920128 learning.py:507] global step 41857: loss = 0.1687 (0.977 sec/step)\n",
      "I0902 09:24:11.917560 139792788920128 learning.py:507] global step 41858: loss = 0.1666 (0.975 sec/step)\n",
      "I0902 09:24:12.877091 139792788920128 learning.py:507] global step 41859: loss = 0.0439 (0.958 sec/step)\n",
      "I0902 09:24:13.834650 139792788920128 learning.py:507] global step 41860: loss = 0.1421 (0.956 sec/step)\n",
      "I0902 09:24:14.815908 139792788920128 learning.py:507] global step 41861: loss = 0.1384 (0.980 sec/step)\n",
      "I0902 09:24:15.777992 139792788920128 learning.py:507] global step 41862: loss = 0.0923 (0.960 sec/step)\n",
      "I0902 09:24:16.754843 139792788920128 learning.py:507] global step 41863: loss = 0.0764 (0.975 sec/step)\n",
      "I0902 09:24:17.709817 139792788920128 learning.py:507] global step 41864: loss = 0.1069 (0.953 sec/step)\n",
      "I0902 09:24:18.675908 139792788920128 learning.py:507] global step 41865: loss = 0.1103 (0.965 sec/step)\n",
      "I0902 09:24:19.656128 139792788920128 learning.py:507] global step 41866: loss = 0.0936 (0.979 sec/step)\n",
      "I0902 09:24:20.610630 139792788920128 learning.py:507] global step 41867: loss = 0.0395 (0.953 sec/step)\n",
      "I0902 09:24:21.592134 139792788920128 learning.py:507] global step 41868: loss = 0.0715 (0.980 sec/step)\n",
      "I0902 09:24:22.560541 139792788920128 learning.py:507] global step 41869: loss = 0.1628 (0.967 sec/step)\n",
      "I0902 09:24:23.540415 139792788920128 learning.py:507] global step 41870: loss = 0.0808 (0.978 sec/step)\n",
      "I0902 09:24:24.515365 139792788920128 learning.py:507] global step 41871: loss = 0.2028 (0.973 sec/step)\n",
      "I0902 09:24:25.471135 139792788920128 learning.py:507] global step 41872: loss = 0.0872 (0.954 sec/step)\n",
      "I0902 09:24:26.433820 139792788920128 learning.py:507] global step 41873: loss = 0.1256 (0.961 sec/step)\n",
      "I0902 09:24:27.415759 139792788920128 learning.py:507] global step 41874: loss = 0.2947 (0.980 sec/step)\n",
      "I0902 09:24:28.373452 139792788920128 learning.py:507] global step 41875: loss = 0.0755 (0.956 sec/step)\n",
      "I0902 09:24:29.356201 139792788920128 learning.py:507] global step 41876: loss = 0.1051 (0.981 sec/step)\n",
      "I0902 09:24:30.329233 139792788920128 learning.py:507] global step 41877: loss = 0.1465 (0.971 sec/step)\n",
      "I0902 09:24:31.312819 139792788920128 learning.py:507] global step 41878: loss = 0.0884 (0.982 sec/step)\n",
      "I0902 09:24:32.274558 139792788920128 learning.py:507] global step 41879: loss = 0.0803 (0.960 sec/step)\n",
      "I0902 09:24:33.242401 139792788920128 learning.py:507] global step 41880: loss = 0.2175 (0.966 sec/step)\n",
      "I0902 09:24:34.237306 139792788920128 learning.py:507] global step 41881: loss = 0.1102 (0.993 sec/step)\n",
      "I0902 09:24:35.211554 139792788920128 learning.py:507] global step 41882: loss = 0.1148 (0.973 sec/step)\n",
      "I0902 09:24:36.190657 139792788920128 learning.py:507] global step 41883: loss = 0.1013 (0.977 sec/step)\n",
      "I0902 09:24:37.150893 139792788920128 learning.py:507] global step 41884: loss = 0.1041 (0.959 sec/step)\n",
      "I0902 09:24:38.147294 139792788920128 learning.py:507] global step 41885: loss = 0.0828 (0.995 sec/step)\n",
      "I0902 09:24:39.120592 139792788920128 learning.py:507] global step 41886: loss = 0.0831 (0.972 sec/step)\n",
      "I0902 09:24:40.100824 139792788920128 learning.py:507] global step 41887: loss = 0.0227 (0.978 sec/step)\n",
      "I0902 09:24:41.060855 139792788920128 learning.py:507] global step 41888: loss = 0.1550 (0.958 sec/step)\n",
      "I0902 09:24:42.039409 139792788920128 learning.py:507] global step 41889: loss = 0.0547 (0.977 sec/step)\n",
      "I0902 09:24:43.026029 139792788920128 learning.py:507] global step 41890: loss = 0.1252 (0.985 sec/step)\n",
      "I0902 09:24:44.014270 139792788920128 learning.py:507] global step 41891: loss = 0.1739 (0.986 sec/step)\n",
      "I0902 09:24:44.980275 139792788920128 learning.py:507] global step 41892: loss = 0.1868 (0.964 sec/step)\n",
      "I0902 09:24:45.964186 139792788920128 learning.py:507] global step 41893: loss = 0.1612 (0.982 sec/step)\n",
      "I0902 09:24:46.937784 139792788920128 learning.py:507] global step 41894: loss = 0.3363 (0.972 sec/step)\n",
      "I0902 09:24:47.915148 139792788920128 learning.py:507] global step 41895: loss = 0.1118 (0.976 sec/step)\n",
      "I0902 09:24:48.909017 139792788920128 learning.py:507] global step 41896: loss = 0.1473 (0.992 sec/step)\n",
      "I0902 09:24:49.896060 139792788920128 learning.py:507] global step 41897: loss = 0.0815 (0.985 sec/step)\n",
      "I0902 09:24:50.887838 139792788920128 learning.py:507] global step 41898: loss = 0.0950 (0.990 sec/step)\n",
      "I0902 09:24:51.870212 139792788920128 learning.py:507] global step 41899: loss = 0.1083 (0.981 sec/step)\n",
      "I0902 09:24:52.878270 139792788920128 learning.py:507] global step 41900: loss = 0.3941 (1.006 sec/step)\n",
      "I0902 09:24:53.858633 139792788920128 learning.py:507] global step 41901: loss = 0.1047 (0.979 sec/step)\n",
      "I0902 09:24:54.818782 139792788920128 learning.py:507] global step 41902: loss = 0.0534 (0.958 sec/step)\n",
      "I0902 09:24:55.789034 139792788920128 learning.py:507] global step 41903: loss = 0.1092 (0.969 sec/step)\n",
      "I0902 09:24:56.772977 139792788920128 learning.py:507] global step 41904: loss = 0.1135 (0.982 sec/step)\n",
      "I0902 09:24:57.758962 139792788920128 learning.py:507] global step 41905: loss = 0.1367 (0.984 sec/step)\n",
      "I0902 09:24:58.737959 139792788920128 learning.py:507] global step 41906: loss = 0.1130 (0.977 sec/step)\n",
      "I0902 09:24:59.715546 139792788920128 learning.py:507] global step 41907: loss = 0.1799 (0.976 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:25:00.688691 139792788920128 learning.py:507] global step 41908: loss = 0.1233 (0.971 sec/step)\n",
      "I0902 09:25:01.678906 139792788920128 learning.py:507] global step 41909: loss = 0.0585 (0.988 sec/step)\n",
      "I0902 09:25:02.695575 139792788920128 learning.py:507] global step 41910: loss = 0.2175 (1.015 sec/step)\n",
      "I0902 09:25:03.670641 139792788920128 learning.py:507] global step 41911: loss = 0.1098 (0.973 sec/step)\n",
      "I0902 09:25:04.628791 139792788920128 learning.py:507] global step 41912: loss = 0.3942 (0.957 sec/step)\n",
      "I0902 09:25:05.601338 139792788920128 learning.py:507] global step 41913: loss = 0.0977 (0.971 sec/step)\n",
      "I0902 09:25:06.563510 139792788920128 learning.py:507] global step 41914: loss = 0.1654 (0.960 sec/step)\n",
      "I0902 09:25:07.526228 139792788920128 learning.py:507] global step 41915: loss = 0.1480 (0.961 sec/step)\n",
      "I0902 09:25:08.504936 139792788920128 learning.py:507] global step 41916: loss = 0.0984 (0.977 sec/step)\n",
      "I0902 09:25:09.484600 139792788920128 learning.py:507] global step 41917: loss = 0.1974 (0.978 sec/step)\n",
      "I0902 09:25:10.471811 139792788920128 learning.py:507] global step 41918: loss = 0.1594 (0.986 sec/step)\n",
      "I0902 09:25:11.466822 139792788920128 learning.py:507] global step 41919: loss = 0.3709 (0.993 sec/step)\n",
      "I0902 09:25:12.453670 139792788920128 learning.py:507] global step 41920: loss = 0.1232 (0.985 sec/step)\n",
      "I0902 09:25:13.444174 139792788920128 learning.py:507] global step 41921: loss = 0.1861 (0.989 sec/step)\n",
      "I0902 09:25:14.411100 139792788920128 learning.py:507] global step 41922: loss = 0.0574 (0.965 sec/step)\n",
      "I0902 09:25:15.378439 139792788920128 learning.py:507] global step 41923: loss = 0.1716 (0.966 sec/step)\n",
      "I0902 09:25:16.357889 139792788920128 learning.py:507] global step 41924: loss = 0.0902 (0.978 sec/step)\n",
      "I0902 09:25:17.329841 139792788920128 learning.py:507] global step 41925: loss = 0.0928 (0.970 sec/step)\n",
      "I0902 09:25:18.301130 139792788920128 learning.py:507] global step 41926: loss = 0.1682 (0.970 sec/step)\n",
      "I0902 09:25:19.289056 139792788920128 learning.py:507] global step 41927: loss = 0.1416 (0.986 sec/step)\n",
      "I0902 09:25:20.257241 139792788920128 learning.py:507] global step 41928: loss = 0.0923 (0.966 sec/step)\n",
      "I0902 09:25:21.220714 139792788920128 learning.py:507] global step 41929: loss = 0.1387 (0.962 sec/step)\n",
      "I0902 09:25:22.205986 139792788920128 learning.py:507] global step 41930: loss = 0.0712 (0.984 sec/step)\n",
      "I0902 09:25:23.161794 139792788920128 learning.py:507] global step 41931: loss = 0.2197 (0.954 sec/step)\n",
      "I0902 09:25:24.125954 139792788920128 learning.py:507] global step 41932: loss = 0.0730 (0.963 sec/step)\n",
      "I0902 09:25:25.106510 139792788920128 learning.py:507] global step 41933: loss = 0.1006 (0.979 sec/step)\n",
      "I0902 09:25:26.096649 139792788920128 learning.py:507] global step 41934: loss = 0.1189 (0.988 sec/step)\n",
      "I0902 09:25:27.087657 139792788920128 learning.py:507] global step 41935: loss = 0.1094 (0.989 sec/step)\n",
      "I0902 09:25:28.040406 139792788920128 learning.py:507] global step 41936: loss = 0.0798 (0.952 sec/step)\n",
      "I0902 09:25:29.000323 139792788920128 learning.py:507] global step 41937: loss = 0.2709 (0.959 sec/step)\n",
      "I0902 09:25:29.965424 139792788920128 learning.py:507] global step 41938: loss = 0.1447 (0.964 sec/step)\n",
      "I0902 09:25:30.948960 139792788920128 learning.py:507] global step 41939: loss = 0.2741 (0.982 sec/step)\n",
      "I0902 09:25:31.912899 139792788920128 learning.py:507] global step 41940: loss = 0.1006 (0.962 sec/step)\n",
      "I0902 09:25:32.866208 139792788920128 learning.py:507] global step 41941: loss = 0.1205 (0.952 sec/step)\n",
      "I0902 09:25:33.830393 139792788920128 learning.py:507] global step 41942: loss = 0.1164 (0.963 sec/step)\n",
      "I0902 09:25:34.801872 139792788920128 learning.py:507] global step 41943: loss = 0.1217 (0.970 sec/step)\n",
      "I0902 09:25:35.763755 139792788920128 learning.py:507] global step 41944: loss = 0.1299 (0.961 sec/step)\n",
      "I0902 09:25:36.732291 139792788920128 learning.py:507] global step 41945: loss = 0.0977 (0.967 sec/step)\n",
      "I0902 09:25:37.687422 139792788920128 learning.py:507] global step 41946: loss = 0.1721 (0.954 sec/step)\n",
      "I0902 09:25:38.687866 139792788920128 learning.py:507] global step 41947: loss = 0.1175 (0.999 sec/step)\n",
      "I0902 09:25:39.648018 139792788920128 learning.py:507] global step 41948: loss = 0.0828 (0.959 sec/step)\n",
      "I0902 09:25:40.624588 139792788920128 learning.py:507] global step 41949: loss = 0.1394 (0.975 sec/step)\n",
      "I0902 09:25:41.584175 139792788920128 learning.py:507] global step 41950: loss = 0.1025 (0.958 sec/step)\n",
      "I0902 09:25:42.577050 139792788920128 learning.py:507] global step 41951: loss = 0.4130 (0.991 sec/step)\n",
      "I0902 09:25:43.517577 139792788920128 learning.py:507] global step 41952: loss = 0.0920 (0.939 sec/step)\n",
      "I0902 09:25:44.480841 139792788920128 learning.py:507] global step 41953: loss = 0.3215 (0.962 sec/step)\n",
      "I0902 09:25:45.453698 139792788920128 learning.py:507] global step 41954: loss = 0.1457 (0.972 sec/step)\n",
      "I0902 09:25:46.399546 139792788920128 learning.py:507] global step 41955: loss = 0.1755 (0.945 sec/step)\n",
      "I0902 09:25:47.388836 139792788920128 learning.py:507] global step 41956: loss = 0.1011 (0.988 sec/step)\n",
      "I0902 09:25:48.361033 139792788920128 learning.py:507] global step 41957: loss = 0.0548 (0.971 sec/step)\n",
      "I0902 09:25:49.345727 139792788920128 learning.py:507] global step 41958: loss = 0.0821 (0.969 sec/step)\n",
      "I0902 09:25:49.960522 139778936784640 supervisor.py:1050] Recording summary at step 41958.\n",
      "I0902 09:25:50.576956 139792788920128 learning.py:507] global step 41959: loss = 0.2158 (1.229 sec/step)\n",
      "I0902 09:25:51.558828 139792788920128 learning.py:507] global step 41960: loss = 0.1023 (0.980 sec/step)\n",
      "I0902 09:25:52.549492 139792788920128 learning.py:507] global step 41961: loss = 0.1313 (0.989 sec/step)\n",
      "I0902 09:25:53.524647 139792788920128 learning.py:507] global step 41962: loss = 0.2458 (0.973 sec/step)\n",
      "I0902 09:25:54.499069 139792788920128 learning.py:507] global step 41963: loss = 0.1687 (0.973 sec/step)\n",
      "I0902 09:25:55.468557 139792788920128 learning.py:507] global step 41964: loss = 0.0580 (0.968 sec/step)\n",
      "I0902 09:25:56.458413 139792788920128 learning.py:507] global step 41965: loss = 0.1624 (0.988 sec/step)\n",
      "I0902 09:25:57.441455 139792788920128 learning.py:507] global step 41966: loss = 0.0828 (0.982 sec/step)\n",
      "I0902 09:25:58.430569 139792788920128 learning.py:507] global step 41967: loss = 0.0852 (0.987 sec/step)\n",
      "I0902 09:25:59.384000 139792788920128 learning.py:507] global step 41968: loss = 0.2134 (0.952 sec/step)\n",
      "I0902 09:26:00.376656 139792788920128 learning.py:507] global step 41969: loss = 0.2119 (0.991 sec/step)\n",
      "I0902 09:26:01.357509 139792788920128 learning.py:507] global step 41970: loss = 0.0613 (0.979 sec/step)\n",
      "I0902 09:26:02.335143 139792788920128 learning.py:507] global step 41971: loss = 0.0866 (0.976 sec/step)\n",
      "I0902 09:26:03.326231 139792788920128 learning.py:507] global step 41972: loss = 0.1321 (0.990 sec/step)\n",
      "I0902 09:26:04.299441 139792788920128 learning.py:507] global step 41973: loss = 0.0937 (0.972 sec/step)\n",
      "I0902 09:26:05.278773 139792788920128 learning.py:507] global step 41974: loss = 0.1652 (0.977 sec/step)\n",
      "I0902 09:26:06.251885 139792788920128 learning.py:507] global step 41975: loss = 0.0959 (0.972 sec/step)\n",
      "I0902 09:26:07.251163 139792788920128 learning.py:507] global step 41976: loss = 0.1275 (0.997 sec/step)\n",
      "I0902 09:26:08.238264 139792788920128 learning.py:507] global step 41977: loss = 0.2281 (0.985 sec/step)\n",
      "I0902 09:26:09.211638 139792788920128 learning.py:507] global step 41978: loss = 0.0955 (0.972 sec/step)\n",
      "I0902 09:26:10.180011 139792788920128 learning.py:507] global step 41979: loss = 0.0718 (0.967 sec/step)\n",
      "I0902 09:26:11.151847 139792788920128 learning.py:507] global step 41980: loss = 0.1024 (0.970 sec/step)\n",
      "I0902 09:26:12.133749 139792788920128 learning.py:507] global step 41981: loss = 0.0845 (0.980 sec/step)\n",
      "I0902 09:26:13.143091 139792788920128 learning.py:507] global step 41982: loss = 0.1812 (1.008 sec/step)\n",
      "I0902 09:26:14.148512 139792788920128 learning.py:507] global step 41983: loss = 0.0961 (1.004 sec/step)\n",
      "I0902 09:26:15.145299 139792788920128 learning.py:507] global step 41984: loss = 0.0873 (0.995 sec/step)\n",
      "I0902 09:26:16.122865 139792788920128 learning.py:507] global step 41985: loss = 0.0627 (0.976 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:26:17.108013 139792788920128 learning.py:507] global step 41986: loss = 0.1758 (0.984 sec/step)\n",
      "I0902 09:26:18.068890 139792788920128 learning.py:507] global step 41987: loss = 0.0966 (0.959 sec/step)\n",
      "I0902 09:26:19.046967 139792788920128 learning.py:507] global step 41988: loss = 0.1024 (0.976 sec/step)\n",
      "I0902 09:26:20.023763 139792788920128 learning.py:507] global step 41989: loss = 0.0975 (0.975 sec/step)\n",
      "I0902 09:26:20.998064 139792788920128 learning.py:507] global step 41990: loss = 0.1813 (0.973 sec/step)\n",
      "I0902 09:26:21.988885 139792788920128 learning.py:507] global step 41991: loss = 0.1129 (0.989 sec/step)\n",
      "I0902 09:26:22.978043 139792788920128 learning.py:507] global step 41992: loss = 0.1369 (0.987 sec/step)\n",
      "I0902 09:26:23.971617 139792788920128 learning.py:507] global step 41993: loss = 0.1624 (0.992 sec/step)\n",
      "I0902 09:26:24.926600 139792788920128 learning.py:507] global step 41994: loss = 0.1027 (0.954 sec/step)\n",
      "I0902 09:26:25.924377 139792788920128 learning.py:507] global step 41995: loss = 0.1604 (0.996 sec/step)\n",
      "I0902 09:26:26.920883 139792788920128 learning.py:507] global step 41996: loss = 0.0544 (0.995 sec/step)\n",
      "I0902 09:26:27.898788 139792788920128 learning.py:507] global step 41997: loss = 0.3875 (0.976 sec/step)\n",
      "I0902 09:26:28.879878 139792788920128 learning.py:507] global step 41998: loss = 0.1170 (0.979 sec/step)\n",
      "I0902 09:26:29.840240 139792788920128 learning.py:507] global step 41999: loss = 0.1768 (0.959 sec/step)\n",
      "I0902 09:26:30.819939 139792788920128 learning.py:507] global step 42000: loss = 0.2123 (0.978 sec/step)\n",
      "I0902 09:26:31.808246 139792788920128 learning.py:507] global step 42001: loss = 0.0419 (0.987 sec/step)\n",
      "I0902 09:26:32.767421 139792788920128 learning.py:507] global step 42002: loss = 0.2339 (0.957 sec/step)\n",
      "I0902 09:26:33.728417 139792788920128 learning.py:507] global step 42003: loss = 0.0735 (0.959 sec/step)\n",
      "I0902 09:26:34.689363 139792788920128 learning.py:507] global step 42004: loss = 0.1544 (0.959 sec/step)\n",
      "I0902 09:26:35.681572 139792788920128 learning.py:507] global step 42005: loss = 0.2584 (0.990 sec/step)\n",
      "I0902 09:26:36.679404 139792788920128 learning.py:507] global step 42006: loss = 0.1148 (0.996 sec/step)\n",
      "I0902 09:26:37.674573 139792788920128 learning.py:507] global step 42007: loss = 0.0948 (0.993 sec/step)\n",
      "I0902 09:26:38.665256 139792788920128 learning.py:507] global step 42008: loss = 0.0799 (0.989 sec/step)\n",
      "I0902 09:26:39.660794 139792788920128 learning.py:507] global step 42009: loss = 0.1759 (0.994 sec/step)\n",
      "I0902 09:26:40.632293 139792788920128 learning.py:507] global step 42010: loss = 0.1500 (0.970 sec/step)\n",
      "I0902 09:26:41.614891 139792788920128 learning.py:507] global step 42011: loss = 0.1388 (0.981 sec/step)\n",
      "I0902 09:26:42.588012 139792788920128 learning.py:507] global step 42012: loss = 0.2394 (0.971 sec/step)\n",
      "I0902 09:26:43.550889 139792788920128 learning.py:507] global step 42013: loss = 0.1593 (0.961 sec/step)\n",
      "I0902 09:26:44.503676 139792788920128 learning.py:507] global step 42014: loss = 0.0845 (0.951 sec/step)\n",
      "I0902 09:26:45.449772 139792788920128 learning.py:507] global step 42015: loss = 0.1257 (0.944 sec/step)\n",
      "I0902 09:26:46.394899 139792788920128 learning.py:507] global step 42016: loss = 0.0593 (0.943 sec/step)\n",
      "I0902 09:26:47.376972 139792788920128 learning.py:507] global step 42017: loss = 0.2226 (0.981 sec/step)\n",
      "I0902 09:26:48.364726 139792788920128 learning.py:507] global step 42018: loss = 0.1233 (0.986 sec/step)\n",
      "I0902 09:26:49.374658 139792788920128 learning.py:507] global step 42019: loss = 0.1365 (1.008 sec/step)\n",
      "I0902 09:26:50.359102 139792788920128 learning.py:507] global step 42020: loss = 0.1046 (0.983 sec/step)\n",
      "I0902 09:26:51.324747 139792788920128 learning.py:507] global step 42021: loss = 0.0963 (0.964 sec/step)\n",
      "I0902 09:26:52.287669 139792788920128 learning.py:507] global step 42022: loss = 0.1484 (0.961 sec/step)\n",
      "I0902 09:26:53.305419 139792788920128 learning.py:507] global step 42023: loss = 0.0922 (1.016 sec/step)\n",
      "I0902 09:26:54.307891 139792788920128 learning.py:507] global step 42024: loss = 0.0838 (1.001 sec/step)\n",
      "I0902 09:26:55.277861 139792788920128 learning.py:507] global step 42025: loss = 0.2986 (0.968 sec/step)\n",
      "I0902 09:26:56.237384 139792788920128 learning.py:507] global step 42026: loss = 0.0893 (0.958 sec/step)\n",
      "I0902 09:26:57.196827 139792788920128 learning.py:507] global step 42027: loss = 0.0936 (0.958 sec/step)\n",
      "I0902 09:26:58.173974 139792788920128 learning.py:507] global step 42028: loss = 0.1260 (0.976 sec/step)\n",
      "I0902 09:26:59.138418 139792788920128 learning.py:507] global step 42029: loss = 0.2809 (0.963 sec/step)\n",
      "I0902 09:27:00.115787 139792788920128 learning.py:507] global step 42030: loss = 0.1493 (0.976 sec/step)\n",
      "I0902 09:27:01.076149 139792788920128 learning.py:507] global step 42031: loss = 0.1900 (0.959 sec/step)\n",
      "I0902 09:27:02.027119 139792788920128 learning.py:507] global step 42032: loss = 0.1045 (0.949 sec/step)\n",
      "I0902 09:27:02.979111 139792788920128 learning.py:507] global step 42033: loss = 0.1497 (0.951 sec/step)\n",
      "I0902 09:27:03.933288 139792788920128 learning.py:507] global step 42034: loss = 0.0777 (0.952 sec/step)\n",
      "I0902 09:27:04.908016 139792788920128 learning.py:507] global step 42035: loss = 0.0936 (0.973 sec/step)\n",
      "I0902 09:27:05.891203 139792788920128 learning.py:507] global step 42036: loss = 0.2096 (0.981 sec/step)\n",
      "I0902 09:27:06.881720 139792788920128 learning.py:507] global step 42037: loss = 0.1569 (0.989 sec/step)\n",
      "I0902 09:27:07.840757 139792788920128 learning.py:507] global step 42038: loss = 0.1605 (0.957 sec/step)\n",
      "I0902 09:27:08.810872 139792788920128 learning.py:507] global step 42039: loss = 0.1122 (0.968 sec/step)\n",
      "I0902 09:27:09.797778 139792788920128 learning.py:507] global step 42040: loss = 0.0798 (0.985 sec/step)\n",
      "I0902 09:27:10.755968 139792788920128 learning.py:507] global step 42041: loss = 0.0989 (0.956 sec/step)\n",
      "I0902 09:27:11.699645 139792788920128 learning.py:507] global step 42042: loss = 0.0559 (0.942 sec/step)\n",
      "I0902 09:27:12.655637 139792788920128 learning.py:507] global step 42043: loss = 0.1018 (0.954 sec/step)\n",
      "I0902 09:27:13.630192 139792788920128 learning.py:507] global step 42044: loss = 0.1381 (0.973 sec/step)\n",
      "I0902 09:27:14.587709 139792788920128 learning.py:507] global step 42045: loss = 0.0494 (0.956 sec/step)\n",
      "I0902 09:27:15.551745 139792788920128 learning.py:507] global step 42046: loss = 0.0571 (0.962 sec/step)\n",
      "I0902 09:27:16.528498 139792788920128 learning.py:507] global step 42047: loss = 0.1384 (0.975 sec/step)\n",
      "I0902 09:27:17.515827 139792788920128 learning.py:507] global step 42048: loss = 0.0994 (0.986 sec/step)\n",
      "I0902 09:27:18.468040 139792788920128 learning.py:507] global step 42049: loss = 0.0466 (0.950 sec/step)\n",
      "I0902 09:27:19.445929 139792788920128 learning.py:507] global step 42050: loss = 0.1354 (0.976 sec/step)\n",
      "I0902 09:27:20.414986 139792788920128 learning.py:507] global step 42051: loss = 0.1811 (0.967 sec/step)\n",
      "I0902 09:27:21.381775 139792788920128 learning.py:507] global step 42052: loss = 0.1433 (0.965 sec/step)\n",
      "I0902 09:27:22.343439 139792788920128 learning.py:507] global step 42053: loss = 0.0813 (0.960 sec/step)\n",
      "I0902 09:27:23.293397 139792788920128 learning.py:507] global step 42054: loss = 0.1009 (0.948 sec/step)\n",
      "I0902 09:27:24.255288 139792788920128 learning.py:507] global step 42055: loss = 0.0804 (0.960 sec/step)\n",
      "I0902 09:27:25.210103 139792788920128 learning.py:507] global step 42056: loss = 0.1154 (0.953 sec/step)\n",
      "I0902 09:27:26.173993 139792788920128 learning.py:507] global step 42057: loss = 0.1427 (0.962 sec/step)\n",
      "I0902 09:27:27.137325 139792788920128 learning.py:507] global step 42058: loss = 0.0880 (0.962 sec/step)\n",
      "I0902 09:27:28.101089 139792788920128 learning.py:507] global step 42059: loss = 0.1815 (0.962 sec/step)\n",
      "I0902 09:27:29.085122 139792788920128 learning.py:507] global step 42060: loss = 0.1574 (0.982 sec/step)\n",
      "I0902 09:27:30.052012 139792788920128 learning.py:507] global step 42061: loss = 0.0938 (0.965 sec/step)\n",
      "I0902 09:27:31.021663 139792788920128 learning.py:507] global step 42062: loss = 0.1012 (0.968 sec/step)\n",
      "I0902 09:27:31.976831 139792788920128 learning.py:507] global step 42063: loss = 0.0773 (0.954 sec/step)\n",
      "I0902 09:27:32.941709 139792788920128 learning.py:507] global step 42064: loss = 0.1143 (0.963 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:27:33.906275 139792788920128 learning.py:507] global step 42065: loss = 0.0977 (0.963 sec/step)\n",
      "I0902 09:27:34.890599 139792788920128 learning.py:507] global step 42066: loss = 0.1311 (0.983 sec/step)\n",
      "I0902 09:27:35.873492 139792788920128 learning.py:507] global step 42067: loss = 0.0869 (0.981 sec/step)\n",
      "I0902 09:27:36.853666 139792788920128 learning.py:507] global step 42068: loss = 0.2433 (0.979 sec/step)\n",
      "I0902 09:27:37.840590 139792788920128 learning.py:507] global step 42069: loss = 0.0838 (0.985 sec/step)\n",
      "I0902 09:27:38.819459 139792788920128 learning.py:507] global step 42070: loss = 0.1129 (0.977 sec/step)\n",
      "I0902 09:27:39.798314 139792788920128 learning.py:507] global step 42071: loss = 0.0999 (0.977 sec/step)\n",
      "I0902 09:27:40.778127 139792788920128 learning.py:507] global step 42072: loss = 0.1518 (0.978 sec/step)\n",
      "I0902 09:27:41.766558 139792788920128 learning.py:507] global step 42073: loss = 0.0770 (0.987 sec/step)\n",
      "I0902 09:27:42.733977 139792788920128 learning.py:507] global step 42074: loss = 0.1000 (0.966 sec/step)\n",
      "I0902 09:27:43.708263 139792788920128 learning.py:507] global step 42075: loss = 0.1190 (0.973 sec/step)\n",
      "I0902 09:27:44.685382 139792788920128 learning.py:507] global step 42076: loss = 0.1148 (0.975 sec/step)\n",
      "I0902 09:27:45.658626 139792788920128 learning.py:507] global step 42077: loss = 0.0819 (0.972 sec/step)\n",
      "I0902 09:27:46.619961 139792788920128 learning.py:507] global step 42078: loss = 0.1135 (0.960 sec/step)\n",
      "I0902 09:27:47.578166 139792788920128 learning.py:507] global step 42079: loss = 0.0411 (0.956 sec/step)\n",
      "I0902 09:27:48.558079 139792788920128 learning.py:507] global step 42080: loss = 0.0898 (0.978 sec/step)\n",
      "I0902 09:27:49.530609 139792788920128 learning.py:507] global step 42081: loss = 0.0886 (0.967 sec/step)\n",
      "I0902 09:27:50.157063 139778936784640 supervisor.py:1050] Recording summary at step 42081.\n",
      "I0902 09:27:50.761127 139792788920128 learning.py:507] global step 42082: loss = 0.0701 (1.229 sec/step)\n",
      "I0902 09:27:51.713493 139792788920128 learning.py:507] global step 42083: loss = 0.0873 (0.951 sec/step)\n",
      "I0902 09:27:52.718059 139792788920128 learning.py:507] global step 42084: loss = 0.1446 (1.003 sec/step)\n",
      "I0902 09:27:53.694653 139792788920128 learning.py:507] global step 42085: loss = 0.0868 (0.975 sec/step)\n",
      "I0902 09:27:54.670455 139792788920128 learning.py:507] global step 42086: loss = 0.1594 (0.974 sec/step)\n",
      "I0902 09:27:55.636895 139792788920128 learning.py:507] global step 42087: loss = 0.0482 (0.965 sec/step)\n",
      "I0902 09:27:56.622920 139792788920128 learning.py:507] global step 42088: loss = 0.1293 (0.984 sec/step)\n",
      "I0902 09:27:57.604585 139792788920128 learning.py:507] global step 42089: loss = 0.1146 (0.980 sec/step)\n",
      "I0902 09:27:58.606884 139792788920128 learning.py:507] global step 42090: loss = 0.1494 (1.001 sec/step)\n",
      "I0902 09:27:59.589607 139792788920128 learning.py:507] global step 42091: loss = 0.2406 (0.981 sec/step)\n",
      "I0902 09:28:00.566164 139792788920128 learning.py:507] global step 42092: loss = 0.0789 (0.975 sec/step)\n",
      "I0902 09:28:01.545991 139792788920128 learning.py:507] global step 42093: loss = 0.0920 (0.978 sec/step)\n",
      "I0902 09:28:02.506990 139792788920128 learning.py:507] global step 42094: loss = 0.0702 (0.959 sec/step)\n",
      "I0902 09:28:03.482079 139792788920128 learning.py:507] global step 42095: loss = 0.0767 (0.974 sec/step)\n",
      "I0902 09:28:04.460099 139792788920128 learning.py:507] global step 42096: loss = 0.1773 (0.977 sec/step)\n",
      "I0902 09:28:05.439913 139792788920128 learning.py:507] global step 42097: loss = 0.0872 (0.978 sec/step)\n",
      "I0902 09:28:06.437795 139792788920128 learning.py:507] global step 42098: loss = 0.1016 (0.996 sec/step)\n",
      "I0902 09:28:07.428117 139792788920128 learning.py:507] global step 42099: loss = 0.1301 (0.989 sec/step)\n",
      "I0902 09:28:08.396409 139792788920128 learning.py:507] global step 42100: loss = 0.0902 (0.967 sec/step)\n",
      "I0902 09:28:09.387851 139792788920128 learning.py:507] global step 42101: loss = 0.1637 (0.990 sec/step)\n",
      "I0902 09:28:10.333760 139792788920128 learning.py:507] global step 42102: loss = 0.1438 (0.944 sec/step)\n",
      "I0902 09:28:11.310786 139792788920128 learning.py:507] global step 42103: loss = 0.1225 (0.975 sec/step)\n",
      "I0902 09:28:12.296916 139792788920128 learning.py:507] global step 42104: loss = 0.0890 (0.985 sec/step)\n",
      "I0902 09:28:13.273520 139792788920128 learning.py:507] global step 42105: loss = 0.3282 (0.975 sec/step)\n",
      "I0902 09:28:14.244611 139792788920128 learning.py:507] global step 42106: loss = 0.0926 (0.969 sec/step)\n",
      "I0902 09:28:15.221001 139792788920128 learning.py:507] global step 42107: loss = 0.0803 (0.975 sec/step)\n",
      "I0902 09:28:16.184545 139792788920128 learning.py:507] global step 42108: loss = 0.0555 (0.962 sec/step)\n",
      "I0902 09:28:17.160290 139792788920128 learning.py:507] global step 42109: loss = 0.1374 (0.974 sec/step)\n",
      "I0902 09:28:18.147791 139792788920128 learning.py:507] global step 42110: loss = 0.0769 (0.986 sec/step)\n",
      "I0902 09:28:19.136997 139792788920128 learning.py:507] global step 42111: loss = 0.1101 (0.988 sec/step)\n",
      "I0902 09:28:20.101707 139792788920128 learning.py:507] global step 42112: loss = 0.0978 (0.963 sec/step)\n",
      "I0902 09:28:21.104530 139792788920128 learning.py:507] global step 42113: loss = 0.0863 (1.001 sec/step)\n",
      "I0902 09:28:22.068170 139792788920128 learning.py:507] global step 42114: loss = 0.2157 (0.962 sec/step)\n",
      "I0902 09:28:23.063214 139792788920128 learning.py:507] global step 42115: loss = 0.1382 (0.993 sec/step)\n",
      "I0902 09:28:24.025374 139792788920128 learning.py:507] global step 42116: loss = 0.1923 (0.961 sec/step)\n",
      "I0902 09:28:24.999540 139792788920128 learning.py:507] global step 42117: loss = 0.1383 (0.972 sec/step)\n",
      "I0902 09:28:25.989111 139792788920128 learning.py:507] global step 42118: loss = 0.1381 (0.988 sec/step)\n",
      "I0902 09:28:26.955427 139792788920128 learning.py:507] global step 42119: loss = 0.1294 (0.965 sec/step)\n",
      "I0902 09:28:27.951739 139792788920128 learning.py:507] global step 42120: loss = 0.1236 (0.995 sec/step)\n",
      "I0902 09:28:28.910078 139792788920128 learning.py:507] global step 42121: loss = 0.0714 (0.957 sec/step)\n",
      "I0902 09:28:29.879095 139792788920128 learning.py:507] global step 42122: loss = 0.1504 (0.967 sec/step)\n",
      "I0902 09:28:30.878283 139792788920128 learning.py:507] global step 42123: loss = 0.0834 (0.997 sec/step)\n",
      "I0902 09:28:31.861026 139792788920128 learning.py:507] global step 42124: loss = 0.1474 (0.981 sec/step)\n",
      "I0902 09:28:32.842105 139792788920128 learning.py:507] global step 42125: loss = 0.1260 (0.979 sec/step)\n",
      "I0902 09:28:33.813714 139792788920128 learning.py:507] global step 42126: loss = 0.0794 (0.970 sec/step)\n",
      "I0902 09:28:34.765503 139792788920128 learning.py:507] global step 42127: loss = 0.0952 (0.950 sec/step)\n",
      "I0902 09:28:35.760805 139792788920128 learning.py:507] global step 42128: loss = 0.1557 (0.993 sec/step)\n",
      "I0902 09:28:36.752381 139792788920128 learning.py:507] global step 42129: loss = 0.0438 (0.990 sec/step)\n",
      "I0902 09:28:37.743778 139792788920128 learning.py:507] global step 42130: loss = 0.1017 (0.990 sec/step)\n",
      "I0902 09:28:38.723584 139792788920128 learning.py:507] global step 42131: loss = 0.0469 (0.978 sec/step)\n",
      "I0902 09:28:39.702543 139792788920128 learning.py:507] global step 42132: loss = 0.1723 (0.977 sec/step)\n",
      "I0902 09:28:40.666474 139792788920128 learning.py:507] global step 42133: loss = 0.1776 (0.962 sec/step)\n",
      "I0902 09:28:41.673836 139792788920128 learning.py:507] global step 42134: loss = 0.0689 (1.006 sec/step)\n",
      "I0902 09:28:42.669496 139792788920128 learning.py:507] global step 42135: loss = 0.1764 (0.994 sec/step)\n",
      "I0902 09:28:43.652708 139792788920128 learning.py:507] global step 42136: loss = 0.1020 (0.982 sec/step)\n",
      "I0902 09:28:44.634744 139792788920128 learning.py:507] global step 42137: loss = 0.0601 (0.981 sec/step)\n",
      "I0902 09:28:45.619963 139792788920128 learning.py:507] global step 42138: loss = 0.1463 (0.984 sec/step)\n",
      "I0902 09:28:46.620604 139792788920128 learning.py:507] global step 42139: loss = 0.0643 (0.999 sec/step)\n",
      "I0902 09:28:47.598443 139792788920128 learning.py:507] global step 42140: loss = 0.0954 (0.976 sec/step)\n",
      "I0902 09:28:48.563583 139792788920128 learning.py:507] global step 42141: loss = 0.0957 (0.963 sec/step)\n",
      "I0902 09:28:49.550694 139792788920128 learning.py:507] global step 42142: loss = 0.1381 (0.986 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:28:50.525158 139792788920128 learning.py:507] global step 42143: loss = 0.1345 (0.973 sec/step)\n",
      "I0902 09:28:51.513828 139792788920128 learning.py:507] global step 42144: loss = 0.1076 (0.987 sec/step)\n",
      "I0902 09:28:52.498690 139792788920128 learning.py:507] global step 42145: loss = 0.0875 (0.983 sec/step)\n",
      "I0902 09:28:53.481184 139792788920128 learning.py:507] global step 42146: loss = 0.0961 (0.981 sec/step)\n",
      "I0902 09:28:54.460471 139792788920128 learning.py:507] global step 42147: loss = 0.3070 (0.978 sec/step)\n",
      "I0902 09:28:55.424870 139792788920128 learning.py:507] global step 42148: loss = 0.1341 (0.963 sec/step)\n",
      "I0902 09:28:56.371062 139792788920128 learning.py:507] global step 42149: loss = 0.0633 (0.945 sec/step)\n",
      "I0902 09:28:57.368741 139792788920128 learning.py:507] global step 42150: loss = 0.1304 (0.996 sec/step)\n",
      "I0902 09:28:58.346391 139792788920128 learning.py:507] global step 42151: loss = 0.3338 (0.976 sec/step)\n",
      "I0902 09:28:59.330041 139792788920128 learning.py:507] global step 42152: loss = 0.1078 (0.982 sec/step)\n",
      "I0902 09:29:00.315233 139792788920128 learning.py:507] global step 42153: loss = 0.0718 (0.983 sec/step)\n",
      "I0902 09:29:01.271236 139792788920128 learning.py:507] global step 42154: loss = 0.0359 (0.954 sec/step)\n",
      "I0902 09:29:02.285093 139792788920128 learning.py:507] global step 42155: loss = 0.1589 (1.012 sec/step)\n",
      "I0902 09:29:03.248478 139792788920128 learning.py:507] global step 42156: loss = 0.1269 (0.962 sec/step)\n",
      "I0902 09:29:04.221022 139792788920128 learning.py:507] global step 42157: loss = 0.3028 (0.971 sec/step)\n",
      "I0902 09:29:05.188991 139792788920128 learning.py:507] global step 42158: loss = 0.1076 (0.966 sec/step)\n",
      "I0902 09:29:06.177982 139792788920128 learning.py:507] global step 42159: loss = 0.1120 (0.987 sec/step)\n",
      "I0902 09:29:07.163267 139792788920128 learning.py:507] global step 42160: loss = 0.1241 (0.984 sec/step)\n",
      "I0902 09:29:08.161411 139792788920128 learning.py:507] global step 42161: loss = 0.1452 (0.997 sec/step)\n",
      "I0902 09:29:09.143959 139792788920128 learning.py:507] global step 42162: loss = 0.0798 (0.981 sec/step)\n",
      "I0902 09:29:10.123147 139792788920128 learning.py:507] global step 42163: loss = 0.0975 (0.977 sec/step)\n",
      "I0902 09:29:11.127285 139792788920128 learning.py:507] global step 42164: loss = 0.1317 (1.002 sec/step)\n",
      "I0902 09:29:12.144764 139792788920128 learning.py:507] global step 42165: loss = 0.2943 (1.015 sec/step)\n",
      "I0902 09:29:13.111855 139792788920128 learning.py:507] global step 42166: loss = 0.1019 (0.965 sec/step)\n",
      "I0902 09:29:14.089968 139792788920128 learning.py:507] global step 42167: loss = 0.1052 (0.976 sec/step)\n",
      "I0902 09:29:15.069214 139792788920128 learning.py:507] global step 42168: loss = 0.1009 (0.978 sec/step)\n",
      "I0902 09:29:16.013702 139792788920128 learning.py:507] global step 42169: loss = 0.0501 (0.943 sec/step)\n",
      "I0902 09:29:16.957870 139792788920128 learning.py:507] global step 42170: loss = 0.1530 (0.942 sec/step)\n",
      "I0902 09:29:17.923323 139792788920128 learning.py:507] global step 42171: loss = 0.0508 (0.964 sec/step)\n",
      "I0902 09:29:18.917822 139792788920128 learning.py:507] global step 42172: loss = 0.1705 (0.993 sec/step)\n",
      "I0902 09:29:19.907533 139792788920128 learning.py:507] global step 42173: loss = 0.2052 (0.988 sec/step)\n",
      "I0902 09:29:20.898763 139792788920128 learning.py:507] global step 42174: loss = 0.1172 (0.990 sec/step)\n",
      "I0902 09:29:21.890916 139792788920128 learning.py:507] global step 42175: loss = 0.1078 (0.990 sec/step)\n",
      "I0902 09:29:22.887110 139792788920128 learning.py:507] global step 42176: loss = 0.0983 (0.995 sec/step)\n",
      "I0902 09:29:23.874891 139792788920128 learning.py:507] global step 42177: loss = 0.0824 (0.986 sec/step)\n",
      "I0902 09:29:24.859773 139792788920128 learning.py:507] global step 42178: loss = 0.1400 (0.983 sec/step)\n",
      "I0902 09:29:25.832176 139792788920128 learning.py:507] global step 42179: loss = 0.1039 (0.971 sec/step)\n",
      "I0902 09:29:26.806633 139792788920128 learning.py:507] global step 42180: loss = 0.0988 (0.973 sec/step)\n",
      "I0902 09:29:27.779659 139792788920128 learning.py:507] global step 42181: loss = 0.0796 (0.971 sec/step)\n",
      "I0902 09:29:28.742698 139792788920128 learning.py:507] global step 42182: loss = 0.0869 (0.962 sec/step)\n",
      "I0902 09:29:29.727974 139792788920128 learning.py:507] global step 42183: loss = 0.1082 (0.984 sec/step)\n",
      "I0902 09:29:30.701173 139792788920128 learning.py:507] global step 42184: loss = 0.1096 (0.972 sec/step)\n",
      "I0902 09:29:31.665603 139792788920128 learning.py:507] global step 42185: loss = 0.2388 (0.963 sec/step)\n",
      "I0902 09:29:32.631179 139792788920128 learning.py:507] global step 42186: loss = 0.1901 (0.964 sec/step)\n",
      "I0902 09:29:33.598963 139792788920128 learning.py:507] global step 42187: loss = 0.1247 (0.966 sec/step)\n",
      "I0902 09:29:34.570132 139792788920128 learning.py:507] global step 42188: loss = 0.1783 (0.969 sec/step)\n",
      "I0902 09:29:35.556200 139792788920128 learning.py:507] global step 42189: loss = 0.3244 (0.985 sec/step)\n",
      "I0902 09:29:36.529174 139792788920128 learning.py:507] global step 42190: loss = 0.1146 (0.971 sec/step)\n",
      "I0902 09:29:37.511837 139792788920128 learning.py:507] global step 42191: loss = 0.1492 (0.981 sec/step)\n",
      "I0902 09:29:38.469217 139792788920128 learning.py:507] global step 42192: loss = 0.1205 (0.956 sec/step)\n",
      "I0902 09:29:39.453019 139792788920128 learning.py:507] global step 42193: loss = 0.1635 (0.982 sec/step)\n",
      "I0902 09:29:40.425771 139792788920128 learning.py:507] global step 42194: loss = 0.0855 (0.971 sec/step)\n",
      "I0902 09:29:41.388078 139792788920128 learning.py:507] global step 42195: loss = 0.0873 (0.961 sec/step)\n",
      "I0902 09:29:42.341441 139792788920128 learning.py:507] global step 42196: loss = 0.0828 (0.952 sec/step)\n",
      "I0902 09:29:43.332127 139792788920128 learning.py:507] global step 42197: loss = 0.0677 (0.989 sec/step)\n",
      "I0902 09:29:44.288516 139792788920128 learning.py:507] global step 42198: loss = 0.1736 (0.955 sec/step)\n",
      "I0902 09:29:45.249154 139792788920128 learning.py:507] global step 42199: loss = 0.1248 (0.959 sec/step)\n",
      "I0902 09:29:46.227043 139792788920128 learning.py:507] global step 42200: loss = 0.1180 (0.976 sec/step)\n",
      "I0902 09:29:47.191573 139792788920128 learning.py:507] global step 42201: loss = 0.1206 (0.963 sec/step)\n",
      "I0902 09:29:48.159613 139792788920128 learning.py:507] global step 42202: loss = 0.1082 (0.966 sec/step)\n",
      "I0902 09:29:49.130387 139792788920128 learning.py:507] global step 42203: loss = 0.1066 (0.969 sec/step)\n",
      "I0902 09:29:50.248482 139792788920128 learning.py:507] global step 42204: loss = 0.1775 (1.115 sec/step)\n",
      "I0902 09:29:50.527720 139778936784640 supervisor.py:1050] Recording summary at step 42204.\n",
      "I0902 09:29:51.305137 139792788920128 learning.py:507] global step 42205: loss = 0.1752 (1.055 sec/step)\n",
      "I0902 09:29:52.267753 139792788920128 learning.py:507] global step 42206: loss = 0.1622 (0.961 sec/step)\n",
      "I0902 09:29:53.232808 139792788920128 learning.py:507] global step 42207: loss = 0.2372 (0.963 sec/step)\n",
      "I0902 09:29:54.228586 139792788920128 learning.py:507] global step 42208: loss = 0.1036 (0.994 sec/step)\n",
      "I0902 09:29:55.193731 139792788920128 learning.py:507] global step 42209: loss = 0.2019 (0.963 sec/step)\n",
      "I0902 09:29:56.176873 139792788920128 learning.py:507] global step 42210: loss = 0.1759 (0.982 sec/step)\n",
      "I0902 09:29:57.159181 139792788920128 learning.py:507] global step 42211: loss = 0.1252 (0.981 sec/step)\n",
      "I0902 09:29:58.149024 139792788920128 learning.py:507] global step 42212: loss = 0.0733 (0.988 sec/step)\n",
      "I0902 09:29:59.107309 139792788920128 learning.py:507] global step 42213: loss = 0.1290 (0.957 sec/step)\n",
      "I0902 09:30:00.067511 139792788920128 learning.py:507] global step 42214: loss = 0.1510 (0.959 sec/step)\n",
      "I0902 09:30:01.030694 139792788920128 learning.py:507] global step 42215: loss = 0.0992 (0.961 sec/step)\n",
      "I0902 09:30:02.042933 139792788920128 learning.py:507] global step 42216: loss = 0.0688 (1.011 sec/step)\n",
      "I0902 09:30:03.017543 139792788920128 learning.py:507] global step 42217: loss = 0.1759 (0.973 sec/step)\n",
      "I0902 09:30:03.975807 139792788920128 learning.py:507] global step 42218: loss = 0.0725 (0.957 sec/step)\n",
      "I0902 09:30:04.935887 139792788920128 learning.py:507] global step 42219: loss = 0.1300 (0.958 sec/step)\n",
      "I0902 09:30:05.874312 139792788920128 learning.py:507] global step 42220: loss = 0.0895 (0.937 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:30:06.867214 139792788920128 learning.py:507] global step 42221: loss = 0.0454 (0.991 sec/step)\n",
      "I0902 09:30:07.840254 139792788920128 learning.py:507] global step 42222: loss = 0.1797 (0.971 sec/step)\n",
      "I0902 09:30:08.814681 139792788920128 learning.py:507] global step 42223: loss = 0.1061 (0.973 sec/step)\n",
      "I0902 09:30:09.788647 139792788920128 learning.py:507] global step 42224: loss = 0.1231 (0.972 sec/step)\n",
      "I0902 09:30:10.743285 139792788920128 learning.py:507] global step 42225: loss = 0.1949 (0.953 sec/step)\n",
      "I0902 09:30:11.684785 139792788920128 learning.py:507] global step 42226: loss = 0.1422 (0.940 sec/step)\n",
      "I0902 09:30:12.642410 139792788920128 learning.py:507] global step 42227: loss = 0.0951 (0.956 sec/step)\n",
      "I0902 09:30:13.601949 139792788920128 learning.py:507] global step 42228: loss = 0.2535 (0.958 sec/step)\n",
      "I0902 09:30:14.570384 139792788920128 learning.py:507] global step 42229: loss = 0.0750 (0.967 sec/step)\n",
      "I0902 09:30:15.553146 139792788920128 learning.py:507] global step 42230: loss = 0.1029 (0.981 sec/step)\n",
      "I0902 09:30:16.518760 139792788920128 learning.py:507] global step 42231: loss = 0.1441 (0.964 sec/step)\n",
      "I0902 09:30:17.501544 139792788920128 learning.py:507] global step 42232: loss = 0.1094 (0.981 sec/step)\n",
      "I0902 09:30:18.480480 139792788920128 learning.py:507] global step 42233: loss = 0.0836 (0.977 sec/step)\n",
      "I0902 09:30:19.454737 139792788920128 learning.py:507] global step 42234: loss = 0.0457 (0.973 sec/step)\n",
      "I0902 09:30:20.418081 139792788920128 learning.py:507] global step 42235: loss = 0.1203 (0.962 sec/step)\n",
      "I0902 09:30:21.405006 139792788920128 learning.py:507] global step 42236: loss = 0.1232 (0.985 sec/step)\n",
      "I0902 09:30:22.371385 139792788920128 learning.py:507] global step 42237: loss = 0.0982 (0.965 sec/step)\n",
      "I0902 09:30:23.366653 139792788920128 learning.py:507] global step 42238: loss = 0.1064 (0.994 sec/step)\n",
      "I0902 09:30:24.352315 139792788920128 learning.py:507] global step 42239: loss = 0.0599 (0.984 sec/step)\n",
      "I0902 09:30:25.328545 139792788920128 learning.py:507] global step 42240: loss = 0.1921 (0.974 sec/step)\n",
      "I0902 09:30:26.310039 139792788920128 learning.py:507] global step 42241: loss = 0.0429 (0.980 sec/step)\n",
      "I0902 09:30:27.289609 139792788920128 learning.py:507] global step 42242: loss = 0.0719 (0.978 sec/step)\n",
      "I0902 09:30:28.284495 139792788920128 learning.py:507] global step 42243: loss = 0.1006 (0.993 sec/step)\n",
      "I0902 09:30:29.271462 139792788920128 learning.py:507] global step 42244: loss = 0.1417 (0.985 sec/step)\n",
      "I0902 09:30:30.237417 139792788920128 learning.py:507] global step 42245: loss = 0.1619 (0.964 sec/step)\n",
      "I0902 09:30:31.210178 139792788920128 learning.py:507] global step 42246: loss = 0.0975 (0.971 sec/step)\n",
      "I0902 09:30:32.189901 139792788920128 learning.py:507] global step 42247: loss = 0.0892 (0.978 sec/step)\n",
      "I0902 09:30:33.155548 139792788920128 learning.py:507] global step 42248: loss = 0.1559 (0.964 sec/step)\n",
      "I0902 09:30:34.129058 139792788920128 learning.py:507] global step 42249: loss = 0.1151 (0.972 sec/step)\n",
      "I0902 09:30:35.102138 139792788920128 learning.py:507] global step 42250: loss = 0.1524 (0.971 sec/step)\n",
      "I0902 09:30:36.074777 139792788920128 learning.py:507] global step 42251: loss = 0.0993 (0.971 sec/step)\n",
      "I0902 09:30:37.065071 139792788920128 learning.py:507] global step 42252: loss = 0.0811 (0.989 sec/step)\n",
      "I0902 09:30:38.045153 139792788920128 learning.py:507] global step 42253: loss = 0.0454 (0.978 sec/step)\n",
      "I0902 09:30:39.007804 139792788920128 learning.py:507] global step 42254: loss = 0.1354 (0.961 sec/step)\n",
      "I0902 09:30:39.996689 139792788920128 learning.py:507] global step 42255: loss = 0.0748 (0.987 sec/step)\n",
      "I0902 09:30:40.974993 139792788920128 learning.py:507] global step 42256: loss = 0.1144 (0.977 sec/step)\n",
      "I0902 09:30:41.960228 139792788920128 learning.py:507] global step 42257: loss = 0.1788 (0.984 sec/step)\n",
      "I0902 09:30:42.950412 139792788920128 learning.py:507] global step 42258: loss = 0.1638 (0.989 sec/step)\n",
      "I0902 09:30:43.917562 139792788920128 learning.py:507] global step 42259: loss = 0.1709 (0.966 sec/step)\n",
      "I0902 09:30:44.910881 139792788920128 learning.py:507] global step 42260: loss = 0.1951 (0.992 sec/step)\n",
      "I0902 09:30:45.898847 139792788920128 learning.py:507] global step 42261: loss = 0.4098 (0.986 sec/step)\n",
      "I0902 09:30:46.878786 139792788920128 learning.py:507] global step 42262: loss = 0.0744 (0.978 sec/step)\n",
      "I0902 09:30:47.860631 139792788920128 learning.py:507] global step 42263: loss = 0.1188 (0.980 sec/step)\n",
      "I0902 09:30:48.808739 139792788920128 learning.py:507] global step 42264: loss = 0.0999 (0.947 sec/step)\n",
      "I0902 09:30:49.788481 139792788920128 learning.py:507] global step 42265: loss = 0.1910 (0.978 sec/step)\n",
      "I0902 09:30:50.760495 139792788920128 learning.py:507] global step 42266: loss = 0.1240 (0.971 sec/step)\n",
      "I0902 09:30:51.746490 139792788920128 learning.py:507] global step 42267: loss = 0.1289 (0.985 sec/step)\n",
      "I0902 09:30:52.722736 139792788920128 learning.py:507] global step 42268: loss = 0.1094 (0.975 sec/step)\n",
      "I0902 09:30:53.698886 139792788920128 learning.py:507] global step 42269: loss = 0.1454 (0.974 sec/step)\n",
      "I0902 09:30:54.680418 139792788920128 learning.py:507] global step 42270: loss = 0.0663 (0.980 sec/step)\n",
      "I0902 09:30:55.659190 139792788920128 learning.py:507] global step 42271: loss = 0.0980 (0.977 sec/step)\n",
      "I0902 09:30:56.635495 139792788920128 learning.py:507] global step 42272: loss = 0.0802 (0.975 sec/step)\n",
      "I0902 09:30:57.630831 139792788920128 learning.py:507] global step 42273: loss = 0.1128 (0.994 sec/step)\n",
      "I0902 09:30:58.628971 139792788920128 learning.py:507] global step 42274: loss = 0.1599 (0.997 sec/step)\n",
      "I0902 09:30:59.615456 139792788920128 learning.py:507] global step 42275: loss = 0.1973 (0.985 sec/step)\n",
      "I0902 09:31:00.584144 139792788920128 learning.py:507] global step 42276: loss = 0.0623 (0.967 sec/step)\n",
      "I0902 09:31:01.560723 139792788920128 learning.py:507] global step 42277: loss = 0.0723 (0.975 sec/step)\n",
      "I0902 09:31:02.534898 139792788920128 learning.py:507] global step 42278: loss = 0.1151 (0.972 sec/step)\n",
      "I0902 09:31:03.528998 139792788920128 learning.py:507] global step 42279: loss = 0.1097 (0.992 sec/step)\n",
      "I0902 09:31:04.493777 139792788920128 learning.py:507] global step 42280: loss = 0.0814 (0.963 sec/step)\n",
      "I0902 09:31:05.462030 139792788920128 learning.py:507] global step 42281: loss = 0.1631 (0.967 sec/step)\n",
      "I0902 09:31:06.419807 139792788920128 learning.py:507] global step 42282: loss = 0.0896 (0.956 sec/step)\n",
      "I0902 09:31:07.388556 139792788920128 learning.py:507] global step 42283: loss = 0.1316 (0.967 sec/step)\n",
      "I0902 09:31:08.361329 139792788920128 learning.py:507] global step 42284: loss = 0.0889 (0.971 sec/step)\n",
      "I0902 09:31:09.305230 139792788920128 learning.py:507] global step 42285: loss = 0.0791 (0.943 sec/step)\n",
      "I0902 09:31:10.260696 139792788920128 learning.py:507] global step 42286: loss = 0.1939 (0.954 sec/step)\n",
      "I0902 09:31:11.251291 139792788920128 learning.py:507] global step 42287: loss = 0.2405 (0.989 sec/step)\n",
      "I0902 09:31:12.211299 139792788920128 learning.py:507] global step 42288: loss = 0.1276 (0.959 sec/step)\n",
      "I0902 09:31:13.181332 139792788920128 learning.py:507] global step 42289: loss = 0.3165 (0.969 sec/step)\n",
      "I0902 09:31:14.151916 139792788920128 learning.py:507] global step 42290: loss = 0.1917 (0.969 sec/step)\n",
      "I0902 09:31:15.127150 139792788920128 learning.py:507] global step 42291: loss = 0.0655 (0.974 sec/step)\n",
      "I0902 09:31:16.092457 139792788920128 learning.py:507] global step 42292: loss = 0.0620 (0.964 sec/step)\n",
      "I0902 09:31:17.062575 139792788920128 learning.py:507] global step 42293: loss = 0.0602 (0.969 sec/step)\n",
      "I0902 09:31:18.025340 139792788920128 learning.py:507] global step 42294: loss = 0.0507 (0.961 sec/step)\n",
      "I0902 09:31:18.986363 139792788920128 learning.py:507] global step 42295: loss = 0.0532 (0.960 sec/step)\n",
      "I0902 09:31:19.965314 139792788920128 learning.py:507] global step 42296: loss = 0.1762 (0.977 sec/step)\n",
      "I0902 09:31:20.914417 139792788920128 learning.py:507] global step 42297: loss = 0.2391 (0.947 sec/step)\n",
      "I0902 09:31:21.895925 139792788920128 learning.py:507] global step 42298: loss = 0.1230 (0.980 sec/step)\n",
      "I0902 09:31:22.853266 139792788920128 learning.py:507] global step 42299: loss = 0.1547 (0.956 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:31:23.821773 139792788920128 learning.py:507] global step 42300: loss = 0.3013 (0.967 sec/step)\n",
      "I0902 09:31:24.794593 139792788920128 learning.py:507] global step 42301: loss = 0.2220 (0.971 sec/step)\n",
      "I0902 09:31:25.772141 139792788920128 learning.py:507] global step 42302: loss = 0.0839 (0.976 sec/step)\n",
      "I0902 09:31:26.758426 139792788920128 learning.py:507] global step 42303: loss = 0.1142 (0.984 sec/step)\n",
      "I0902 09:31:27.739062 139792788920128 learning.py:507] global step 42304: loss = 0.1368 (0.979 sec/step)\n",
      "I0902 09:31:28.722092 139792788920128 learning.py:507] global step 42305: loss = 0.1435 (0.981 sec/step)\n",
      "I0902 09:31:29.676521 139792788920128 learning.py:507] global step 42306: loss = 0.1090 (0.953 sec/step)\n",
      "I0902 09:31:30.663756 139792788920128 learning.py:507] global step 42307: loss = 0.1595 (0.986 sec/step)\n",
      "I0902 09:31:31.610673 139792788920128 learning.py:507] global step 42308: loss = 0.1069 (0.945 sec/step)\n",
      "I0902 09:31:32.579429 139792788920128 learning.py:507] global step 42309: loss = 0.1013 (0.967 sec/step)\n",
      "I0902 09:31:33.546450 139792788920128 learning.py:507] global step 42310: loss = 0.0917 (0.965 sec/step)\n",
      "I0902 09:31:34.492288 139792788920128 learning.py:507] global step 42311: loss = 0.1368 (0.944 sec/step)\n",
      "I0902 09:31:35.455291 139792788920128 learning.py:507] global step 42312: loss = 0.0934 (0.961 sec/step)\n",
      "I0902 09:31:36.424474 139792788920128 learning.py:507] global step 42313: loss = 0.1035 (0.968 sec/step)\n",
      "I0902 09:31:37.414012 139792788920128 learning.py:507] global step 42314: loss = 0.0804 (0.988 sec/step)\n",
      "I0902 09:31:38.385208 139792788920128 learning.py:507] global step 42315: loss = 0.1582 (0.969 sec/step)\n",
      "I0902 09:31:39.375122 139792788920128 learning.py:507] global step 42316: loss = 0.1549 (0.988 sec/step)\n",
      "I0902 09:31:40.366247 139792788920128 learning.py:507] global step 42317: loss = 0.1023 (0.989 sec/step)\n",
      "I0902 09:31:41.367247 139792788920128 learning.py:507] global step 42318: loss = 0.1832 (0.999 sec/step)\n",
      "I0902 09:31:42.327944 139792788920128 learning.py:507] global step 42319: loss = 0.1176 (0.959 sec/step)\n",
      "I0902 09:31:43.288392 139792788920128 learning.py:507] global step 42320: loss = 0.1095 (0.959 sec/step)\n",
      "I0902 09:31:44.251884 139792788920128 learning.py:507] global step 42321: loss = 0.0953 (0.962 sec/step)\n",
      "I0902 09:31:45.218174 139792788920128 learning.py:507] global step 42322: loss = 0.2350 (0.965 sec/step)\n",
      "I0902 09:31:46.199760 139792788920128 learning.py:507] global step 42323: loss = 0.0421 (0.980 sec/step)\n",
      "I0902 09:31:47.172170 139792788920128 learning.py:507] global step 42324: loss = 0.0569 (0.971 sec/step)\n",
      "I0902 09:31:48.155370 139792788920128 learning.py:507] global step 42325: loss = 0.1675 (0.981 sec/step)\n",
      "I0902 09:31:49.109390 139792788920128 learning.py:507] global step 42326: loss = 0.1151 (0.952 sec/step)\n",
      "I0902 09:31:50.227825 139792788920128 learning.py:507] global step 42327: loss = 0.1558 (1.117 sec/step)\n",
      "I0902 09:31:50.526725 139778936784640 supervisor.py:1050] Recording summary at step 42327.\n",
      "I0902 09:31:51.303591 139792788920128 learning.py:507] global step 42328: loss = 0.1876 (1.073 sec/step)\n",
      "I0902 09:31:52.295907 139792788920128 learning.py:507] global step 42329: loss = 0.0950 (0.991 sec/step)\n",
      "I0902 09:31:53.285824 139792788920128 learning.py:507] global step 42330: loss = 0.1835 (0.988 sec/step)\n",
      "I0902 09:31:54.279515 139792788920128 learning.py:507] global step 42331: loss = 0.0933 (0.992 sec/step)\n",
      "I0902 09:31:55.254044 139792788920128 learning.py:507] global step 42332: loss = 0.1502 (0.973 sec/step)\n",
      "I0902 09:31:56.223245 139792788920128 learning.py:507] global step 42333: loss = 0.1071 (0.968 sec/step)\n",
      "I0902 09:31:57.236590 139792788920128 learning.py:507] global step 42334: loss = 0.2299 (1.012 sec/step)\n",
      "I0902 09:31:58.214511 139792788920128 learning.py:507] global step 42335: loss = 0.1299 (0.976 sec/step)\n",
      "I0902 09:31:59.187327 139792788920128 learning.py:507] global step 42336: loss = 0.1777 (0.972 sec/step)\n",
      "I0902 09:32:00.166954 139792788920128 learning.py:507] global step 42337: loss = 0.1408 (0.978 sec/step)\n",
      "I0902 09:32:01.131161 139792788920128 learning.py:507] global step 42338: loss = 0.2115 (0.963 sec/step)\n",
      "I0902 09:32:02.081575 139792788920128 learning.py:507] global step 42339: loss = 0.1042 (0.949 sec/step)\n",
      "I0902 09:32:03.062752 139792788920128 learning.py:507] global step 42340: loss = 0.0706 (0.979 sec/step)\n",
      "I0902 09:32:04.034051 139792788920128 learning.py:507] global step 42341: loss = 0.0834 (0.970 sec/step)\n",
      "I0902 09:32:05.012983 139792788920128 learning.py:507] global step 42342: loss = 0.0320 (0.978 sec/step)\n",
      "I0902 09:32:05.997619 139792788920128 learning.py:507] global step 42343: loss = 0.0795 (0.983 sec/step)\n",
      "I0902 09:32:06.983847 139792788920128 learning.py:507] global step 42344: loss = 0.0960 (0.985 sec/step)\n",
      "I0902 09:32:07.949569 139792788920128 learning.py:507] global step 42345: loss = 0.1917 (0.964 sec/step)\n",
      "I0902 09:32:08.929497 139792788920128 learning.py:507] global step 42346: loss = 0.0837 (0.978 sec/step)\n",
      "I0902 09:32:09.890251 139792788920128 learning.py:507] global step 42347: loss = 0.1408 (0.959 sec/step)\n",
      "I0902 09:32:10.848123 139792788920128 learning.py:507] global step 42348: loss = 0.0649 (0.956 sec/step)\n",
      "I0902 09:32:11.819322 139792788920128 learning.py:507] global step 42349: loss = 0.2566 (0.969 sec/step)\n",
      "I0902 09:32:12.778836 139792788920128 learning.py:507] global step 42350: loss = 0.0984 (0.958 sec/step)\n",
      "I0902 09:32:13.750985 139792788920128 learning.py:507] global step 42351: loss = 0.0868 (0.971 sec/step)\n",
      "I0902 09:32:14.722224 139792788920128 learning.py:507] global step 42352: loss = 0.0863 (0.970 sec/step)\n",
      "I0902 09:32:15.699343 139792788920128 learning.py:507] global step 42353: loss = 0.1721 (0.976 sec/step)\n",
      "I0902 09:32:16.678575 139792788920128 learning.py:507] global step 42354: loss = 0.2036 (0.978 sec/step)\n",
      "I0902 09:32:17.638697 139792788920128 learning.py:507] global step 42355: loss = 0.0615 (0.958 sec/step)\n",
      "I0902 09:32:18.615206 139792788920128 learning.py:507] global step 42356: loss = 0.2910 (0.975 sec/step)\n",
      "I0902 09:32:19.598740 139792788920128 learning.py:507] global step 42357: loss = 0.1040 (0.982 sec/step)\n",
      "I0902 09:32:20.558718 139792788920128 learning.py:507] global step 42358: loss = 0.0821 (0.959 sec/step)\n",
      "I0902 09:32:21.522460 139792788920128 learning.py:507] global step 42359: loss = 0.0683 (0.962 sec/step)\n",
      "I0902 09:32:22.488928 139792788920128 learning.py:507] global step 42360: loss = 0.1292 (0.965 sec/step)\n",
      "I0902 09:32:23.445942 139792788920128 learning.py:507] global step 42361: loss = 0.1218 (0.955 sec/step)\n",
      "I0902 09:32:24.415810 139792788920128 learning.py:507] global step 42362: loss = 0.1081 (0.968 sec/step)\n",
      "I0902 09:32:25.390747 139792788920128 learning.py:507] global step 42363: loss = 0.1022 (0.973 sec/step)\n",
      "I0902 09:32:26.362612 139792788920128 learning.py:507] global step 42364: loss = 0.4255 (0.970 sec/step)\n",
      "I0902 09:32:27.332439 139792788920128 learning.py:507] global step 42365: loss = 0.2169 (0.968 sec/step)\n",
      "I0902 09:32:28.278387 139792788920128 learning.py:507] global step 42366: loss = 0.0841 (0.944 sec/step)\n",
      "I0902 09:32:29.239027 139792788920128 learning.py:507] global step 42367: loss = 0.0913 (0.959 sec/step)\n",
      "I0902 09:32:30.184223 139792788920128 learning.py:507] global step 42368: loss = 0.2695 (0.943 sec/step)\n",
      "I0902 09:32:31.141915 139792788920128 learning.py:507] global step 42369: loss = 0.1159 (0.956 sec/step)\n",
      "I0902 09:32:32.105245 139792788920128 learning.py:507] global step 42370: loss = 0.1527 (0.961 sec/step)\n",
      "I0902 09:32:33.078951 139792788920128 learning.py:507] global step 42371: loss = 0.1556 (0.972 sec/step)\n",
      "I0902 09:32:34.053369 139792788920128 learning.py:507] global step 42372: loss = 0.0890 (0.973 sec/step)\n",
      "I0902 09:32:35.021897 139792788920128 learning.py:507] global step 42373: loss = 0.0534 (0.967 sec/step)\n",
      "I0902 09:32:35.974452 139792788920128 learning.py:507] global step 42374: loss = 0.1043 (0.951 sec/step)\n",
      "I0902 09:32:36.920295 139792788920128 learning.py:507] global step 42375: loss = 0.0772 (0.944 sec/step)\n",
      "I0902 09:32:37.884058 139792788920128 learning.py:507] global step 42376: loss = 0.1707 (0.962 sec/step)\n",
      "I0902 09:32:38.875789 139792788920128 learning.py:507] global step 42377: loss = 0.0878 (0.990 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:32:39.851729 139792788920128 learning.py:507] global step 42378: loss = 0.0714 (0.974 sec/step)\n",
      "I0902 09:32:40.811921 139792788920128 learning.py:507] global step 42379: loss = 0.1611 (0.959 sec/step)\n",
      "I0902 09:32:41.770570 139792788920128 learning.py:507] global step 42380: loss = 0.0857 (0.957 sec/step)\n",
      "I0902 09:32:42.746108 139792788920128 learning.py:507] global step 42381: loss = 0.1484 (0.974 sec/step)\n",
      "I0902 09:32:43.722180 139792788920128 learning.py:507] global step 42382: loss = 0.1075 (0.974 sec/step)\n",
      "I0902 09:32:44.682796 139792788920128 learning.py:507] global step 42383: loss = 0.0742 (0.959 sec/step)\n",
      "I0902 09:32:45.641903 139792788920128 learning.py:507] global step 42384: loss = 0.1292 (0.957 sec/step)\n",
      "I0902 09:32:46.598985 139792788920128 learning.py:507] global step 42385: loss = 0.1047 (0.955 sec/step)\n",
      "I0902 09:32:47.556405 139792788920128 learning.py:507] global step 42386: loss = 0.2573 (0.956 sec/step)\n",
      "I0902 09:32:48.532590 139792788920128 learning.py:507] global step 42387: loss = 0.0862 (0.974 sec/step)\n",
      "I0902 09:32:49.492384 139792788920128 learning.py:507] global step 42388: loss = 0.0952 (0.958 sec/step)\n",
      "I0902 09:32:50.483774 139792788920128 learning.py:507] global step 42389: loss = 0.2703 (0.990 sec/step)\n",
      "I0902 09:32:51.436196 139792788920128 learning.py:507] global step 42390: loss = 0.1980 (0.951 sec/step)\n",
      "I0902 09:32:52.420528 139792788920128 learning.py:507] global step 42391: loss = 0.0932 (0.983 sec/step)\n",
      "I0902 09:32:53.391139 139792788920128 learning.py:507] global step 42392: loss = 0.2000 (0.969 sec/step)\n",
      "I0902 09:32:54.352210 139792788920128 learning.py:507] global step 42393: loss = 0.0651 (0.959 sec/step)\n",
      "I0902 09:32:55.314031 139792788920128 learning.py:507] global step 42394: loss = 0.2669 (0.960 sec/step)\n",
      "I0902 09:32:56.299050 139792788920128 learning.py:507] global step 42395: loss = 0.1530 (0.983 sec/step)\n",
      "I0902 09:32:57.267459 139792788920128 learning.py:507] global step 42396: loss = 0.1550 (0.967 sec/step)\n",
      "I0902 09:32:58.235479 139792788920128 learning.py:507] global step 42397: loss = 0.0824 (0.966 sec/step)\n",
      "I0902 09:32:59.197916 139792788920128 learning.py:507] global step 42398: loss = 0.0917 (0.961 sec/step)\n",
      "I0902 09:33:00.177820 139792788920128 learning.py:507] global step 42399: loss = 0.0696 (0.978 sec/step)\n",
      "I0902 09:33:01.152877 139792788920128 learning.py:507] global step 42400: loss = 0.0890 (0.974 sec/step)\n",
      "I0902 09:33:02.124934 139792788920128 learning.py:507] global step 42401: loss = 0.1167 (0.970 sec/step)\n",
      "I0902 09:33:03.079096 139792788920128 learning.py:507] global step 42402: loss = 0.0747 (0.952 sec/step)\n",
      "I0902 09:33:04.040545 139792788920128 learning.py:507] global step 42403: loss = 0.0996 (0.960 sec/step)\n",
      "I0902 09:33:05.001670 139792788920128 learning.py:507] global step 42404: loss = 0.0690 (0.959 sec/step)\n",
      "I0902 09:33:05.958115 139792788920128 learning.py:507] global step 42405: loss = 0.1578 (0.955 sec/step)\n",
      "I0902 09:33:06.951546 139792788920128 learning.py:507] global step 42406: loss = 0.1130 (0.992 sec/step)\n",
      "I0902 09:33:07.922608 139792788920128 learning.py:507] global step 42407: loss = 0.1821 (0.969 sec/step)\n",
      "I0902 09:33:08.917738 139792788920128 learning.py:507] global step 42408: loss = 0.0908 (0.994 sec/step)\n",
      "I0902 09:33:09.879467 139792788920128 learning.py:507] global step 42409: loss = 0.1014 (0.960 sec/step)\n",
      "I0902 09:33:10.845707 139792788920128 learning.py:507] global step 42410: loss = 0.1151 (0.965 sec/step)\n",
      "I0902 09:33:11.802621 139792788920128 learning.py:507] global step 42411: loss = 0.1309 (0.955 sec/step)\n",
      "I0902 09:33:12.780159 139792788920128 learning.py:507] global step 42412: loss = 0.1033 (0.976 sec/step)\n",
      "I0902 09:33:13.752878 139792788920128 learning.py:507] global step 42413: loss = 0.1251 (0.971 sec/step)\n",
      "I0902 09:33:14.714928 139792788920128 learning.py:507] global step 42414: loss = 0.0861 (0.960 sec/step)\n",
      "I0902 09:33:15.676400 139792788920128 learning.py:507] global step 42415: loss = 0.1218 (0.960 sec/step)\n",
      "I0902 09:33:16.657378 139792788920128 learning.py:507] global step 42416: loss = 0.3186 (0.979 sec/step)\n",
      "I0902 09:33:17.613166 139792788920128 learning.py:507] global step 42417: loss = 0.2435 (0.954 sec/step)\n",
      "I0902 09:33:18.584078 139792788920128 learning.py:507] global step 42418: loss = 0.1008 (0.969 sec/step)\n",
      "I0902 09:33:19.553837 139792788920128 learning.py:507] global step 42419: loss = 0.1220 (0.968 sec/step)\n",
      "I0902 09:33:20.541170 139792788920128 learning.py:507] global step 42420: loss = 0.1082 (0.986 sec/step)\n",
      "I0902 09:33:21.516328 139792788920128 learning.py:507] global step 42421: loss = 0.1863 (0.973 sec/step)\n",
      "I0902 09:33:22.464935 139792788920128 learning.py:507] global step 42422: loss = 0.2984 (0.947 sec/step)\n",
      "I0902 09:33:23.444265 139792788920128 learning.py:507] global step 42423: loss = 0.1671 (0.977 sec/step)\n",
      "I0902 09:33:24.396557 139792788920128 learning.py:507] global step 42424: loss = 0.0934 (0.951 sec/step)\n",
      "I0902 09:33:25.343929 139792788920128 learning.py:507] global step 42425: loss = 0.1170 (0.946 sec/step)\n",
      "I0902 09:33:26.337469 139792788920128 learning.py:507] global step 42426: loss = 0.0818 (0.992 sec/step)\n",
      "I0902 09:33:27.315711 139792788920128 learning.py:507] global step 42427: loss = 0.2479 (0.977 sec/step)\n",
      "I0902 09:33:28.282604 139792788920128 learning.py:507] global step 42428: loss = 0.0748 (0.965 sec/step)\n",
      "I0902 09:33:29.238271 139792788920128 learning.py:507] global step 42429: loss = 0.1822 (0.954 sec/step)\n",
      "I0902 09:33:30.226799 139792788920128 learning.py:507] global step 42430: loss = 0.1211 (0.987 sec/step)\n",
      "I0902 09:33:31.175860 139792788920128 learning.py:507] global step 42431: loss = 0.0559 (0.947 sec/step)\n",
      "I0902 09:33:32.152154 139792788920128 learning.py:507] global step 42432: loss = 0.0692 (0.974 sec/step)\n",
      "I0902 09:33:33.114953 139792788920128 learning.py:507] global step 42433: loss = 0.0525 (0.961 sec/step)\n",
      "I0902 09:33:34.063703 139792788920128 learning.py:507] global step 42434: loss = 0.0891 (0.947 sec/step)\n",
      "I0902 09:33:35.049538 139792788920128 learning.py:507] global step 42435: loss = 0.1743 (0.984 sec/step)\n",
      "I0902 09:33:36.032802 139792788920128 learning.py:507] global step 42436: loss = 0.0962 (0.982 sec/step)\n",
      "I0902 09:33:36.996145 139792788920128 learning.py:507] global step 42437: loss = 0.1455 (0.962 sec/step)\n",
      "I0902 09:33:37.945271 139792788920128 learning.py:507] global step 42438: loss = 0.1305 (0.947 sec/step)\n",
      "I0902 09:33:38.907613 139792788920128 learning.py:507] global step 42439: loss = 0.2828 (0.961 sec/step)\n",
      "I0902 09:33:39.866071 139792788920128 learning.py:507] global step 42440: loss = 0.0867 (0.957 sec/step)\n",
      "I0902 09:33:40.828913 139792788920128 learning.py:507] global step 42441: loss = 0.1234 (0.961 sec/step)\n",
      "I0902 09:33:41.803701 139792788920128 learning.py:507] global step 42442: loss = 0.0837 (0.973 sec/step)\n",
      "I0902 09:33:42.786691 139792788920128 learning.py:507] global step 42443: loss = 0.0680 (0.981 sec/step)\n",
      "I0902 09:33:43.762691 139792788920128 learning.py:507] global step 42444: loss = 0.3983 (0.974 sec/step)\n",
      "I0902 09:33:44.737787 139792788920128 learning.py:507] global step 42445: loss = 0.1163 (0.974 sec/step)\n",
      "I0902 09:33:45.704101 139792788920128 learning.py:507] global step 42446: loss = 0.1267 (0.965 sec/step)\n",
      "I0902 09:33:46.662401 139792788920128 learning.py:507] global step 42447: loss = 0.1308 (0.957 sec/step)\n",
      "I0902 09:33:47.641023 139792788920128 learning.py:507] global step 42448: loss = 0.1300 (0.977 sec/step)\n",
      "I0902 09:33:48.597750 139792788920128 learning.py:507] global step 42449: loss = 0.1468 (0.955 sec/step)\n",
      "I0902 09:33:49.270353 139778953570048 supervisor.py:1117] Saving checkpoint to path data_dir/mixed_experiment/checkpoints_v2/model.ckpt\n",
      "I0902 09:33:49.606925 139792788920128 learning.py:507] global step 42450: loss = 0.1152 (1.008 sec/step)\n",
      "I0902 09:33:50.224910 139778936784640 supervisor.py:1050] Recording summary at step 42450.\n",
      "I0902 09:33:50.827698 139792788920128 learning.py:507] global step 42451: loss = 0.1352 (1.218 sec/step)\n",
      "I0902 09:33:51.801202 139792788920128 learning.py:507] global step 42452: loss = 0.1256 (0.972 sec/step)\n",
      "I0902 09:33:52.780110 139792788920128 learning.py:507] global step 42453: loss = 0.0316 (0.977 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:33:53.734877 139792788920128 learning.py:507] global step 42454: loss = 0.3840 (0.953 sec/step)\n",
      "I0902 09:33:54.715095 139792788920128 learning.py:507] global step 42455: loss = 0.1190 (0.979 sec/step)\n",
      "I0902 09:33:55.680792 139792788920128 learning.py:507] global step 42456: loss = 0.1354 (0.964 sec/step)\n",
      "I0902 09:33:56.637489 139792788920128 learning.py:507] global step 42457: loss = 0.1136 (0.955 sec/step)\n",
      "I0902 09:33:57.606373 139792788920128 learning.py:507] global step 42458: loss = 0.1050 (0.967 sec/step)\n",
      "I0902 09:33:58.574510 139792788920128 learning.py:507] global step 42459: loss = 0.1731 (0.967 sec/step)\n",
      "I0902 09:33:59.540138 139792788920128 learning.py:507] global step 42460: loss = 0.1647 (0.964 sec/step)\n",
      "I0902 09:34:00.497514 139792788920128 learning.py:507] global step 42461: loss = 0.1357 (0.956 sec/step)\n",
      "I0902 09:34:01.478014 139792788920128 learning.py:507] global step 42462: loss = 0.0723 (0.979 sec/step)\n",
      "I0902 09:34:02.468358 139792788920128 learning.py:507] global step 42463: loss = 0.1749 (0.989 sec/step)\n",
      "I0902 09:34:03.426846 139792788920128 learning.py:507] global step 42464: loss = 0.0680 (0.957 sec/step)\n",
      "I0902 09:34:04.381914 139792788920128 learning.py:507] global step 42465: loss = 0.0905 (0.953 sec/step)\n",
      "I0902 09:34:05.352538 139792788920128 learning.py:507] global step 42466: loss = 0.0860 (0.969 sec/step)\n",
      "I0902 09:34:06.325500 139792788920128 learning.py:507] global step 42467: loss = 0.0811 (0.971 sec/step)\n",
      "I0902 09:34:07.299939 139792788920128 learning.py:507] global step 42468: loss = 0.1246 (0.973 sec/step)\n",
      "I0902 09:34:08.276686 139792788920128 learning.py:507] global step 42469: loss = 0.1254 (0.975 sec/step)\n",
      "I0902 09:34:09.263192 139792788920128 learning.py:507] global step 42470: loss = 0.1600 (0.985 sec/step)\n",
      "I0902 09:34:10.224503 139792788920128 learning.py:507] global step 42471: loss = 0.1763 (0.960 sec/step)\n",
      "I0902 09:34:11.189826 139792788920128 learning.py:507] global step 42472: loss = 0.1156 (0.963 sec/step)\n",
      "I0902 09:34:12.173501 139792788920128 learning.py:507] global step 42473: loss = 0.1600 (0.982 sec/step)\n",
      "I0902 09:34:13.149624 139792788920128 learning.py:507] global step 42474: loss = 0.1211 (0.974 sec/step)\n",
      "I0902 09:34:14.112419 139792788920128 learning.py:507] global step 42475: loss = 0.0764 (0.961 sec/step)\n",
      "I0902 09:34:15.064474 139792788920128 learning.py:507] global step 42476: loss = 0.0402 (0.950 sec/step)\n",
      "I0902 09:34:16.037398 139792788920128 learning.py:507] global step 42477: loss = 0.1302 (0.971 sec/step)\n",
      "I0902 09:34:17.001300 139792788920128 learning.py:507] global step 42478: loss = 0.0841 (0.962 sec/step)\n",
      "I0902 09:34:17.954643 139792788920128 learning.py:507] global step 42479: loss = 0.1154 (0.952 sec/step)\n",
      "I0902 09:34:18.939951 139792788920128 learning.py:507] global step 42480: loss = 0.0861 (0.984 sec/step)\n",
      "I0902 09:34:19.905891 139792788920128 learning.py:507] global step 42481: loss = 0.1817 (0.964 sec/step)\n",
      "I0902 09:34:20.876041 139792788920128 learning.py:507] global step 42482: loss = 0.1936 (0.969 sec/step)\n",
      "I0902 09:34:21.862751 139792788920128 learning.py:507] global step 42483: loss = 0.1288 (0.985 sec/step)\n",
      "I0902 09:34:22.864116 139792788920128 learning.py:507] global step 42484: loss = 0.1785 (1.000 sec/step)\n",
      "I0902 09:34:23.843762 139792788920128 learning.py:507] global step 42485: loss = 0.2192 (0.978 sec/step)\n",
      "I0902 09:34:24.807270 139792788920128 learning.py:507] global step 42486: loss = 0.0936 (0.962 sec/step)\n",
      "I0902 09:34:25.764142 139792788920128 learning.py:507] global step 42487: loss = 0.2789 (0.955 sec/step)\n",
      "I0902 09:34:26.747439 139792788920128 learning.py:507] global step 42488: loss = 0.0977 (0.982 sec/step)\n",
      "I0902 09:34:27.719367 139792788920128 learning.py:507] global step 42489: loss = 0.2097 (0.970 sec/step)\n",
      "I0902 09:34:28.676949 139792788920128 learning.py:507] global step 42490: loss = 0.0827 (0.956 sec/step)\n",
      "I0902 09:34:29.644902 139792788920128 learning.py:507] global step 42491: loss = 0.0855 (0.966 sec/step)\n",
      "I0902 09:34:30.638833 139792788920128 learning.py:507] global step 42492: loss = 0.1659 (0.992 sec/step)\n",
      "I0902 09:34:31.585557 139792788920128 learning.py:507] global step 42493: loss = 0.1883 (0.945 sec/step)\n",
      "I0902 09:34:32.565764 139792788920128 learning.py:507] global step 42494: loss = 0.0394 (0.979 sec/step)\n",
      "I0902 09:34:33.526960 139792788920128 learning.py:507] global step 42495: loss = 0.0805 (0.959 sec/step)\n",
      "I0902 09:34:34.491231 139792788920128 learning.py:507] global step 42496: loss = 0.1509 (0.963 sec/step)\n",
      "I0902 09:34:35.477376 139792788920128 learning.py:507] global step 42497: loss = 0.1056 (0.985 sec/step)\n",
      "I0902 09:34:36.453036 139792788920128 learning.py:507] global step 42498: loss = 0.1354 (0.974 sec/step)\n",
      "I0902 09:34:37.401029 139792788920128 learning.py:507] global step 42499: loss = 0.0814 (0.946 sec/step)\n",
      "I0902 09:34:38.365565 139792788920128 learning.py:507] global step 42500: loss = 0.2023 (0.963 sec/step)\n",
      "I0902 09:34:39.336703 139792788920128 learning.py:507] global step 42501: loss = 0.1003 (0.969 sec/step)\n",
      "I0902 09:34:40.315344 139792788920128 learning.py:507] global step 42502: loss = 0.0529 (0.977 sec/step)\n",
      "I0902 09:34:41.293921 139792788920128 learning.py:507] global step 42503: loss = 0.0645 (0.977 sec/step)\n",
      "I0902 09:34:42.261009 139792788920128 learning.py:507] global step 42504: loss = 0.3276 (0.965 sec/step)\n",
      "I0902 09:34:43.243100 139792788920128 learning.py:507] global step 42505: loss = 0.0657 (0.981 sec/step)\n",
      "I0902 09:34:44.200160 139792788920128 learning.py:507] global step 42506: loss = 0.0955 (0.956 sec/step)\n",
      "I0902 09:34:45.179747 139792788920128 learning.py:507] global step 42507: loss = 0.1846 (0.978 sec/step)\n",
      "I0902 09:34:46.150722 139792788920128 learning.py:507] global step 42508: loss = 0.0658 (0.970 sec/step)\n",
      "I0902 09:34:47.120311 139792788920128 learning.py:507] global step 42509: loss = 0.0752 (0.968 sec/step)\n",
      "I0902 09:34:48.097464 139792788920128 learning.py:507] global step 42510: loss = 0.0826 (0.976 sec/step)\n",
      "I0902 09:34:49.084057 139792788920128 learning.py:507] global step 42511: loss = 0.0853 (0.985 sec/step)\n",
      "I0902 09:34:50.044014 139792788920128 learning.py:507] global step 42512: loss = 0.0574 (0.958 sec/step)\n",
      "I0902 09:34:51.008256 139792788920128 learning.py:507] global step 42513: loss = 0.1179 (0.962 sec/step)\n",
      "I0902 09:34:51.985053 139792788920128 learning.py:507] global step 42514: loss = 0.1427 (0.975 sec/step)\n",
      "I0902 09:34:52.971078 139792788920128 learning.py:507] global step 42515: loss = 0.1731 (0.984 sec/step)\n",
      "I0902 09:34:53.947925 139792788920128 learning.py:507] global step 42516: loss = 0.1461 (0.975 sec/step)\n",
      "I0902 09:34:54.911392 139792788920128 learning.py:507] global step 42517: loss = 0.0678 (0.962 sec/step)\n",
      "I0902 09:34:55.890141 139792788920128 learning.py:507] global step 42518: loss = 0.0797 (0.977 sec/step)\n",
      "I0902 09:34:56.880186 139792788920128 learning.py:507] global step 42519: loss = 0.0724 (0.988 sec/step)\n",
      "I0902 09:34:57.844683 139792788920128 learning.py:507] global step 42520: loss = 0.1272 (0.963 sec/step)\n",
      "I0902 09:34:58.832413 139792788920128 learning.py:507] global step 42521: loss = 0.2449 (0.986 sec/step)\n",
      "I0902 09:34:59.845760 139792788920128 learning.py:507] global step 42522: loss = 0.1246 (1.012 sec/step)\n",
      "I0902 09:35:00.821804 139792788920128 learning.py:507] global step 42523: loss = 0.0409 (0.975 sec/step)\n",
      "I0902 09:35:01.808788 139792788920128 learning.py:507] global step 42524: loss = 0.0436 (0.985 sec/step)\n",
      "I0902 09:35:02.790180 139792788920128 learning.py:507] global step 42525: loss = 0.0530 (0.980 sec/step)\n",
      "I0902 09:35:03.768850 139792788920128 learning.py:507] global step 42526: loss = 0.1052 (0.977 sec/step)\n",
      "I0902 09:35:04.749030 139792788920128 learning.py:507] global step 42527: loss = 0.1063 (0.979 sec/step)\n",
      "I0902 09:35:05.739357 139792788920128 learning.py:507] global step 42528: loss = 0.2465 (0.989 sec/step)\n",
      "I0902 09:35:06.714880 139792788920128 learning.py:507] global step 42529: loss = 0.1392 (0.974 sec/step)\n",
      "I0902 09:35:07.664826 139792788920128 learning.py:507] global step 42530: loss = 0.0850 (0.948 sec/step)\n",
      "I0902 09:35:08.626549 139792788920128 learning.py:507] global step 42531: loss = 0.1932 (0.960 sec/step)\n",
      "I0902 09:35:09.577060 139792788920128 learning.py:507] global step 42532: loss = 0.0802 (0.949 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:35:10.558754 139792788920128 learning.py:507] global step 42533: loss = 0.0864 (0.980 sec/step)\n",
      "I0902 09:35:11.544464 139792788920128 learning.py:507] global step 42534: loss = 0.3092 (0.984 sec/step)\n",
      "I0902 09:35:12.515956 139792788920128 learning.py:507] global step 42535: loss = 0.2643 (0.970 sec/step)\n",
      "I0902 09:35:13.469893 139792788920128 learning.py:507] global step 42536: loss = 0.1377 (0.952 sec/step)\n",
      "I0902 09:35:14.450815 139792788920128 learning.py:507] global step 42537: loss = 0.3840 (0.979 sec/step)\n",
      "I0902 09:35:15.425253 139792788920128 learning.py:507] global step 42538: loss = 0.1037 (0.973 sec/step)\n",
      "I0902 09:35:16.390630 139792788920128 learning.py:507] global step 42539: loss = 0.1290 (0.964 sec/step)\n",
      "I0902 09:35:17.373620 139792788920128 learning.py:507] global step 42540: loss = 0.1660 (0.981 sec/step)\n",
      "I0902 09:35:18.356850 139792788920128 learning.py:507] global step 42541: loss = 0.0894 (0.981 sec/step)\n",
      "I0902 09:35:19.321759 139792788920128 learning.py:507] global step 42542: loss = 0.0902 (0.963 sec/step)\n",
      "I0902 09:35:20.295052 139792788920128 learning.py:507] global step 42543: loss = 0.1700 (0.972 sec/step)\n",
      "I0902 09:35:21.261378 139792788920128 learning.py:507] global step 42544: loss = 0.1500 (0.965 sec/step)\n",
      "I0902 09:35:22.233649 139792788920128 learning.py:507] global step 42545: loss = 0.1192 (0.971 sec/step)\n",
      "I0902 09:35:23.208001 139792788920128 learning.py:507] global step 42546: loss = 0.1157 (0.973 sec/step)\n",
      "I0902 09:35:24.209613 139792788920128 learning.py:507] global step 42547: loss = 0.1506 (1.000 sec/step)\n",
      "I0902 09:35:25.195910 139792788920128 learning.py:507] global step 42548: loss = 0.3499 (0.985 sec/step)\n",
      "I0902 09:35:26.164808 139792788920128 learning.py:507] global step 42549: loss = 0.1729 (0.967 sec/step)\n",
      "I0902 09:35:27.141331 139792788920128 learning.py:507] global step 42550: loss = 0.0815 (0.975 sec/step)\n",
      "I0902 09:35:28.132170 139792788920128 learning.py:507] global step 42551: loss = 0.1051 (0.989 sec/step)\n",
      "I0902 09:35:29.096064 139792788920128 learning.py:507] global step 42552: loss = 0.0764 (0.962 sec/step)\n",
      "I0902 09:35:30.086996 139792788920128 learning.py:507] global step 42553: loss = 0.1131 (0.989 sec/step)\n",
      "I0902 09:35:31.086773 139792788920128 learning.py:507] global step 42554: loss = 0.0802 (0.998 sec/step)\n",
      "I0902 09:35:32.065514 139792788920128 learning.py:507] global step 42555: loss = 0.1464 (0.977 sec/step)\n",
      "I0902 09:35:33.042867 139792788920128 learning.py:507] global step 42556: loss = 0.1156 (0.976 sec/step)\n",
      "I0902 09:35:34.007601 139792788920128 learning.py:507] global step 42557: loss = 0.0912 (0.963 sec/step)\n",
      "I0902 09:35:34.983917 139792788920128 learning.py:507] global step 42558: loss = 0.1647 (0.975 sec/step)\n",
      "I0902 09:35:35.969021 139792788920128 learning.py:507] global step 42559: loss = 0.1311 (0.984 sec/step)\n",
      "I0902 09:35:36.941586 139792788920128 learning.py:507] global step 42560: loss = 0.0613 (0.971 sec/step)\n",
      "I0902 09:35:37.908146 139792788920128 learning.py:507] global step 42561: loss = 0.0581 (0.965 sec/step)\n",
      "I0902 09:35:38.900834 139792788920128 learning.py:507] global step 42562: loss = 0.1173 (0.991 sec/step)\n",
      "I0902 09:35:39.887168 139792788920128 learning.py:507] global step 42563: loss = 0.0857 (0.985 sec/step)\n",
      "I0902 09:35:40.869399 139792788920128 learning.py:507] global step 42564: loss = 0.0801 (0.981 sec/step)\n",
      "I0902 09:35:41.858560 139792788920128 learning.py:507] global step 42565: loss = 0.1195 (0.987 sec/step)\n",
      "I0902 09:35:42.819591 139792788920128 learning.py:507] global step 42566: loss = 0.0825 (0.959 sec/step)\n",
      "I0902 09:35:43.809307 139792788920128 learning.py:507] global step 42567: loss = 0.0895 (0.988 sec/step)\n",
      "I0902 09:35:44.788546 139792788920128 learning.py:507] global step 42568: loss = 0.1382 (0.978 sec/step)\n",
      "I0902 09:35:45.757146 139792788920128 learning.py:507] global step 42569: loss = 0.1921 (0.967 sec/step)\n",
      "I0902 09:35:46.743906 139792788920128 learning.py:507] global step 42570: loss = 0.1504 (0.985 sec/step)\n",
      "I0902 09:35:47.722975 139792788920128 learning.py:507] global step 42571: loss = 0.1121 (0.977 sec/step)\n",
      "I0902 09:35:48.723463 139792788920128 learning.py:507] global step 42572: loss = 0.1831 (0.999 sec/step)\n",
      "I0902 09:35:49.827990 139792788920128 learning.py:507] global step 42573: loss = 0.1044 (1.101 sec/step)\n",
      "I0902 09:35:50.144218 139778936784640 supervisor.py:1050] Recording summary at step 42573.\n",
      "I0902 09:35:50.947713 139792788920128 learning.py:507] global step 42574: loss = 0.0634 (1.107 sec/step)\n",
      "I0902 09:35:51.921448 139792788920128 learning.py:507] global step 42575: loss = 0.0882 (0.972 sec/step)\n",
      "I0902 09:35:52.881207 139792788920128 learning.py:507] global step 42576: loss = 0.0750 (0.958 sec/step)\n",
      "I0902 09:35:53.839459 139792788920128 learning.py:507] global step 42577: loss = 0.1153 (0.957 sec/step)\n",
      "I0902 09:35:54.806354 139792788920128 learning.py:507] global step 42578: loss = 0.1206 (0.965 sec/step)\n",
      "I0902 09:35:55.765166 139792788920128 learning.py:507] global step 42579: loss = 0.1591 (0.957 sec/step)\n",
      "I0902 09:35:56.737601 139792788920128 learning.py:507] global step 42580: loss = 0.1195 (0.971 sec/step)\n",
      "I0902 09:35:57.696879 139792788920128 learning.py:507] global step 42581: loss = 0.1489 (0.957 sec/step)\n",
      "I0902 09:35:58.648547 139792788920128 learning.py:507] global step 42582: loss = 0.0524 (0.950 sec/step)\n",
      "I0902 09:35:59.656759 139792788920128 learning.py:507] global step 42583: loss = 0.2423 (1.006 sec/step)\n",
      "I0902 09:36:00.634289 139792788920128 learning.py:507] global step 42584: loss = 0.1473 (0.976 sec/step)\n",
      "I0902 09:36:01.588338 139792788920128 learning.py:507] global step 42585: loss = 0.1341 (0.953 sec/step)\n",
      "I0902 09:36:02.541005 139792788920128 learning.py:507] global step 42586: loss = 0.0825 (0.951 sec/step)\n",
      "I0902 09:36:03.514066 139792788920128 learning.py:507] global step 42587: loss = 0.1432 (0.972 sec/step)\n",
      "I0902 09:36:04.481971 139792788920128 learning.py:507] global step 42588: loss = 0.0605 (0.966 sec/step)\n",
      "I0902 09:36:05.473503 139792788920128 learning.py:507] global step 42589: loss = 0.1749 (0.990 sec/step)\n",
      "I0902 09:36:06.452759 139792788920128 learning.py:507] global step 42590: loss = 0.0769 (0.978 sec/step)\n",
      "I0902 09:36:07.424263 139792788920128 learning.py:507] global step 42591: loss = 0.0837 (0.970 sec/step)\n",
      "I0902 09:36:08.395309 139792788920128 learning.py:507] global step 42592: loss = 0.1555 (0.969 sec/step)\n",
      "I0902 09:36:09.377211 139792788920128 learning.py:507] global step 42593: loss = 0.1353 (0.980 sec/step)\n",
      "I0902 09:36:10.366556 139792788920128 learning.py:507] global step 42594: loss = 0.1526 (0.987 sec/step)\n",
      "I0902 09:36:11.352185 139792788920128 learning.py:507] global step 42595: loss = 0.0735 (0.984 sec/step)\n",
      "I0902 09:36:12.330253 139792788920128 learning.py:507] global step 42596: loss = 0.0739 (0.976 sec/step)\n",
      "I0902 09:36:13.303896 139792788920128 learning.py:507] global step 42597: loss = 0.1420 (0.972 sec/step)\n",
      "I0902 09:36:14.268014 139792788920128 learning.py:507] global step 42598: loss = 0.1101 (0.962 sec/step)\n",
      "I0902 09:36:15.230772 139792788920128 learning.py:507] global step 42599: loss = 0.0808 (0.961 sec/step)\n",
      "I0902 09:36:16.191202 139792788920128 learning.py:507] global step 42600: loss = 0.1362 (0.959 sec/step)\n",
      "I0902 09:36:17.164625 139792788920128 learning.py:507] global step 42601: loss = 0.2231 (0.972 sec/step)\n",
      "I0902 09:36:18.153857 139792788920128 learning.py:507] global step 42602: loss = 0.1769 (0.988 sec/step)\n",
      "I0902 09:36:19.131500 139792788920128 learning.py:507] global step 42603: loss = 0.1434 (0.977 sec/step)\n",
      "I0902 09:36:20.112962 139792788920128 learning.py:507] global step 42604: loss = 0.1666 (0.980 sec/step)\n",
      "I0902 09:36:21.080924 139792788920128 learning.py:507] global step 42605: loss = 0.1164 (0.966 sec/step)\n",
      "I0902 09:36:22.061643 139792788920128 learning.py:507] global step 42606: loss = 0.2792 (0.979 sec/step)\n",
      "I0902 09:36:23.032162 139792788920128 learning.py:507] global step 42607: loss = 0.1762 (0.969 sec/step)\n",
      "I0902 09:36:24.017921 139792788920128 learning.py:507] global step 42608: loss = 0.1752 (0.984 sec/step)\n",
      "I0902 09:36:24.991750 139792788920128 learning.py:507] global step 42609: loss = 0.1166 (0.973 sec/step)\n",
      "I0902 09:36:25.995476 139792788920128 learning.py:507] global step 42610: loss = 0.2407 (1.002 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:36:26.977798 139792788920128 learning.py:507] global step 42611: loss = 0.0986 (0.981 sec/step)\n",
      "I0902 09:36:27.977144 139792788920128 learning.py:507] global step 42612: loss = 0.1403 (0.998 sec/step)\n",
      "I0902 09:36:28.965818 139792788920128 learning.py:507] global step 42613: loss = 0.1508 (0.987 sec/step)\n",
      "I0902 09:36:29.926496 139792788920128 learning.py:507] global step 42614: loss = 0.1247 (0.959 sec/step)\n",
      "I0902 09:36:30.903256 139792788920128 learning.py:507] global step 42615: loss = 0.0715 (0.975 sec/step)\n",
      "I0902 09:36:31.876665 139792788920128 learning.py:507] global step 42616: loss = 0.1312 (0.972 sec/step)\n",
      "I0902 09:36:32.854135 139792788920128 learning.py:507] global step 42617: loss = 0.0781 (0.976 sec/step)\n",
      "I0902 09:36:33.837039 139792788920128 learning.py:507] global step 42618: loss = 0.1404 (0.981 sec/step)\n",
      "I0902 09:36:34.814083 139792788920128 learning.py:507] global step 42619: loss = 0.0866 (0.975 sec/step)\n",
      "I0902 09:36:35.808319 139792788920128 learning.py:507] global step 42620: loss = 0.0996 (0.993 sec/step)\n",
      "I0902 09:36:36.795032 139792788920128 learning.py:507] global step 42621: loss = 0.1221 (0.985 sec/step)\n",
      "I0902 09:36:37.777135 139792788920128 learning.py:507] global step 42622: loss = 0.0427 (0.981 sec/step)\n",
      "I0902 09:36:38.761250 139792788920128 learning.py:507] global step 42623: loss = 0.0881 (0.982 sec/step)\n",
      "I0902 09:36:39.729429 139792788920128 learning.py:507] global step 42624: loss = 0.1500 (0.967 sec/step)\n",
      "I0902 09:36:40.709280 139792788920128 learning.py:507] global step 42625: loss = 0.1342 (0.978 sec/step)\n",
      "I0902 09:36:41.704347 139792788920128 learning.py:507] global step 42626: loss = 0.2107 (0.993 sec/step)\n",
      "I0902 09:36:42.670794 139792788920128 learning.py:507] global step 42627: loss = 0.1266 (0.965 sec/step)\n",
      "I0902 09:36:43.660870 139792788920128 learning.py:507] global step 42628: loss = 0.1141 (0.988 sec/step)\n",
      "I0902 09:36:44.647805 139792788920128 learning.py:507] global step 42629: loss = 0.0911 (0.985 sec/step)\n",
      "I0902 09:36:45.632878 139792788920128 learning.py:507] global step 42630: loss = 0.0755 (0.983 sec/step)\n",
      "I0902 09:36:46.628940 139792788920128 learning.py:507] global step 42631: loss = 0.0547 (0.995 sec/step)\n",
      "I0902 09:36:47.620908 139792788920128 learning.py:507] global step 42632: loss = 0.1765 (0.990 sec/step)\n",
      "I0902 09:36:48.623939 139792788920128 learning.py:507] global step 42633: loss = 0.0978 (1.001 sec/step)\n",
      "I0902 09:36:49.606220 139792788920128 learning.py:507] global step 42634: loss = 0.1249 (0.981 sec/step)\n",
      "I0902 09:36:50.594063 139792788920128 learning.py:507] global step 42635: loss = 0.0797 (0.986 sec/step)\n",
      "I0902 09:36:51.557874 139792788920128 learning.py:507] global step 42636: loss = 0.1817 (0.962 sec/step)\n",
      "I0902 09:36:52.539483 139792788920128 learning.py:507] global step 42637: loss = 0.0953 (0.980 sec/step)\n",
      "I0902 09:36:53.523166 139792788920128 learning.py:507] global step 42638: loss = 0.2169 (0.982 sec/step)\n",
      "I0902 09:36:54.495733 139792788920128 learning.py:507] global step 42639: loss = 0.0849 (0.971 sec/step)\n",
      "I0902 09:36:55.454079 139792788920128 learning.py:507] global step 42640: loss = 0.0627 (0.957 sec/step)\n",
      "I0902 09:36:56.421722 139792788920128 learning.py:507] global step 42641: loss = 0.0568 (0.966 sec/step)\n",
      "I0902 09:36:57.388388 139792788920128 learning.py:507] global step 42642: loss = 0.1574 (0.965 sec/step)\n",
      "I0902 09:36:58.362793 139792788920128 learning.py:507] global step 42643: loss = 0.0804 (0.973 sec/step)\n",
      "I0902 09:36:59.326810 139792788920128 learning.py:507] global step 42644: loss = 0.2106 (0.962 sec/step)\n",
      "I0902 09:37:00.308399 139792788920128 learning.py:507] global step 42645: loss = 0.1076 (0.980 sec/step)\n",
      "I0902 09:37:01.295667 139792788920128 learning.py:507] global step 42646: loss = 0.0722 (0.986 sec/step)\n",
      "I0902 09:37:02.271667 139792788920128 learning.py:507] global step 42647: loss = 0.2328 (0.974 sec/step)\n",
      "I0902 09:37:03.227044 139792788920128 learning.py:507] global step 42648: loss = 0.3094 (0.954 sec/step)\n",
      "I0902 09:37:04.202498 139792788920128 learning.py:507] global step 42649: loss = 0.1304 (0.974 sec/step)\n",
      "I0902 09:37:05.150045 139792788920128 learning.py:507] global step 42650: loss = 0.0420 (0.946 sec/step)\n",
      "I0902 09:37:06.121598 139792788920128 learning.py:507] global step 42651: loss = 0.1154 (0.970 sec/step)\n",
      "I0902 09:37:07.096856 139792788920128 learning.py:507] global step 42652: loss = 0.0960 (0.974 sec/step)\n",
      "I0902 09:37:08.084020 139792788920128 learning.py:507] global step 42653: loss = 0.1473 (0.986 sec/step)\n",
      "I0902 09:37:09.060373 139792788920128 learning.py:507] global step 42654: loss = 0.0604 (0.975 sec/step)\n",
      "I0902 09:37:10.058093 139792788920128 learning.py:507] global step 42655: loss = 0.1097 (0.996 sec/step)\n",
      "I0902 09:37:11.039190 139792788920128 learning.py:507] global step 42656: loss = 0.1096 (0.979 sec/step)\n",
      "I0902 09:37:12.028162 139792788920128 learning.py:507] global step 42657: loss = 0.0764 (0.987 sec/step)\n",
      "I0902 09:37:13.010445 139792788920128 learning.py:507] global step 42658: loss = 0.0742 (0.980 sec/step)\n",
      "I0902 09:37:13.988230 139792788920128 learning.py:507] global step 42659: loss = 0.0343 (0.976 sec/step)\n",
      "I0902 09:37:14.954147 139792788920128 learning.py:507] global step 42660: loss = 0.1063 (0.964 sec/step)\n",
      "I0902 09:37:15.912467 139792788920128 learning.py:507] global step 42661: loss = 0.1188 (0.957 sec/step)\n",
      "I0902 09:37:16.907708 139792788920128 learning.py:507] global step 42662: loss = 0.0895 (0.993 sec/step)\n",
      "I0902 09:37:17.872784 139792788920128 learning.py:507] global step 42663: loss = 0.2143 (0.963 sec/step)\n",
      "I0902 09:37:18.843758 139792788920128 learning.py:507] global step 42664: loss = 0.1194 (0.969 sec/step)\n",
      "I0902 09:37:19.822171 139792788920128 learning.py:507] global step 42665: loss = 0.0886 (0.977 sec/step)\n",
      "I0902 09:37:20.804496 139792788920128 learning.py:507] global step 42666: loss = 0.0941 (0.981 sec/step)\n",
      "I0902 09:37:21.789497 139792788920128 learning.py:507] global step 42667: loss = 0.0832 (0.983 sec/step)\n",
      "I0902 09:37:22.772934 139792788920128 learning.py:507] global step 42668: loss = 0.0772 (0.982 sec/step)\n",
      "I0902 09:37:23.773152 139792788920128 learning.py:507] global step 42669: loss = 0.0840 (0.998 sec/step)\n",
      "I0902 09:37:24.754892 139792788920128 learning.py:507] global step 42670: loss = 0.1216 (0.980 sec/step)\n",
      "I0902 09:37:25.750614 139792788920128 learning.py:507] global step 42671: loss = 0.1427 (0.994 sec/step)\n",
      "I0902 09:37:26.753957 139792788920128 learning.py:507] global step 42672: loss = 0.1274 (1.002 sec/step)\n",
      "I0902 09:37:27.723940 139792788920128 learning.py:507] global step 42673: loss = 0.1144 (0.968 sec/step)\n",
      "I0902 09:37:28.707864 139792788920128 learning.py:507] global step 42674: loss = 0.1374 (0.982 sec/step)\n",
      "I0902 09:37:29.687797 139792788920128 learning.py:507] global step 42675: loss = 0.1201 (0.978 sec/step)\n",
      "I0902 09:37:30.662585 139792788920128 learning.py:507] global step 42676: loss = 0.1795 (0.973 sec/step)\n",
      "I0902 09:37:31.669496 139792788920128 learning.py:507] global step 42677: loss = 0.0550 (1.005 sec/step)\n",
      "I0902 09:37:32.651909 139792788920128 learning.py:507] global step 42678: loss = 0.2468 (0.981 sec/step)\n",
      "I0902 09:37:33.644155 139792788920128 learning.py:507] global step 42679: loss = 0.0934 (0.991 sec/step)\n",
      "I0902 09:37:34.629670 139792788920128 learning.py:507] global step 42680: loss = 0.0640 (0.984 sec/step)\n",
      "I0902 09:37:35.603927 139792788920128 learning.py:507] global step 42681: loss = 0.1130 (0.973 sec/step)\n",
      "I0902 09:37:36.582168 139792788920128 learning.py:507] global step 42682: loss = 0.0795 (0.977 sec/step)\n",
      "I0902 09:37:37.557554 139792788920128 learning.py:507] global step 42683: loss = 0.1723 (0.974 sec/step)\n",
      "I0902 09:37:38.526241 139792788920128 learning.py:507] global step 42684: loss = 0.0676 (0.967 sec/step)\n",
      "I0902 09:37:39.505007 139792788920128 learning.py:507] global step 42685: loss = 0.0927 (0.977 sec/step)\n",
      "I0902 09:37:40.484807 139792788920128 learning.py:507] global step 42686: loss = 0.0776 (0.978 sec/step)\n",
      "I0902 09:37:41.458451 139792788920128 learning.py:507] global step 42687: loss = 0.0731 (0.972 sec/step)\n",
      "I0902 09:37:42.432868 139792788920128 learning.py:507] global step 42688: loss = 0.1408 (0.973 sec/step)\n",
      "I0902 09:37:43.394635 139792788920128 learning.py:507] global step 42689: loss = 0.0762 (0.960 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:37:44.338555 139792788920128 learning.py:507] global step 42690: loss = 0.0790 (0.942 sec/step)\n",
      "I0902 09:37:45.304599 139792788920128 learning.py:507] global step 42691: loss = 0.1486 (0.964 sec/step)\n",
      "I0902 09:37:46.282255 139792788920128 learning.py:507] global step 42692: loss = 0.1219 (0.976 sec/step)\n",
      "I0902 09:37:47.245249 139792788920128 learning.py:507] global step 42693: loss = 0.1896 (0.962 sec/step)\n",
      "I0902 09:37:48.194453 139792788920128 learning.py:507] global step 42694: loss = 0.0673 (0.948 sec/step)\n",
      "I0902 09:37:49.155076 139792788920128 learning.py:507] global step 42695: loss = 0.2645 (0.959 sec/step)\n",
      "I0902 09:37:50.293518 139792788920128 learning.py:507] global step 42696: loss = 0.1508 (1.136 sec/step)\n",
      "I0902 09:37:50.433539 139778936784640 supervisor.py:1050] Recording summary at step 42696.\n",
      "I0902 09:37:51.344223 139792788920128 learning.py:507] global step 42697: loss = 0.1217 (1.049 sec/step)\n",
      "I0902 09:37:52.335410 139792788920128 learning.py:507] global step 42698: loss = 0.0957 (0.990 sec/step)\n",
      "I0902 09:37:53.302430 139792788920128 learning.py:507] global step 42699: loss = 0.1550 (0.965 sec/step)\n",
      "I0902 09:37:54.285650 139792788920128 learning.py:507] global step 42700: loss = 0.0882 (0.982 sec/step)\n",
      "I0902 09:37:55.268953 139792788920128 learning.py:507] global step 42701: loss = 0.2068 (0.981 sec/step)\n",
      "I0902 09:37:56.250685 139792788920128 learning.py:507] global step 42702: loss = 0.1563 (0.980 sec/step)\n",
      "I0902 09:37:57.239124 139792788920128 learning.py:507] global step 42703: loss = 0.0981 (0.987 sec/step)\n",
      "I0902 09:37:58.250809 139792788920128 learning.py:507] global step 42704: loss = 0.2207 (1.010 sec/step)\n",
      "I0902 09:37:59.215077 139792788920128 learning.py:507] global step 42705: loss = 0.0837 (0.963 sec/step)\n",
      "I0902 09:38:00.189877 139792788920128 learning.py:507] global step 42706: loss = 0.1072 (0.973 sec/step)\n",
      "I0902 09:38:01.177770 139792788920128 learning.py:507] global step 42707: loss = 0.0984 (0.986 sec/step)\n",
      "I0902 09:38:02.165908 139792788920128 learning.py:507] global step 42708: loss = 0.1337 (0.986 sec/step)\n",
      "I0902 09:38:03.164562 139792788920128 learning.py:507] global step 42709: loss = 0.0681 (0.997 sec/step)\n",
      "I0902 09:38:04.155244 139792788920128 learning.py:507] global step 42710: loss = 0.1417 (0.989 sec/step)\n",
      "I0902 09:38:05.112593 139792788920128 learning.py:507] global step 42711: loss = 0.0616 (0.955 sec/step)\n",
      "I0902 09:38:06.088562 139792788920128 learning.py:507] global step 42712: loss = 0.1522 (0.974 sec/step)\n",
      "I0902 09:38:07.050934 139792788920128 learning.py:507] global step 42713: loss = 0.1177 (0.961 sec/step)\n",
      "I0902 09:38:08.031573 139792788920128 learning.py:507] global step 42714: loss = 0.1230 (0.979 sec/step)\n",
      "I0902 09:38:09.011232 139792788920128 learning.py:507] global step 42715: loss = 0.1209 (0.978 sec/step)\n",
      "I0902 09:38:09.998393 139792788920128 learning.py:507] global step 42716: loss = 0.1912 (0.986 sec/step)\n",
      "I0902 09:38:10.961642 139792788920128 learning.py:507] global step 42717: loss = 0.1888 (0.962 sec/step)\n",
      "I0902 09:38:11.945810 139792788920128 learning.py:507] global step 42718: loss = 0.1116 (0.983 sec/step)\n",
      "I0902 09:38:12.926787 139792788920128 learning.py:507] global step 42719: loss = 0.1135 (0.979 sec/step)\n",
      "I0902 09:38:13.898249 139792788920128 learning.py:507] global step 42720: loss = 0.1301 (0.970 sec/step)\n",
      "I0902 09:38:14.878416 139792788920128 learning.py:507] global step 42721: loss = 0.0918 (0.978 sec/step)\n",
      "I0902 09:38:15.829077 139792788920128 learning.py:507] global step 42722: loss = 0.2345 (0.949 sec/step)\n",
      "I0902 09:38:16.800947 139792788920128 learning.py:507] global step 42723: loss = 0.0888 (0.970 sec/step)\n",
      "I0902 09:38:17.788226 139792788920128 learning.py:507] global step 42724: loss = 0.1400 (0.985 sec/step)\n",
      "I0902 09:38:18.770631 139792788920128 learning.py:507] global step 42725: loss = 0.0658 (0.981 sec/step)\n",
      "I0902 09:38:19.760550 139792788920128 learning.py:507] global step 42726: loss = 0.0986 (0.988 sec/step)\n",
      "I0902 09:38:20.713441 139792788920128 learning.py:507] global step 42727: loss = 0.1257 (0.952 sec/step)\n",
      "I0902 09:38:21.689977 139792788920128 learning.py:507] global step 42728: loss = 0.1138 (0.975 sec/step)\n",
      "I0902 09:38:22.684766 139792788920128 learning.py:507] global step 42729: loss = 0.0465 (0.993 sec/step)\n",
      "I0902 09:38:23.661635 139792788920128 learning.py:507] global step 42730: loss = 0.1617 (0.975 sec/step)\n",
      "I0902 09:38:24.661829 139792788920128 learning.py:507] global step 42731: loss = 0.1638 (0.999 sec/step)\n",
      "I0902 09:38:25.642971 139792788920128 learning.py:507] global step 42732: loss = 0.0342 (0.979 sec/step)\n",
      "I0902 09:38:26.633507 139792788920128 learning.py:507] global step 42733: loss = 0.1264 (0.989 sec/step)\n",
      "I0902 09:38:27.600485 139792788920128 learning.py:507] global step 42734: loss = 0.0912 (0.966 sec/step)\n",
      "I0902 09:38:28.572936 139792788920128 learning.py:507] global step 42735: loss = 0.1527 (0.971 sec/step)\n",
      "I0902 09:38:29.544461 139792788920128 learning.py:507] global step 42736: loss = 0.0392 (0.970 sec/step)\n",
      "I0902 09:38:30.520457 139792788920128 learning.py:507] global step 42737: loss = 0.0619 (0.975 sec/step)\n",
      "I0902 09:38:31.481921 139792788920128 learning.py:507] global step 42738: loss = 0.0807 (0.960 sec/step)\n",
      "I0902 09:38:32.464527 139792788920128 learning.py:507] global step 42739: loss = 0.1713 (0.981 sec/step)\n",
      "I0902 09:38:33.440056 139792788920128 learning.py:507] global step 42740: loss = 0.2670 (0.974 sec/step)\n",
      "I0902 09:38:34.403840 139792788920128 learning.py:507] global step 42741: loss = 0.0948 (0.962 sec/step)\n",
      "I0902 09:38:35.368532 139792788920128 learning.py:507] global step 42742: loss = 0.2766 (0.963 sec/step)\n",
      "I0902 09:38:36.331952 139792788920128 learning.py:507] global step 42743: loss = 0.1002 (0.962 sec/step)\n",
      "I0902 09:38:37.296000 139792788920128 learning.py:507] global step 42744: loss = 0.3530 (0.962 sec/step)\n",
      "I0902 09:38:38.248358 139792788920128 learning.py:507] global step 42745: loss = 0.0885 (0.951 sec/step)\n",
      "I0902 09:38:39.210551 139792788920128 learning.py:507] global step 42746: loss = 0.1929 (0.961 sec/step)\n",
      "I0902 09:38:40.204257 139792788920128 learning.py:507] global step 42747: loss = 0.1730 (0.992 sec/step)\n",
      "I0902 09:38:41.173037 139792788920128 learning.py:507] global step 42748: loss = 0.1004 (0.967 sec/step)\n",
      "I0902 09:38:42.143926 139792788920128 learning.py:507] global step 42749: loss = 0.0946 (0.969 sec/step)\n",
      "I0902 09:38:43.097995 139792788920128 learning.py:507] global step 42750: loss = 0.1344 (0.952 sec/step)\n",
      "I0902 09:38:44.081117 139792788920128 learning.py:507] global step 42751: loss = 0.0777 (0.982 sec/step)\n",
      "I0902 09:38:45.044814 139792788920128 learning.py:507] global step 42752: loss = 0.0889 (0.962 sec/step)\n",
      "I0902 09:38:46.003918 139792788920128 learning.py:507] global step 42753: loss = 0.0947 (0.957 sec/step)\n",
      "I0902 09:38:46.961621 139792788920128 learning.py:507] global step 42754: loss = 0.1442 (0.956 sec/step)\n",
      "I0902 09:38:47.955404 139792788920128 learning.py:507] global step 42755: loss = 0.1066 (0.992 sec/step)\n",
      "I0902 09:38:48.939407 139792788920128 learning.py:507] global step 42756: loss = 0.1085 (0.982 sec/step)\n",
      "I0902 09:38:49.927210 139792788920128 learning.py:507] global step 42757: loss = 0.0949 (0.986 sec/step)\n",
      "I0902 09:38:50.939879 139792788920128 learning.py:507] global step 42758: loss = 0.1176 (1.011 sec/step)\n",
      "I0902 09:38:51.947547 139792788920128 learning.py:507] global step 42759: loss = 0.1388 (1.006 sec/step)\n",
      "I0902 09:38:52.930706 139792788920128 learning.py:507] global step 42760: loss = 0.1036 (0.981 sec/step)\n",
      "I0902 09:38:53.913583 139792788920128 learning.py:507] global step 42761: loss = 0.1115 (0.981 sec/step)\n",
      "I0902 09:38:54.886868 139792788920128 learning.py:507] global step 42762: loss = 0.1137 (0.971 sec/step)\n",
      "I0902 09:38:55.866386 139792788920128 learning.py:507] global step 42763: loss = 0.0566 (0.978 sec/step)\n",
      "I0902 09:38:56.856468 139792788920128 learning.py:507] global step 42764: loss = 0.2477 (0.988 sec/step)\n",
      "I0902 09:38:57.830381 139792788920128 learning.py:507] global step 42765: loss = 0.1336 (0.972 sec/step)\n",
      "I0902 09:38:58.794134 139792788920128 learning.py:507] global step 42766: loss = 0.0812 (0.962 sec/step)\n",
      "I0902 09:38:59.751607 139792788920128 learning.py:507] global step 42767: loss = 0.1045 (0.956 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:39:00.723418 139792788920128 learning.py:507] global step 42768: loss = 0.1690 (0.970 sec/step)\n",
      "I0902 09:39:01.689149 139792788920128 learning.py:507] global step 42769: loss = 0.0554 (0.964 sec/step)\n",
      "I0902 09:39:02.666033 139792788920128 learning.py:507] global step 42770: loss = 0.1753 (0.975 sec/step)\n",
      "I0902 09:39:03.648354 139792788920128 learning.py:507] global step 42771: loss = 0.1921 (0.981 sec/step)\n",
      "I0902 09:39:04.625659 139792788920128 learning.py:507] global step 42772: loss = 0.0930 (0.976 sec/step)\n",
      "I0902 09:39:05.601901 139792788920128 learning.py:507] global step 42773: loss = 0.2711 (0.975 sec/step)\n",
      "I0902 09:39:06.571856 139792788920128 learning.py:507] global step 42774: loss = 0.1440 (0.968 sec/step)\n",
      "I0902 09:39:07.539913 139792788920128 learning.py:507] global step 42775: loss = 0.1010 (0.966 sec/step)\n",
      "I0902 09:39:08.517306 139792788920128 learning.py:507] global step 42776: loss = 0.3330 (0.976 sec/step)\n",
      "I0902 09:39:09.490125 139792788920128 learning.py:507] global step 42777: loss = 0.0927 (0.971 sec/step)\n",
      "I0902 09:39:10.461048 139792788920128 learning.py:507] global step 42778: loss = 0.2387 (0.969 sec/step)\n",
      "I0902 09:39:11.439160 139792788920128 learning.py:507] global step 42779: loss = 0.1363 (0.976 sec/step)\n",
      "I0902 09:39:12.453756 139792788920128 learning.py:507] global step 42780: loss = 0.0657 (1.013 sec/step)\n",
      "I0902 09:39:13.424873 139792788920128 learning.py:507] global step 42781: loss = 0.1270 (0.969 sec/step)\n",
      "I0902 09:39:14.388539 139792788920128 learning.py:507] global step 42782: loss = 0.0891 (0.962 sec/step)\n",
      "I0902 09:39:15.376464 139792788920128 learning.py:507] global step 42783: loss = 0.0766 (0.986 sec/step)\n",
      "I0902 09:39:16.350184 139792788920128 learning.py:507] global step 42784: loss = 0.1434 (0.972 sec/step)\n",
      "I0902 09:39:17.324150 139792788920128 learning.py:507] global step 42785: loss = 0.1403 (0.972 sec/step)\n",
      "I0902 09:39:18.304543 139792788920128 learning.py:507] global step 42786: loss = 0.1137 (0.979 sec/step)\n",
      "I0902 09:39:19.265673 139792788920128 learning.py:507] global step 42787: loss = 0.0738 (0.959 sec/step)\n",
      "I0902 09:39:20.244117 139792788920128 learning.py:507] global step 42788: loss = 0.0951 (0.977 sec/step)\n",
      "I0902 09:39:21.221135 139792788920128 learning.py:507] global step 42789: loss = 0.1981 (0.975 sec/step)\n",
      "I0902 09:39:22.185089 139792788920128 learning.py:507] global step 42790: loss = 0.0700 (0.962 sec/step)\n",
      "I0902 09:39:23.164268 139792788920128 learning.py:507] global step 42791: loss = 0.1152 (0.978 sec/step)\n",
      "I0902 09:39:24.163046 139792788920128 learning.py:507] global step 42792: loss = 0.2322 (0.997 sec/step)\n",
      "I0902 09:39:25.114357 139792788920128 learning.py:507] global step 42793: loss = 0.1042 (0.950 sec/step)\n",
      "I0902 09:39:26.081485 139792788920128 learning.py:507] global step 42794: loss = 0.1115 (0.965 sec/step)\n",
      "I0902 09:39:27.044005 139792788920128 learning.py:507] global step 42795: loss = 0.1251 (0.961 sec/step)\n",
      "I0902 09:39:28.019189 139792788920128 learning.py:507] global step 42796: loss = 0.1129 (0.973 sec/step)\n",
      "I0902 09:39:29.019523 139792788920128 learning.py:507] global step 42797: loss = 0.1825 (0.999 sec/step)\n",
      "I0902 09:39:30.021879 139792788920128 learning.py:507] global step 42798: loss = 0.1138 (1.001 sec/step)\n",
      "I0902 09:39:31.004307 139792788920128 learning.py:507] global step 42799: loss = 0.1220 (0.981 sec/step)\n",
      "I0902 09:39:32.003697 139792788920128 learning.py:507] global step 42800: loss = 0.0800 (0.998 sec/step)\n",
      "I0902 09:39:32.992196 139792788920128 learning.py:507] global step 42801: loss = 0.0951 (0.987 sec/step)\n",
      "I0902 09:39:33.985532 139792788920128 learning.py:507] global step 42802: loss = 0.1143 (0.992 sec/step)\n",
      "I0902 09:39:34.986999 139792788920128 learning.py:507] global step 42803: loss = 0.5272 (1.000 sec/step)\n",
      "I0902 09:39:35.978944 139792788920128 learning.py:507] global step 42804: loss = 0.1253 (0.990 sec/step)\n",
      "I0902 09:39:36.961424 139792788920128 learning.py:507] global step 42805: loss = 0.0574 (0.981 sec/step)\n",
      "I0902 09:39:37.921922 139792788920128 learning.py:507] global step 42806: loss = 0.1325 (0.959 sec/step)\n",
      "I0902 09:39:38.880849 139792788920128 learning.py:507] global step 42807: loss = 0.0591 (0.957 sec/step)\n",
      "I0902 09:39:39.838207 139792788920128 learning.py:507] global step 42808: loss = 0.2206 (0.956 sec/step)\n",
      "I0902 09:39:40.804939 139792788920128 learning.py:507] global step 42809: loss = 0.2107 (0.965 sec/step)\n",
      "I0902 09:39:41.761618 139792788920128 learning.py:507] global step 42810: loss = 0.0657 (0.955 sec/step)\n",
      "I0902 09:39:42.732933 139792788920128 learning.py:507] global step 42811: loss = 0.0969 (0.970 sec/step)\n",
      "I0902 09:39:43.697391 139792788920128 learning.py:507] global step 42812: loss = 0.0858 (0.963 sec/step)\n",
      "I0902 09:39:44.663493 139792788920128 learning.py:507] global step 42813: loss = 0.0811 (0.964 sec/step)\n",
      "I0902 09:39:45.623104 139792788920128 learning.py:507] global step 42814: loss = 0.1156 (0.958 sec/step)\n",
      "I0902 09:39:46.613382 139792788920128 learning.py:507] global step 42815: loss = 0.0988 (0.989 sec/step)\n",
      "I0902 09:39:47.589270 139792788920128 learning.py:507] global step 42816: loss = 0.0782 (0.974 sec/step)\n",
      "I0902 09:39:48.567769 139792788920128 learning.py:507] global step 42817: loss = 0.1523 (0.977 sec/step)\n",
      "I0902 09:39:49.525753 139792788920128 learning.py:507] global step 42818: loss = 0.1471 (0.956 sec/step)\n",
      "I0902 09:39:50.156845 139778936784640 supervisor.py:1050] Recording summary at step 42818.\n",
      "I0902 09:39:50.765750 139792788920128 learning.py:507] global step 42819: loss = 0.0993 (1.237 sec/step)\n",
      "I0902 09:39:51.730506 139792788920128 learning.py:507] global step 42820: loss = 0.1147 (0.963 sec/step)\n",
      "I0902 09:39:52.699866 139792788920128 learning.py:507] global step 42821: loss = 0.1096 (0.968 sec/step)\n",
      "I0902 09:39:53.691334 139792788920128 learning.py:507] global step 42822: loss = 0.1076 (0.990 sec/step)\n",
      "I0902 09:39:54.652286 139792788920128 learning.py:507] global step 42823: loss = 0.0931 (0.959 sec/step)\n",
      "I0902 09:39:55.639347 139792788920128 learning.py:507] global step 42824: loss = 0.1048 (0.985 sec/step)\n",
      "I0902 09:39:56.637684 139792788920128 learning.py:507] global step 42825: loss = 0.0754 (0.997 sec/step)\n",
      "I0902 09:39:57.621762 139792788920128 learning.py:507] global step 42826: loss = 0.1300 (0.982 sec/step)\n",
      "I0902 09:39:58.599058 139792788920128 learning.py:507] global step 42827: loss = 0.1605 (0.976 sec/step)\n",
      "I0902 09:39:59.592512 139792788920128 learning.py:507] global step 42828: loss = 0.1036 (0.992 sec/step)\n",
      "I0902 09:40:00.573779 139792788920128 learning.py:507] global step 42829: loss = 0.2660 (0.980 sec/step)\n",
      "I0902 09:40:01.576170 139792788920128 learning.py:507] global step 42830: loss = 0.0628 (1.001 sec/step)\n",
      "I0902 09:40:02.564239 139792788920128 learning.py:507] global step 42831: loss = 0.1239 (0.986 sec/step)\n",
      "I0902 09:40:03.544841 139792788920128 learning.py:507] global step 42832: loss = 0.0738 (0.979 sec/step)\n",
      "I0902 09:40:04.517230 139792788920128 learning.py:507] global step 42833: loss = 0.2100 (0.971 sec/step)\n",
      "I0902 09:40:05.492259 139792788920128 learning.py:507] global step 42834: loss = 0.1953 (0.973 sec/step)\n",
      "I0902 09:40:06.474128 139792788920128 learning.py:507] global step 42835: loss = 0.2520 (0.980 sec/step)\n",
      "I0902 09:40:07.440872 139792788920128 learning.py:507] global step 42836: loss = 0.0594 (0.965 sec/step)\n",
      "I0902 09:40:08.413926 139792788920128 learning.py:507] global step 42837: loss = 0.1844 (0.971 sec/step)\n",
      "I0902 09:40:09.391843 139792788920128 learning.py:507] global step 42838: loss = 0.1772 (0.976 sec/step)\n",
      "I0902 09:40:10.385723 139792788920128 learning.py:507] global step 42839: loss = 0.2699 (0.992 sec/step)\n",
      "I0902 09:40:11.362350 139792788920128 learning.py:507] global step 42840: loss = 0.0570 (0.975 sec/step)\n",
      "I0902 09:40:12.346563 139792788920128 learning.py:507] global step 42841: loss = 0.1587 (0.983 sec/step)\n",
      "I0902 09:40:13.295065 139792788920128 learning.py:507] global step 42842: loss = 0.0928 (0.947 sec/step)\n",
      "I0902 09:40:14.317585 139792788920128 learning.py:507] global step 42843: loss = 0.1375 (1.021 sec/step)\n",
      "I0902 09:40:15.325142 139792788920128 learning.py:507] global step 42844: loss = 0.0966 (1.006 sec/step)\n",
      "I0902 09:40:16.322353 139792788920128 learning.py:507] global step 42845: loss = 0.2351 (0.996 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:40:17.312538 139792788920128 learning.py:507] global step 42846: loss = 0.1088 (0.989 sec/step)\n",
      "I0902 09:40:18.287126 139792788920128 learning.py:507] global step 42847: loss = 0.0509 (0.973 sec/step)\n",
      "I0902 09:40:19.267194 139792788920128 learning.py:507] global step 42848: loss = 0.0940 (0.978 sec/step)\n",
      "I0902 09:40:20.233079 139792788920128 learning.py:507] global step 42849: loss = 0.0925 (0.964 sec/step)\n",
      "I0902 09:40:21.173009 139792788920128 learning.py:507] global step 42850: loss = 0.0591 (0.938 sec/step)\n",
      "I0902 09:40:22.143734 139792788920128 learning.py:507] global step 42851: loss = 0.0471 (0.969 sec/step)\n",
      "I0902 09:40:23.108759 139792788920128 learning.py:507] global step 42852: loss = 0.1244 (0.963 sec/step)\n",
      "I0902 09:40:24.075312 139792788920128 learning.py:507] global step 42853: loss = 0.1490 (0.965 sec/step)\n",
      "I0902 09:40:25.051895 139792788920128 learning.py:507] global step 42854: loss = 0.0547 (0.975 sec/step)\n",
      "I0902 09:40:26.017048 139792788920128 learning.py:507] global step 42855: loss = 0.1097 (0.963 sec/step)\n",
      "I0902 09:40:26.979217 139792788920128 learning.py:507] global step 42856: loss = 0.2529 (0.960 sec/step)\n",
      "I0902 09:40:27.957715 139792788920128 learning.py:507] global step 42857: loss = 0.0811 (0.977 sec/step)\n",
      "I0902 09:40:28.923340 139792788920128 learning.py:507] global step 42858: loss = 0.1388 (0.964 sec/step)\n",
      "I0902 09:40:29.894408 139792788920128 learning.py:507] global step 42859: loss = 0.1437 (0.969 sec/step)\n",
      "I0902 09:40:30.859468 139792788920128 learning.py:507] global step 42860: loss = 0.0880 (0.964 sec/step)\n",
      "I0902 09:40:31.819925 139792788920128 learning.py:507] global step 42861: loss = 0.0822 (0.959 sec/step)\n",
      "I0902 09:40:32.802034 139792788920128 learning.py:507] global step 42862: loss = 0.0884 (0.981 sec/step)\n",
      "I0902 09:40:33.783870 139792788920128 learning.py:507] global step 42863: loss = 0.1316 (0.980 sec/step)\n",
      "I0902 09:40:34.747234 139792788920128 learning.py:507] global step 42864: loss = 0.0884 (0.962 sec/step)\n",
      "I0902 09:40:35.702508 139792788920128 learning.py:507] global step 42865: loss = 0.1197 (0.954 sec/step)\n",
      "I0902 09:40:36.686486 139792788920128 learning.py:507] global step 42866: loss = 0.1144 (0.982 sec/step)\n",
      "I0902 09:40:37.669072 139792788920128 learning.py:507] global step 42867: loss = 0.0392 (0.981 sec/step)\n",
      "I0902 09:40:38.657748 139792788920128 learning.py:507] global step 42868: loss = 0.1015 (0.987 sec/step)\n",
      "I0902 09:40:39.619383 139792788920128 learning.py:507] global step 42869: loss = 0.1699 (0.960 sec/step)\n",
      "I0902 09:40:40.588414 139792788920128 learning.py:507] global step 42870: loss = 0.0819 (0.967 sec/step)\n",
      "I0902 09:40:41.552675 139792788920128 learning.py:507] global step 42871: loss = 0.1138 (0.963 sec/step)\n",
      "I0902 09:40:42.529495 139792788920128 learning.py:507] global step 42872: loss = 0.0345 (0.975 sec/step)\n",
      "I0902 09:40:43.489417 139792788920128 learning.py:507] global step 42873: loss = 0.1146 (0.958 sec/step)\n",
      "I0902 09:40:44.456400 139792788920128 learning.py:507] global step 42874: loss = 0.1258 (0.966 sec/step)\n",
      "I0902 09:40:45.436983 139792788920128 learning.py:507] global step 42875: loss = 0.0809 (0.979 sec/step)\n",
      "I0902 09:40:46.406247 139792788920128 learning.py:507] global step 42876: loss = 0.0405 (0.968 sec/step)\n",
      "I0902 09:40:47.382042 139792788920128 learning.py:507] global step 42877: loss = 0.0628 (0.974 sec/step)\n",
      "I0902 09:40:48.358379 139792788920128 learning.py:507] global step 42878: loss = 0.1080 (0.975 sec/step)\n",
      "I0902 09:40:49.339673 139792788920128 learning.py:507] global step 42879: loss = 0.1347 (0.980 sec/step)\n",
      "I0902 09:40:50.295863 139792788920128 learning.py:507] global step 42880: loss = 0.1110 (0.954 sec/step)\n",
      "I0902 09:40:51.258511 139792788920128 learning.py:507] global step 42881: loss = 0.2107 (0.961 sec/step)\n",
      "I0902 09:40:52.237080 139792788920128 learning.py:507] global step 42882: loss = 0.1880 (0.977 sec/step)\n",
      "I0902 09:40:53.221626 139792788920128 learning.py:507] global step 42883: loss = 0.0742 (0.983 sec/step)\n",
      "I0902 09:40:54.199612 139792788920128 learning.py:507] global step 42884: loss = 0.0889 (0.976 sec/step)\n",
      "I0902 09:40:55.169413 139792788920128 learning.py:507] global step 42885: loss = 0.1238 (0.968 sec/step)\n",
      "I0902 09:40:56.145609 139792788920128 learning.py:507] global step 42886: loss = 0.1421 (0.975 sec/step)\n",
      "I0902 09:40:57.125758 139792788920128 learning.py:507] global step 42887: loss = 0.1024 (0.979 sec/step)\n",
      "I0902 09:40:58.092204 139792788920128 learning.py:507] global step 42888: loss = 0.0953 (0.965 sec/step)\n",
      "I0902 09:40:59.080787 139792788920128 learning.py:507] global step 42889: loss = 0.1171 (0.987 sec/step)\n",
      "I0902 09:41:00.038337 139792788920128 learning.py:507] global step 42890: loss = 0.1872 (0.956 sec/step)\n",
      "I0902 09:41:01.006328 139792788920128 learning.py:507] global step 42891: loss = 0.1317 (0.966 sec/step)\n",
      "I0902 09:41:01.984028 139792788920128 learning.py:507] global step 42892: loss = 0.1773 (0.976 sec/step)\n",
      "I0902 09:41:02.960333 139792788920128 learning.py:507] global step 42893: loss = 0.0661 (0.974 sec/step)\n",
      "I0902 09:41:03.913805 139792788920128 learning.py:507] global step 42894: loss = 0.1253 (0.952 sec/step)\n",
      "I0902 09:41:04.892607 139792788920128 learning.py:507] global step 42895: loss = 0.0851 (0.977 sec/step)\n",
      "I0902 09:41:05.878345 139792788920128 learning.py:507] global step 42896: loss = 0.0795 (0.984 sec/step)\n",
      "I0902 09:41:06.849725 139792788920128 learning.py:507] global step 42897: loss = 0.0910 (0.970 sec/step)\n",
      "I0902 09:41:07.832335 139792788920128 learning.py:507] global step 42898: loss = 0.1838 (0.981 sec/step)\n",
      "I0902 09:41:08.803404 139792788920128 learning.py:507] global step 42899: loss = 0.0688 (0.969 sec/step)\n",
      "I0902 09:41:09.788810 139792788920128 learning.py:507] global step 42900: loss = 0.1625 (0.984 sec/step)\n",
      "I0902 09:41:10.771778 139792788920128 learning.py:507] global step 42901: loss = 0.2306 (0.981 sec/step)\n",
      "I0902 09:41:11.754704 139792788920128 learning.py:507] global step 42902: loss = 0.0632 (0.981 sec/step)\n",
      "I0902 09:41:12.737736 139792788920128 learning.py:507] global step 42903: loss = 0.2881 (0.982 sec/step)\n",
      "I0902 09:41:13.709497 139792788920128 learning.py:507] global step 42904: loss = 0.1384 (0.970 sec/step)\n",
      "I0902 09:41:14.739502 139792788920128 learning.py:507] global step 42905: loss = 0.1309 (1.028 sec/step)\n",
      "I0902 09:41:15.726742 139792788920128 learning.py:507] global step 42906: loss = 0.2501 (0.986 sec/step)\n",
      "I0902 09:41:16.713501 139792788920128 learning.py:507] global step 42907: loss = 0.1336 (0.985 sec/step)\n",
      "I0902 09:41:17.680460 139792788920128 learning.py:507] global step 42908: loss = 0.1158 (0.965 sec/step)\n",
      "I0902 09:41:18.647593 139792788920128 learning.py:507] global step 42909: loss = 0.0635 (0.965 sec/step)\n",
      "I0902 09:41:19.639324 139792788920128 learning.py:507] global step 42910: loss = 0.2406 (0.990 sec/step)\n",
      "I0902 09:41:20.608166 139792788920128 learning.py:507] global step 42911: loss = 0.1902 (0.967 sec/step)\n",
      "I0902 09:41:21.578744 139792788920128 learning.py:507] global step 42912: loss = 0.1195 (0.969 sec/step)\n",
      "I0902 09:41:22.562834 139792788920128 learning.py:507] global step 42913: loss = 0.0909 (0.982 sec/step)\n",
      "I0902 09:41:23.526928 139792788920128 learning.py:507] global step 42914: loss = 0.0635 (0.962 sec/step)\n",
      "I0902 09:41:24.508903 139792788920128 learning.py:507] global step 42915: loss = 0.1632 (0.981 sec/step)\n",
      "I0902 09:41:25.498918 139792788920128 learning.py:507] global step 42916: loss = 0.1991 (0.988 sec/step)\n",
      "I0902 09:41:26.458906 139792788920128 learning.py:507] global step 42917: loss = 0.0727 (0.958 sec/step)\n",
      "I0902 09:41:27.413944 139792788920128 learning.py:507] global step 42918: loss = 0.0830 (0.953 sec/step)\n",
      "I0902 09:41:28.385508 139792788920128 learning.py:507] global step 42919: loss = 0.2027 (0.970 sec/step)\n",
      "I0902 09:41:29.366161 139792788920128 learning.py:507] global step 42920: loss = 0.0680 (0.979 sec/step)\n",
      "I0902 09:41:30.329098 139792788920128 learning.py:507] global step 42921: loss = 0.0924 (0.961 sec/step)\n",
      "I0902 09:41:31.296961 139792788920128 learning.py:507] global step 42922: loss = 0.2923 (0.966 sec/step)\n",
      "I0902 09:41:32.276306 139792788920128 learning.py:507] global step 42923: loss = 0.0764 (0.978 sec/step)\n",
      "I0902 09:41:33.230659 139792788920128 learning.py:507] global step 42924: loss = 0.0836 (0.953 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:41:34.194050 139792788920128 learning.py:507] global step 42925: loss = 0.1709 (0.962 sec/step)\n",
      "I0902 09:41:35.170402 139792788920128 learning.py:507] global step 42926: loss = 0.1883 (0.975 sec/step)\n",
      "I0902 09:41:36.127433 139792788920128 learning.py:507] global step 42927: loss = 0.0516 (0.955 sec/step)\n",
      "I0902 09:41:37.076889 139792788920128 learning.py:507] global step 42928: loss = 0.1857 (0.948 sec/step)\n",
      "I0902 09:41:38.063212 139792788920128 learning.py:507] global step 42929: loss = 0.1285 (0.985 sec/step)\n",
      "I0902 09:41:39.066796 139792788920128 learning.py:507] global step 42930: loss = 0.1356 (1.002 sec/step)\n",
      "I0902 09:41:40.085814 139792788920128 learning.py:507] global step 42931: loss = 0.1204 (1.017 sec/step)\n",
      "I0902 09:41:41.054360 139792788920128 learning.py:507] global step 42932: loss = 0.1221 (0.967 sec/step)\n",
      "I0902 09:41:42.060548 139792788920128 learning.py:507] global step 42933: loss = 0.0847 (1.004 sec/step)\n",
      "I0902 09:41:43.022573 139792788920128 learning.py:507] global step 42934: loss = 0.2935 (0.960 sec/step)\n",
      "I0902 09:41:43.974847 139792788920128 learning.py:507] global step 42935: loss = 0.1205 (0.951 sec/step)\n",
      "I0902 09:41:44.947775 139792788920128 learning.py:507] global step 42936: loss = 0.0890 (0.971 sec/step)\n",
      "I0902 09:41:45.901596 139792788920128 learning.py:507] global step 42937: loss = 0.1208 (0.952 sec/step)\n",
      "I0902 09:41:46.874845 139792788920128 learning.py:507] global step 42938: loss = 0.0863 (0.972 sec/step)\n",
      "I0902 09:41:47.835208 139792788920128 learning.py:507] global step 42939: loss = 0.1767 (0.959 sec/step)\n",
      "I0902 09:41:48.812175 139792788920128 learning.py:507] global step 42940: loss = 0.1359 (0.975 sec/step)\n",
      "I0902 09:41:49.931868 139792788920128 learning.py:507] global step 42941: loss = 0.0601 (1.115 sec/step)\n",
      "I0902 09:41:50.252989 139778936784640 supervisor.py:1050] Recording summary at step 42941.\n",
      "I0902 09:41:51.033886 139792788920128 learning.py:507] global step 42942: loss = 0.1115 (1.100 sec/step)\n",
      "I0902 09:41:52.014153 139792788920128 learning.py:507] global step 42943: loss = 0.0651 (0.979 sec/step)\n",
      "I0902 09:41:52.990414 139792788920128 learning.py:507] global step 42944: loss = 0.0685 (0.975 sec/step)\n",
      "I0902 09:41:53.973276 139792788920128 learning.py:507] global step 42945: loss = 0.1132 (0.981 sec/step)\n",
      "I0902 09:41:54.950007 139792788920128 learning.py:507] global step 42946: loss = 0.0573 (0.975 sec/step)\n",
      "I0902 09:41:55.910090 139792788920128 learning.py:507] global step 42947: loss = 0.1665 (0.959 sec/step)\n",
      "I0902 09:41:56.884763 139792788920128 learning.py:507] global step 42948: loss = 0.0925 (0.973 sec/step)\n",
      "I0902 09:41:57.851662 139792788920128 learning.py:507] global step 42949: loss = 0.2005 (0.965 sec/step)\n",
      "I0902 09:41:58.809489 139792788920128 learning.py:507] global step 42950: loss = 0.3131 (0.956 sec/step)\n",
      "I0902 09:41:59.783437 139792788920128 learning.py:507] global step 42951: loss = 0.0969 (0.972 sec/step)\n",
      "I0902 09:42:00.746131 139792788920128 learning.py:507] global step 42952: loss = 0.1732 (0.961 sec/step)\n",
      "I0902 09:42:01.728289 139792788920128 learning.py:507] global step 42953: loss = 0.1248 (0.981 sec/step)\n",
      "I0902 09:42:02.703002 139792788920128 learning.py:507] global step 42954: loss = 0.0776 (0.973 sec/step)\n",
      "I0902 09:42:03.671664 139792788920128 learning.py:507] global step 42955: loss = 0.0719 (0.967 sec/step)\n",
      "I0902 09:42:04.644986 139792788920128 learning.py:507] global step 42956: loss = 0.0661 (0.972 sec/step)\n",
      "I0902 09:42:05.631074 139792788920128 learning.py:507] global step 42957: loss = 0.1331 (0.984 sec/step)\n",
      "I0902 09:42:06.611518 139792788920128 learning.py:507] global step 42958: loss = 0.1651 (0.979 sec/step)\n",
      "I0902 09:42:07.594284 139792788920128 learning.py:507] global step 42959: loss = 0.1709 (0.981 sec/step)\n",
      "I0902 09:42:08.556969 139792788920128 learning.py:507] global step 42960: loss = 0.0571 (0.961 sec/step)\n",
      "I0902 09:42:09.514048 139792788920128 learning.py:507] global step 42961: loss = 0.0679 (0.956 sec/step)\n",
      "I0902 09:42:10.496051 139792788920128 learning.py:507] global step 42962: loss = 0.1148 (0.981 sec/step)\n",
      "I0902 09:42:11.458877 139792788920128 learning.py:507] global step 42963: loss = 0.2147 (0.961 sec/step)\n",
      "I0902 09:42:12.429350 139792788920128 learning.py:507] global step 42964: loss = 0.0422 (0.969 sec/step)\n",
      "I0902 09:42:13.382283 139792788920128 learning.py:507] global step 42965: loss = 0.0950 (0.951 sec/step)\n",
      "I0902 09:42:14.355650 139792788920128 learning.py:507] global step 42966: loss = 0.1735 (0.972 sec/step)\n",
      "I0902 09:42:15.345543 139792788920128 learning.py:507] global step 42967: loss = 0.0951 (0.988 sec/step)\n",
      "I0902 09:42:16.342978 139792788920128 learning.py:507] global step 42968: loss = 0.1672 (0.996 sec/step)\n",
      "I0902 09:42:17.341553 139792788920128 learning.py:507] global step 42969: loss = 0.0952 (0.997 sec/step)\n",
      "I0902 09:42:18.316201 139792788920128 learning.py:507] global step 42970: loss = 0.1832 (0.973 sec/step)\n",
      "I0902 09:42:19.280558 139792788920128 learning.py:507] global step 42971: loss = 0.0807 (0.963 sec/step)\n",
      "I0902 09:42:20.274481 139792788920128 learning.py:507] global step 42972: loss = 0.0939 (0.992 sec/step)\n",
      "I0902 09:42:21.241852 139792788920128 learning.py:507] global step 42973: loss = 0.1491 (0.966 sec/step)\n",
      "I0902 09:42:22.235109 139792788920128 learning.py:507] global step 42974: loss = 0.0941 (0.991 sec/step)\n",
      "I0902 09:42:23.217495 139792788920128 learning.py:507] global step 42975: loss = 0.1063 (0.981 sec/step)\n",
      "I0902 09:42:24.165013 139792788920128 learning.py:507] global step 42976: loss = 0.1268 (0.946 sec/step)\n",
      "I0902 09:42:25.126131 139792788920128 learning.py:507] global step 42977: loss = 0.1133 (0.960 sec/step)\n",
      "I0902 09:42:26.112581 139792788920128 learning.py:507] global step 42978: loss = 0.1444 (0.985 sec/step)\n",
      "I0902 09:42:27.088727 139792788920128 learning.py:507] global step 42979: loss = 0.0668 (0.974 sec/step)\n",
      "I0902 09:42:28.047717 139792788920128 learning.py:507] global step 42980: loss = 0.1211 (0.957 sec/step)\n",
      "I0902 09:42:29.061684 139792788920128 learning.py:507] global step 42981: loss = 0.1346 (1.012 sec/step)\n",
      "I0902 09:42:30.034477 139792788920128 learning.py:507] global step 42982: loss = 0.1083 (0.971 sec/step)\n",
      "I0902 09:42:31.015630 139792788920128 learning.py:507] global step 42983: loss = 0.1160 (0.979 sec/step)\n",
      "I0902 09:42:31.975769 139792788920128 learning.py:507] global step 42984: loss = 0.2242 (0.959 sec/step)\n",
      "I0902 09:42:32.949213 139792788920128 learning.py:507] global step 42985: loss = 0.0592 (0.972 sec/step)\n",
      "I0902 09:42:33.921260 139792788920128 learning.py:507] global step 42986: loss = 0.1753 (0.970 sec/step)\n",
      "I0902 09:42:34.899914 139792788920128 learning.py:507] global step 42987: loss = 0.2381 (0.977 sec/step)\n",
      "I0902 09:42:35.876051 139792788920128 learning.py:507] global step 42988: loss = 0.0714 (0.974 sec/step)\n",
      "I0902 09:42:36.853669 139792788920128 learning.py:507] global step 42989: loss = 0.1312 (0.976 sec/step)\n",
      "I0902 09:42:37.835800 139792788920128 learning.py:507] global step 42990: loss = 0.1702 (0.980 sec/step)\n",
      "I0902 09:42:38.800505 139792788920128 learning.py:507] global step 42991: loss = 0.1901 (0.963 sec/step)\n",
      "I0902 09:42:39.793711 139792788920128 learning.py:507] global step 42992: loss = 0.0833 (0.991 sec/step)\n",
      "I0902 09:42:40.772750 139792788920128 learning.py:507] global step 42993: loss = 0.0891 (0.977 sec/step)\n",
      "I0902 09:42:41.747613 139792788920128 learning.py:507] global step 42994: loss = 0.2141 (0.973 sec/step)\n",
      "I0902 09:42:42.723124 139792788920128 learning.py:507] global step 42995: loss = 0.0902 (0.974 sec/step)\n",
      "I0902 09:42:43.672201 139792788920128 learning.py:507] global step 42996: loss = 0.0829 (0.947 sec/step)\n",
      "I0902 09:42:44.622086 139792788920128 learning.py:507] global step 42997: loss = 0.0886 (0.948 sec/step)\n",
      "I0902 09:42:45.583792 139792788920128 learning.py:507] global step 42998: loss = 0.1042 (0.960 sec/step)\n",
      "I0902 09:42:46.555278 139792788920128 learning.py:507] global step 42999: loss = 0.1689 (0.970 sec/step)\n",
      "I0902 09:42:47.513742 139792788920128 learning.py:507] global step 43000: loss = 0.0682 (0.957 sec/step)\n",
      "I0902 09:42:48.484825 139792788920128 learning.py:507] global step 43001: loss = 0.1249 (0.970 sec/step)\n",
      "I0902 09:42:49.443433 139792788920128 learning.py:507] global step 43002: loss = 0.0695 (0.957 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:42:50.403565 139792788920128 learning.py:507] global step 43003: loss = 0.0959 (0.958 sec/step)\n",
      "I0902 09:42:51.392057 139792788920128 learning.py:507] global step 43004: loss = 0.1256 (0.987 sec/step)\n",
      "I0902 09:42:52.372348 139792788920128 learning.py:507] global step 43005: loss = 0.1293 (0.979 sec/step)\n",
      "I0902 09:42:53.347131 139792788920128 learning.py:507] global step 43006: loss = 0.1191 (0.973 sec/step)\n",
      "I0902 09:42:54.310744 139792788920128 learning.py:507] global step 43007: loss = 0.2233 (0.962 sec/step)\n",
      "I0902 09:42:55.290215 139792788920128 learning.py:507] global step 43008: loss = 0.1144 (0.978 sec/step)\n",
      "I0902 09:42:56.242948 139792788920128 learning.py:507] global step 43009: loss = 0.0497 (0.951 sec/step)\n",
      "I0902 09:42:57.221868 139792788920128 learning.py:507] global step 43010: loss = 0.1022 (0.978 sec/step)\n",
      "I0902 09:42:58.186013 139792788920128 learning.py:507] global step 43011: loss = 0.1582 (0.962 sec/step)\n",
      "I0902 09:42:59.150674 139792788920128 learning.py:507] global step 43012: loss = 0.1588 (0.963 sec/step)\n",
      "I0902 09:43:00.111502 139792788920128 learning.py:507] global step 43013: loss = 0.0570 (0.959 sec/step)\n",
      "I0902 09:43:01.071952 139792788920128 learning.py:507] global step 43014: loss = 0.1452 (0.959 sec/step)\n",
      "I0902 09:43:02.053519 139792788920128 learning.py:507] global step 43015: loss = 0.0633 (0.980 sec/step)\n",
      "I0902 09:43:03.041064 139792788920128 learning.py:507] global step 43016: loss = 0.1087 (0.986 sec/step)\n",
      "I0902 09:43:04.010991 139792788920128 learning.py:507] global step 43017: loss = 0.0773 (0.968 sec/step)\n",
      "I0902 09:43:05.002361 139792788920128 learning.py:507] global step 43018: loss = 0.1878 (0.990 sec/step)\n",
      "I0902 09:43:06.000194 139792788920128 learning.py:507] global step 43019: loss = 0.2655 (0.996 sec/step)\n",
      "I0902 09:43:06.970224 139792788920128 learning.py:507] global step 43020: loss = 0.0940 (0.968 sec/step)\n",
      "I0902 09:43:07.942331 139792788920128 learning.py:507] global step 43021: loss = 0.1242 (0.971 sec/step)\n",
      "I0902 09:43:08.934087 139792788920128 learning.py:507] global step 43022: loss = 0.0988 (0.990 sec/step)\n",
      "I0902 09:43:09.910799 139792788920128 learning.py:507] global step 43023: loss = 0.1224 (0.975 sec/step)\n",
      "I0902 09:43:10.896717 139792788920128 learning.py:507] global step 43024: loss = 0.0703 (0.984 sec/step)\n",
      "I0902 09:43:11.857211 139792788920128 learning.py:507] global step 43025: loss = 0.1239 (0.959 sec/step)\n",
      "I0902 09:43:12.837918 139792788920128 learning.py:507] global step 43026: loss = 0.0678 (0.979 sec/step)\n",
      "I0902 09:43:13.820457 139792788920128 learning.py:507] global step 43027: loss = 0.0654 (0.981 sec/step)\n",
      "I0902 09:43:14.819257 139792788920128 learning.py:507] global step 43028: loss = 0.0914 (0.997 sec/step)\n",
      "I0902 09:43:15.793480 139792788920128 learning.py:507] global step 43029: loss = 0.3038 (0.973 sec/step)\n",
      "I0902 09:43:16.778902 139792788920128 learning.py:507] global step 43030: loss = 0.2035 (0.984 sec/step)\n",
      "I0902 09:43:17.780858 139792788920128 learning.py:507] global step 43031: loss = 0.1533 (1.000 sec/step)\n",
      "I0902 09:43:18.774043 139792788920128 learning.py:507] global step 43032: loss = 0.1287 (0.991 sec/step)\n",
      "I0902 09:43:19.748269 139792788920128 learning.py:507] global step 43033: loss = 0.0514 (0.973 sec/step)\n",
      "I0902 09:43:20.720830 139792788920128 learning.py:507] global step 43034: loss = 0.0930 (0.971 sec/step)\n",
      "I0902 09:43:21.712804 139792788920128 learning.py:507] global step 43035: loss = 0.1499 (0.990 sec/step)\n",
      "I0902 09:43:22.702149 139792788920128 learning.py:507] global step 43036: loss = 0.0957 (0.988 sec/step)\n",
      "I0902 09:43:23.708281 139792788920128 learning.py:507] global step 43037: loss = 0.1889 (1.005 sec/step)\n",
      "I0902 09:43:24.669075 139792788920128 learning.py:507] global step 43038: loss = 0.1123 (0.959 sec/step)\n",
      "I0902 09:43:25.626384 139792788920128 learning.py:507] global step 43039: loss = 0.0738 (0.956 sec/step)\n",
      "I0902 09:43:26.610168 139792788920128 learning.py:507] global step 43040: loss = 0.1347 (0.982 sec/step)\n",
      "I0902 09:43:27.588553 139792788920128 learning.py:507] global step 43041: loss = 0.0471 (0.977 sec/step)\n",
      "I0902 09:43:28.547562 139792788920128 learning.py:507] global step 43042: loss = 0.2859 (0.958 sec/step)\n",
      "I0902 09:43:29.496863 139792788920128 learning.py:507] global step 43043: loss = 0.1615 (0.948 sec/step)\n",
      "I0902 09:43:30.483135 139792788920128 learning.py:507] global step 43044: loss = 0.2643 (0.985 sec/step)\n",
      "I0902 09:43:31.461148 139792788920128 learning.py:507] global step 43045: loss = 0.1510 (0.976 sec/step)\n",
      "I0902 09:43:32.449017 139792788920128 learning.py:507] global step 43046: loss = 0.1089 (0.986 sec/step)\n",
      "I0902 09:43:33.429375 139792788920128 learning.py:507] global step 43047: loss = 0.1924 (0.979 sec/step)\n",
      "I0902 09:43:34.428027 139792788920128 learning.py:507] global step 43048: loss = 0.0921 (0.997 sec/step)\n",
      "I0902 09:43:35.425178 139792788920128 learning.py:507] global step 43049: loss = 0.0812 (0.995 sec/step)\n",
      "I0902 09:43:36.411232 139792788920128 learning.py:507] global step 43050: loss = 0.0807 (0.984 sec/step)\n",
      "I0902 09:43:37.382983 139792788920128 learning.py:507] global step 43051: loss = 0.0435 (0.970 sec/step)\n",
      "I0902 09:43:38.372678 139792788920128 learning.py:507] global step 43052: loss = 0.1148 (0.988 sec/step)\n",
      "I0902 09:43:39.345856 139792788920128 learning.py:507] global step 43053: loss = 0.1130 (0.972 sec/step)\n",
      "I0902 09:43:40.323453 139792788920128 learning.py:507] global step 43054: loss = 0.0883 (0.976 sec/step)\n",
      "I0902 09:43:41.311050 139792788920128 learning.py:507] global step 43055: loss = 0.0758 (0.986 sec/step)\n",
      "I0902 09:43:42.287585 139792788920128 learning.py:507] global step 43056: loss = 0.2353 (0.975 sec/step)\n",
      "I0902 09:43:43.274417 139792788920128 learning.py:507] global step 43057: loss = 0.1094 (0.985 sec/step)\n",
      "I0902 09:43:44.248416 139792788920128 learning.py:507] global step 43058: loss = 0.1440 (0.973 sec/step)\n",
      "I0902 09:43:45.239844 139792788920128 learning.py:507] global step 43059: loss = 0.1175 (0.990 sec/step)\n",
      "I0902 09:43:46.197444 139792788920128 learning.py:507] global step 43060: loss = 0.1004 (0.956 sec/step)\n",
      "I0902 09:43:47.176068 139792788920128 learning.py:507] global step 43061: loss = 0.1451 (0.977 sec/step)\n",
      "I0902 09:43:48.129621 139792788920128 learning.py:507] global step 43062: loss = 0.2351 (0.952 sec/step)\n",
      "I0902 09:43:49.102618 139792788920128 learning.py:507] global step 43063: loss = 0.3080 (0.971 sec/step)\n",
      "I0902 09:43:49.270352 139778953570048 supervisor.py:1117] Saving checkpoint to path data_dir/mixed_experiment/checkpoints_v2/model.ckpt\n",
      "I0902 09:43:50.432895 139792788920128 learning.py:507] global step 43064: loss = 0.0675 (1.234 sec/step)\n",
      "I0902 09:43:50.433386 139778936784640 supervisor.py:1050] Recording summary at step 43064.\n",
      "I0902 09:43:51.514725 139792788920128 learning.py:507] global step 43065: loss = 0.1923 (0.990 sec/step)\n",
      "I0902 09:43:52.521583 139792788920128 learning.py:507] global step 43066: loss = 0.1250 (1.005 sec/step)\n",
      "I0902 09:43:53.516978 139792788920128 learning.py:507] global step 43067: loss = 0.1516 (0.994 sec/step)\n",
      "I0902 09:43:54.472528 139792788920128 learning.py:507] global step 43068: loss = 0.1269 (0.954 sec/step)\n",
      "I0902 09:43:55.443946 139792788920128 learning.py:507] global step 43069: loss = 0.1056 (0.970 sec/step)\n",
      "I0902 09:43:56.416990 139792788920128 learning.py:507] global step 43070: loss = 0.1261 (0.971 sec/step)\n",
      "I0902 09:43:57.415424 139792788920128 learning.py:507] global step 43071: loss = 0.1203 (0.997 sec/step)\n",
      "I0902 09:43:58.388325 139792788920128 learning.py:507] global step 43072: loss = 0.1341 (0.971 sec/step)\n",
      "I0902 09:43:59.374011 139792788920128 learning.py:507] global step 43073: loss = 0.1114 (0.984 sec/step)\n",
      "I0902 09:44:00.350779 139792788920128 learning.py:507] global step 43074: loss = 0.2442 (0.975 sec/step)\n",
      "I0902 09:44:01.303795 139792788920128 learning.py:507] global step 43075: loss = 0.1132 (0.951 sec/step)\n",
      "I0902 09:44:02.286187 139792788920128 learning.py:507] global step 43076: loss = 0.1539 (0.981 sec/step)\n",
      "I0902 09:44:03.253564 139792788920128 learning.py:507] global step 43077: loss = 0.1697 (0.966 sec/step)\n",
      "I0902 09:44:04.205783 139792788920128 learning.py:507] global step 43078: loss = 0.0911 (0.951 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:44:05.168243 139792788920128 learning.py:507] global step 43079: loss = 0.0602 (0.961 sec/step)\n",
      "I0902 09:44:06.138952 139792788920128 learning.py:507] global step 43080: loss = 0.0542 (0.969 sec/step)\n",
      "I0902 09:44:07.132221 139792788920128 learning.py:507] global step 43081: loss = 0.1073 (0.992 sec/step)\n",
      "I0902 09:44:08.105818 139792788920128 learning.py:507] global step 43082: loss = 0.1250 (0.972 sec/step)\n",
      "I0902 09:44:09.070522 139792788920128 learning.py:507] global step 43083: loss = 0.1556 (0.963 sec/step)\n",
      "I0902 09:44:10.043119 139792788920128 learning.py:507] global step 43084: loss = 0.0931 (0.971 sec/step)\n",
      "I0902 09:44:11.016404 139792788920128 learning.py:507] global step 43085: loss = 0.1890 (0.972 sec/step)\n",
      "I0902 09:44:11.988052 139792788920128 learning.py:507] global step 43086: loss = 0.1578 (0.970 sec/step)\n",
      "I0902 09:44:12.945919 139792788920128 learning.py:507] global step 43087: loss = 0.0810 (0.956 sec/step)\n",
      "I0902 09:44:13.932322 139792788920128 learning.py:507] global step 43088: loss = 0.0868 (0.985 sec/step)\n",
      "I0902 09:44:14.903485 139792788920128 learning.py:507] global step 43089: loss = 0.1217 (0.970 sec/step)\n",
      "I0902 09:44:15.879493 139792788920128 learning.py:507] global step 43090: loss = 0.1282 (0.974 sec/step)\n",
      "I0902 09:44:16.877879 139792788920128 learning.py:507] global step 43091: loss = 0.1513 (0.997 sec/step)\n",
      "I0902 09:44:17.840407 139792788920128 learning.py:507] global step 43092: loss = 0.1403 (0.961 sec/step)\n",
      "I0902 09:44:18.803969 139792788920128 learning.py:507] global step 43093: loss = 0.1141 (0.962 sec/step)\n",
      "I0902 09:44:19.767225 139792788920128 learning.py:507] global step 43094: loss = 0.1820 (0.961 sec/step)\n",
      "I0902 09:44:20.735838 139792788920128 learning.py:507] global step 43095: loss = 0.1660 (0.967 sec/step)\n",
      "I0902 09:44:21.717075 139792788920128 learning.py:507] global step 43096: loss = 0.0924 (0.980 sec/step)\n",
      "I0902 09:44:22.689967 139792788920128 learning.py:507] global step 43097: loss = 0.1613 (0.971 sec/step)\n",
      "I0902 09:44:23.666353 139792788920128 learning.py:507] global step 43098: loss = 0.0728 (0.975 sec/step)\n",
      "I0902 09:44:24.647570 139792788920128 learning.py:507] global step 43099: loss = 0.0628 (0.980 sec/step)\n",
      "I0902 09:44:25.610491 139792788920128 learning.py:507] global step 43100: loss = 0.1551 (0.961 sec/step)\n",
      "I0902 09:44:26.567055 139792788920128 learning.py:507] global step 43101: loss = 0.1197 (0.955 sec/step)\n",
      "I0902 09:44:27.547502 139792788920128 learning.py:507] global step 43102: loss = 0.0902 (0.979 sec/step)\n",
      "I0902 09:44:28.515615 139792788920128 learning.py:507] global step 43103: loss = 0.1999 (0.966 sec/step)\n",
      "I0902 09:44:29.483312 139792788920128 learning.py:507] global step 43104: loss = 0.2334 (0.966 sec/step)\n",
      "I0902 09:44:30.439968 139792788920128 learning.py:507] global step 43105: loss = 0.0984 (0.955 sec/step)\n",
      "I0902 09:44:31.406146 139792788920128 learning.py:507] global step 43106: loss = 0.0893 (0.964 sec/step)\n",
      "I0902 09:44:32.364221 139792788920128 learning.py:507] global step 43107: loss = 0.1177 (0.956 sec/step)\n",
      "I0902 09:44:33.334466 139792788920128 learning.py:507] global step 43108: loss = 0.1017 (0.968 sec/step)\n",
      "I0902 09:44:34.291408 139792788920128 learning.py:507] global step 43109: loss = 0.1191 (0.955 sec/step)\n",
      "I0902 09:44:35.246548 139792788920128 learning.py:507] global step 43110: loss = 0.0685 (0.954 sec/step)\n",
      "I0902 09:44:36.221526 139792788920128 learning.py:507] global step 43111: loss = 0.0724 (0.973 sec/step)\n",
      "I0902 09:44:37.203753 139792788920128 learning.py:507] global step 43112: loss = 0.1131 (0.981 sec/step)\n",
      "I0902 09:44:38.159517 139792788920128 learning.py:507] global step 43113: loss = 0.1271 (0.954 sec/step)\n",
      "I0902 09:44:39.122924 139792788920128 learning.py:507] global step 43114: loss = 0.1148 (0.962 sec/step)\n",
      "I0902 09:44:40.098664 139792788920128 learning.py:507] global step 43115: loss = 0.0899 (0.974 sec/step)\n",
      "I0902 09:44:41.071195 139792788920128 learning.py:507] global step 43116: loss = 0.0867 (0.971 sec/step)\n",
      "I0902 09:44:42.013143 139792788920128 learning.py:507] global step 43117: loss = 0.1731 (0.940 sec/step)\n",
      "I0902 09:44:42.996636 139792788920128 learning.py:507] global step 43118: loss = 0.0777 (0.982 sec/step)\n",
      "I0902 09:44:43.978781 139792788920128 learning.py:507] global step 43119: loss = 0.1140 (0.980 sec/step)\n",
      "I0902 09:44:44.936070 139792788920128 learning.py:507] global step 43120: loss = 0.0826 (0.956 sec/step)\n",
      "I0902 09:44:45.888191 139792788920128 learning.py:507] global step 43121: loss = 0.3874 (0.951 sec/step)\n",
      "I0902 09:44:46.886751 139792788920128 learning.py:507] global step 43122: loss = 0.1256 (0.997 sec/step)\n",
      "I0902 09:44:47.875138 139792788920128 learning.py:507] global step 43123: loss = 0.0913 (0.987 sec/step)\n",
      "I0902 09:44:48.866760 139792788920128 learning.py:507] global step 43124: loss = 0.1363 (0.990 sec/step)\n",
      "I0902 09:44:49.831693 139792788920128 learning.py:507] global step 43125: loss = 0.1641 (0.963 sec/step)\n",
      "I0902 09:44:50.814551 139792788920128 learning.py:507] global step 43126: loss = 0.0578 (0.981 sec/step)\n",
      "I0902 09:44:51.789520 139792788920128 learning.py:507] global step 43127: loss = 0.2395 (0.974 sec/step)\n",
      "I0902 09:44:52.790462 139792788920128 learning.py:507] global step 43128: loss = 0.0603 (0.999 sec/step)\n",
      "I0902 09:44:53.767799 139792788920128 learning.py:507] global step 43129: loss = 0.0751 (0.976 sec/step)\n",
      "I0902 09:44:54.743899 139792788920128 learning.py:507] global step 43130: loss = 0.1621 (0.975 sec/step)\n",
      "I0902 09:44:55.714139 139792788920128 learning.py:507] global step 43131: loss = 0.2650 (0.968 sec/step)\n",
      "I0902 09:44:56.696794 139792788920128 learning.py:507] global step 43132: loss = 0.1195 (0.981 sec/step)\n",
      "I0902 09:44:57.665496 139792788920128 learning.py:507] global step 43133: loss = 0.0939 (0.967 sec/step)\n",
      "I0902 09:44:58.640979 139792788920128 learning.py:507] global step 43134: loss = 0.0848 (0.974 sec/step)\n",
      "I0902 09:44:59.618784 139792788920128 learning.py:507] global step 43135: loss = 0.1012 (0.976 sec/step)\n",
      "I0902 09:45:00.576034 139792788920128 learning.py:507] global step 43136: loss = 0.1559 (0.956 sec/step)\n",
      "I0902 09:45:01.551204 139792788920128 learning.py:507] global step 43137: loss = 0.0973 (0.973 sec/step)\n",
      "I0902 09:45:02.521178 139792788920128 learning.py:507] global step 43138: loss = 0.0930 (0.968 sec/step)\n",
      "I0902 09:45:03.506225 139792788920128 learning.py:507] global step 43139: loss = 0.1050 (0.983 sec/step)\n",
      "I0902 09:45:04.487208 139792788920128 learning.py:507] global step 43140: loss = 0.2066 (0.979 sec/step)\n",
      "I0902 09:45:05.478649 139792788920128 learning.py:507] global step 43141: loss = 0.0607 (0.990 sec/step)\n",
      "I0902 09:45:06.436888 139792788920128 learning.py:507] global step 43142: loss = 0.1231 (0.956 sec/step)\n",
      "I0902 09:45:07.421345 139792788920128 learning.py:507] global step 43143: loss = 0.0773 (0.983 sec/step)\n",
      "I0902 09:45:08.387098 139792788920128 learning.py:507] global step 43144: loss = 0.1662 (0.964 sec/step)\n",
      "I0902 09:45:09.338502 139792788920128 learning.py:507] global step 43145: loss = 0.1009 (0.950 sec/step)\n",
      "I0902 09:45:10.295396 139792788920128 learning.py:507] global step 43146: loss = 0.1871 (0.955 sec/step)\n",
      "I0902 09:45:11.281231 139792788920128 learning.py:507] global step 43147: loss = 0.0778 (0.984 sec/step)\n",
      "I0902 09:45:12.233742 139792788920128 learning.py:507] global step 43148: loss = 0.1206 (0.951 sec/step)\n",
      "I0902 09:45:13.200700 139792788920128 learning.py:507] global step 43149: loss = 0.1007 (0.965 sec/step)\n",
      "I0902 09:45:14.167478 139792788920128 learning.py:507] global step 43150: loss = 0.0892 (0.965 sec/step)\n",
      "I0902 09:45:15.138331 139792788920128 learning.py:507] global step 43151: loss = 0.0622 (0.969 sec/step)\n",
      "I0902 09:45:16.117799 139792788920128 learning.py:507] global step 43152: loss = 0.1481 (0.978 sec/step)\n",
      "I0902 09:45:17.096598 139792788920128 learning.py:507] global step 43153: loss = 0.1749 (0.977 sec/step)\n",
      "I0902 09:45:18.054996 139792788920128 learning.py:507] global step 43154: loss = 0.2166 (0.957 sec/step)\n",
      "I0902 09:45:19.062124 139792788920128 learning.py:507] global step 43155: loss = 0.1075 (1.005 sec/step)\n",
      "I0902 09:45:20.023778 139792788920128 learning.py:507] global step 43156: loss = 0.1455 (0.960 sec/step)\n",
      "I0902 09:45:21.006421 139792788920128 learning.py:507] global step 43157: loss = 0.1190 (0.981 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:45:21.976490 139792788920128 learning.py:507] global step 43158: loss = 0.0660 (0.968 sec/step)\n",
      "I0902 09:45:22.955820 139792788920128 learning.py:507] global step 43159: loss = 0.2301 (0.978 sec/step)\n",
      "I0902 09:45:23.923324 139792788920128 learning.py:507] global step 43160: loss = 0.1238 (0.966 sec/step)\n",
      "I0902 09:45:24.879151 139792788920128 learning.py:507] global step 43161: loss = 0.1900 (0.954 sec/step)\n",
      "I0902 09:45:25.829722 139792788920128 learning.py:507] global step 43162: loss = 0.1033 (0.949 sec/step)\n",
      "I0902 09:45:26.793155 139792788920128 learning.py:507] global step 43163: loss = 0.0988 (0.962 sec/step)\n",
      "I0902 09:45:27.769615 139792788920128 learning.py:507] global step 43164: loss = 0.1738 (0.975 sec/step)\n",
      "I0902 09:45:28.744485 139792788920128 learning.py:507] global step 43165: loss = 0.0960 (0.973 sec/step)\n",
      "I0902 09:45:29.706764 139792788920128 learning.py:507] global step 43166: loss = 0.2027 (0.961 sec/step)\n",
      "I0902 09:45:30.713654 139792788920128 learning.py:507] global step 43167: loss = 0.0717 (1.005 sec/step)\n",
      "I0902 09:45:31.714995 139792788920128 learning.py:507] global step 43168: loss = 0.0641 (1.000 sec/step)\n",
      "I0902 09:45:32.684415 139792788920128 learning.py:507] global step 43169: loss = 0.1083 (0.968 sec/step)\n",
      "I0902 09:45:33.673565 139792788920128 learning.py:507] global step 43170: loss = 0.1219 (0.988 sec/step)\n",
      "I0902 09:45:34.634253 139792788920128 learning.py:507] global step 43171: loss = 0.1076 (0.959 sec/step)\n",
      "I0902 09:45:35.632947 139792788920128 learning.py:507] global step 43172: loss = 0.0662 (0.997 sec/step)\n",
      "I0902 09:45:36.606357 139792788920128 learning.py:507] global step 43173: loss = 0.1036 (0.972 sec/step)\n",
      "I0902 09:45:37.564368 139792788920128 learning.py:507] global step 43174: loss = 0.1619 (0.956 sec/step)\n",
      "I0902 09:45:38.533653 139792788920128 learning.py:507] global step 43175: loss = 0.0650 (0.968 sec/step)\n",
      "I0902 09:45:39.499761 139792788920128 learning.py:507] global step 43176: loss = 0.1131 (0.965 sec/step)\n",
      "I0902 09:45:40.470594 139792788920128 learning.py:507] global step 43177: loss = 0.0983 (0.969 sec/step)\n",
      "I0902 09:45:41.431741 139792788920128 learning.py:507] global step 43178: loss = 0.0770 (0.959 sec/step)\n",
      "I0902 09:45:42.396027 139792788920128 learning.py:507] global step 43179: loss = 0.1511 (0.962 sec/step)\n",
      "I0902 09:45:43.375159 139792788920128 learning.py:507] global step 43180: loss = 0.0599 (0.977 sec/step)\n",
      "I0902 09:45:44.349129 139792788920128 learning.py:507] global step 43181: loss = 0.0997 (0.972 sec/step)\n",
      "I0902 09:45:45.299494 139792788920128 learning.py:507] global step 43182: loss = 0.1374 (0.949 sec/step)\n",
      "I0902 09:45:46.270277 139792788920128 learning.py:507] global step 43183: loss = 0.3468 (0.969 sec/step)\n",
      "I0902 09:45:47.246737 139792788920128 learning.py:507] global step 43184: loss = 0.1331 (0.975 sec/step)\n",
      "I0902 09:45:48.202510 139792788920128 learning.py:507] global step 43185: loss = 0.0682 (0.954 sec/step)\n",
      "I0902 09:45:49.156002 139792788920128 learning.py:507] global step 43186: loss = 0.1256 (0.952 sec/step)\n",
      "I0902 09:45:50.261006 139792788920128 learning.py:507] global step 43187: loss = 0.1615 (1.102 sec/step)\n",
      "I0902 09:45:50.440925 139778936784640 supervisor.py:1050] Recording summary at step 43187.\n",
      "I0902 09:45:51.317507 139792788920128 learning.py:507] global step 43188: loss = 0.1839 (1.054 sec/step)\n",
      "I0902 09:45:52.291686 139792788920128 learning.py:507] global step 43189: loss = 0.1918 (0.973 sec/step)\n",
      "I0902 09:45:53.251979 139792788920128 learning.py:507] global step 43190: loss = 0.2775 (0.959 sec/step)\n",
      "I0902 09:45:54.212273 139792788920128 learning.py:507] global step 43191: loss = 0.0457 (0.959 sec/step)\n",
      "I0902 09:45:55.174066 139792788920128 learning.py:507] global step 43192: loss = 0.0490 (0.960 sec/step)\n",
      "I0902 09:45:56.139990 139792788920128 learning.py:507] global step 43193: loss = 0.1228 (0.964 sec/step)\n",
      "I0902 09:45:57.107741 139792788920128 learning.py:507] global step 43194: loss = 0.0725 (0.966 sec/step)\n",
      "I0902 09:45:58.066647 139792788920128 learning.py:507] global step 43195: loss = 0.0523 (0.957 sec/step)\n",
      "I0902 09:45:59.037610 139792788920128 learning.py:507] global step 43196: loss = 0.0776 (0.969 sec/step)\n",
      "I0902 09:46:00.006231 139792788920128 learning.py:507] global step 43197: loss = 0.1435 (0.967 sec/step)\n",
      "I0902 09:46:00.956159 139792788920128 learning.py:507] global step 43198: loss = 0.0775 (0.948 sec/step)\n",
      "I0902 09:46:01.952069 139792788920128 learning.py:507] global step 43199: loss = 0.1545 (0.994 sec/step)\n",
      "I0902 09:46:02.923474 139792788920128 learning.py:507] global step 43200: loss = 0.1260 (0.970 sec/step)\n",
      "I0902 09:46:03.889760 139792788920128 learning.py:507] global step 43201: loss = 0.0965 (0.965 sec/step)\n",
      "I0902 09:46:04.849244 139792788920128 learning.py:507] global step 43202: loss = 0.1155 (0.958 sec/step)\n",
      "I0902 09:46:05.800845 139792788920128 learning.py:507] global step 43203: loss = 0.2830 (0.950 sec/step)\n",
      "I0902 09:46:06.802339 139792788920128 learning.py:507] global step 43204: loss = 0.1428 (1.000 sec/step)\n",
      "I0902 09:46:07.762153 139792788920128 learning.py:507] global step 43205: loss = 0.0858 (0.958 sec/step)\n",
      "I0902 09:46:08.730193 139792788920128 learning.py:507] global step 43206: loss = 0.1961 (0.966 sec/step)\n",
      "I0902 09:46:09.684631 139792788920128 learning.py:507] global step 43207: loss = 0.0793 (0.953 sec/step)\n",
      "I0902 09:46:10.681088 139792788920128 learning.py:507] global step 43208: loss = 0.1911 (0.995 sec/step)\n",
      "I0902 09:46:11.670321 139792788920128 learning.py:507] global step 43209: loss = 0.1986 (0.988 sec/step)\n",
      "I0902 09:46:12.632910 139792788920128 learning.py:507] global step 43210: loss = 0.0893 (0.961 sec/step)\n",
      "I0902 09:46:13.588586 139792788920128 learning.py:507] global step 43211: loss = 0.5723 (0.954 sec/step)\n",
      "I0902 09:46:14.557057 139792788920128 learning.py:507] global step 43212: loss = 0.1201 (0.967 sec/step)\n",
      "I0902 09:46:15.547147 139792788920128 learning.py:507] global step 43213: loss = 0.1104 (0.989 sec/step)\n",
      "I0902 09:46:16.502577 139792788920128 learning.py:507] global step 43214: loss = 0.0951 (0.954 sec/step)\n",
      "I0902 09:46:17.460525 139792788920128 learning.py:507] global step 43215: loss = 0.1286 (0.956 sec/step)\n",
      "I0902 09:46:18.433197 139792788920128 learning.py:507] global step 43216: loss = 0.0729 (0.971 sec/step)\n",
      "I0902 09:46:19.422076 139792788920128 learning.py:507] global step 43217: loss = 0.0716 (0.987 sec/step)\n",
      "I0902 09:46:20.386322 139792788920128 learning.py:507] global step 43218: loss = 0.1347 (0.963 sec/step)\n",
      "I0902 09:46:21.375148 139792788920128 learning.py:507] global step 43219: loss = 0.0960 (0.987 sec/step)\n",
      "I0902 09:46:22.367184 139792788920128 learning.py:507] global step 43220: loss = 0.1581 (0.990 sec/step)\n",
      "I0902 09:46:23.345400 139792788920128 learning.py:507] global step 43221: loss = 0.1028 (0.977 sec/step)\n",
      "I0902 09:46:24.316912 139792788920128 learning.py:507] global step 43222: loss = 0.0922 (0.970 sec/step)\n",
      "I0902 09:46:25.266683 139792788920128 learning.py:507] global step 43223: loss = 0.1732 (0.948 sec/step)\n",
      "I0902 09:46:26.246467 139792788920128 learning.py:507] global step 43224: loss = 0.1326 (0.978 sec/step)\n",
      "I0902 09:46:27.253537 139792788920128 learning.py:507] global step 43225: loss = 0.1857 (1.005 sec/step)\n",
      "I0902 09:46:28.209999 139792788920128 learning.py:507] global step 43226: loss = 0.0346 (0.955 sec/step)\n",
      "I0902 09:46:29.173582 139792788920128 learning.py:507] global step 43227: loss = 0.1084 (0.962 sec/step)\n",
      "I0902 09:46:30.153291 139792788920128 learning.py:507] global step 43228: loss = 0.0878 (0.978 sec/step)\n",
      "I0902 09:46:31.131276 139792788920128 learning.py:507] global step 43229: loss = 0.1915 (0.977 sec/step)\n",
      "I0902 09:46:32.116036 139792788920128 learning.py:507] global step 43230: loss = 0.1149 (0.983 sec/step)\n",
      "I0902 09:46:33.089481 139792788920128 learning.py:507] global step 43231: loss = 0.0723 (0.972 sec/step)\n",
      "I0902 09:46:34.078958 139792788920128 learning.py:507] global step 43232: loss = 0.1165 (0.988 sec/step)\n",
      "I0902 09:46:35.048990 139792788920128 learning.py:507] global step 43233: loss = 0.0859 (0.968 sec/step)\n",
      "I0902 09:46:36.063599 139792788920128 learning.py:507] global step 43234: loss = 0.0571 (1.013 sec/step)\n",
      "I0902 09:46:37.042853 139792788920128 learning.py:507] global step 43235: loss = 0.2565 (0.977 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:46:38.001655 139792788920128 learning.py:507] global step 43236: loss = 0.1303 (0.957 sec/step)\n",
      "I0902 09:46:38.984099 139792788920128 learning.py:507] global step 43237: loss = 0.0496 (0.981 sec/step)\n",
      "I0902 09:46:39.966158 139792788920128 learning.py:507] global step 43238: loss = 0.1373 (0.980 sec/step)\n",
      "I0902 09:46:40.931521 139792788920128 learning.py:507] global step 43239: loss = 0.1640 (0.964 sec/step)\n",
      "I0902 09:46:41.931824 139792788920128 learning.py:507] global step 43240: loss = 0.1511 (0.999 sec/step)\n",
      "I0902 09:46:42.916408 139792788920128 learning.py:507] global step 43241: loss = 0.1069 (0.983 sec/step)\n",
      "I0902 09:46:43.888544 139792788920128 learning.py:507] global step 43242: loss = 0.0684 (0.971 sec/step)\n",
      "I0902 09:46:44.877286 139792788920128 learning.py:507] global step 43243: loss = 0.1837 (0.987 sec/step)\n",
      "I0902 09:46:45.840093 139792788920128 learning.py:507] global step 43244: loss = 0.1989 (0.961 sec/step)\n",
      "I0902 09:46:46.798793 139792788920128 learning.py:507] global step 43245: loss = 0.0834 (0.957 sec/step)\n",
      "I0902 09:46:47.777616 139792788920128 learning.py:507] global step 43246: loss = 0.0911 (0.977 sec/step)\n",
      "I0902 09:46:48.746582 139792788920128 learning.py:507] global step 43247: loss = 0.0822 (0.967 sec/step)\n",
      "I0902 09:46:49.733742 139792788920128 learning.py:507] global step 43248: loss = 0.0553 (0.986 sec/step)\n",
      "I0902 09:46:50.692582 139792788920128 learning.py:507] global step 43249: loss = 0.1000 (0.957 sec/step)\n",
      "I0902 09:46:51.666635 139792788920128 learning.py:507] global step 43250: loss = 0.0613 (0.972 sec/step)\n",
      "I0902 09:46:52.643662 139792788920128 learning.py:507] global step 43251: loss = 0.0763 (0.975 sec/step)\n",
      "I0902 09:46:53.599245 139792788920128 learning.py:507] global step 43252: loss = 0.1074 (0.954 sec/step)\n",
      "I0902 09:46:54.581485 139792788920128 learning.py:507] global step 43253: loss = 0.1279 (0.981 sec/step)\n",
      "I0902 09:46:55.562973 139792788920128 learning.py:507] global step 43254: loss = 0.1378 (0.980 sec/step)\n",
      "I0902 09:46:56.554019 139792788920128 learning.py:507] global step 43255: loss = 0.0506 (0.989 sec/step)\n",
      "I0902 09:46:57.536231 139792788920128 learning.py:507] global step 43256: loss = 0.0672 (0.981 sec/step)\n",
      "I0902 09:46:58.494051 139792788920128 learning.py:507] global step 43257: loss = 0.1051 (0.956 sec/step)\n",
      "I0902 09:46:59.501403 139792788920128 learning.py:507] global step 43258: loss = 0.2812 (1.006 sec/step)\n",
      "I0902 09:47:00.479749 139792788920128 learning.py:507] global step 43259: loss = 0.1358 (0.977 sec/step)\n",
      "I0902 09:47:01.458725 139792788920128 learning.py:507] global step 43260: loss = 0.0889 (0.977 sec/step)\n",
      "I0902 09:47:02.500079 139792788920128 learning.py:507] global step 43261: loss = 0.3007 (1.040 sec/step)\n",
      "I0902 09:47:03.492601 139792788920128 learning.py:507] global step 43262: loss = 0.1361 (0.991 sec/step)\n",
      "I0902 09:47:04.486788 139792788920128 learning.py:507] global step 43263: loss = 0.1235 (0.993 sec/step)\n",
      "I0902 09:47:05.472209 139792788920128 learning.py:507] global step 43264: loss = 0.1006 (0.984 sec/step)\n",
      "I0902 09:47:06.436114 139792788920128 learning.py:507] global step 43265: loss = 0.2107 (0.962 sec/step)\n",
      "I0902 09:47:07.406892 139792788920128 learning.py:507] global step 43266: loss = 0.0907 (0.969 sec/step)\n",
      "I0902 09:47:08.377888 139792788920128 learning.py:507] global step 43267: loss = 0.0652 (0.970 sec/step)\n",
      "I0902 09:47:09.345991 139792788920128 learning.py:507] global step 43268: loss = 0.0509 (0.966 sec/step)\n",
      "I0902 09:47:10.296039 139792788920128 learning.py:507] global step 43269: loss = 0.0738 (0.948 sec/step)\n",
      "I0902 09:47:11.277811 139792788920128 learning.py:507] global step 43270: loss = 0.1309 (0.980 sec/step)\n",
      "I0902 09:47:12.265172 139792788920128 learning.py:507] global step 43271: loss = 0.1080 (0.986 sec/step)\n",
      "I0902 09:47:13.236785 139792788920128 learning.py:507] global step 43272: loss = 0.1397 (0.970 sec/step)\n",
      "I0902 09:47:14.206857 139792788920128 learning.py:507] global step 43273: loss = 0.1163 (0.968 sec/step)\n",
      "I0902 09:47:15.188568 139792788920128 learning.py:507] global step 43274: loss = 0.1774 (0.980 sec/step)\n",
      "I0902 09:47:16.162135 139792788920128 learning.py:507] global step 43275: loss = 0.1475 (0.972 sec/step)\n",
      "I0902 09:47:17.134530 139792788920128 learning.py:507] global step 43276: loss = 0.0786 (0.971 sec/step)\n",
      "I0902 09:47:18.102008 139792788920128 learning.py:507] global step 43277: loss = 0.1043 (0.966 sec/step)\n",
      "I0902 09:47:19.071463 139792788920128 learning.py:507] global step 43278: loss = 0.0774 (0.968 sec/step)\n",
      "I0902 09:47:20.068410 139792788920128 learning.py:507] global step 43279: loss = 0.0678 (0.995 sec/step)\n",
      "I0902 09:47:21.051732 139792788920128 learning.py:507] global step 43280: loss = 0.1184 (0.982 sec/step)\n",
      "I0902 09:47:22.025572 139792788920128 learning.py:507] global step 43281: loss = 0.0767 (0.972 sec/step)\n",
      "I0902 09:47:23.004790 139792788920128 learning.py:507] global step 43282: loss = 0.1707 (0.978 sec/step)\n",
      "I0902 09:47:23.988395 139792788920128 learning.py:507] global step 43283: loss = 0.3845 (0.982 sec/step)\n",
      "I0902 09:47:24.949064 139792788920128 learning.py:507] global step 43284: loss = 0.1883 (0.959 sec/step)\n",
      "I0902 09:47:25.919927 139792788920128 learning.py:507] global step 43285: loss = 0.0891 (0.969 sec/step)\n",
      "I0902 09:47:26.923472 139792788920128 learning.py:507] global step 43286: loss = 0.0811 (1.002 sec/step)\n",
      "I0902 09:47:27.888740 139792788920128 learning.py:507] global step 43287: loss = 0.1302 (0.964 sec/step)\n",
      "I0902 09:47:28.852670 139792788920128 learning.py:507] global step 43288: loss = 0.0642 (0.962 sec/step)\n",
      "I0902 09:47:29.822221 139792788920128 learning.py:507] global step 43289: loss = 0.1414 (0.968 sec/step)\n",
      "I0902 09:47:30.801593 139792788920128 learning.py:507] global step 43290: loss = 0.1151 (0.978 sec/step)\n",
      "I0902 09:47:31.782629 139792788920128 learning.py:507] global step 43291: loss = 0.0517 (0.979 sec/step)\n",
      "I0902 09:47:32.752156 139792788920128 learning.py:507] global step 43292: loss = 0.1498 (0.968 sec/step)\n",
      "I0902 09:47:33.722270 139792788920128 learning.py:507] global step 43293: loss = 0.0510 (0.968 sec/step)\n",
      "I0902 09:47:34.683689 139792788920128 learning.py:507] global step 43294: loss = 0.1200 (0.960 sec/step)\n",
      "I0902 09:47:35.659001 139792788920128 learning.py:507] global step 43295: loss = 0.1509 (0.974 sec/step)\n",
      "I0902 09:47:36.622644 139792788920128 learning.py:507] global step 43296: loss = 0.0378 (0.962 sec/step)\n",
      "I0902 09:47:37.570683 139792788920128 learning.py:507] global step 43297: loss = 0.0790 (0.946 sec/step)\n",
      "I0902 09:47:38.533368 139792788920128 learning.py:507] global step 43298: loss = 0.1164 (0.961 sec/step)\n",
      "I0902 09:47:39.527163 139792788920128 learning.py:507] global step 43299: loss = 0.0987 (0.992 sec/step)\n",
      "I0902 09:47:40.539035 139792788920128 learning.py:507] global step 43300: loss = 0.1935 (1.010 sec/step)\n",
      "I0902 09:47:41.517405 139792788920128 learning.py:507] global step 43301: loss = 0.3398 (0.977 sec/step)\n",
      "I0902 09:47:42.498803 139792788920128 learning.py:507] global step 43302: loss = 0.1112 (0.980 sec/step)\n",
      "I0902 09:47:43.486780 139792788920128 learning.py:507] global step 43303: loss = 0.1368 (0.986 sec/step)\n",
      "I0902 09:47:44.441816 139792788920128 learning.py:507] global step 43304: loss = 0.1541 (0.953 sec/step)\n",
      "I0902 09:47:45.437868 139792788920128 learning.py:507] global step 43305: loss = 0.1315 (0.994 sec/step)\n",
      "I0902 09:47:46.409052 139792788920128 learning.py:507] global step 43306: loss = 0.0662 (0.969 sec/step)\n",
      "I0902 09:47:47.408837 139792788920128 learning.py:507] global step 43307: loss = 0.1043 (0.998 sec/step)\n",
      "I0902 09:47:48.387977 139792788920128 learning.py:507] global step 43308: loss = 0.2551 (0.978 sec/step)\n",
      "I0902 09:47:49.374246 139792788920128 learning.py:507] global step 43309: loss = 0.3560 (0.980 sec/step)\n",
      "I0902 09:47:50.005314 139778936784640 supervisor.py:1050] Recording summary at step 43309.\n",
      "I0902 09:47:50.616776 139792788920128 learning.py:507] global step 43310: loss = 0.1368 (1.241 sec/step)\n",
      "I0902 09:47:51.576992 139792788920128 learning.py:507] global step 43311: loss = 0.2278 (0.958 sec/step)\n",
      "I0902 09:47:52.549030 139792788920128 learning.py:507] global step 43312: loss = 0.0826 (0.970 sec/step)\n",
      "I0902 09:47:53.515448 139792788920128 learning.py:507] global step 43313: loss = 0.1101 (0.965 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:47:54.489541 139792788920128 learning.py:507] global step 43314: loss = 0.1138 (0.973 sec/step)\n",
      "I0902 09:47:55.451116 139792788920128 learning.py:507] global step 43315: loss = 0.0779 (0.960 sec/step)\n",
      "I0902 09:47:56.419888 139792788920128 learning.py:507] global step 43316: loss = 0.0728 (0.967 sec/step)\n",
      "I0902 09:47:57.397023 139792788920128 learning.py:507] global step 43317: loss = 0.1046 (0.975 sec/step)\n",
      "I0902 09:47:58.362984 139792788920128 learning.py:507] global step 43318: loss = 0.0536 (0.964 sec/step)\n",
      "I0902 09:47:59.331207 139792788920128 learning.py:507] global step 43319: loss = 0.1983 (0.967 sec/step)\n",
      "I0902 09:48:00.272288 139792788920128 learning.py:507] global step 43320: loss = 0.1481 (0.939 sec/step)\n",
      "I0902 09:48:01.231534 139792788920128 learning.py:507] global step 43321: loss = 0.1019 (0.958 sec/step)\n",
      "I0902 09:48:02.195534 139792788920128 learning.py:507] global step 43322: loss = 0.0663 (0.963 sec/step)\n",
      "I0902 09:48:03.174812 139792788920128 learning.py:507] global step 43323: loss = 0.1512 (0.978 sec/step)\n",
      "I0902 09:48:04.146926 139792788920128 learning.py:507] global step 43324: loss = 0.1080 (0.970 sec/step)\n",
      "I0902 09:48:05.122094 139792788920128 learning.py:507] global step 43325: loss = 0.0962 (0.974 sec/step)\n",
      "I0902 09:48:06.080131 139792788920128 learning.py:507] global step 43326: loss = 0.1493 (0.956 sec/step)\n",
      "I0902 09:48:07.050188 139792788920128 learning.py:507] global step 43327: loss = 0.1689 (0.968 sec/step)\n",
      "I0902 09:48:08.013080 139792788920128 learning.py:507] global step 43328: loss = 0.0393 (0.961 sec/step)\n",
      "I0902 09:48:08.976042 139792788920128 learning.py:507] global step 43329: loss = 0.3470 (0.961 sec/step)\n",
      "I0902 09:48:09.939770 139792788920128 learning.py:507] global step 43330: loss = 0.0940 (0.962 sec/step)\n",
      "I0902 09:48:10.884359 139792788920128 learning.py:507] global step 43331: loss = 0.1719 (0.943 sec/step)\n",
      "I0902 09:48:11.842036 139792788920128 learning.py:507] global step 43332: loss = 0.1027 (0.956 sec/step)\n",
      "I0902 09:48:12.807404 139792788920128 learning.py:507] global step 43333: loss = 0.0820 (0.964 sec/step)\n",
      "I0902 09:48:13.774227 139792788920128 learning.py:507] global step 43334: loss = 0.1419 (0.965 sec/step)\n",
      "I0902 09:48:14.749165 139792788920128 learning.py:507] global step 43335: loss = 0.0959 (0.973 sec/step)\n",
      "I0902 09:48:15.709113 139792788920128 learning.py:507] global step 43336: loss = 0.0525 (0.958 sec/step)\n",
      "I0902 09:48:16.673937 139792788920128 learning.py:507] global step 43337: loss = 0.2650 (0.963 sec/step)\n",
      "I0902 09:48:17.643024 139792788920128 learning.py:507] global step 43338: loss = 0.1695 (0.968 sec/step)\n",
      "I0902 09:48:18.626417 139792788920128 learning.py:507] global step 43339: loss = 0.2407 (0.982 sec/step)\n",
      "I0902 09:48:19.590351 139792788920128 learning.py:507] global step 43340: loss = 0.1113 (0.962 sec/step)\n",
      "I0902 09:48:20.548115 139792788920128 learning.py:507] global step 43341: loss = 0.0898 (0.956 sec/step)\n",
      "I0902 09:48:21.503850 139792788920128 learning.py:507] global step 43342: loss = 0.1581 (0.954 sec/step)\n",
      "I0902 09:48:22.473146 139792788920128 learning.py:507] global step 43343: loss = 0.1564 (0.967 sec/step)\n",
      "I0902 09:48:23.449501 139792788920128 learning.py:507] global step 43344: loss = 0.1353 (0.975 sec/step)\n",
      "I0902 09:48:24.422435 139792788920128 learning.py:507] global step 43345: loss = 0.1288 (0.972 sec/step)\n",
      "I0902 09:48:25.377857 139792788920128 learning.py:507] global step 43346: loss = 0.1086 (0.954 sec/step)\n",
      "I0902 09:48:26.333526 139792788920128 learning.py:507] global step 43347: loss = 0.1631 (0.954 sec/step)\n",
      "I0902 09:48:27.304119 139792788920128 learning.py:507] global step 43348: loss = 0.0975 (0.969 sec/step)\n",
      "I0902 09:48:28.279440 139792788920128 learning.py:507] global step 43349: loss = 0.1188 (0.974 sec/step)\n",
      "I0902 09:48:29.252153 139792788920128 learning.py:507] global step 43350: loss = 0.1901 (0.972 sec/step)\n",
      "I0902 09:48:30.221055 139792788920128 learning.py:507] global step 43351: loss = 0.2984 (0.967 sec/step)\n",
      "I0902 09:48:31.202239 139792788920128 learning.py:507] global step 43352: loss = 0.1158 (0.980 sec/step)\n",
      "I0902 09:48:32.178449 139792788920128 learning.py:507] global step 43353: loss = 0.1996 (0.975 sec/step)\n",
      "I0902 09:48:33.130502 139792788920128 learning.py:507] global step 43354: loss = 0.1456 (0.951 sec/step)\n",
      "I0902 09:48:34.083020 139792788920128 learning.py:507] global step 43355: loss = 0.1323 (0.951 sec/step)\n",
      "I0902 09:48:35.047460 139792788920128 learning.py:507] global step 43356: loss = 0.0675 (0.963 sec/step)\n",
      "I0902 09:48:36.033863 139792788920128 learning.py:507] global step 43357: loss = 0.1378 (0.985 sec/step)\n",
      "I0902 09:48:37.013740 139792788920128 learning.py:507] global step 43358: loss = 0.1037 (0.978 sec/step)\n",
      "I0902 09:48:37.974656 139792788920128 learning.py:507] global step 43359: loss = 0.0535 (0.959 sec/step)\n",
      "I0902 09:48:38.942098 139792788920128 learning.py:507] global step 43360: loss = 0.0555 (0.966 sec/step)\n",
      "I0902 09:48:39.912969 139792788920128 learning.py:507] global step 43361: loss = 0.1026 (0.969 sec/step)\n",
      "I0902 09:48:40.887604 139792788920128 learning.py:507] global step 43362: loss = 0.1078 (0.973 sec/step)\n",
      "I0902 09:48:41.853301 139792788920128 learning.py:507] global step 43363: loss = 0.1590 (0.964 sec/step)\n",
      "I0902 09:48:42.840769 139792788920128 learning.py:507] global step 43364: loss = 0.2026 (0.986 sec/step)\n",
      "I0902 09:48:43.807427 139792788920128 learning.py:507] global step 43365: loss = 0.0691 (0.965 sec/step)\n",
      "I0902 09:48:44.776138 139792788920128 learning.py:507] global step 43366: loss = 0.0969 (0.967 sec/step)\n",
      "I0902 09:48:45.722336 139792788920128 learning.py:507] global step 43367: loss = 0.1227 (0.944 sec/step)\n",
      "I0902 09:48:46.688000 139792788920128 learning.py:507] global step 43368: loss = 0.1263 (0.964 sec/step)\n",
      "I0902 09:48:47.650568 139792788920128 learning.py:507] global step 43369: loss = 0.1602 (0.961 sec/step)\n",
      "I0902 09:48:48.613804 139792788920128 learning.py:507] global step 43370: loss = 0.0780 (0.962 sec/step)\n",
      "I0902 09:48:49.585502 139792788920128 learning.py:507] global step 43371: loss = 0.1155 (0.970 sec/step)\n",
      "I0902 09:48:50.553880 139792788920128 learning.py:507] global step 43372: loss = 0.1636 (0.967 sec/step)\n",
      "I0902 09:48:51.519464 139792788920128 learning.py:507] global step 43373: loss = 0.0899 (0.964 sec/step)\n",
      "I0902 09:48:52.482645 139792788920128 learning.py:507] global step 43374: loss = 0.1436 (0.962 sec/step)\n",
      "I0902 09:48:53.435443 139792788920128 learning.py:507] global step 43375: loss = 0.0776 (0.951 sec/step)\n",
      "I0902 09:48:54.406158 139792788920128 learning.py:507] global step 43376: loss = 0.0845 (0.969 sec/step)\n",
      "I0902 09:48:55.390269 139792788920128 learning.py:507] global step 43377: loss = 0.0975 (0.982 sec/step)\n",
      "I0902 09:48:56.359278 139792788920128 learning.py:507] global step 43378: loss = 0.1689 (0.968 sec/step)\n",
      "I0902 09:48:57.314981 139792788920128 learning.py:507] global step 43379: loss = 0.0777 (0.954 sec/step)\n",
      "I0902 09:48:58.318933 139792788920128 learning.py:507] global step 43380: loss = 0.1710 (1.002 sec/step)\n",
      "I0902 09:48:59.279410 139792788920128 learning.py:507] global step 43381: loss = 0.1646 (0.959 sec/step)\n",
      "I0902 09:49:00.260092 139792788920128 learning.py:507] global step 43382: loss = 0.1113 (0.979 sec/step)\n",
      "I0902 09:49:01.221252 139792788920128 learning.py:507] global step 43383: loss = 0.1651 (0.959 sec/step)\n",
      "I0902 09:49:02.180693 139792788920128 learning.py:507] global step 43384: loss = 0.1117 (0.958 sec/step)\n",
      "I0902 09:49:03.135334 139792788920128 learning.py:507] global step 43385: loss = 0.1377 (0.953 sec/step)\n",
      "I0902 09:49:04.123436 139792788920128 learning.py:507] global step 43386: loss = 0.0769 (0.986 sec/step)\n",
      "I0902 09:49:05.083210 139792788920128 learning.py:507] global step 43387: loss = 0.1978 (0.958 sec/step)\n",
      "I0902 09:49:06.041420 139792788920128 learning.py:507] global step 43388: loss = 0.1293 (0.957 sec/step)\n",
      "I0902 09:49:07.003574 139792788920128 learning.py:507] global step 43389: loss = 0.1019 (0.960 sec/step)\n",
      "I0902 09:49:07.978245 139792788920128 learning.py:507] global step 43390: loss = 0.0835 (0.973 sec/step)\n",
      "I0902 09:49:08.943641 139792788920128 learning.py:507] global step 43391: loss = 0.0966 (0.964 sec/step)\n",
      "I0902 09:49:09.901918 139792788920128 learning.py:507] global step 43392: loss = 0.1478 (0.957 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:49:10.869033 139792788920128 learning.py:507] global step 43393: loss = 0.1467 (0.966 sec/step)\n",
      "I0902 09:49:11.861757 139792788920128 learning.py:507] global step 43394: loss = 0.1197 (0.991 sec/step)\n",
      "I0902 09:49:12.841275 139792788920128 learning.py:507] global step 43395: loss = 0.0994 (0.978 sec/step)\n",
      "I0902 09:49:13.811568 139792788920128 learning.py:507] global step 43396: loss = 0.1107 (0.969 sec/step)\n",
      "I0902 09:49:14.775343 139792788920128 learning.py:507] global step 43397: loss = 0.2372 (0.962 sec/step)\n",
      "I0902 09:49:15.745023 139792788920128 learning.py:507] global step 43398: loss = 0.1024 (0.968 sec/step)\n",
      "I0902 09:49:16.714724 139792788920128 learning.py:507] global step 43399: loss = 0.0705 (0.968 sec/step)\n",
      "I0902 09:49:17.678703 139792788920128 learning.py:507] global step 43400: loss = 0.0798 (0.962 sec/step)\n",
      "I0902 09:49:18.649783 139792788920128 learning.py:507] global step 43401: loss = 0.1226 (0.969 sec/step)\n",
      "I0902 09:49:19.614677 139792788920128 learning.py:507] global step 43402: loss = 0.1161 (0.963 sec/step)\n",
      "I0902 09:49:20.578165 139792788920128 learning.py:507] global step 43403: loss = 0.2298 (0.962 sec/step)\n",
      "I0902 09:49:21.556194 139792788920128 learning.py:507] global step 43404: loss = 0.2024 (0.976 sec/step)\n",
      "I0902 09:49:22.517805 139792788920128 learning.py:507] global step 43405: loss = 0.1037 (0.960 sec/step)\n",
      "I0902 09:49:23.469105 139792788920128 learning.py:507] global step 43406: loss = 0.1516 (0.950 sec/step)\n",
      "I0902 09:49:24.431630 139792788920128 learning.py:507] global step 43407: loss = 0.0742 (0.961 sec/step)\n",
      "I0902 09:49:25.411568 139792788920128 learning.py:507] global step 43408: loss = 0.1488 (0.978 sec/step)\n",
      "I0902 09:49:26.365432 139792788920128 learning.py:507] global step 43409: loss = 0.0926 (0.952 sec/step)\n",
      "I0902 09:49:27.329237 139792788920128 learning.py:507] global step 43410: loss = 0.0607 (0.962 sec/step)\n",
      "I0902 09:49:28.280103 139792788920128 learning.py:507] global step 43411: loss = 0.0824 (0.949 sec/step)\n",
      "I0902 09:49:29.260493 139792788920128 learning.py:507] global step 43412: loss = 0.1048 (0.979 sec/step)\n",
      "I0902 09:49:30.235149 139792788920128 learning.py:507] global step 43413: loss = 0.1533 (0.973 sec/step)\n",
      "I0902 09:49:31.203325 139792788920128 learning.py:507] global step 43414: loss = 0.0531 (0.967 sec/step)\n",
      "I0902 09:49:32.175334 139792788920128 learning.py:507] global step 43415: loss = 0.0793 (0.970 sec/step)\n",
      "I0902 09:49:33.137437 139792788920128 learning.py:507] global step 43416: loss = 0.1563 (0.960 sec/step)\n",
      "I0902 09:49:34.114100 139792788920128 learning.py:507] global step 43417: loss = 0.1488 (0.975 sec/step)\n",
      "I0902 09:49:35.081223 139792788920128 learning.py:507] global step 43418: loss = 0.1098 (0.965 sec/step)\n",
      "I0902 09:49:36.056076 139792788920128 learning.py:507] global step 43419: loss = 0.1625 (0.973 sec/step)\n",
      "I0902 09:49:37.024237 139792788920128 learning.py:507] global step 43420: loss = 0.1518 (0.967 sec/step)\n",
      "I0902 09:49:37.985320 139792788920128 learning.py:507] global step 43421: loss = 0.1445 (0.959 sec/step)\n",
      "I0902 09:49:38.931513 139792788920128 learning.py:507] global step 43422: loss = 0.1179 (0.944 sec/step)\n",
      "I0902 09:49:39.900336 139792788920128 learning.py:507] global step 43423: loss = 0.0615 (0.967 sec/step)\n",
      "I0902 09:49:40.887004 139792788920128 learning.py:507] global step 43424: loss = 0.1387 (0.985 sec/step)\n",
      "I0902 09:49:41.870149 139792788920128 learning.py:507] global step 43425: loss = 0.1276 (0.981 sec/step)\n",
      "I0902 09:49:42.845933 139792788920128 learning.py:507] global step 43426: loss = 0.1716 (0.974 sec/step)\n",
      "I0902 09:49:43.822516 139792788920128 learning.py:507] global step 43427: loss = 0.1652 (0.975 sec/step)\n",
      "I0902 09:49:44.773738 139792788920128 learning.py:507] global step 43428: loss = 0.1198 (0.950 sec/step)\n",
      "I0902 09:49:45.742359 139792788920128 learning.py:507] global step 43429: loss = 0.0539 (0.967 sec/step)\n",
      "I0902 09:49:46.704488 139792788920128 learning.py:507] global step 43430: loss = 0.0628 (0.960 sec/step)\n",
      "I0902 09:49:47.669469 139792788920128 learning.py:507] global step 43431: loss = 0.1871 (0.963 sec/step)\n",
      "I0902 09:49:48.626358 139792788920128 learning.py:507] global step 43432: loss = 0.0983 (0.955 sec/step)\n",
      "I0902 09:49:49.602180 139792788920128 learning.py:507] global step 43433: loss = 0.1118 (0.967 sec/step)\n",
      "I0902 09:49:50.222949 139778936784640 supervisor.py:1050] Recording summary at step 43433.\n",
      "I0902 09:49:50.830763 139792788920128 learning.py:507] global step 43434: loss = 0.1046 (1.227 sec/step)\n",
      "I0902 09:49:51.815909 139792788920128 learning.py:507] global step 43435: loss = 0.1047 (0.983 sec/step)\n",
      "I0902 09:49:52.791095 139792788920128 learning.py:507] global step 43436: loss = 0.1347 (0.973 sec/step)\n",
      "I0902 09:49:53.764824 139792788920128 learning.py:507] global step 43437: loss = 0.1104 (0.972 sec/step)\n",
      "I0902 09:49:54.742679 139792788920128 learning.py:507] global step 43438: loss = 0.1679 (0.976 sec/step)\n",
      "I0902 09:49:55.718295 139792788920128 learning.py:507] global step 43439: loss = 0.1675 (0.974 sec/step)\n",
      "I0902 09:49:56.677957 139792788920128 learning.py:507] global step 43440: loss = 0.1981 (0.958 sec/step)\n",
      "I0902 09:49:57.637025 139792788920128 learning.py:507] global step 43441: loss = 0.0882 (0.957 sec/step)\n",
      "I0902 09:49:58.595249 139792788920128 learning.py:507] global step 43442: loss = 0.1012 (0.957 sec/step)\n",
      "I0902 09:49:59.558126 139792788920128 learning.py:507] global step 43443: loss = 0.0753 (0.961 sec/step)\n",
      "I0902 09:50:00.556204 139792788920128 learning.py:507] global step 43444: loss = 0.1954 (0.996 sec/step)\n",
      "I0902 09:50:01.551429 139792788920128 learning.py:507] global step 43445: loss = 0.2856 (0.993 sec/step)\n",
      "I0902 09:50:02.527973 139792788920128 learning.py:507] global step 43446: loss = 0.0825 (0.975 sec/step)\n",
      "I0902 09:50:03.505141 139792788920128 learning.py:507] global step 43447: loss = 0.0811 (0.976 sec/step)\n",
      "I0902 09:50:04.481454 139792788920128 learning.py:507] global step 43448: loss = 0.1206 (0.975 sec/step)\n",
      "I0902 09:50:05.463122 139792788920128 learning.py:507] global step 43449: loss = 0.1287 (0.980 sec/step)\n",
      "I0902 09:50:06.437453 139792788920128 learning.py:507] global step 43450: loss = 0.1017 (0.973 sec/step)\n",
      "I0902 09:50:07.416807 139792788920128 learning.py:507] global step 43451: loss = 0.0923 (0.978 sec/step)\n",
      "I0902 09:50:08.382796 139792788920128 learning.py:507] global step 43452: loss = 0.2275 (0.964 sec/step)\n",
      "I0902 09:50:09.373589 139792788920128 learning.py:507] global step 43453: loss = 0.1703 (0.989 sec/step)\n",
      "I0902 09:50:10.334876 139792788920128 learning.py:507] global step 43454: loss = 0.0707 (0.960 sec/step)\n",
      "I0902 09:50:11.316352 139792788920128 learning.py:507] global step 43455: loss = 0.1514 (0.980 sec/step)\n",
      "I0902 09:50:12.273994 139792788920128 learning.py:507] global step 43456: loss = 0.0899 (0.956 sec/step)\n",
      "I0902 09:50:13.244086 139792788920128 learning.py:507] global step 43457: loss = 0.1016 (0.968 sec/step)\n",
      "I0902 09:50:14.202688 139792788920128 learning.py:507] global step 43458: loss = 0.0924 (0.957 sec/step)\n",
      "I0902 09:50:15.173214 139792788920128 learning.py:507] global step 43459: loss = 0.0959 (0.969 sec/step)\n",
      "I0902 09:50:16.147669 139792788920128 learning.py:507] global step 43460: loss = 0.2798 (0.973 sec/step)\n",
      "I0902 09:50:17.116665 139792788920128 learning.py:507] global step 43461: loss = 0.0853 (0.967 sec/step)\n",
      "I0902 09:50:18.092746 139792788920128 learning.py:507] global step 43462: loss = 0.0853 (0.974 sec/step)\n",
      "I0902 09:50:19.074719 139792788920128 learning.py:507] global step 43463: loss = 0.1356 (0.980 sec/step)\n",
      "I0902 09:50:20.060035 139792788920128 learning.py:507] global step 43464: loss = 0.0906 (0.984 sec/step)\n",
      "I0902 09:50:21.051548 139792788920128 learning.py:507] global step 43465: loss = 0.1490 (0.990 sec/step)\n",
      "I0902 09:50:22.012749 139792788920128 learning.py:507] global step 43466: loss = 0.1379 (0.960 sec/step)\n",
      "I0902 09:50:22.989249 139792788920128 learning.py:507] global step 43467: loss = 0.1294 (0.975 sec/step)\n",
      "I0902 09:50:23.978521 139792788920128 learning.py:507] global step 43468: loss = 0.1163 (0.988 sec/step)\n",
      "I0902 09:50:24.928637 139792788920128 learning.py:507] global step 43469: loss = 0.1098 (0.948 sec/step)\n",
      "I0902 09:50:25.879448 139792788920128 learning.py:507] global step 43470: loss = 0.1628 (0.949 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:50:26.878654 139792788920128 learning.py:507] global step 43471: loss = 0.1401 (0.997 sec/step)\n",
      "I0902 09:50:27.880151 139792788920128 learning.py:507] global step 43472: loss = 0.1044 (1.000 sec/step)\n",
      "I0902 09:50:28.873976 139792788920128 learning.py:507] global step 43473: loss = 0.0994 (0.992 sec/step)\n",
      "I0902 09:50:29.856489 139792788920128 learning.py:507] global step 43474: loss = 0.0967 (0.981 sec/step)\n",
      "I0902 09:50:30.844029 139792788920128 learning.py:507] global step 43475: loss = 0.1385 (0.986 sec/step)\n",
      "I0902 09:50:31.812782 139792788920128 learning.py:507] global step 43476: loss = 0.2747 (0.967 sec/step)\n",
      "I0902 09:50:32.787116 139792788920128 learning.py:507] global step 43477: loss = 0.2494 (0.973 sec/step)\n",
      "I0902 09:50:33.755560 139792788920128 learning.py:507] global step 43478: loss = 0.1510 (0.967 sec/step)\n",
      "I0902 09:50:34.716856 139792788920128 learning.py:507] global step 43479: loss = 0.1908 (0.960 sec/step)\n",
      "I0902 09:50:35.716463 139792788920128 learning.py:507] global step 43480: loss = 0.1540 (0.998 sec/step)\n",
      "I0902 09:50:36.711916 139792788920128 learning.py:507] global step 43481: loss = 0.1087 (0.994 sec/step)\n",
      "I0902 09:50:37.712528 139792788920128 learning.py:507] global step 43482: loss = 0.1049 (0.999 sec/step)\n",
      "I0902 09:50:38.705853 139792788920128 learning.py:507] global step 43483: loss = 0.2386 (0.992 sec/step)\n",
      "I0902 09:50:39.684193 139792788920128 learning.py:507] global step 43484: loss = 0.0941 (0.977 sec/step)\n",
      "I0902 09:50:40.682934 139792788920128 learning.py:507] global step 43485: loss = 0.1649 (0.998 sec/step)\n",
      "I0902 09:50:41.666308 139792788920128 learning.py:507] global step 43486: loss = 0.2612 (0.982 sec/step)\n",
      "I0902 09:50:42.644566 139792788920128 learning.py:507] global step 43487: loss = 0.1320 (0.977 sec/step)\n",
      "I0902 09:50:43.617018 139792788920128 learning.py:507] global step 43488: loss = 0.1261 (0.971 sec/step)\n",
      "I0902 09:50:44.559595 139792788920128 learning.py:507] global step 43489: loss = 0.1239 (0.941 sec/step)\n",
      "I0902 09:50:45.543192 139792788920128 learning.py:507] global step 43490: loss = 0.1395 (0.982 sec/step)\n",
      "I0902 09:50:46.524829 139792788920128 learning.py:507] global step 43491: loss = 0.0924 (0.980 sec/step)\n",
      "I0902 09:50:47.501479 139792788920128 learning.py:507] global step 43492: loss = 0.0951 (0.975 sec/step)\n",
      "I0902 09:50:48.504257 139792788920128 learning.py:507] global step 43493: loss = 0.1943 (1.001 sec/step)\n",
      "I0902 09:50:49.482475 139792788920128 learning.py:507] global step 43494: loss = 0.1814 (0.977 sec/step)\n",
      "I0902 09:50:50.444141 139792788920128 learning.py:507] global step 43495: loss = 0.1126 (0.960 sec/step)\n",
      "I0902 09:50:51.414587 139792788920128 learning.py:507] global step 43496: loss = 0.0994 (0.969 sec/step)\n",
      "I0902 09:50:52.402356 139792788920128 learning.py:507] global step 43497: loss = 0.1427 (0.986 sec/step)\n",
      "I0902 09:50:53.376708 139792788920128 learning.py:507] global step 43498: loss = 0.0929 (0.973 sec/step)\n",
      "I0902 09:50:54.341007 139792788920128 learning.py:507] global step 43499: loss = 0.0790 (0.963 sec/step)\n",
      "I0902 09:50:55.295471 139792788920128 learning.py:507] global step 43500: loss = 0.0885 (0.953 sec/step)\n",
      "I0902 09:50:56.252806 139792788920128 learning.py:507] global step 43501: loss = 0.1465 (0.956 sec/step)\n",
      "I0902 09:50:57.214430 139792788920128 learning.py:507] global step 43502: loss = 0.1168 (0.960 sec/step)\n",
      "I0902 09:50:58.197705 139792788920128 learning.py:507] global step 43503: loss = 0.1738 (0.982 sec/step)\n",
      "I0902 09:50:59.175203 139792788920128 learning.py:507] global step 43504: loss = 0.0857 (0.976 sec/step)\n",
      "I0902 09:51:00.127409 139792788920128 learning.py:507] global step 43505: loss = 0.0885 (0.950 sec/step)\n",
      "I0902 09:51:01.120146 139792788920128 learning.py:507] global step 43506: loss = 0.1336 (0.991 sec/step)\n",
      "I0902 09:51:02.099259 139792788920128 learning.py:507] global step 43507: loss = 0.0840 (0.977 sec/step)\n",
      "I0902 09:51:03.089725 139792788920128 learning.py:507] global step 43508: loss = 0.1034 (0.989 sec/step)\n",
      "I0902 09:51:04.059610 139792788920128 learning.py:507] global step 43509: loss = 0.1767 (0.968 sec/step)\n",
      "I0902 09:51:05.023149 139792788920128 learning.py:507] global step 43510: loss = 0.1050 (0.962 sec/step)\n",
      "I0902 09:51:05.979491 139792788920128 learning.py:507] global step 43511: loss = 0.0540 (0.955 sec/step)\n",
      "I0902 09:51:06.931289 139792788920128 learning.py:507] global step 43512: loss = 0.1053 (0.950 sec/step)\n",
      "I0902 09:51:07.912646 139792788920128 learning.py:507] global step 43513: loss = 0.1251 (0.979 sec/step)\n",
      "I0902 09:51:08.877803 139792788920128 learning.py:507] global step 43514: loss = 0.0975 (0.963 sec/step)\n",
      "I0902 09:51:09.848608 139792788920128 learning.py:507] global step 43515: loss = 0.0626 (0.969 sec/step)\n",
      "I0902 09:51:10.817655 139792788920128 learning.py:507] global step 43516: loss = 0.1815 (0.968 sec/step)\n",
      "I0902 09:51:11.805030 139792788920128 learning.py:507] global step 43517: loss = 0.2426 (0.986 sec/step)\n",
      "I0902 09:51:12.784780 139792788920128 learning.py:507] global step 43518: loss = 0.1006 (0.978 sec/step)\n",
      "I0902 09:51:13.768112 139792788920128 learning.py:507] global step 43519: loss = 0.1202 (0.982 sec/step)\n",
      "I0902 09:51:14.746066 139792788920128 learning.py:507] global step 43520: loss = 0.0954 (0.976 sec/step)\n",
      "I0902 09:51:15.726807 139792788920128 learning.py:507] global step 43521: loss = 0.1525 (0.979 sec/step)\n",
      "I0902 09:51:16.709063 139792788920128 learning.py:507] global step 43522: loss = 0.1234 (0.981 sec/step)\n",
      "I0902 09:51:17.661546 139792788920128 learning.py:507] global step 43523: loss = 0.0503 (0.951 sec/step)\n",
      "I0902 09:51:18.632581 139792788920128 learning.py:507] global step 43524: loss = 0.1700 (0.969 sec/step)\n",
      "I0902 09:51:19.592526 139792788920128 learning.py:507] global step 43525: loss = 0.1180 (0.958 sec/step)\n",
      "I0902 09:51:20.577224 139792788920128 learning.py:507] global step 43526: loss = 0.1059 (0.983 sec/step)\n",
      "I0902 09:51:21.518884 139792788920128 learning.py:507] global step 43527: loss = 0.2257 (0.940 sec/step)\n",
      "I0902 09:51:22.483836 139792788920128 learning.py:507] global step 43528: loss = 0.1100 (0.963 sec/step)\n",
      "I0902 09:51:23.445955 139792788920128 learning.py:507] global step 43529: loss = 0.1177 (0.960 sec/step)\n",
      "I0902 09:51:24.422168 139792788920128 learning.py:507] global step 43530: loss = 0.1609 (0.974 sec/step)\n",
      "I0902 09:51:25.400571 139792788920128 learning.py:507] global step 43531: loss = 0.1172 (0.977 sec/step)\n",
      "I0902 09:51:26.376227 139792788920128 learning.py:507] global step 43532: loss = 0.1564 (0.974 sec/step)\n",
      "I0902 09:51:27.355911 139792788920128 learning.py:507] global step 43533: loss = 0.1240 (0.978 sec/step)\n",
      "I0902 09:51:28.319011 139792788920128 learning.py:507] global step 43534: loss = 0.1090 (0.961 sec/step)\n",
      "I0902 09:51:29.284041 139792788920128 learning.py:507] global step 43535: loss = 0.1080 (0.963 sec/step)\n",
      "I0902 09:51:30.252432 139792788920128 learning.py:507] global step 43536: loss = 0.0913 (0.967 sec/step)\n",
      "I0902 09:51:31.234209 139792788920128 learning.py:507] global step 43537: loss = 0.1375 (0.980 sec/step)\n",
      "I0902 09:51:32.198500 139792788920128 learning.py:507] global step 43538: loss = 0.1944 (0.963 sec/step)\n",
      "I0902 09:51:33.160392 139792788920128 learning.py:507] global step 43539: loss = 0.1370 (0.960 sec/step)\n",
      "I0902 09:51:34.138837 139792788920128 learning.py:507] global step 43540: loss = 0.3339 (0.977 sec/step)\n",
      "I0902 09:51:35.125834 139792788920128 learning.py:507] global step 43541: loss = 0.1700 (0.985 sec/step)\n",
      "I0902 09:51:36.112883 139792788920128 learning.py:507] global step 43542: loss = 0.1149 (0.985 sec/step)\n",
      "I0902 09:51:37.167493 139792788920128 learning.py:507] global step 43543: loss = 0.2953 (1.053 sec/step)\n",
      "I0902 09:51:38.170001 139792788920128 learning.py:507] global step 43544: loss = 0.0784 (1.001 sec/step)\n",
      "I0902 09:51:39.157674 139792788920128 learning.py:507] global step 43545: loss = 0.0693 (0.986 sec/step)\n",
      "I0902 09:51:40.150664 139792788920128 learning.py:507] global step 43546: loss = 0.0527 (0.991 sec/step)\n",
      "I0902 09:51:41.149802 139792788920128 learning.py:507] global step 43547: loss = 0.0498 (0.998 sec/step)\n",
      "I0902 09:51:42.129579 139792788920128 learning.py:507] global step 43548: loss = 0.3309 (0.978 sec/step)\n",
      "I0902 09:51:43.105902 139792788920128 learning.py:507] global step 43549: loss = 0.0870 (0.975 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:51:44.079149 139792788920128 learning.py:507] global step 43550: loss = 0.0525 (0.972 sec/step)\n",
      "I0902 09:51:45.040267 139792788920128 learning.py:507] global step 43551: loss = 0.0372 (0.959 sec/step)\n",
      "I0902 09:51:45.993173 139792788920128 learning.py:507] global step 43552: loss = 0.0844 (0.951 sec/step)\n",
      "I0902 09:51:46.973554 139792788920128 learning.py:507] global step 43553: loss = 0.2120 (0.979 sec/step)\n",
      "I0902 09:51:47.954136 139792788920128 learning.py:507] global step 43554: loss = 0.1740 (0.979 sec/step)\n",
      "I0902 09:51:48.937016 139792788920128 learning.py:507] global step 43555: loss = 0.0775 (0.981 sec/step)\n",
      "I0902 09:51:50.068699 139792788920128 learning.py:507] global step 43556: loss = 0.0909 (1.125 sec/step)\n",
      "I0902 09:51:50.259041 139778936784640 supervisor.py:1050] Recording summary at step 43556.\n",
      "I0902 09:51:51.167833 139792788920128 learning.py:507] global step 43557: loss = 0.0554 (1.097 sec/step)\n",
      "I0902 09:51:52.128399 139792788920128 learning.py:507] global step 43558: loss = 0.0656 (0.959 sec/step)\n",
      "I0902 09:51:53.093063 139792788920128 learning.py:507] global step 43559: loss = 0.1312 (0.963 sec/step)\n",
      "I0902 09:51:54.069954 139792788920128 learning.py:507] global step 43560: loss = 0.1085 (0.975 sec/step)\n",
      "I0902 09:51:55.027333 139792788920128 learning.py:507] global step 43561: loss = 0.2431 (0.956 sec/step)\n",
      "I0902 09:51:55.979200 139792788920128 learning.py:507] global step 43562: loss = 0.5291 (0.950 sec/step)\n",
      "I0902 09:51:56.931045 139792788920128 learning.py:507] global step 43563: loss = 0.0633 (0.950 sec/step)\n",
      "I0902 09:51:57.882802 139792788920128 learning.py:507] global step 43564: loss = 0.1793 (0.950 sec/step)\n",
      "I0902 09:51:58.848339 139792788920128 learning.py:507] global step 43565: loss = 0.1043 (0.964 sec/step)\n",
      "I0902 09:51:59.822521 139792788920128 learning.py:507] global step 43566: loss = 0.1612 (0.972 sec/step)\n",
      "I0902 09:52:00.808574 139792788920128 learning.py:507] global step 43567: loss = 0.1846 (0.984 sec/step)\n",
      "I0902 09:52:01.774511 139792788920128 learning.py:507] global step 43568: loss = 0.3336 (0.964 sec/step)\n",
      "I0902 09:52:02.752088 139792788920128 learning.py:507] global step 43569: loss = 0.1462 (0.976 sec/step)\n",
      "I0902 09:52:03.717734 139792788920128 learning.py:507] global step 43570: loss = 0.1573 (0.964 sec/step)\n",
      "I0902 09:52:04.685083 139792788920128 learning.py:507] global step 43571: loss = 0.0649 (0.966 sec/step)\n",
      "I0902 09:52:05.649655 139792788920128 learning.py:507] global step 43572: loss = 0.0942 (0.963 sec/step)\n",
      "I0902 09:52:06.617525 139792788920128 learning.py:507] global step 43573: loss = 0.1024 (0.966 sec/step)\n",
      "I0902 09:52:07.575467 139792788920128 learning.py:507] global step 43574: loss = 0.1067 (0.956 sec/step)\n",
      "I0902 09:52:08.535601 139792788920128 learning.py:507] global step 43575: loss = 0.0517 (0.959 sec/step)\n",
      "I0902 09:52:09.495740 139792788920128 learning.py:507] global step 43576: loss = 0.0603 (0.959 sec/step)\n",
      "I0902 09:52:10.458646 139792788920128 learning.py:507] global step 43577: loss = 0.1512 (0.961 sec/step)\n",
      "I0902 09:52:11.447374 139792788920128 learning.py:507] global step 43578: loss = 0.2492 (0.987 sec/step)\n",
      "I0902 09:52:12.434464 139792788920128 learning.py:507] global step 43579: loss = 0.1578 (0.985 sec/step)\n",
      "I0902 09:52:13.400399 139792788920128 learning.py:507] global step 43580: loss = 0.0477 (0.964 sec/step)\n",
      "I0902 09:52:14.362797 139792788920128 learning.py:507] global step 43581: loss = 0.0695 (0.961 sec/step)\n",
      "I0902 09:52:15.317071 139792788920128 learning.py:507] global step 43582: loss = 0.0735 (0.953 sec/step)\n",
      "I0902 09:52:16.283334 139792788920128 learning.py:507] global step 43583: loss = 0.1538 (0.964 sec/step)\n",
      "I0902 09:52:17.268868 139792788920128 learning.py:507] global step 43584: loss = 0.0626 (0.984 sec/step)\n",
      "I0902 09:52:18.220635 139792788920128 learning.py:507] global step 43585: loss = 0.0749 (0.950 sec/step)\n",
      "I0902 09:52:19.195124 139792788920128 learning.py:507] global step 43586: loss = 0.1224 (0.973 sec/step)\n",
      "I0902 09:52:20.167078 139792788920128 learning.py:507] global step 43587: loss = 0.1577 (0.970 sec/step)\n",
      "I0902 09:52:21.130111 139792788920128 learning.py:507] global step 43588: loss = 0.0723 (0.961 sec/step)\n",
      "I0902 09:52:22.122262 139792788920128 learning.py:507] global step 43589: loss = 0.0918 (0.991 sec/step)\n",
      "I0902 09:52:23.073379 139792788920128 learning.py:507] global step 43590: loss = 0.0552 (0.949 sec/step)\n",
      "I0902 09:52:24.045719 139792788920128 learning.py:507] global step 43591: loss = 0.1505 (0.971 sec/step)\n",
      "I0902 09:52:25.004659 139792788920128 learning.py:507] global step 43592: loss = 0.0841 (0.957 sec/step)\n",
      "I0902 09:52:25.965127 139792788920128 learning.py:507] global step 43593: loss = 0.1772 (0.959 sec/step)\n",
      "I0902 09:52:26.922440 139792788920128 learning.py:507] global step 43594: loss = 0.0888 (0.956 sec/step)\n",
      "I0902 09:52:27.895081 139792788920128 learning.py:507] global step 43595: loss = 0.0617 (0.971 sec/step)\n",
      "I0902 09:52:28.869582 139792788920128 learning.py:507] global step 43596: loss = 0.1130 (0.973 sec/step)\n",
      "I0902 09:52:29.833810 139792788920128 learning.py:507] global step 43597: loss = 0.1105 (0.963 sec/step)\n",
      "I0902 09:52:30.807380 139792788920128 learning.py:507] global step 43598: loss = 0.1761 (0.972 sec/step)\n",
      "I0902 09:52:31.770663 139792788920128 learning.py:507] global step 43599: loss = 0.1774 (0.962 sec/step)\n",
      "I0902 09:52:32.733260 139792788920128 learning.py:507] global step 43600: loss = 0.1217 (0.961 sec/step)\n",
      "I0902 09:52:33.689697 139792788920128 learning.py:507] global step 43601: loss = 0.1429 (0.955 sec/step)\n",
      "I0902 09:52:34.658743 139792788920128 learning.py:507] global step 43602: loss = 0.1179 (0.968 sec/step)\n",
      "I0902 09:52:35.649967 139792788920128 learning.py:507] global step 43603: loss = 0.1025 (0.990 sec/step)\n",
      "I0902 09:52:36.612631 139792788920128 learning.py:507] global step 43604: loss = 0.0857 (0.961 sec/step)\n",
      "I0902 09:52:37.577909 139792788920128 learning.py:507] global step 43605: loss = 0.1458 (0.964 sec/step)\n",
      "I0902 09:52:38.552552 139792788920128 learning.py:507] global step 43606: loss = 0.1056 (0.973 sec/step)\n",
      "I0902 09:52:39.514902 139792788920128 learning.py:507] global step 43607: loss = 0.0800 (0.961 sec/step)\n",
      "I0902 09:52:40.496550 139792788920128 learning.py:507] global step 43608: loss = 0.1540 (0.980 sec/step)\n",
      "I0902 09:52:41.493559 139792788920128 learning.py:507] global step 43609: loss = 0.0641 (0.995 sec/step)\n",
      "I0902 09:52:42.461506 139792788920128 learning.py:507] global step 43610: loss = 0.0778 (0.966 sec/step)\n",
      "I0902 09:52:43.441653 139792788920128 learning.py:507] global step 43611: loss = 0.1111 (0.979 sec/step)\n",
      "I0902 09:52:44.453606 139792788920128 learning.py:507] global step 43612: loss = 0.1690 (1.010 sec/step)\n",
      "I0902 09:52:45.421912 139792788920128 learning.py:507] global step 43613: loss = 0.1321 (0.967 sec/step)\n",
      "I0902 09:52:46.383541 139792788920128 learning.py:507] global step 43614: loss = 0.0715 (0.960 sec/step)\n",
      "I0902 09:52:47.350940 139792788920128 learning.py:507] global step 43615: loss = 0.1629 (0.966 sec/step)\n",
      "I0902 09:52:48.312584 139792788920128 learning.py:507] global step 43616: loss = 0.1180 (0.960 sec/step)\n",
      "I0902 09:52:49.281864 139792788920128 learning.py:507] global step 43617: loss = 0.1628 (0.968 sec/step)\n",
      "I0902 09:52:50.248489 139792788920128 learning.py:507] global step 43618: loss = 0.1261 (0.965 sec/step)\n",
      "I0902 09:52:51.244925 139792788920128 learning.py:507] global step 43619: loss = 0.1764 (0.995 sec/step)\n",
      "I0902 09:52:52.226837 139792788920128 learning.py:507] global step 43620: loss = 0.1697 (0.980 sec/step)\n",
      "I0902 09:52:53.213492 139792788920128 learning.py:507] global step 43621: loss = 0.0813 (0.985 sec/step)\n",
      "I0902 09:52:54.157601 139792788920128 learning.py:507] global step 43622: loss = 0.0877 (0.942 sec/step)\n",
      "I0902 09:52:55.125653 139792788920128 learning.py:507] global step 43623: loss = 0.1143 (0.967 sec/step)\n",
      "I0902 09:52:56.115102 139792788920128 learning.py:507] global step 43624: loss = 0.1052 (0.988 sec/step)\n",
      "I0902 09:52:57.076469 139792788920128 learning.py:507] global step 43625: loss = 0.0916 (0.960 sec/step)\n",
      "I0902 09:52:58.035785 139792788920128 learning.py:507] global step 43626: loss = 0.0775 (0.958 sec/step)\n",
      "I0902 09:52:59.012305 139792788920128 learning.py:507] global step 43627: loss = 0.0917 (0.975 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:53:00.008890 139792788920128 learning.py:507] global step 43628: loss = 0.0720 (0.995 sec/step)\n",
      "I0902 09:53:00.989822 139792788920128 learning.py:507] global step 43629: loss = 0.0607 (0.979 sec/step)\n",
      "I0902 09:53:01.983885 139792788920128 learning.py:507] global step 43630: loss = 0.0685 (0.992 sec/step)\n",
      "I0902 09:53:02.975093 139792788920128 learning.py:507] global step 43631: loss = 0.1068 (0.989 sec/step)\n",
      "I0902 09:53:03.946168 139792788920128 learning.py:507] global step 43632: loss = 0.0865 (0.970 sec/step)\n",
      "I0902 09:53:04.949794 139792788920128 learning.py:507] global step 43633: loss = 0.0847 (1.002 sec/step)\n",
      "I0902 09:53:05.951113 139792788920128 learning.py:507] global step 43634: loss = 0.0974 (1.000 sec/step)\n",
      "I0902 09:53:06.927395 139792788920128 learning.py:507] global step 43635: loss = 0.0425 (0.975 sec/step)\n",
      "I0902 09:53:07.915068 139792788920128 learning.py:507] global step 43636: loss = 0.0754 (0.986 sec/step)\n",
      "I0902 09:53:08.899986 139792788920128 learning.py:507] global step 43637: loss = 0.0606 (0.983 sec/step)\n",
      "I0902 09:53:09.845701 139792788920128 learning.py:507] global step 43638: loss = 0.1565 (0.944 sec/step)\n",
      "I0902 09:53:10.821985 139792788920128 learning.py:507] global step 43639: loss = 0.0548 (0.975 sec/step)\n",
      "I0902 09:53:11.810514 139792788920128 learning.py:507] global step 43640: loss = 0.0882 (0.987 sec/step)\n",
      "I0902 09:53:12.791276 139792788920128 learning.py:507] global step 43641: loss = 0.1353 (0.979 sec/step)\n",
      "I0902 09:53:13.787237 139792788920128 learning.py:507] global step 43642: loss = 0.1467 (0.994 sec/step)\n",
      "I0902 09:53:14.759423 139792788920128 learning.py:507] global step 43643: loss = 0.1517 (0.971 sec/step)\n",
      "I0902 09:53:15.718523 139792788920128 learning.py:507] global step 43644: loss = 0.0858 (0.958 sec/step)\n",
      "I0902 09:53:16.703621 139792788920128 learning.py:507] global step 43645: loss = 0.1103 (0.984 sec/step)\n",
      "I0902 09:53:17.669895 139792788920128 learning.py:507] global step 43646: loss = 0.1477 (0.965 sec/step)\n",
      "I0902 09:53:18.642498 139792788920128 learning.py:507] global step 43647: loss = 0.3023 (0.971 sec/step)\n",
      "I0902 09:53:19.619663 139792788920128 learning.py:507] global step 43648: loss = 0.2281 (0.976 sec/step)\n",
      "I0902 09:53:20.591659 139792788920128 learning.py:507] global step 43649: loss = 0.1268 (0.971 sec/step)\n",
      "I0902 09:53:21.575237 139792788920128 learning.py:507] global step 43650: loss = 0.0736 (0.982 sec/step)\n",
      "I0902 09:53:22.528483 139792788920128 learning.py:507] global step 43651: loss = 0.0761 (0.952 sec/step)\n",
      "I0902 09:53:23.503651 139792788920128 learning.py:507] global step 43652: loss = 0.1340 (0.974 sec/step)\n",
      "I0902 09:53:24.460494 139792788920128 learning.py:507] global step 43653: loss = 0.1160 (0.955 sec/step)\n",
      "I0902 09:53:25.439023 139792788920128 learning.py:507] global step 43654: loss = 0.0541 (0.977 sec/step)\n",
      "I0902 09:53:26.408205 139792788920128 learning.py:507] global step 43655: loss = 0.1057 (0.968 sec/step)\n",
      "I0902 09:53:27.365980 139792788920128 learning.py:507] global step 43656: loss = 0.1625 (0.956 sec/step)\n",
      "I0902 09:53:28.332321 139792788920128 learning.py:507] global step 43657: loss = 0.1701 (0.965 sec/step)\n",
      "I0902 09:53:29.308837 139792788920128 learning.py:507] global step 43658: loss = 0.1515 (0.975 sec/step)\n",
      "I0902 09:53:30.284260 139792788920128 learning.py:507] global step 43659: loss = 0.0572 (0.974 sec/step)\n",
      "I0902 09:53:31.282515 139792788920128 learning.py:507] global step 43660: loss = 0.1650 (0.997 sec/step)\n",
      "I0902 09:53:32.267932 139792788920128 learning.py:507] global step 43661: loss = 0.1433 (0.984 sec/step)\n",
      "I0902 09:53:33.238827 139792788920128 learning.py:507] global step 43662: loss = 0.1220 (0.969 sec/step)\n",
      "I0902 09:53:34.229043 139792788920128 learning.py:507] global step 43663: loss = 0.1020 (0.988 sec/step)\n",
      "I0902 09:53:35.210402 139792788920128 learning.py:507] global step 43664: loss = 0.1736 (0.980 sec/step)\n",
      "I0902 09:53:36.174544 139792788920128 learning.py:507] global step 43665: loss = 0.0639 (0.962 sec/step)\n",
      "I0902 09:53:37.120539 139792788920128 learning.py:507] global step 43666: loss = 0.1307 (0.944 sec/step)\n",
      "I0902 09:53:38.097329 139792788920128 learning.py:507] global step 43667: loss = 0.1017 (0.975 sec/step)\n",
      "I0902 09:53:39.065369 139792788920128 learning.py:507] global step 43668: loss = 0.1466 (0.966 sec/step)\n",
      "I0902 09:53:40.046498 139792788920128 learning.py:507] global step 43669: loss = 0.0632 (0.980 sec/step)\n",
      "I0902 09:53:40.995531 139792788920128 learning.py:507] global step 43670: loss = 0.1364 (0.947 sec/step)\n",
      "I0902 09:53:41.969595 139792788920128 learning.py:507] global step 43671: loss = 0.1003 (0.972 sec/step)\n",
      "I0902 09:53:42.935379 139792788920128 learning.py:507] global step 43672: loss = 0.1068 (0.964 sec/step)\n",
      "I0902 09:53:43.921670 139792788920128 learning.py:507] global step 43673: loss = 0.0693 (0.985 sec/step)\n",
      "I0902 09:53:44.902675 139792788920128 learning.py:507] global step 43674: loss = 0.1542 (0.979 sec/step)\n",
      "I0902 09:53:45.861768 139792788920128 learning.py:507] global step 43675: loss = 0.0475 (0.957 sec/step)\n",
      "I0902 09:53:46.844170 139792788920128 learning.py:507] global step 43676: loss = 0.1071 (0.981 sec/step)\n",
      "I0902 09:53:47.845345 139792788920128 learning.py:507] global step 43677: loss = 0.0874 (1.000 sec/step)\n",
      "I0902 09:53:48.818764 139792788920128 learning.py:507] global step 43678: loss = 0.1341 (0.972 sec/step)\n",
      "I0902 09:53:49.270389 139778953570048 supervisor.py:1117] Saving checkpoint to path data_dir/mixed_experiment/checkpoints_v2/model.ckpt\n",
      "I0902 09:53:49.916899 139792788920128 learning.py:507] global step 43679: loss = 0.1088 (1.068 sec/step)\n",
      "I0902 09:53:50.054813 139778936784640 supervisor.py:1050] Recording summary at step 43679.\n",
      "I0902 09:53:51.030561 139792788920128 learning.py:507] global step 43680: loss = 0.2803 (0.981 sec/step)\n",
      "I0902 09:53:52.005186 139792788920128 learning.py:507] global step 43681: loss = 0.1235 (0.973 sec/step)\n",
      "I0902 09:53:52.977893 139792788920128 learning.py:507] global step 43682: loss = 0.1135 (0.971 sec/step)\n",
      "I0902 09:53:53.961174 139792788920128 learning.py:507] global step 43683: loss = 0.1164 (0.982 sec/step)\n",
      "I0902 09:53:54.927952 139792788920128 learning.py:507] global step 43684: loss = 0.1121 (0.966 sec/step)\n",
      "I0902 09:53:55.927571 139792788920128 learning.py:507] global step 43685: loss = 0.2347 (0.998 sec/step)\n",
      "I0902 09:53:56.901939 139792788920128 learning.py:507] global step 43686: loss = 0.1463 (0.973 sec/step)\n",
      "I0902 09:53:57.871749 139792788920128 learning.py:507] global step 43687: loss = 0.0845 (0.968 sec/step)\n",
      "I0902 09:53:58.857867 139792788920128 learning.py:507] global step 43688: loss = 0.0748 (0.985 sec/step)\n",
      "I0902 09:53:59.847254 139792788920128 learning.py:507] global step 43689: loss = 0.1018 (0.988 sec/step)\n",
      "I0902 09:54:00.823513 139792788920128 learning.py:507] global step 43690: loss = 0.0540 (0.975 sec/step)\n",
      "I0902 09:54:01.791476 139792788920128 learning.py:507] global step 43691: loss = 0.0726 (0.966 sec/step)\n",
      "I0902 09:54:02.780416 139792788920128 learning.py:507] global step 43692: loss = 0.1780 (0.987 sec/step)\n",
      "I0902 09:54:03.756469 139792788920128 learning.py:507] global step 43693: loss = 0.1157 (0.974 sec/step)\n",
      "I0902 09:54:04.732751 139792788920128 learning.py:507] global step 43694: loss = 0.0508 (0.975 sec/step)\n",
      "I0902 09:54:05.710252 139792788920128 learning.py:507] global step 43695: loss = 0.1212 (0.976 sec/step)\n",
      "I0902 09:54:06.673454 139792788920128 learning.py:507] global step 43696: loss = 0.0807 (0.961 sec/step)\n",
      "I0902 09:54:07.640847 139792788920128 learning.py:507] global step 43697: loss = 0.0757 (0.966 sec/step)\n",
      "I0902 09:54:08.625859 139792788920128 learning.py:507] global step 43698: loss = 0.1189 (0.984 sec/step)\n",
      "I0902 09:54:09.612332 139792788920128 learning.py:507] global step 43699: loss = 0.1124 (0.985 sec/step)\n",
      "I0902 09:54:10.600757 139792788920128 learning.py:507] global step 43700: loss = 0.0879 (0.987 sec/step)\n",
      "I0902 09:54:11.578388 139792788920128 learning.py:507] global step 43701: loss = 0.2283 (0.976 sec/step)\n",
      "I0902 09:54:12.563154 139792788920128 learning.py:507] global step 43702: loss = 0.1573 (0.983 sec/step)\n",
      "I0902 09:54:13.543775 139792788920128 learning.py:507] global step 43703: loss = 0.0824 (0.979 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:54:14.522064 139792788920128 learning.py:507] global step 43704: loss = 0.0797 (0.976 sec/step)\n",
      "I0902 09:54:15.504670 139792788920128 learning.py:507] global step 43705: loss = 0.0932 (0.981 sec/step)\n",
      "I0902 09:54:16.513423 139792788920128 learning.py:507] global step 43706: loss = 0.1118 (1.007 sec/step)\n",
      "I0902 09:54:17.489965 139792788920128 learning.py:507] global step 43707: loss = 0.1316 (0.975 sec/step)\n",
      "I0902 09:54:18.503099 139792788920128 learning.py:507] global step 43708: loss = 0.0517 (1.012 sec/step)\n",
      "I0902 09:54:19.506445 139792788920128 learning.py:507] global step 43709: loss = 0.0598 (1.002 sec/step)\n",
      "I0902 09:54:20.508423 139792788920128 learning.py:507] global step 43710: loss = 0.1317 (1.000 sec/step)\n",
      "I0902 09:54:21.484840 139792788920128 learning.py:507] global step 43711: loss = 0.1123 (0.975 sec/step)\n",
      "I0902 09:54:22.457730 139792788920128 learning.py:507] global step 43712: loss = 0.0598 (0.971 sec/step)\n",
      "I0902 09:54:23.423171 139792788920128 learning.py:507] global step 43713: loss = 0.1645 (0.964 sec/step)\n",
      "I0902 09:54:24.403705 139792788920128 learning.py:507] global step 43714: loss = 0.1356 (0.979 sec/step)\n",
      "I0902 09:54:25.424849 139792788920128 learning.py:507] global step 43715: loss = 0.0792 (1.020 sec/step)\n",
      "I0902 09:54:26.409996 139792788920128 learning.py:507] global step 43716: loss = 0.1522 (0.984 sec/step)\n",
      "I0902 09:54:27.406016 139792788920128 learning.py:507] global step 43717: loss = 0.2330 (0.995 sec/step)\n",
      "I0902 09:54:28.376076 139792788920128 learning.py:507] global step 43718: loss = 0.0830 (0.968 sec/step)\n",
      "I0902 09:54:29.366129 139792788920128 learning.py:507] global step 43719: loss = 0.0522 (0.988 sec/step)\n",
      "I0902 09:54:30.361336 139792788920128 learning.py:507] global step 43720: loss = 0.0920 (0.994 sec/step)\n",
      "I0902 09:54:31.316370 139792788920128 learning.py:507] global step 43721: loss = 0.0713 (0.953 sec/step)\n",
      "I0902 09:54:32.288579 139792788920128 learning.py:507] global step 43722: loss = 0.0689 (0.971 sec/step)\n",
      "I0902 09:54:33.252810 139792788920128 learning.py:507] global step 43723: loss = 0.0790 (0.963 sec/step)\n",
      "I0902 09:54:34.236947 139792788920128 learning.py:507] global step 43724: loss = 0.0763 (0.982 sec/step)\n",
      "I0902 09:54:35.205189 139792788920128 learning.py:507] global step 43725: loss = 0.1345 (0.967 sec/step)\n",
      "I0902 09:54:36.176047 139792788920128 learning.py:507] global step 43726: loss = 0.2818 (0.969 sec/step)\n",
      "I0902 09:54:37.182247 139792788920128 learning.py:507] global step 43727: loss = 0.1497 (1.005 sec/step)\n",
      "I0902 09:54:38.151616 139792788920128 learning.py:507] global step 43728: loss = 0.0871 (0.968 sec/step)\n",
      "I0902 09:54:39.124585 139792788920128 learning.py:507] global step 43729: loss = 0.0515 (0.971 sec/step)\n",
      "I0902 09:54:40.074786 139792788920128 learning.py:507] global step 43730: loss = 0.2275 (0.949 sec/step)\n",
      "I0902 09:54:41.045356 139792788920128 learning.py:507] global step 43731: loss = 0.1143 (0.969 sec/step)\n",
      "I0902 09:54:42.045930 139792788920128 learning.py:507] global step 43732: loss = 0.0834 (0.999 sec/step)\n",
      "I0902 09:54:43.057780 139792788920128 learning.py:507] global step 43733: loss = 0.2740 (1.010 sec/step)\n",
      "I0902 09:54:44.039492 139792788920128 learning.py:507] global step 43734: loss = 0.0966 (0.980 sec/step)\n",
      "I0902 09:54:45.017289 139792788920128 learning.py:507] global step 43735: loss = 0.2038 (0.976 sec/step)\n",
      "I0902 09:54:45.992690 139792788920128 learning.py:507] global step 43736: loss = 0.0983 (0.974 sec/step)\n",
      "I0902 09:54:46.959466 139792788920128 learning.py:507] global step 43737: loss = 0.1754 (0.965 sec/step)\n",
      "I0902 09:54:47.942765 139792788920128 learning.py:507] global step 43738: loss = 0.1024 (0.982 sec/step)\n",
      "I0902 09:54:48.909024 139792788920128 learning.py:507] global step 43739: loss = 0.1733 (0.965 sec/step)\n",
      "I0902 09:54:49.882362 139792788920128 learning.py:507] global step 43740: loss = 0.1216 (0.972 sec/step)\n",
      "I0902 09:54:50.852395 139792788920128 learning.py:507] global step 43741: loss = 0.0806 (0.969 sec/step)\n",
      "I0902 09:54:51.824779 139792788920128 learning.py:507] global step 43742: loss = 0.0851 (0.971 sec/step)\n",
      "I0902 09:54:52.800222 139792788920128 learning.py:507] global step 43743: loss = 0.2500 (0.974 sec/step)\n",
      "I0902 09:54:53.781210 139792788920128 learning.py:507] global step 43744: loss = 0.1610 (0.979 sec/step)\n",
      "I0902 09:54:54.756250 139792788920128 learning.py:507] global step 43745: loss = 0.0816 (0.973 sec/step)\n",
      "I0902 09:54:55.743564 139792788920128 learning.py:507] global step 43746: loss = 0.1507 (0.986 sec/step)\n",
      "I0902 09:54:56.701869 139792788920128 learning.py:507] global step 43747: loss = 0.0849 (0.957 sec/step)\n",
      "I0902 09:54:57.668719 139792788920128 learning.py:507] global step 43748: loss = 0.1534 (0.965 sec/step)\n",
      "I0902 09:54:58.650498 139792788920128 learning.py:507] global step 43749: loss = 0.1288 (0.980 sec/step)\n",
      "I0902 09:54:59.642120 139792788920128 learning.py:507] global step 43750: loss = 0.2752 (0.990 sec/step)\n",
      "I0902 09:55:00.618115 139792788920128 learning.py:507] global step 43751: loss = 0.0742 (0.974 sec/step)\n",
      "I0902 09:55:01.593304 139792788920128 learning.py:507] global step 43752: loss = 0.0877 (0.974 sec/step)\n",
      "I0902 09:55:02.582498 139792788920128 learning.py:507] global step 43753: loss = 0.1101 (0.987 sec/step)\n",
      "I0902 09:55:03.563592 139792788920128 learning.py:507] global step 43754: loss = 0.0773 (0.979 sec/step)\n",
      "I0902 09:55:04.542784 139792788920128 learning.py:507] global step 43755: loss = 0.0594 (0.977 sec/step)\n",
      "I0902 09:55:05.525298 139792788920128 learning.py:507] global step 43756: loss = 0.0512 (0.981 sec/step)\n",
      "I0902 09:55:06.502481 139792788920128 learning.py:507] global step 43757: loss = 0.1270 (0.976 sec/step)\n",
      "I0902 09:55:07.483856 139792788920128 learning.py:507] global step 43758: loss = 0.0903 (0.980 sec/step)\n",
      "I0902 09:55:08.477367 139792788920128 learning.py:507] global step 43759: loss = 0.0760 (0.992 sec/step)\n",
      "I0902 09:55:09.456933 139792788920128 learning.py:507] global step 43760: loss = 0.0845 (0.978 sec/step)\n",
      "I0902 09:55:10.416157 139792788920128 learning.py:507] global step 43761: loss = 0.1170 (0.958 sec/step)\n",
      "I0902 09:55:11.416614 139792788920128 learning.py:507] global step 43762: loss = 0.1413 (0.999 sec/step)\n",
      "I0902 09:55:12.414189 139792788920128 learning.py:507] global step 43763: loss = 0.1374 (0.996 sec/step)\n",
      "I0902 09:55:13.392356 139792788920128 learning.py:507] global step 43764: loss = 0.0770 (0.977 sec/step)\n",
      "I0902 09:55:14.399253 139792788920128 learning.py:507] global step 43765: loss = 0.1287 (1.005 sec/step)\n",
      "I0902 09:55:15.385519 139792788920128 learning.py:507] global step 43766: loss = 0.2718 (0.985 sec/step)\n",
      "I0902 09:55:16.353364 139792788920128 learning.py:507] global step 43767: loss = 0.1256 (0.966 sec/step)\n",
      "I0902 09:55:17.340217 139792788920128 learning.py:507] global step 43768: loss = 0.1382 (0.985 sec/step)\n",
      "I0902 09:55:18.321612 139792788920128 learning.py:507] global step 43769: loss = 0.1755 (0.980 sec/step)\n",
      "I0902 09:55:19.337357 139792788920128 learning.py:507] global step 43770: loss = 0.2890 (1.014 sec/step)\n",
      "I0902 09:55:20.336360 139792788920128 learning.py:507] global step 43771: loss = 0.1247 (0.997 sec/step)\n",
      "I0902 09:55:21.323140 139792788920128 learning.py:507] global step 43772: loss = 0.0966 (0.985 sec/step)\n",
      "I0902 09:55:22.297751 139792788920128 learning.py:507] global step 43773: loss = 0.0879 (0.973 sec/step)\n",
      "I0902 09:55:23.277355 139792788920128 learning.py:507] global step 43774: loss = 0.1447 (0.978 sec/step)\n",
      "I0902 09:55:24.257744 139792788920128 learning.py:507] global step 43775: loss = 0.0602 (0.979 sec/step)\n",
      "I0902 09:55:25.233440 139792788920128 learning.py:507] global step 43776: loss = 0.0850 (0.974 sec/step)\n",
      "I0902 09:55:26.218724 139792788920128 learning.py:507] global step 43777: loss = 0.1203 (0.984 sec/step)\n",
      "I0902 09:55:27.199474 139792788920128 learning.py:507] global step 43778: loss = 0.0999 (0.980 sec/step)\n",
      "I0902 09:55:28.162084 139792788920128 learning.py:507] global step 43779: loss = 0.0717 (0.961 sec/step)\n",
      "I0902 09:55:29.122920 139792788920128 learning.py:507] global step 43780: loss = 0.1459 (0.959 sec/step)\n",
      "I0902 09:55:30.097728 139792788920128 learning.py:507] global step 43781: loss = 0.1463 (0.973 sec/step)\n",
      "I0902 09:55:31.090540 139792788920128 learning.py:507] global step 43782: loss = 0.1119 (0.992 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:55:32.076180 139792788920128 learning.py:507] global step 43783: loss = 0.0852 (0.984 sec/step)\n",
      "I0902 09:55:33.072843 139792788920128 learning.py:507] global step 43784: loss = 0.0906 (0.995 sec/step)\n",
      "I0902 09:55:34.057742 139792788920128 learning.py:507] global step 43785: loss = 0.1231 (0.983 sec/step)\n",
      "I0902 09:55:35.010219 139792788920128 learning.py:507] global step 43786: loss = 0.1843 (0.951 sec/step)\n",
      "I0902 09:55:35.984052 139792788920128 learning.py:507] global step 43787: loss = 0.1184 (0.972 sec/step)\n",
      "I0902 09:55:36.943941 139792788920128 learning.py:507] global step 43788: loss = 0.1073 (0.958 sec/step)\n",
      "I0902 09:55:37.907976 139792788920128 learning.py:507] global step 43789: loss = 0.1261 (0.962 sec/step)\n",
      "I0902 09:55:38.882879 139792788920128 learning.py:507] global step 43790: loss = 0.3002 (0.973 sec/step)\n",
      "I0902 09:55:39.861508 139792788920128 learning.py:507] global step 43791: loss = 0.1439 (0.977 sec/step)\n",
      "I0902 09:55:40.832717 139792788920128 learning.py:507] global step 43792: loss = 0.0717 (0.969 sec/step)\n",
      "I0902 09:55:41.829125 139792788920128 learning.py:507] global step 43793: loss = 0.1764 (0.995 sec/step)\n",
      "I0902 09:55:42.812691 139792788920128 learning.py:507] global step 43794: loss = 0.1482 (0.982 sec/step)\n",
      "I0902 09:55:43.768584 139792788920128 learning.py:507] global step 43795: loss = 0.1293 (0.954 sec/step)\n",
      "I0902 09:55:44.763810 139792788920128 learning.py:507] global step 43796: loss = 0.0745 (0.994 sec/step)\n",
      "I0902 09:55:45.748298 139792788920128 learning.py:507] global step 43797: loss = 0.1802 (0.983 sec/step)\n",
      "I0902 09:55:46.723533 139792788920128 learning.py:507] global step 43798: loss = 0.1660 (0.974 sec/step)\n",
      "I0902 09:55:47.701814 139792788920128 learning.py:507] global step 43799: loss = 0.1535 (0.977 sec/step)\n",
      "I0902 09:55:48.688534 139792788920128 learning.py:507] global step 43800: loss = 0.0883 (0.985 sec/step)\n",
      "I0902 09:55:49.811356 139792788920128 learning.py:507] global step 43801: loss = 0.0920 (1.117 sec/step)\n",
      "I0902 09:55:50.130121 139778936784640 supervisor.py:1050] Recording summary at step 43801.\n",
      "I0902 09:55:50.924541 139792788920128 learning.py:507] global step 43802: loss = 0.0638 (1.109 sec/step)\n",
      "I0902 09:55:51.910569 139792788920128 learning.py:507] global step 43803: loss = 0.1669 (0.985 sec/step)\n",
      "I0902 09:55:52.876264 139792788920128 learning.py:507] global step 43804: loss = 0.0543 (0.964 sec/step)\n",
      "I0902 09:55:53.851812 139792788920128 learning.py:507] global step 43805: loss = 0.1054 (0.974 sec/step)\n",
      "I0902 09:55:54.811704 139792788920128 learning.py:507] global step 43806: loss = 0.1330 (0.958 sec/step)\n",
      "I0902 09:55:55.791723 139792788920128 learning.py:507] global step 43807: loss = 0.1356 (0.978 sec/step)\n",
      "I0902 09:55:56.750938 139792788920128 learning.py:507] global step 43808: loss = 0.2016 (0.958 sec/step)\n",
      "I0902 09:55:57.740175 139792788920128 learning.py:507] global step 43809: loss = 0.1121 (0.988 sec/step)\n",
      "I0902 09:55:58.716844 139792788920128 learning.py:507] global step 43810: loss = 0.3404 (0.975 sec/step)\n",
      "I0902 09:55:59.698046 139792788920128 learning.py:507] global step 43811: loss = 0.1068 (0.980 sec/step)\n",
      "I0902 09:56:00.685441 139792788920128 learning.py:507] global step 43812: loss = 0.0785 (0.986 sec/step)\n",
      "I0902 09:56:01.657634 139792788920128 learning.py:507] global step 43813: loss = 0.0973 (0.971 sec/step)\n",
      "I0902 09:56:02.648340 139792788920128 learning.py:507] global step 43814: loss = 0.1569 (0.989 sec/step)\n",
      "I0902 09:56:03.630245 139792788920128 learning.py:507] global step 43815: loss = 0.0772 (0.980 sec/step)\n",
      "I0902 09:56:04.614038 139792788920128 learning.py:507] global step 43816: loss = 0.1258 (0.982 sec/step)\n",
      "I0902 09:56:05.602830 139792788920128 learning.py:507] global step 43817: loss = 0.0976 (0.987 sec/step)\n",
      "I0902 09:56:06.554767 139792788920128 learning.py:507] global step 43818: loss = 0.1203 (0.950 sec/step)\n",
      "I0902 09:56:07.527616 139792788920128 learning.py:507] global step 43819: loss = 0.0562 (0.971 sec/step)\n",
      "I0902 09:56:08.499393 139792788920128 learning.py:507] global step 43820: loss = 0.1235 (0.970 sec/step)\n",
      "I0902 09:56:09.481422 139792788920128 learning.py:507] global step 43821: loss = 0.1142 (0.981 sec/step)\n",
      "I0902 09:56:10.465421 139792788920128 learning.py:507] global step 43822: loss = 0.2677 (0.982 sec/step)\n",
      "I0902 09:56:11.454379 139792788920128 learning.py:507] global step 43823: loss = 0.1012 (0.987 sec/step)\n",
      "I0902 09:56:12.447910 139792788920128 learning.py:507] global step 43824: loss = 0.1476 (0.992 sec/step)\n",
      "I0902 09:56:13.425981 139792788920128 learning.py:507] global step 43825: loss = 0.0808 (0.977 sec/step)\n",
      "I0902 09:56:14.387808 139792788920128 learning.py:507] global step 43826: loss = 0.1394 (0.960 sec/step)\n",
      "I0902 09:56:15.357785 139792788920128 learning.py:507] global step 43827: loss = 0.0738 (0.968 sec/step)\n",
      "I0902 09:56:16.344306 139792788920128 learning.py:507] global step 43828: loss = 0.0671 (0.985 sec/step)\n",
      "I0902 09:56:17.316898 139792788920128 learning.py:507] global step 43829: loss = 0.1532 (0.971 sec/step)\n",
      "I0902 09:56:18.306150 139792788920128 learning.py:507] global step 43830: loss = 0.1561 (0.988 sec/step)\n",
      "I0902 09:56:19.305056 139792788920128 learning.py:507] global step 43831: loss = 0.0970 (0.997 sec/step)\n",
      "I0902 09:56:20.303491 139792788920128 learning.py:507] global step 43832: loss = 0.1491 (0.997 sec/step)\n",
      "I0902 09:56:21.280556 139792788920128 learning.py:507] global step 43833: loss = 0.0598 (0.975 sec/step)\n",
      "I0902 09:56:22.234770 139792788920128 learning.py:507] global step 43834: loss = 0.0806 (0.952 sec/step)\n",
      "I0902 09:56:23.220475 139792788920128 learning.py:507] global step 43835: loss = 0.1191 (0.984 sec/step)\n",
      "I0902 09:56:24.205115 139792788920128 learning.py:507] global step 43836: loss = 0.0726 (0.983 sec/step)\n",
      "I0902 09:56:25.198962 139792788920128 learning.py:507] global step 43837: loss = 0.1812 (0.992 sec/step)\n",
      "I0902 09:56:26.176500 139792788920128 learning.py:507] global step 43838: loss = 0.0973 (0.976 sec/step)\n",
      "I0902 09:56:27.158445 139792788920128 learning.py:507] global step 43839: loss = 0.0881 (0.980 sec/step)\n",
      "I0902 09:56:28.121719 139792788920128 learning.py:507] global step 43840: loss = 0.0782 (0.962 sec/step)\n",
      "I0902 09:56:29.088624 139792788920128 learning.py:507] global step 43841: loss = 0.2176 (0.965 sec/step)\n",
      "I0902 09:56:30.056774 139792788920128 learning.py:507] global step 43842: loss = 0.0667 (0.966 sec/step)\n",
      "I0902 09:56:31.027279 139792788920128 learning.py:507] global step 43843: loss = 0.1978 (0.969 sec/step)\n",
      "I0902 09:56:31.992609 139792788920128 learning.py:507] global step 43844: loss = 0.0631 (0.964 sec/step)\n",
      "I0902 09:56:32.969784 139792788920128 learning.py:507] global step 43845: loss = 0.1879 (0.975 sec/step)\n",
      "I0902 09:56:33.943330 139792788920128 learning.py:507] global step 43846: loss = 0.1493 (0.972 sec/step)\n",
      "I0902 09:56:34.916774 139792788920128 learning.py:507] global step 43847: loss = 0.2099 (0.972 sec/step)\n",
      "I0902 09:56:35.897830 139792788920128 learning.py:507] global step 43848: loss = 0.0953 (0.979 sec/step)\n",
      "I0902 09:56:36.871170 139792788920128 learning.py:507] global step 43849: loss = 0.1569 (0.972 sec/step)\n",
      "I0902 09:56:37.857765 139792788920128 learning.py:507] global step 43850: loss = 0.1186 (0.985 sec/step)\n",
      "I0902 09:56:38.822228 139792788920128 learning.py:507] global step 43851: loss = 0.0621 (0.963 sec/step)\n",
      "I0902 09:56:39.809160 139792788920128 learning.py:507] global step 43852: loss = 0.0978 (0.985 sec/step)\n",
      "I0902 09:56:40.788273 139792788920128 learning.py:507] global step 43853: loss = 0.1127 (0.978 sec/step)\n",
      "I0902 09:56:41.772607 139792788920128 learning.py:507] global step 43854: loss = 0.1611 (0.983 sec/step)\n",
      "I0902 09:56:42.771698 139792788920128 learning.py:507] global step 43855: loss = 0.1118 (0.997 sec/step)\n",
      "I0902 09:56:43.759550 139792788920128 learning.py:507] global step 43856: loss = 0.0949 (0.986 sec/step)\n",
      "I0902 09:56:44.739733 139792788920128 learning.py:507] global step 43857: loss = 0.1496 (0.978 sec/step)\n",
      "I0902 09:56:45.751539 139792788920128 learning.py:507] global step 43858: loss = 0.2212 (1.010 sec/step)\n",
      "I0902 09:56:46.748137 139792788920128 learning.py:507] global step 43859: loss = 0.0478 (0.995 sec/step)\n",
      "I0902 09:56:47.728078 139792788920128 learning.py:507] global step 43860: loss = 0.1219 (0.979 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:56:48.732930 139792788920128 learning.py:507] global step 43861: loss = 0.0633 (1.003 sec/step)\n",
      "I0902 09:56:49.697947 139792788920128 learning.py:507] global step 43862: loss = 0.1271 (0.964 sec/step)\n",
      "I0902 09:56:50.660760 139792788920128 learning.py:507] global step 43863: loss = 0.4078 (0.961 sec/step)\n",
      "I0902 09:56:51.639494 139792788920128 learning.py:507] global step 43864: loss = 0.1223 (0.977 sec/step)\n",
      "I0902 09:56:52.634882 139792788920128 learning.py:507] global step 43865: loss = 0.1899 (0.994 sec/step)\n",
      "I0902 09:56:53.613506 139792788920128 learning.py:507] global step 43866: loss = 0.0497 (0.977 sec/step)\n",
      "I0902 09:56:54.593429 139792788920128 learning.py:507] global step 43867: loss = 0.1665 (0.978 sec/step)\n",
      "I0902 09:56:55.555643 139792788920128 learning.py:507] global step 43868: loss = 0.1070 (0.961 sec/step)\n",
      "I0902 09:56:56.523044 139792788920128 learning.py:507] global step 43869: loss = 0.1494 (0.966 sec/step)\n",
      "I0902 09:56:57.499794 139792788920128 learning.py:507] global step 43870: loss = 0.1212 (0.975 sec/step)\n",
      "I0902 09:56:58.477196 139792788920128 learning.py:507] global step 43871: loss = 0.1240 (0.976 sec/step)\n",
      "I0902 09:56:59.440814 139792788920128 learning.py:507] global step 43872: loss = 0.1235 (0.962 sec/step)\n",
      "I0902 09:57:00.418393 139792788920128 learning.py:507] global step 43873: loss = 0.0732 (0.976 sec/step)\n",
      "I0902 09:57:01.414111 139792788920128 learning.py:507] global step 43874: loss = 0.1343 (0.994 sec/step)\n",
      "I0902 09:57:02.378880 139792788920128 learning.py:507] global step 43875: loss = 0.0786 (0.963 sec/step)\n",
      "I0902 09:57:03.367533 139792788920128 learning.py:507] global step 43876: loss = 0.1441 (0.987 sec/step)\n",
      "I0902 09:57:04.341946 139792788920128 learning.py:507] global step 43877: loss = 0.1893 (0.973 sec/step)\n",
      "I0902 09:57:05.307564 139792788920128 learning.py:507] global step 43878: loss = 0.2390 (0.964 sec/step)\n",
      "I0902 09:57:06.288664 139792788920128 learning.py:507] global step 43879: loss = 0.2469 (0.979 sec/step)\n",
      "I0902 09:57:07.289321 139792788920128 learning.py:507] global step 43880: loss = 0.0954 (0.999 sec/step)\n",
      "I0902 09:57:08.260233 139792788920128 learning.py:507] global step 43881: loss = 0.4854 (0.969 sec/step)\n",
      "I0902 09:57:09.246422 139792788920128 learning.py:507] global step 43882: loss = 0.1021 (0.985 sec/step)\n",
      "I0902 09:57:10.228410 139792788920128 learning.py:507] global step 43883: loss = 0.2244 (0.980 sec/step)\n",
      "I0902 09:57:11.193466 139792788920128 learning.py:507] global step 43884: loss = 0.0913 (0.963 sec/step)\n",
      "I0902 09:57:12.179088 139792788920128 learning.py:507] global step 43885: loss = 0.1159 (0.984 sec/step)\n",
      "I0902 09:57:13.133274 139792788920128 learning.py:507] global step 43886: loss = 0.0509 (0.952 sec/step)\n",
      "I0902 09:57:14.096900 139792788920128 learning.py:507] global step 43887: loss = 0.1412 (0.962 sec/step)\n",
      "I0902 09:57:15.055045 139792788920128 learning.py:507] global step 43888: loss = 0.1690 (0.956 sec/step)\n",
      "I0902 09:57:16.020774 139792788920128 learning.py:507] global step 43889: loss = 0.0422 (0.964 sec/step)\n",
      "I0902 09:57:16.993759 139792788920128 learning.py:507] global step 43890: loss = 0.2420 (0.971 sec/step)\n",
      "I0902 09:57:17.962736 139792788920128 learning.py:507] global step 43891: loss = 0.1522 (0.967 sec/step)\n",
      "I0902 09:57:18.927728 139792788920128 learning.py:507] global step 43892: loss = 0.1138 (0.963 sec/step)\n",
      "I0902 09:57:19.912923 139792788920128 learning.py:507] global step 43893: loss = 0.0665 (0.983 sec/step)\n",
      "I0902 09:57:20.906181 139792788920128 learning.py:507] global step 43894: loss = 0.0942 (0.992 sec/step)\n",
      "I0902 09:57:21.877201 139792788920128 learning.py:507] global step 43895: loss = 0.1968 (0.969 sec/step)\n",
      "I0902 09:57:22.841530 139792788920128 learning.py:507] global step 43896: loss = 0.3097 (0.963 sec/step)\n",
      "I0902 09:57:23.825387 139792788920128 learning.py:507] global step 43897: loss = 0.1003 (0.982 sec/step)\n",
      "I0902 09:57:24.811716 139792788920128 learning.py:507] global step 43898: loss = 0.0569 (0.985 sec/step)\n",
      "I0902 09:57:25.780256 139792788920128 learning.py:507] global step 43899: loss = 0.0918 (0.967 sec/step)\n",
      "I0902 09:57:26.776405 139792788920128 learning.py:507] global step 43900: loss = 0.1421 (0.994 sec/step)\n",
      "I0902 09:57:27.776595 139792788920128 learning.py:507] global step 43901: loss = 0.1618 (0.998 sec/step)\n",
      "I0902 09:57:28.755396 139792788920128 learning.py:507] global step 43902: loss = 0.1348 (0.977 sec/step)\n",
      "I0902 09:57:29.715602 139792788920128 learning.py:507] global step 43903: loss = 0.1212 (0.958 sec/step)\n",
      "I0902 09:57:30.709194 139792788920128 learning.py:507] global step 43904: loss = 0.1568 (0.992 sec/step)\n",
      "I0902 09:57:31.688320 139792788920128 learning.py:507] global step 43905: loss = 0.1751 (0.978 sec/step)\n",
      "I0902 09:57:32.650041 139792788920128 learning.py:507] global step 43906: loss = 0.0732 (0.960 sec/step)\n",
      "I0902 09:57:33.631757 139792788920128 learning.py:507] global step 43907: loss = 0.0764 (0.980 sec/step)\n",
      "I0902 09:57:34.613281 139792788920128 learning.py:507] global step 43908: loss = 0.1138 (0.980 sec/step)\n",
      "I0902 09:57:35.587433 139792788920128 learning.py:507] global step 43909: loss = 0.0870 (0.972 sec/step)\n",
      "I0902 09:57:36.558643 139792788920128 learning.py:507] global step 43910: loss = 0.1065 (0.970 sec/step)\n",
      "I0902 09:57:37.534632 139792788920128 learning.py:507] global step 43911: loss = 0.0886 (0.974 sec/step)\n",
      "I0902 09:57:38.493522 139792788920128 learning.py:507] global step 43912: loss = 0.0362 (0.957 sec/step)\n",
      "I0902 09:57:39.473812 139792788920128 learning.py:507] global step 43913: loss = 0.1555 (0.979 sec/step)\n",
      "I0902 09:57:40.449852 139792788920128 learning.py:507] global step 43914: loss = 0.1091 (0.975 sec/step)\n",
      "I0902 09:57:41.446276 139792788920128 learning.py:507] global step 43915: loss = 0.0755 (0.995 sec/step)\n",
      "I0902 09:57:42.433807 139792788920128 learning.py:507] global step 43916: loss = 0.2433 (0.986 sec/step)\n",
      "I0902 09:57:43.407960 139792788920128 learning.py:507] global step 43917: loss = 0.1006 (0.972 sec/step)\n",
      "I0902 09:57:44.371786 139792788920128 learning.py:507] global step 43918: loss = 0.1343 (0.962 sec/step)\n",
      "I0902 09:57:45.349146 139792788920128 learning.py:507] global step 43919: loss = 0.0998 (0.975 sec/step)\n",
      "I0902 09:57:46.329385 139792788920128 learning.py:507] global step 43920: loss = 0.1923 (0.979 sec/step)\n",
      "I0902 09:57:47.323493 139792788920128 learning.py:507] global step 43921: loss = 0.1454 (0.992 sec/step)\n",
      "I0902 09:57:48.304550 139792788920128 learning.py:507] global step 43922: loss = 0.0973 (0.979 sec/step)\n",
      "I0902 09:57:49.261589 139792788920128 learning.py:507] global step 43923: loss = 0.1444 (0.955 sec/step)\n",
      "I0902 09:57:49.908978 139778936784640 supervisor.py:1050] Recording summary at step 43923.\n",
      "I0902 09:57:50.518382 139792788920128 learning.py:507] global step 43924: loss = 0.0607 (1.255 sec/step)\n",
      "I0902 09:57:51.492212 139792788920128 learning.py:507] global step 43925: loss = 0.0583 (0.972 sec/step)\n",
      "I0902 09:57:52.462345 139792788920128 learning.py:507] global step 43926: loss = 0.1616 (0.968 sec/step)\n",
      "I0902 09:57:53.453779 139792788920128 learning.py:507] global step 43927: loss = 0.1645 (0.990 sec/step)\n",
      "I0902 09:57:54.422547 139792788920128 learning.py:507] global step 43928: loss = 0.1141 (0.967 sec/step)\n",
      "I0902 09:57:55.399366 139792788920128 learning.py:507] global step 43929: loss = 0.0511 (0.975 sec/step)\n",
      "I0902 09:57:56.362006 139792788920128 learning.py:507] global step 43930: loss = 0.0867 (0.961 sec/step)\n",
      "I0902 09:57:57.337136 139792788920128 learning.py:507] global step 43931: loss = 0.2318 (0.973 sec/step)\n",
      "I0902 09:57:58.314069 139792788920128 learning.py:507] global step 43932: loss = 0.1176 (0.975 sec/step)\n",
      "I0902 09:57:59.265085 139792788920128 learning.py:507] global step 43933: loss = 0.1406 (0.949 sec/step)\n",
      "I0902 09:58:00.239877 139792788920128 learning.py:507] global step 43934: loss = 0.1041 (0.973 sec/step)\n",
      "I0902 09:58:01.204199 139792788920128 learning.py:507] global step 43935: loss = 0.1208 (0.963 sec/step)\n",
      "I0902 09:58:02.169216 139792788920128 learning.py:507] global step 43936: loss = 0.1430 (0.964 sec/step)\n",
      "I0902 09:58:03.132763 139792788920128 learning.py:507] global step 43937: loss = 0.1905 (0.962 sec/step)\n",
      "I0902 09:58:04.090146 139792788920128 learning.py:507] global step 43938: loss = 0.0762 (0.956 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:58:05.066472 139792788920128 learning.py:507] global step 43939: loss = 0.1543 (0.975 sec/step)\n",
      "I0902 09:58:06.029304 139792788920128 learning.py:507] global step 43940: loss = 0.1543 (0.961 sec/step)\n",
      "I0902 09:58:06.993366 139792788920128 learning.py:507] global step 43941: loss = 0.0903 (0.963 sec/step)\n",
      "I0902 09:58:07.962156 139792788920128 learning.py:507] global step 43942: loss = 0.1254 (0.967 sec/step)\n",
      "I0902 09:58:08.945727 139792788920128 learning.py:507] global step 43943: loss = 0.0762 (0.982 sec/step)\n",
      "I0902 09:58:09.946800 139792788920128 learning.py:507] global step 43944: loss = 0.2369 (0.999 sec/step)\n",
      "I0902 09:58:10.909881 139792788920128 learning.py:507] global step 43945: loss = 0.1174 (0.962 sec/step)\n",
      "I0902 09:58:11.879590 139792788920128 learning.py:507] global step 43946: loss = 0.0678 (0.968 sec/step)\n",
      "I0902 09:58:12.861522 139792788920128 learning.py:507] global step 43947: loss = 0.1162 (0.980 sec/step)\n",
      "I0902 09:58:13.828394 139792788920128 learning.py:507] global step 43948: loss = 0.1402 (0.965 sec/step)\n",
      "I0902 09:58:14.811727 139792788920128 learning.py:507] global step 43949: loss = 0.1576 (0.982 sec/step)\n",
      "I0902 09:58:15.791861 139792788920128 learning.py:507] global step 43950: loss = 0.1025 (0.979 sec/step)\n",
      "I0902 09:58:16.779446 139792788920128 learning.py:507] global step 43951: loss = 0.1731 (0.986 sec/step)\n",
      "I0902 09:58:17.745999 139792788920128 learning.py:507] global step 43952: loss = 0.0461 (0.965 sec/step)\n",
      "I0902 09:58:18.739021 139792788920128 learning.py:507] global step 43953: loss = 0.1275 (0.991 sec/step)\n",
      "I0902 09:58:19.705524 139792788920128 learning.py:507] global step 43954: loss = 0.0576 (0.965 sec/step)\n",
      "I0902 09:58:20.693340 139792788920128 learning.py:507] global step 43955: loss = 0.0704 (0.986 sec/step)\n",
      "I0902 09:58:21.673880 139792788920128 learning.py:507] global step 43956: loss = 0.1925 (0.979 sec/step)\n",
      "I0902 09:58:22.655124 139792788920128 learning.py:507] global step 43957: loss = 0.0589 (0.980 sec/step)\n",
      "I0902 09:58:23.644270 139792788920128 learning.py:507] global step 43958: loss = 0.1456 (0.987 sec/step)\n",
      "I0902 09:58:24.641918 139792788920128 learning.py:507] global step 43959: loss = 0.0749 (0.996 sec/step)\n",
      "I0902 09:58:25.602750 139792788920128 learning.py:507] global step 43960: loss = 0.1268 (0.959 sec/step)\n",
      "I0902 09:58:26.586712 139792788920128 learning.py:507] global step 43961: loss = 0.1129 (0.982 sec/step)\n",
      "I0902 09:58:27.558346 139792788920128 learning.py:507] global step 43962: loss = 0.1160 (0.970 sec/step)\n",
      "I0902 09:58:28.536643 139792788920128 learning.py:507] global step 43963: loss = 0.0775 (0.977 sec/step)\n",
      "I0902 09:58:29.518612 139792788920128 learning.py:507] global step 43964: loss = 0.2586 (0.980 sec/step)\n",
      "I0902 09:58:30.493075 139792788920128 learning.py:507] global step 43965: loss = 0.1902 (0.973 sec/step)\n",
      "I0902 09:58:31.477024 139792788920128 learning.py:507] global step 43966: loss = 0.1307 (0.982 sec/step)\n",
      "I0902 09:58:32.441062 139792788920128 learning.py:507] global step 43967: loss = 0.0955 (0.962 sec/step)\n",
      "I0902 09:58:33.403616 139792788920128 learning.py:507] global step 43968: loss = 0.1063 (0.961 sec/step)\n",
      "I0902 09:58:34.404298 139792788920128 learning.py:507] global step 43969: loss = 0.1645 (0.999 sec/step)\n",
      "I0902 09:58:35.404851 139792788920128 learning.py:507] global step 43970: loss = 0.1046 (0.999 sec/step)\n",
      "I0902 09:58:36.357024 139792788920128 learning.py:507] global step 43971: loss = 0.2360 (0.951 sec/step)\n",
      "I0902 09:58:37.326906 139792788920128 learning.py:507] global step 43972: loss = 0.1171 (0.968 sec/step)\n",
      "I0902 09:58:38.311765 139792788920128 learning.py:507] global step 43973: loss = 0.0603 (0.983 sec/step)\n",
      "I0902 09:58:39.284409 139792788920128 learning.py:507] global step 43974: loss = 0.0963 (0.971 sec/step)\n",
      "I0902 09:58:40.269275 139792788920128 learning.py:507] global step 43975: loss = 0.0865 (0.983 sec/step)\n",
      "I0902 09:58:41.268951 139792788920128 learning.py:507] global step 43976: loss = 0.0912 (0.998 sec/step)\n",
      "I0902 09:58:42.273530 139792788920128 learning.py:507] global step 43977: loss = 0.1135 (1.003 sec/step)\n",
      "I0902 09:58:43.254083 139792788920128 learning.py:507] global step 43978: loss = 0.0549 (0.979 sec/step)\n",
      "I0902 09:58:44.240596 139792788920128 learning.py:507] global step 43979: loss = 0.1884 (0.985 sec/step)\n",
      "I0902 09:58:45.203397 139792788920128 learning.py:507] global step 43980: loss = 0.0760 (0.961 sec/step)\n",
      "I0902 09:58:46.194058 139792788920128 learning.py:507] global step 43981: loss = 0.1633 (0.989 sec/step)\n",
      "I0902 09:58:47.161112 139792788920128 learning.py:507] global step 43982: loss = 0.1038 (0.965 sec/step)\n",
      "I0902 09:58:48.125771 139792788920128 learning.py:507] global step 43983: loss = 0.0838 (0.963 sec/step)\n",
      "I0902 09:58:49.105446 139792788920128 learning.py:507] global step 43984: loss = 0.0643 (0.978 sec/step)\n",
      "I0902 09:58:50.093091 139792788920128 learning.py:507] global step 43985: loss = 0.1671 (0.986 sec/step)\n",
      "I0902 09:58:51.062020 139792788920128 learning.py:507] global step 43986: loss = 0.0752 (0.967 sec/step)\n",
      "I0902 09:58:52.031136 139792788920128 learning.py:507] global step 43987: loss = 0.0827 (0.968 sec/step)\n",
      "I0902 09:58:52.993142 139792788920128 learning.py:507] global step 43988: loss = 0.0783 (0.960 sec/step)\n",
      "I0902 09:58:53.965534 139792788920128 learning.py:507] global step 43989: loss = 0.1082 (0.971 sec/step)\n",
      "I0902 09:58:54.920182 139792788920128 learning.py:507] global step 43990: loss = 0.0744 (0.953 sec/step)\n",
      "I0902 09:58:55.879594 139792788920128 learning.py:507] global step 43991: loss = 0.1071 (0.958 sec/step)\n",
      "I0902 09:58:56.850765 139792788920128 learning.py:507] global step 43992: loss = 0.1068 (0.969 sec/step)\n",
      "I0902 09:58:57.828932 139792788920128 learning.py:507] global step 43993: loss = 0.1869 (0.976 sec/step)\n",
      "I0902 09:58:58.802041 139792788920128 learning.py:507] global step 43994: loss = 0.1148 (0.971 sec/step)\n",
      "I0902 09:58:59.777569 139792788920128 learning.py:507] global step 43995: loss = 0.0658 (0.974 sec/step)\n",
      "I0902 09:59:00.732759 139792788920128 learning.py:507] global step 43996: loss = 0.2065 (0.954 sec/step)\n",
      "I0902 09:59:01.705955 139792788920128 learning.py:507] global step 43997: loss = 0.1209 (0.972 sec/step)\n",
      "I0902 09:59:02.729073 139792788920128 learning.py:507] global step 43998: loss = 0.2409 (1.021 sec/step)\n",
      "I0902 09:59:03.718583 139792788920128 learning.py:507] global step 43999: loss = 0.1251 (0.988 sec/step)\n",
      "I0902 09:59:04.700285 139792788920128 learning.py:507] global step 44000: loss = 0.2147 (0.980 sec/step)\n",
      "I0902 09:59:05.678747 139792788920128 learning.py:507] global step 44001: loss = 0.3554 (0.977 sec/step)\n",
      "I0902 09:59:06.650832 139792788920128 learning.py:507] global step 44002: loss = 0.0715 (0.970 sec/step)\n",
      "I0902 09:59:07.616172 139792788920128 learning.py:507] global step 44003: loss = 0.1456 (0.964 sec/step)\n",
      "I0902 09:59:08.604077 139792788920128 learning.py:507] global step 44004: loss = 0.1383 (0.986 sec/step)\n",
      "I0902 09:59:09.576081 139792788920128 learning.py:507] global step 44005: loss = 0.1068 (0.970 sec/step)\n",
      "I0902 09:59:10.548291 139792788920128 learning.py:507] global step 44006: loss = 0.1557 (0.970 sec/step)\n",
      "I0902 09:59:11.509690 139792788920128 learning.py:507] global step 44007: loss = 0.1225 (0.960 sec/step)\n",
      "I0902 09:59:12.484205 139792788920128 learning.py:507] global step 44008: loss = 0.1402 (0.973 sec/step)\n",
      "I0902 09:59:13.487374 139792788920128 learning.py:507] global step 44009: loss = 0.2236 (1.001 sec/step)\n",
      "I0902 09:59:14.473669 139792788920128 learning.py:507] global step 44010: loss = 0.1940 (0.985 sec/step)\n",
      "I0902 09:59:15.449970 139792788920128 learning.py:507] global step 44011: loss = 0.2326 (0.975 sec/step)\n",
      "I0902 09:59:16.433181 139792788920128 learning.py:507] global step 44012: loss = 0.1796 (0.982 sec/step)\n",
      "I0902 09:59:17.397054 139792788920128 learning.py:507] global step 44013: loss = 0.0712 (0.962 sec/step)\n",
      "I0902 09:59:18.353370 139792788920128 learning.py:507] global step 44014: loss = 0.1697 (0.955 sec/step)\n",
      "I0902 09:59:19.322832 139792788920128 learning.py:507] global step 44015: loss = 0.0492 (0.968 sec/step)\n",
      "I0902 09:59:20.270717 139792788920128 learning.py:507] global step 44016: loss = 0.1183 (0.946 sec/step)\n",
      "I0902 09:59:21.234338 139792788920128 learning.py:507] global step 44017: loss = 0.1626 (0.962 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 09:59:22.215108 139792788920128 learning.py:507] global step 44018: loss = 0.1394 (0.979 sec/step)\n",
      "I0902 09:59:23.179380 139792788920128 learning.py:507] global step 44019: loss = 0.0772 (0.963 sec/step)\n",
      "I0902 09:59:24.133700 139792788920128 learning.py:507] global step 44020: loss = 0.0928 (0.953 sec/step)\n",
      "I0902 09:59:25.099724 139792788920128 learning.py:507] global step 44021: loss = 0.0619 (0.964 sec/step)\n",
      "I0902 09:59:26.063525 139792788920128 learning.py:507] global step 44022: loss = 0.0384 (0.962 sec/step)\n",
      "I0902 09:59:27.014036 139792788920128 learning.py:507] global step 44023: loss = 0.0926 (0.949 sec/step)\n",
      "I0902 09:59:27.966731 139792788920128 learning.py:507] global step 44024: loss = 0.0911 (0.951 sec/step)\n",
      "I0902 09:59:28.951680 139792788920128 learning.py:507] global step 44025: loss = 0.1478 (0.983 sec/step)\n",
      "I0902 09:59:29.928790 139792788920128 learning.py:507] global step 44026: loss = 0.1429 (0.975 sec/step)\n",
      "I0902 09:59:30.887606 139792788920128 learning.py:507] global step 44027: loss = 0.1708 (0.957 sec/step)\n",
      "I0902 09:59:31.864255 139792788920128 learning.py:507] global step 44028: loss = 0.1755 (0.975 sec/step)\n",
      "I0902 09:59:32.844136 139792788920128 learning.py:507] global step 44029: loss = 0.2176 (0.978 sec/step)\n",
      "I0902 09:59:33.802441 139792788920128 learning.py:507] global step 44030: loss = 0.1595 (0.957 sec/step)\n",
      "I0902 09:59:34.771792 139792788920128 learning.py:507] global step 44031: loss = 0.1187 (0.968 sec/step)\n",
      "I0902 09:59:35.738315 139792788920128 learning.py:507] global step 44032: loss = 0.0660 (0.965 sec/step)\n",
      "I0902 09:59:36.720599 139792788920128 learning.py:507] global step 44033: loss = 0.1002 (0.980 sec/step)\n",
      "I0902 09:59:37.663995 139792788920128 learning.py:507] global step 44034: loss = 0.0841 (0.942 sec/step)\n",
      "I0902 09:59:38.656193 139792788920128 learning.py:507] global step 44035: loss = 0.1180 (0.990 sec/step)\n",
      "I0902 09:59:39.622732 139792788920128 learning.py:507] global step 44036: loss = 0.0983 (0.965 sec/step)\n",
      "I0902 09:59:40.584546 139792788920128 learning.py:507] global step 44037: loss = 0.1289 (0.960 sec/step)\n",
      "I0902 09:59:41.560934 139792788920128 learning.py:507] global step 44038: loss = 0.0787 (0.975 sec/step)\n",
      "I0902 09:59:42.547398 139792788920128 learning.py:507] global step 44039: loss = 0.1509 (0.985 sec/step)\n",
      "I0902 09:59:43.510316 139792788920128 learning.py:507] global step 44040: loss = 0.0952 (0.961 sec/step)\n",
      "I0902 09:59:44.493275 139792788920128 learning.py:507] global step 44041: loss = 0.1635 (0.981 sec/step)\n",
      "I0902 09:59:45.456533 139792788920128 learning.py:507] global step 44042: loss = 0.0862 (0.962 sec/step)\n",
      "I0902 09:59:46.410908 139792788920128 learning.py:507] global step 44043: loss = 0.1240 (0.953 sec/step)\n",
      "I0902 09:59:47.383193 139792788920128 learning.py:507] global step 44044: loss = 0.0776 (0.971 sec/step)\n",
      "I0902 09:59:48.369424 139792788920128 learning.py:507] global step 44045: loss = 0.0665 (0.985 sec/step)\n",
      "I0902 09:59:49.357828 139792788920128 learning.py:507] global step 44046: loss = 0.2425 (0.983 sec/step)\n",
      "I0902 09:59:49.975269 139778936784640 supervisor.py:1050] Recording summary at step 44046.\n",
      "I0902 09:59:50.601802 139792788920128 learning.py:507] global step 44047: loss = 0.0729 (1.241 sec/step)\n",
      "I0902 09:59:51.554287 139792788920128 learning.py:507] global step 44048: loss = 0.3019 (0.951 sec/step)\n",
      "I0902 09:59:52.533678 139792788920128 learning.py:507] global step 44049: loss = 0.0973 (0.978 sec/step)\n",
      "I0902 09:59:53.481851 139792788920128 learning.py:507] global step 44050: loss = 0.1339 (0.947 sec/step)\n",
      "I0902 09:59:54.456823 139792788920128 learning.py:507] global step 44051: loss = 0.1843 (0.973 sec/step)\n",
      "I0902 09:59:55.411546 139792788920128 learning.py:507] global step 44052: loss = 0.0664 (0.953 sec/step)\n",
      "I0902 09:59:56.371960 139792788920128 learning.py:507] global step 44053: loss = 0.0642 (0.959 sec/step)\n",
      "I0902 09:59:57.346356 139792788920128 learning.py:507] global step 44054: loss = 0.1474 (0.973 sec/step)\n",
      "I0902 09:59:58.296679 139792788920128 learning.py:507] global step 44055: loss = 0.0751 (0.949 sec/step)\n",
      "I0902 09:59:59.310470 139792788920128 learning.py:507] global step 44056: loss = 0.1080 (1.012 sec/step)\n",
      "I0902 10:00:00.273986 139792788920128 learning.py:507] global step 44057: loss = 0.2637 (0.962 sec/step)\n",
      "I0902 10:00:01.252319 139792788920128 learning.py:507] global step 44058: loss = 0.1681 (0.977 sec/step)\n",
      "I0902 10:00:02.234278 139792788920128 learning.py:507] global step 44059: loss = 0.2389 (0.980 sec/step)\n",
      "I0902 10:00:03.202775 139792788920128 learning.py:507] global step 44060: loss = 0.0916 (0.967 sec/step)\n",
      "I0902 10:00:04.191709 139792788920128 learning.py:507] global step 44061: loss = 0.1146 (0.987 sec/step)\n",
      "I0902 10:00:05.152660 139792788920128 learning.py:507] global step 44062: loss = 0.1308 (0.959 sec/step)\n",
      "I0902 10:00:06.134650 139792788920128 learning.py:507] global step 44063: loss = 0.2348 (0.980 sec/step)\n",
      "I0902 10:00:07.093110 139792788920128 learning.py:507] global step 44064: loss = 0.0765 (0.957 sec/step)\n",
      "I0902 10:00:08.064721 139792788920128 learning.py:507] global step 44065: loss = 0.0776 (0.970 sec/step)\n",
      "I0902 10:00:09.028391 139792788920128 learning.py:507] global step 44066: loss = 0.1225 (0.962 sec/step)\n",
      "I0902 10:00:10.015428 139792788920128 learning.py:507] global step 44067: loss = 0.1121 (0.985 sec/step)\n",
      "I0902 10:00:11.003520 139792788920128 learning.py:507] global step 44068: loss = 0.0648 (0.986 sec/step)\n",
      "I0902 10:00:11.959989 139792788920128 learning.py:507] global step 44069: loss = 0.0945 (0.955 sec/step)\n",
      "I0902 10:00:12.923556 139792788920128 learning.py:507] global step 44070: loss = 0.1398 (0.962 sec/step)\n",
      "I0902 10:00:13.906186 139792788920128 learning.py:507] global step 44071: loss = 0.0755 (0.981 sec/step)\n",
      "I0902 10:00:14.870915 139792788920128 learning.py:507] global step 44072: loss = 0.0800 (0.963 sec/step)\n",
      "I0902 10:00:15.828496 139792788920128 learning.py:507] global step 44073: loss = 0.1715 (0.956 sec/step)\n",
      "I0902 10:00:16.798398 139792788920128 learning.py:507] global step 44074: loss = 0.1189 (0.968 sec/step)\n",
      "I0902 10:00:17.757957 139792788920128 learning.py:507] global step 44075: loss = 0.0995 (0.958 sec/step)\n",
      "I0902 10:00:18.713343 139792788920128 learning.py:507] global step 44076: loss = 0.0662 (0.954 sec/step)\n",
      "I0902 10:00:19.681625 139792788920128 learning.py:507] global step 44077: loss = 0.2270 (0.967 sec/step)\n",
      "I0902 10:00:20.661270 139792788920128 learning.py:507] global step 44078: loss = 0.3256 (0.978 sec/step)\n",
      "I0902 10:00:21.628461 139792788920128 learning.py:507] global step 44079: loss = 0.1069 (0.965 sec/step)\n",
      "I0902 10:00:22.600026 139792788920128 learning.py:507] global step 44080: loss = 0.0771 (0.970 sec/step)\n",
      "I0902 10:00:23.556815 139792788920128 learning.py:507] global step 44081: loss = 0.0933 (0.955 sec/step)\n",
      "I0902 10:00:24.520546 139792788920128 learning.py:507] global step 44082: loss = 0.0964 (0.962 sec/step)\n",
      "I0902 10:00:25.515771 139792788920128 learning.py:507] global step 44083: loss = 0.0990 (0.994 sec/step)\n",
      "I0902 10:00:26.489194 139792788920128 learning.py:507] global step 44084: loss = 0.2000 (0.972 sec/step)\n",
      "I0902 10:00:27.457975 139792788920128 learning.py:507] global step 44085: loss = 0.1017 (0.967 sec/step)\n",
      "I0902 10:00:28.452998 139792788920128 learning.py:507] global step 44086: loss = 0.1242 (0.993 sec/step)\n",
      "I0902 10:00:29.444713 139792788920128 learning.py:507] global step 44087: loss = 0.0758 (0.990 sec/step)\n",
      "I0902 10:00:30.435789 139792788920128 learning.py:507] global step 44088: loss = 0.0867 (0.989 sec/step)\n",
      "I0902 10:00:31.403433 139792788920128 learning.py:507] global step 44089: loss = 0.0499 (0.966 sec/step)\n",
      "I0902 10:00:32.366129 139792788920128 learning.py:507] global step 44090: loss = 0.1107 (0.961 sec/step)\n",
      "I0902 10:00:33.342294 139792788920128 learning.py:507] global step 44091: loss = 0.1280 (0.975 sec/step)\n",
      "I0902 10:00:34.328034 139792788920128 learning.py:507] global step 44092: loss = 0.1903 (0.984 sec/step)\n",
      "I0902 10:00:35.303445 139792788920128 learning.py:507] global step 44093: loss = 0.3110 (0.974 sec/step)\n",
      "I0902 10:00:36.286364 139792788920128 learning.py:507] global step 44094: loss = 0.0738 (0.981 sec/step)\n",
      "I0902 10:00:37.269404 139792788920128 learning.py:507] global step 44095: loss = 0.1331 (0.982 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:00:38.235797 139792788920128 learning.py:507] global step 44096: loss = 0.0753 (0.965 sec/step)\n",
      "I0902 10:00:39.242850 139792788920128 learning.py:507] global step 44097: loss = 0.2346 (1.005 sec/step)\n",
      "I0902 10:00:40.234120 139792788920128 learning.py:507] global step 44098: loss = 0.3653 (0.990 sec/step)\n",
      "I0902 10:00:41.216027 139792788920128 learning.py:507] global step 44099: loss = 0.0879 (0.980 sec/step)\n",
      "I0902 10:00:42.200016 139792788920128 learning.py:507] global step 44100: loss = 0.1684 (0.982 sec/step)\n",
      "I0902 10:00:43.165690 139792788920128 learning.py:507] global step 44101: loss = 0.0754 (0.964 sec/step)\n",
      "I0902 10:00:44.147785 139792788920128 learning.py:507] global step 44102: loss = 0.1253 (0.980 sec/step)\n",
      "I0902 10:00:45.122560 139792788920128 learning.py:507] global step 44103: loss = 0.1116 (0.973 sec/step)\n",
      "I0902 10:00:46.089375 139792788920128 learning.py:507] global step 44104: loss = 0.0695 (0.965 sec/step)\n",
      "I0902 10:00:47.042500 139792788920128 learning.py:507] global step 44105: loss = 0.1862 (0.951 sec/step)\n",
      "I0902 10:00:48.000627 139792788920128 learning.py:507] global step 44106: loss = 0.2538 (0.956 sec/step)\n",
      "I0902 10:00:49.002971 139792788920128 learning.py:507] global step 44107: loss = 0.2596 (1.001 sec/step)\n",
      "I0902 10:00:49.975785 139792788920128 learning.py:507] global step 44108: loss = 0.2889 (0.971 sec/step)\n",
      "I0902 10:00:50.949838 139792788920128 learning.py:507] global step 44109: loss = 0.0753 (0.973 sec/step)\n",
      "I0902 10:00:51.934846 139792788920128 learning.py:507] global step 44110: loss = 0.0869 (0.983 sec/step)\n",
      "I0902 10:00:52.891707 139792788920128 learning.py:507] global step 44111: loss = 0.2914 (0.955 sec/step)\n",
      "I0902 10:00:53.875605 139792788920128 learning.py:507] global step 44112: loss = 0.0890 (0.982 sec/step)\n",
      "I0902 10:00:54.852545 139792788920128 learning.py:507] global step 44113: loss = 0.0596 (0.975 sec/step)\n",
      "I0902 10:00:55.838483 139792788920128 learning.py:507] global step 44114: loss = 0.1359 (0.984 sec/step)\n",
      "I0902 10:00:56.825468 139792788920128 learning.py:507] global step 44115: loss = 0.0911 (0.985 sec/step)\n",
      "I0902 10:00:57.824102 139792788920128 learning.py:507] global step 44116: loss = 0.0798 (0.997 sec/step)\n",
      "I0902 10:00:58.806945 139792788920128 learning.py:507] global step 44117: loss = 0.1084 (0.981 sec/step)\n",
      "I0902 10:00:59.797969 139792788920128 learning.py:507] global step 44118: loss = 0.1188 (0.989 sec/step)\n",
      "I0902 10:01:00.813145 139792788920128 learning.py:507] global step 44119: loss = 0.0715 (1.014 sec/step)\n",
      "I0902 10:01:01.790576 139792788920128 learning.py:507] global step 44120: loss = 0.1154 (0.976 sec/step)\n",
      "I0902 10:01:02.769696 139792788920128 learning.py:507] global step 44121: loss = 0.1080 (0.978 sec/step)\n",
      "I0902 10:01:03.746079 139792788920128 learning.py:507] global step 44122: loss = 0.0769 (0.975 sec/step)\n",
      "I0902 10:01:04.733770 139792788920128 learning.py:507] global step 44123: loss = 0.0735 (0.986 sec/step)\n",
      "I0902 10:01:05.693535 139792788920128 learning.py:507] global step 44124: loss = 0.0844 (0.958 sec/step)\n",
      "I0902 10:01:06.651330 139792788920128 learning.py:507] global step 44125: loss = 0.1506 (0.956 sec/step)\n",
      "I0902 10:01:07.632283 139792788920128 learning.py:507] global step 44126: loss = 0.0939 (0.979 sec/step)\n",
      "I0902 10:01:08.596508 139792788920128 learning.py:507] global step 44127: loss = 0.0703 (0.962 sec/step)\n",
      "I0902 10:01:09.578162 139792788920128 learning.py:507] global step 44128: loss = 0.1060 (0.980 sec/step)\n",
      "I0902 10:01:10.550456 139792788920128 learning.py:507] global step 44129: loss = 0.1838 (0.971 sec/step)\n",
      "I0902 10:01:11.530105 139792788920128 learning.py:507] global step 44130: loss = 0.0602 (0.978 sec/step)\n",
      "I0902 10:01:12.513201 139792788920128 learning.py:507] global step 44131: loss = 0.2866 (0.982 sec/step)\n",
      "I0902 10:01:13.485189 139792788920128 learning.py:507] global step 44132: loss = 0.2197 (0.970 sec/step)\n",
      "I0902 10:01:14.461438 139792788920128 learning.py:507] global step 44133: loss = 0.0428 (0.975 sec/step)\n",
      "I0902 10:01:15.437751 139792788920128 learning.py:507] global step 44134: loss = 0.0819 (0.975 sec/step)\n",
      "I0902 10:01:16.395824 139792788920128 learning.py:507] global step 44135: loss = 0.1594 (0.956 sec/step)\n",
      "I0902 10:01:17.348078 139792788920128 learning.py:507] global step 44136: loss = 0.2030 (0.951 sec/step)\n",
      "I0902 10:01:18.332226 139792788920128 learning.py:507] global step 44137: loss = 0.2709 (0.982 sec/step)\n",
      "I0902 10:01:19.283189 139792788920128 learning.py:507] global step 44138: loss = 0.1849 (0.949 sec/step)\n",
      "I0902 10:01:20.240007 139792788920128 learning.py:507] global step 44139: loss = 0.1112 (0.955 sec/step)\n",
      "I0902 10:01:21.198421 139792788920128 learning.py:507] global step 44140: loss = 0.1360 (0.957 sec/step)\n",
      "I0902 10:01:22.176995 139792788920128 learning.py:507] global step 44141: loss = 0.1317 (0.977 sec/step)\n",
      "I0902 10:01:23.148709 139792788920128 learning.py:507] global step 44142: loss = 0.1072 (0.970 sec/step)\n",
      "I0902 10:01:24.120334 139792788920128 learning.py:507] global step 44143: loss = 0.2720 (0.970 sec/step)\n",
      "I0902 10:01:25.063289 139792788920128 learning.py:507] global step 44144: loss = 0.5488 (0.941 sec/step)\n",
      "I0902 10:01:26.031802 139792788920128 learning.py:507] global step 44145: loss = 0.1789 (0.967 sec/step)\n",
      "I0902 10:01:26.972472 139792788920128 learning.py:507] global step 44146: loss = 0.2315 (0.939 sec/step)\n",
      "I0902 10:01:27.947703 139792788920128 learning.py:507] global step 44147: loss = 0.0992 (0.974 sec/step)\n",
      "I0902 10:01:28.929324 139792788920128 learning.py:507] global step 44148: loss = 0.1276 (0.980 sec/step)\n",
      "I0902 10:01:29.885921 139792788920128 learning.py:507] global step 44149: loss = 0.0882 (0.955 sec/step)\n",
      "I0902 10:01:30.843279 139792788920128 learning.py:507] global step 44150: loss = 0.1022 (0.956 sec/step)\n",
      "I0902 10:01:31.827110 139792788920128 learning.py:507] global step 44151: loss = 0.0933 (0.982 sec/step)\n",
      "I0902 10:01:32.793909 139792788920128 learning.py:507] global step 44152: loss = 0.1396 (0.965 sec/step)\n",
      "I0902 10:01:33.752922 139792788920128 learning.py:507] global step 44153: loss = 0.2589 (0.957 sec/step)\n",
      "I0902 10:01:34.723362 139792788920128 learning.py:507] global step 44154: loss = 0.1243 (0.969 sec/step)\n",
      "I0902 10:01:35.710926 139792788920128 learning.py:507] global step 44155: loss = 0.0839 (0.986 sec/step)\n",
      "I0902 10:01:36.686772 139792788920128 learning.py:507] global step 44156: loss = 0.0792 (0.974 sec/step)\n",
      "I0902 10:01:37.689662 139792788920128 learning.py:507] global step 44157: loss = 0.1211 (1.001 sec/step)\n",
      "I0902 10:01:38.650129 139792788920128 learning.py:507] global step 44158: loss = 0.1881 (0.959 sec/step)\n",
      "I0902 10:01:39.629881 139792788920128 learning.py:507] global step 44159: loss = 0.1575 (0.978 sec/step)\n",
      "I0902 10:01:40.590682 139792788920128 learning.py:507] global step 44160: loss = 0.0860 (0.959 sec/step)\n",
      "I0902 10:01:41.562969 139792788920128 learning.py:507] global step 44161: loss = 0.1129 (0.971 sec/step)\n",
      "I0902 10:01:42.538045 139792788920128 learning.py:507] global step 44162: loss = 0.1145 (0.973 sec/step)\n",
      "I0902 10:01:43.502190 139792788920128 learning.py:507] global step 44163: loss = 0.0986 (0.962 sec/step)\n",
      "I0902 10:01:44.462506 139792788920128 learning.py:507] global step 44164: loss = 0.1551 (0.959 sec/step)\n",
      "I0902 10:01:45.419039 139792788920128 learning.py:507] global step 44165: loss = 0.1619 (0.955 sec/step)\n",
      "I0902 10:01:46.377399 139792788920128 learning.py:507] global step 44166: loss = 0.1209 (0.957 sec/step)\n",
      "I0902 10:01:47.343415 139792788920128 learning.py:507] global step 44167: loss = 0.1305 (0.964 sec/step)\n",
      "I0902 10:01:48.331810 139792788920128 learning.py:507] global step 44168: loss = 0.0943 (0.987 sec/step)\n",
      "I0902 10:01:49.329082 139792788920128 learning.py:507] global step 44169: loss = 0.2316 (0.980 sec/step)\n",
      "I0902 10:01:49.972853 139778936784640 supervisor.py:1050] Recording summary at step 44169.\n",
      "I0902 10:01:50.585043 139792788920128 learning.py:507] global step 44170: loss = 0.0995 (1.251 sec/step)\n",
      "I0902 10:01:51.560335 139792788920128 learning.py:507] global step 44171: loss = 0.1598 (0.974 sec/step)\n",
      "I0902 10:01:52.532174 139792788920128 learning.py:507] global step 44172: loss = 0.1417 (0.970 sec/step)\n",
      "I0902 10:01:53.488244 139792788920128 learning.py:507] global step 44173: loss = 0.0832 (0.954 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:01:54.464758 139792788920128 learning.py:507] global step 44174: loss = 0.1788 (0.975 sec/step)\n",
      "I0902 10:01:55.424010 139792788920128 learning.py:507] global step 44175: loss = 0.1153 (0.958 sec/step)\n",
      "I0902 10:01:56.391900 139792788920128 learning.py:507] global step 44176: loss = 0.0563 (0.966 sec/step)\n",
      "I0902 10:01:57.366894 139792788920128 learning.py:507] global step 44177: loss = 0.0663 (0.973 sec/step)\n",
      "I0902 10:01:58.349066 139792788920128 learning.py:507] global step 44178: loss = 0.1780 (0.981 sec/step)\n",
      "I0902 10:01:59.317013 139792788920128 learning.py:507] global step 44179: loss = 0.2276 (0.966 sec/step)\n",
      "I0902 10:02:00.288680 139792788920128 learning.py:507] global step 44180: loss = 0.0581 (0.970 sec/step)\n",
      "I0902 10:02:01.285247 139792788920128 learning.py:507] global step 44181: loss = 0.3291 (0.995 sec/step)\n",
      "I0902 10:02:02.259404 139792788920128 learning.py:507] global step 44182: loss = 0.1290 (0.973 sec/step)\n",
      "I0902 10:02:03.245566 139792788920128 learning.py:507] global step 44183: loss = 0.0625 (0.984 sec/step)\n",
      "I0902 10:02:04.221075 139792788920128 learning.py:507] global step 44184: loss = 0.0531 (0.974 sec/step)\n",
      "I0902 10:02:05.198177 139792788920128 learning.py:507] global step 44185: loss = 0.1019 (0.976 sec/step)\n",
      "I0902 10:02:06.180566 139792788920128 learning.py:507] global step 44186: loss = 0.2113 (0.981 sec/step)\n",
      "I0902 10:02:07.147636 139792788920128 learning.py:507] global step 44187: loss = 0.1375 (0.966 sec/step)\n",
      "I0902 10:02:08.109360 139792788920128 learning.py:507] global step 44188: loss = 0.0714 (0.960 sec/step)\n",
      "I0902 10:02:09.077094 139792788920128 learning.py:507] global step 44189: loss = 0.0797 (0.966 sec/step)\n",
      "I0902 10:02:10.039769 139792788920128 learning.py:507] global step 44190: loss = 0.0703 (0.961 sec/step)\n",
      "I0902 10:02:11.004471 139792788920128 learning.py:507] global step 44191: loss = 0.1006 (0.963 sec/step)\n",
      "I0902 10:02:11.976777 139792788920128 learning.py:507] global step 44192: loss = 0.1051 (0.971 sec/step)\n",
      "I0902 10:02:12.949813 139792788920128 learning.py:507] global step 44193: loss = 0.0758 (0.971 sec/step)\n",
      "I0902 10:02:13.901425 139792788920128 learning.py:507] global step 44194: loss = 0.1142 (0.950 sec/step)\n",
      "I0902 10:02:14.864268 139792788920128 learning.py:507] global step 44195: loss = 0.1398 (0.961 sec/step)\n",
      "I0902 10:02:15.825381 139792788920128 learning.py:507] global step 44196: loss = 0.0966 (0.960 sec/step)\n",
      "I0902 10:02:16.789144 139792788920128 learning.py:507] global step 44197: loss = 0.1248 (0.962 sec/step)\n",
      "I0902 10:02:17.744755 139792788920128 learning.py:507] global step 44198: loss = 0.2729 (0.954 sec/step)\n",
      "I0902 10:02:18.725311 139792788920128 learning.py:507] global step 44199: loss = 0.1474 (0.979 sec/step)\n",
      "I0902 10:02:19.699098 139792788920128 learning.py:507] global step 44200: loss = 0.1272 (0.972 sec/step)\n",
      "I0902 10:02:20.677658 139792788920128 learning.py:507] global step 44201: loss = 0.0795 (0.977 sec/step)\n",
      "I0902 10:02:21.655270 139792788920128 learning.py:507] global step 44202: loss = 0.1341 (0.976 sec/step)\n",
      "I0902 10:02:22.632000 139792788920128 learning.py:507] global step 44203: loss = 0.0948 (0.975 sec/step)\n",
      "I0902 10:02:23.592270 139792788920128 learning.py:507] global step 44204: loss = 0.1072 (0.959 sec/step)\n",
      "I0902 10:02:24.554979 139792788920128 learning.py:507] global step 44205: loss = 0.1253 (0.961 sec/step)\n",
      "I0902 10:02:25.522091 139792788920128 learning.py:507] global step 44206: loss = 0.0994 (0.965 sec/step)\n",
      "I0902 10:02:26.497778 139792788920128 learning.py:507] global step 44207: loss = 0.3930 (0.974 sec/step)\n",
      "I0902 10:02:27.478008 139792788920128 learning.py:507] global step 44208: loss = 0.1190 (0.979 sec/step)\n",
      "I0902 10:02:28.455088 139792788920128 learning.py:507] global step 44209: loss = 0.2546 (0.975 sec/step)\n",
      "I0902 10:02:29.420282 139792788920128 learning.py:507] global step 44210: loss = 0.1036 (0.964 sec/step)\n",
      "I0902 10:02:30.385127 139792788920128 learning.py:507] global step 44211: loss = 0.0877 (0.963 sec/step)\n",
      "I0902 10:02:31.377150 139792788920128 learning.py:507] global step 44212: loss = 0.1935 (0.990 sec/step)\n",
      "I0902 10:02:32.328049 139792788920128 learning.py:507] global step 44213: loss = 0.1573 (0.949 sec/step)\n",
      "I0902 10:02:33.299829 139792788920128 learning.py:507] global step 44214: loss = 0.0894 (0.970 sec/step)\n",
      "I0902 10:02:34.278500 139792788920128 learning.py:507] global step 44215: loss = 0.0924 (0.977 sec/step)\n",
      "I0902 10:02:35.257079 139792788920128 learning.py:507] global step 44216: loss = 0.1573 (0.977 sec/step)\n",
      "I0902 10:02:36.216686 139792788920128 learning.py:507] global step 44217: loss = 0.1246 (0.958 sec/step)\n",
      "I0902 10:02:37.209777 139792788920128 learning.py:507] global step 44218: loss = 0.1113 (0.991 sec/step)\n",
      "I0902 10:02:38.184732 139792788920128 learning.py:507] global step 44219: loss = 0.1829 (0.973 sec/step)\n",
      "I0902 10:02:39.142493 139792788920128 learning.py:507] global step 44220: loss = 0.1109 (0.956 sec/step)\n",
      "I0902 10:02:40.114321 139792788920128 learning.py:507] global step 44221: loss = 0.0880 (0.970 sec/step)\n",
      "I0902 10:02:41.072877 139792788920128 learning.py:507] global step 44222: loss = 0.0880 (0.957 sec/step)\n",
      "I0902 10:02:42.045039 139792788920128 learning.py:507] global step 44223: loss = 0.0887 (0.970 sec/step)\n",
      "I0902 10:02:43.018542 139792788920128 learning.py:507] global step 44224: loss = 0.2931 (0.972 sec/step)\n",
      "I0902 10:02:43.979858 139792788920128 learning.py:507] global step 44225: loss = 0.1199 (0.960 sec/step)\n",
      "I0902 10:02:44.971122 139792788920128 learning.py:507] global step 44226: loss = 0.1095 (0.990 sec/step)\n",
      "I0902 10:02:45.930309 139792788920128 learning.py:507] global step 44227: loss = 0.1503 (0.958 sec/step)\n",
      "I0902 10:02:46.910408 139792788920128 learning.py:507] global step 44228: loss = 0.1426 (0.979 sec/step)\n",
      "I0902 10:02:47.868157 139792788920128 learning.py:507] global step 44229: loss = 0.0543 (0.956 sec/step)\n",
      "I0902 10:02:48.843476 139792788920128 learning.py:507] global step 44230: loss = 0.0840 (0.974 sec/step)\n",
      "I0902 10:02:49.807167 139792788920128 learning.py:507] global step 44231: loss = 0.1193 (0.962 sec/step)\n",
      "I0902 10:02:50.779926 139792788920128 learning.py:507] global step 44232: loss = 0.0765 (0.971 sec/step)\n",
      "I0902 10:02:51.744160 139792788920128 learning.py:507] global step 44233: loss = 0.2003 (0.963 sec/step)\n",
      "I0902 10:02:52.736526 139792788920128 learning.py:507] global step 44234: loss = 0.2735 (0.991 sec/step)\n",
      "I0902 10:02:53.705170 139792788920128 learning.py:507] global step 44235: loss = 0.1185 (0.967 sec/step)\n",
      "I0902 10:02:54.704099 139792788920128 learning.py:507] global step 44236: loss = 0.3094 (0.997 sec/step)\n",
      "I0902 10:02:55.692088 139792788920128 learning.py:507] global step 44237: loss = 0.0837 (0.986 sec/step)\n",
      "I0902 10:02:56.645386 139792788920128 learning.py:507] global step 44238: loss = 0.0606 (0.952 sec/step)\n",
      "I0902 10:02:57.602934 139792788920128 learning.py:507] global step 44239: loss = 0.1510 (0.956 sec/step)\n",
      "I0902 10:02:58.572722 139792788920128 learning.py:507] global step 44240: loss = 0.1756 (0.968 sec/step)\n",
      "I0902 10:02:59.552701 139792788920128 learning.py:507] global step 44241: loss = 0.2027 (0.978 sec/step)\n",
      "I0902 10:03:00.511941 139792788920128 learning.py:507] global step 44242: loss = 0.0650 (0.958 sec/step)\n",
      "I0902 10:03:01.496799 139792788920128 learning.py:507] global step 44243: loss = 0.1285 (0.983 sec/step)\n",
      "I0902 10:03:02.455375 139792788920128 learning.py:507] global step 44244: loss = 0.1161 (0.957 sec/step)\n",
      "I0902 10:03:03.440324 139792788920128 learning.py:507] global step 44245: loss = 0.1004 (0.983 sec/step)\n",
      "I0902 10:03:04.400401 139792788920128 learning.py:507] global step 44246: loss = 0.2564 (0.958 sec/step)\n",
      "I0902 10:03:05.378006 139792788920128 learning.py:507] global step 44247: loss = 0.3311 (0.976 sec/step)\n",
      "I0902 10:03:06.348381 139792788920128 learning.py:507] global step 44248: loss = 0.2670 (0.969 sec/step)\n",
      "I0902 10:03:07.311989 139792788920128 learning.py:507] global step 44249: loss = 0.0964 (0.962 sec/step)\n",
      "I0902 10:03:08.289857 139792788920128 learning.py:507] global step 44250: loss = 0.2642 (0.976 sec/step)\n",
      "I0902 10:03:09.256185 139792788920128 learning.py:507] global step 44251: loss = 0.1282 (0.965 sec/step)\n",
      "I0902 10:03:10.210876 139792788920128 learning.py:507] global step 44252: loss = 0.0974 (0.953 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:03:11.176293 139792788920128 learning.py:507] global step 44253: loss = 0.1150 (0.964 sec/step)\n",
      "I0902 10:03:12.146827 139792788920128 learning.py:507] global step 44254: loss = 0.1808 (0.969 sec/step)\n",
      "I0902 10:03:13.121915 139792788920128 learning.py:507] global step 44255: loss = 0.1535 (0.973 sec/step)\n",
      "I0902 10:03:14.094945 139792788920128 learning.py:507] global step 44256: loss = 0.1002 (0.972 sec/step)\n",
      "I0902 10:03:15.062971 139792788920128 learning.py:507] global step 44257: loss = 0.1288 (0.966 sec/step)\n",
      "I0902 10:03:16.046945 139792788920128 learning.py:507] global step 44258: loss = 0.0906 (0.982 sec/step)\n",
      "I0902 10:03:17.024055 139792788920128 learning.py:507] global step 44259: loss = 0.0863 (0.975 sec/step)\n",
      "I0902 10:03:17.986289 139792788920128 learning.py:507] global step 44260: loss = 0.0724 (0.960 sec/step)\n",
      "I0902 10:03:18.952875 139792788920128 learning.py:507] global step 44261: loss = 0.1020 (0.965 sec/step)\n",
      "I0902 10:03:19.913372 139792788920128 learning.py:507] global step 44262: loss = 0.0416 (0.959 sec/step)\n",
      "I0902 10:03:20.892229 139792788920128 learning.py:507] global step 44263: loss = 0.1701 (0.977 sec/step)\n",
      "I0902 10:03:21.849319 139792788920128 learning.py:507] global step 44264: loss = 0.1159 (0.955 sec/step)\n",
      "I0902 10:03:22.799005 139792788920128 learning.py:507] global step 44265: loss = 0.0611 (0.948 sec/step)\n",
      "I0902 10:03:23.761412 139792788920128 learning.py:507] global step 44266: loss = 0.2793 (0.961 sec/step)\n",
      "I0902 10:03:24.734970 139792788920128 learning.py:507] global step 44267: loss = 0.1017 (0.972 sec/step)\n",
      "I0902 10:03:25.691010 139792788920128 learning.py:507] global step 44268: loss = 0.1072 (0.955 sec/step)\n",
      "I0902 10:03:26.689890 139792788920128 learning.py:507] global step 44269: loss = 0.0860 (0.997 sec/step)\n",
      "I0902 10:03:27.666018 139792788920128 learning.py:507] global step 44270: loss = 0.1243 (0.974 sec/step)\n",
      "I0902 10:03:28.636001 139792788920128 learning.py:507] global step 44271: loss = 0.1360 (0.968 sec/step)\n",
      "I0902 10:03:29.596971 139792788920128 learning.py:507] global step 44272: loss = 0.1822 (0.959 sec/step)\n",
      "I0902 10:03:30.573888 139792788920128 learning.py:507] global step 44273: loss = 0.1221 (0.975 sec/step)\n",
      "I0902 10:03:31.541658 139792788920128 learning.py:507] global step 44274: loss = 0.1139 (0.966 sec/step)\n",
      "I0902 10:03:32.504900 139792788920128 learning.py:507] global step 44275: loss = 0.1106 (0.961 sec/step)\n",
      "I0902 10:03:33.456033 139792788920128 learning.py:507] global step 44276: loss = 0.1049 (0.949 sec/step)\n",
      "I0902 10:03:34.441441 139792788920128 learning.py:507] global step 44277: loss = 0.1274 (0.984 sec/step)\n",
      "I0902 10:03:35.424162 139792788920128 learning.py:507] global step 44278: loss = 0.1255 (0.981 sec/step)\n",
      "I0902 10:03:36.389734 139792788920128 learning.py:507] global step 44279: loss = 0.1310 (0.964 sec/step)\n",
      "I0902 10:03:37.357197 139792788920128 learning.py:507] global step 44280: loss = 0.0603 (0.966 sec/step)\n",
      "I0902 10:03:38.319107 139792788920128 learning.py:507] global step 44281: loss = 0.1307 (0.960 sec/step)\n",
      "I0902 10:03:39.291920 139792788920128 learning.py:507] global step 44282: loss = 0.1468 (0.971 sec/step)\n",
      "I0902 10:03:40.255153 139792788920128 learning.py:507] global step 44283: loss = 0.0863 (0.962 sec/step)\n",
      "I0902 10:03:41.216243 139792788920128 learning.py:507] global step 44284: loss = 0.0525 (0.959 sec/step)\n",
      "I0902 10:03:42.210520 139792788920128 learning.py:507] global step 44285: loss = 0.1099 (0.993 sec/step)\n",
      "I0902 10:03:43.176980 139792788920128 learning.py:507] global step 44286: loss = 0.2468 (0.965 sec/step)\n",
      "I0902 10:03:44.145801 139792788920128 learning.py:507] global step 44287: loss = 0.2210 (0.967 sec/step)\n",
      "I0902 10:03:45.093643 139792788920128 learning.py:507] global step 44288: loss = 0.1334 (0.946 sec/step)\n",
      "I0902 10:03:46.047087 139792788920128 learning.py:507] global step 44289: loss = 0.1103 (0.952 sec/step)\n",
      "I0902 10:03:47.041841 139792788920128 learning.py:507] global step 44290: loss = 0.0497 (0.993 sec/step)\n",
      "I0902 10:03:48.024081 139792788920128 learning.py:507] global step 44291: loss = 0.0748 (0.981 sec/step)\n",
      "I0902 10:03:48.993963 139792788920128 learning.py:507] global step 44292: loss = 0.1967 (0.968 sec/step)\n",
      "I0902 10:03:49.270475 139778953570048 supervisor.py:1117] Saving checkpoint to path data_dir/mixed_experiment/checkpoints_v2/model.ckpt\n",
      "I0902 10:03:50.388695 139792788920128 learning.py:507] global step 44293: loss = 0.1165 (1.183 sec/step)\n",
      "I0902 10:03:50.389447 139778936784640 supervisor.py:1050] Recording summary at step 44293.\n",
      "I0902 10:03:51.368726 139792788920128 learning.py:507] global step 44294: loss = 0.2338 (0.968 sec/step)\n",
      "I0902 10:03:52.348356 139792788920128 learning.py:507] global step 44295: loss = 0.1401 (0.978 sec/step)\n",
      "I0902 10:03:53.313366 139792788920128 learning.py:507] global step 44296: loss = 0.1490 (0.963 sec/step)\n",
      "I0902 10:03:54.277610 139792788920128 learning.py:507] global step 44297: loss = 0.1798 (0.963 sec/step)\n",
      "I0902 10:03:55.253107 139792788920128 learning.py:507] global step 44298: loss = 0.1201 (0.974 sec/step)\n",
      "I0902 10:03:56.211009 139792788920128 learning.py:507] global step 44299: loss = 0.1655 (0.956 sec/step)\n",
      "I0902 10:03:57.171969 139792788920128 learning.py:507] global step 44300: loss = 0.1392 (0.959 sec/step)\n",
      "I0902 10:03:58.129154 139792788920128 learning.py:507] global step 44301: loss = 0.1006 (0.956 sec/step)\n",
      "I0902 10:03:59.110479 139792788920128 learning.py:507] global step 44302: loss = 0.1138 (0.980 sec/step)\n",
      "I0902 10:04:00.085387 139792788920128 learning.py:507] global step 44303: loss = 0.1596 (0.973 sec/step)\n",
      "I0902 10:04:01.044844 139792788920128 learning.py:507] global step 44304: loss = 0.1724 (0.958 sec/step)\n",
      "I0902 10:04:02.021783 139792788920128 learning.py:507] global step 44305: loss = 0.0873 (0.975 sec/step)\n",
      "I0902 10:04:02.989837 139792788920128 learning.py:507] global step 44306: loss = 0.1147 (0.967 sec/step)\n",
      "I0902 10:04:03.950848 139792788920128 learning.py:507] global step 44307: loss = 0.3335 (0.959 sec/step)\n",
      "I0902 10:04:04.930527 139792788920128 learning.py:507] global step 44308: loss = 0.0740 (0.978 sec/step)\n",
      "I0902 10:04:05.892119 139792788920128 learning.py:507] global step 44309: loss = 0.0758 (0.960 sec/step)\n",
      "I0902 10:04:06.853032 139792788920128 learning.py:507] global step 44310: loss = 0.1422 (0.959 sec/step)\n",
      "I0902 10:04:07.806468 139792788920128 learning.py:507] global step 44311: loss = 0.1110 (0.952 sec/step)\n",
      "I0902 10:04:08.765736 139792788920128 learning.py:507] global step 44312: loss = 0.1181 (0.958 sec/step)\n",
      "I0902 10:04:09.721524 139792788920128 learning.py:507] global step 44313: loss = 0.0800 (0.954 sec/step)\n",
      "I0902 10:04:10.703245 139792788920128 learning.py:507] global step 44314: loss = 0.1468 (0.980 sec/step)\n",
      "I0902 10:04:11.684141 139792788920128 learning.py:507] global step 44315: loss = 0.1505 (0.979 sec/step)\n",
      "I0902 10:04:12.654045 139792788920128 learning.py:507] global step 44316: loss = 0.1507 (0.968 sec/step)\n",
      "I0902 10:04:13.631785 139792788920128 learning.py:507] global step 44317: loss = 0.0638 (0.976 sec/step)\n",
      "I0902 10:04:14.596508 139792788920128 learning.py:507] global step 44318: loss = 0.1260 (0.963 sec/step)\n",
      "I0902 10:04:15.575113 139792788920128 learning.py:507] global step 44319: loss = 0.0792 (0.977 sec/step)\n",
      "I0902 10:04:16.535190 139792788920128 learning.py:507] global step 44320: loss = 0.1033 (0.958 sec/step)\n",
      "I0902 10:04:17.510224 139792788920128 learning.py:507] global step 44321: loss = 0.1539 (0.973 sec/step)\n",
      "I0902 10:04:18.469986 139792788920128 learning.py:507] global step 44322: loss = 0.1228 (0.958 sec/step)\n",
      "I0902 10:04:19.454920 139792788920128 learning.py:507] global step 44323: loss = 0.1027 (0.983 sec/step)\n",
      "I0902 10:04:20.411958 139792788920128 learning.py:507] global step 44324: loss = 0.1443 (0.955 sec/step)\n",
      "I0902 10:04:21.387670 139792788920128 learning.py:507] global step 44325: loss = 0.0742 (0.974 sec/step)\n",
      "I0902 10:04:22.345912 139792788920128 learning.py:507] global step 44326: loss = 0.1039 (0.957 sec/step)\n",
      "I0902 10:04:23.313933 139792788920128 learning.py:507] global step 44327: loss = 0.2276 (0.966 sec/step)\n",
      "I0902 10:04:24.270047 139792788920128 learning.py:507] global step 44328: loss = 0.1054 (0.954 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:04:25.245325 139792788920128 learning.py:507] global step 44329: loss = 0.1283 (0.973 sec/step)\n",
      "I0902 10:04:26.218015 139792788920128 learning.py:507] global step 44330: loss = 0.2189 (0.971 sec/step)\n",
      "I0902 10:04:27.182410 139792788920128 learning.py:507] global step 44331: loss = 0.0940 (0.963 sec/step)\n",
      "I0902 10:04:28.159806 139792788920128 learning.py:507] global step 44332: loss = 0.0955 (0.976 sec/step)\n",
      "I0902 10:04:29.117111 139792788920128 learning.py:507] global step 44333: loss = 0.1567 (0.956 sec/step)\n",
      "I0902 10:04:30.086520 139792788920128 learning.py:507] global step 44334: loss = 0.0882 (0.968 sec/step)\n",
      "I0902 10:04:31.026065 139792788920128 learning.py:507] global step 44335: loss = 0.0440 (0.938 sec/step)\n",
      "I0902 10:04:31.994848 139792788920128 learning.py:507] global step 44336: loss = 0.1086 (0.967 sec/step)\n",
      "I0902 10:04:32.960787 139792788920128 learning.py:507] global step 44337: loss = 0.0655 (0.964 sec/step)\n",
      "I0902 10:04:33.917582 139792788920128 learning.py:507] global step 44338: loss = 0.1237 (0.955 sec/step)\n",
      "I0902 10:04:34.904928 139792788920128 learning.py:507] global step 44339: loss = 0.0799 (0.986 sec/step)\n",
      "I0902 10:04:35.880579 139792788920128 learning.py:507] global step 44340: loss = 0.0858 (0.974 sec/step)\n",
      "I0902 10:04:36.862115 139792788920128 learning.py:507] global step 44341: loss = 0.1561 (0.980 sec/step)\n",
      "I0902 10:04:37.813027 139792788920128 learning.py:507] global step 44342: loss = 0.1135 (0.949 sec/step)\n",
      "I0902 10:04:38.791153 139792788920128 learning.py:507] global step 44343: loss = 0.2017 (0.977 sec/step)\n",
      "I0902 10:04:39.758896 139792788920128 learning.py:507] global step 44344: loss = 0.1329 (0.966 sec/step)\n",
      "I0902 10:04:40.719660 139792788920128 learning.py:507] global step 44345: loss = 0.0477 (0.959 sec/step)\n",
      "I0902 10:04:41.684247 139792788920128 learning.py:507] global step 44346: loss = 0.1253 (0.963 sec/step)\n",
      "I0902 10:04:42.646073 139792788920128 learning.py:507] global step 44347: loss = 0.1439 (0.960 sec/step)\n",
      "I0902 10:04:43.605799 139792788920128 learning.py:507] global step 44348: loss = 0.1429 (0.958 sec/step)\n",
      "I0902 10:04:44.582627 139792788920128 learning.py:507] global step 44349: loss = 0.1280 (0.975 sec/step)\n",
      "I0902 10:04:45.543432 139792788920128 learning.py:507] global step 44350: loss = 0.1499 (0.959 sec/step)\n",
      "I0902 10:04:46.516552 139792788920128 learning.py:507] global step 44351: loss = 0.0761 (0.971 sec/step)\n",
      "I0902 10:04:47.505593 139792788920128 learning.py:507] global step 44352: loss = 0.0957 (0.987 sec/step)\n",
      "I0902 10:04:48.488028 139792788920128 learning.py:507] global step 44353: loss = 0.1699 (0.981 sec/step)\n",
      "I0902 10:04:49.443289 139792788920128 learning.py:507] global step 44354: loss = 0.2533 (0.954 sec/step)\n",
      "I0902 10:04:50.430588 139792788920128 learning.py:507] global step 44355: loss = 0.3545 (0.986 sec/step)\n",
      "I0902 10:04:51.386800 139792788920128 learning.py:507] global step 44356: loss = 0.0801 (0.955 sec/step)\n",
      "I0902 10:04:52.350615 139792788920128 learning.py:507] global step 44357: loss = 0.0912 (0.962 sec/step)\n",
      "I0902 10:04:53.320665 139792788920128 learning.py:507] global step 44358: loss = 0.0985 (0.968 sec/step)\n",
      "I0902 10:04:54.289407 139792788920128 learning.py:507] global step 44359: loss = 0.0605 (0.967 sec/step)\n",
      "I0902 10:04:55.255883 139792788920128 learning.py:507] global step 44360: loss = 0.0511 (0.965 sec/step)\n",
      "I0902 10:04:56.209942 139792788920128 learning.py:507] global step 44361: loss = 0.1201 (0.952 sec/step)\n",
      "I0902 10:04:57.178744 139792788920128 learning.py:507] global step 44362: loss = 0.1188 (0.967 sec/step)\n",
      "I0902 10:04:58.152239 139792788920128 learning.py:507] global step 44363: loss = 0.0686 (0.972 sec/step)\n",
      "I0902 10:04:59.119485 139792788920128 learning.py:507] global step 44364: loss = 0.0971 (0.966 sec/step)\n",
      "I0902 10:05:00.095638 139792788920128 learning.py:507] global step 44365: loss = 0.1211 (0.975 sec/step)\n",
      "I0902 10:05:01.048538 139792788920128 learning.py:507] global step 44366: loss = 0.1347 (0.951 sec/step)\n",
      "I0902 10:05:02.029111 139792788920128 learning.py:507] global step 44367: loss = 0.0910 (0.979 sec/step)\n",
      "I0902 10:05:02.969977 139792788920128 learning.py:507] global step 44368: loss = 0.1110 (0.939 sec/step)\n",
      "I0902 10:05:03.960127 139792788920128 learning.py:507] global step 44369: loss = 0.1008 (0.989 sec/step)\n",
      "I0902 10:05:04.943737 139792788920128 learning.py:507] global step 44370: loss = 0.1300 (0.982 sec/step)\n",
      "I0902 10:05:05.934274 139792788920128 learning.py:507] global step 44371: loss = 0.1379 (0.989 sec/step)\n",
      "I0902 10:05:06.918698 139792788920128 learning.py:507] global step 44372: loss = 0.1028 (0.983 sec/step)\n",
      "I0902 10:05:07.880584 139792788920128 learning.py:507] global step 44373: loss = 0.0947 (0.960 sec/step)\n",
      "I0902 10:05:08.850718 139792788920128 learning.py:507] global step 44374: loss = 0.0875 (0.969 sec/step)\n",
      "I0902 10:05:09.812132 139792788920128 learning.py:507] global step 44375: loss = 0.0960 (0.960 sec/step)\n",
      "I0902 10:05:10.768783 139792788920128 learning.py:507] global step 44376: loss = 0.0770 (0.955 sec/step)\n",
      "I0902 10:05:11.729181 139792788920128 learning.py:507] global step 44377: loss = 0.0868 (0.959 sec/step)\n",
      "I0902 10:05:12.695572 139792788920128 learning.py:507] global step 44378: loss = 0.0533 (0.965 sec/step)\n",
      "I0902 10:05:13.679869 139792788920128 learning.py:507] global step 44379: loss = 0.1048 (0.983 sec/step)\n",
      "I0902 10:05:14.639856 139792788920128 learning.py:507] global step 44380: loss = 0.1525 (0.958 sec/step)\n",
      "I0902 10:05:15.607510 139792788920128 learning.py:507] global step 44381: loss = 0.0695 (0.966 sec/step)\n",
      "I0902 10:05:16.561455 139792788920128 learning.py:507] global step 44382: loss = 0.1353 (0.952 sec/step)\n",
      "I0902 10:05:17.520741 139792788920128 learning.py:507] global step 44383: loss = 0.0873 (0.957 sec/step)\n",
      "I0902 10:05:18.497119 139792788920128 learning.py:507] global step 44384: loss = 0.1169 (0.975 sec/step)\n",
      "I0902 10:05:19.461840 139792788920128 learning.py:507] global step 44385: loss = 0.1225 (0.963 sec/step)\n",
      "I0902 10:05:20.441035 139792788920128 learning.py:507] global step 44386: loss = 0.0990 (0.977 sec/step)\n",
      "I0902 10:05:21.401571 139792788920128 learning.py:507] global step 44387: loss = 0.0469 (0.959 sec/step)\n",
      "I0902 10:05:22.358915 139792788920128 learning.py:507] global step 44388: loss = 0.1522 (0.956 sec/step)\n",
      "I0902 10:05:23.328042 139792788920128 learning.py:507] global step 44389: loss = 0.0974 (0.968 sec/step)\n",
      "I0902 10:05:24.287868 139792788920128 learning.py:507] global step 44390: loss = 0.0921 (0.958 sec/step)\n",
      "I0902 10:05:25.247025 139792788920128 learning.py:507] global step 44391: loss = 0.0916 (0.957 sec/step)\n",
      "I0902 10:05:26.211068 139792788920128 learning.py:507] global step 44392: loss = 0.0751 (0.962 sec/step)\n",
      "I0902 10:05:27.177405 139792788920128 learning.py:507] global step 44393: loss = 0.0825 (0.965 sec/step)\n",
      "I0902 10:05:28.159494 139792788920128 learning.py:507] global step 44394: loss = 0.0660 (0.981 sec/step)\n",
      "I0902 10:05:29.136543 139792788920128 learning.py:507] global step 44395: loss = 0.0917 (0.975 sec/step)\n",
      "I0902 10:05:30.103927 139792788920128 learning.py:507] global step 44396: loss = 0.1041 (0.966 sec/step)\n",
      "I0902 10:05:31.083936 139792788920128 learning.py:507] global step 44397: loss = 0.1424 (0.978 sec/step)\n",
      "I0902 10:05:32.064012 139792788920128 learning.py:507] global step 44398: loss = 0.1411 (0.979 sec/step)\n",
      "I0902 10:05:33.033955 139792788920128 learning.py:507] global step 44399: loss = 0.0642 (0.968 sec/step)\n",
      "I0902 10:05:34.027760 139792788920128 learning.py:507] global step 44400: loss = 0.0970 (0.992 sec/step)\n",
      "I0902 10:05:34.976922 139792788920128 learning.py:507] global step 44401: loss = 0.1306 (0.947 sec/step)\n",
      "I0902 10:05:35.949879 139792788920128 learning.py:507] global step 44402: loss = 0.0630 (0.971 sec/step)\n",
      "I0902 10:05:36.923740 139792788920128 learning.py:507] global step 44403: loss = 0.1045 (0.972 sec/step)\n",
      "I0902 10:05:37.914826 139792788920128 learning.py:507] global step 44404: loss = 0.0830 (0.989 sec/step)\n",
      "I0902 10:05:38.884646 139792788920128 learning.py:507] global step 44405: loss = 0.1806 (0.968 sec/step)\n",
      "I0902 10:05:39.850798 139792788920128 learning.py:507] global step 44406: loss = 0.0525 (0.965 sec/step)\n",
      "I0902 10:05:40.814834 139792788920128 learning.py:507] global step 44407: loss = 0.0431 (0.962 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:05:41.796766 139792788920128 learning.py:507] global step 44408: loss = 0.1423 (0.980 sec/step)\n",
      "I0902 10:05:42.766294 139792788920128 learning.py:507] global step 44409: loss = 0.1695 (0.968 sec/step)\n",
      "I0902 10:05:43.755461 139792788920128 learning.py:507] global step 44410: loss = 0.1521 (0.988 sec/step)\n",
      "I0902 10:05:44.726500 139792788920128 learning.py:507] global step 44411: loss = 0.0778 (0.969 sec/step)\n",
      "I0902 10:05:45.699076 139792788920128 learning.py:507] global step 44412: loss = 0.0912 (0.971 sec/step)\n",
      "I0902 10:05:46.668487 139792788920128 learning.py:507] global step 44413: loss = 0.2857 (0.968 sec/step)\n",
      "I0902 10:05:47.636165 139792788920128 learning.py:507] global step 44414: loss = 0.1868 (0.966 sec/step)\n",
      "I0902 10:05:48.591665 139792788920128 learning.py:507] global step 44415: loss = 0.2771 (0.954 sec/step)\n",
      "I0902 10:05:49.571758 139792788920128 learning.py:507] global step 44416: loss = 0.1279 (0.969 sec/step)\n",
      "I0902 10:05:50.223442 139778936784640 supervisor.py:1050] Recording summary at step 44416.\n",
      "I0902 10:05:50.835159 139792788920128 learning.py:507] global step 44417: loss = 0.0719 (1.260 sec/step)\n",
      "I0902 10:05:51.809886 139792788920128 learning.py:507] global step 44418: loss = 0.1556 (0.973 sec/step)\n",
      "I0902 10:05:52.779150 139792788920128 learning.py:507] global step 44419: loss = 0.0919 (0.968 sec/step)\n",
      "I0902 10:05:53.751629 139792788920128 learning.py:507] global step 44420: loss = 0.1766 (0.971 sec/step)\n",
      "I0902 10:05:54.714887 139792788920128 learning.py:507] global step 44421: loss = 0.4080 (0.962 sec/step)\n",
      "I0902 10:05:55.666152 139792788920128 learning.py:507] global step 44422: loss = 0.0843 (0.950 sec/step)\n",
      "I0902 10:05:56.636600 139792788920128 learning.py:507] global step 44423: loss = 0.0794 (0.969 sec/step)\n",
      "I0902 10:05:57.609741 139792788920128 learning.py:507] global step 44424: loss = 0.1054 (0.971 sec/step)\n",
      "I0902 10:05:58.570415 139792788920128 learning.py:507] global step 44425: loss = 0.1210 (0.959 sec/step)\n",
      "I0902 10:05:59.532400 139792788920128 learning.py:507] global step 44426: loss = 0.2251 (0.960 sec/step)\n",
      "I0902 10:06:00.501857 139792788920128 learning.py:507] global step 44427: loss = 0.1023 (0.968 sec/step)\n",
      "I0902 10:06:01.468719 139792788920128 learning.py:507] global step 44428: loss = 0.1400 (0.965 sec/step)\n",
      "I0902 10:06:02.430075 139792788920128 learning.py:507] global step 44429: loss = 0.0901 (0.960 sec/step)\n",
      "I0902 10:06:03.750491 139792788920128 learning.py:507] global step 44430: loss = 0.1480 (1.319 sec/step)\n",
      "I0902 10:06:04.736528 139792788920128 learning.py:507] global step 44431: loss = 0.0840 (0.984 sec/step)\n",
      "I0902 10:06:05.709734 139792788920128 learning.py:507] global step 44432: loss = 0.1266 (0.972 sec/step)\n",
      "I0902 10:06:06.678253 139792788920128 learning.py:507] global step 44433: loss = 0.2358 (0.967 sec/step)\n",
      "I0902 10:06:07.641017 139792788920128 learning.py:507] global step 44434: loss = 0.0667 (0.961 sec/step)\n",
      "I0902 10:06:08.625898 139792788920128 learning.py:507] global step 44435: loss = 0.1708 (0.983 sec/step)\n",
      "I0902 10:06:09.602904 139792788920128 learning.py:507] global step 44436: loss = 0.0693 (0.975 sec/step)\n",
      "I0902 10:06:10.585299 139792788920128 learning.py:507] global step 44437: loss = 0.0649 (0.981 sec/step)\n",
      "I0902 10:06:11.562196 139792788920128 learning.py:507] global step 44438: loss = 0.0626 (0.975 sec/step)\n",
      "I0902 10:06:12.528516 139792788920128 learning.py:507] global step 44439: loss = 0.0827 (0.965 sec/step)\n",
      "I0902 10:06:13.539532 139792788920128 learning.py:507] global step 44440: loss = 0.0754 (1.009 sec/step)\n",
      "I0902 10:06:14.494900 139792788920128 learning.py:507] global step 44441: loss = 0.0516 (0.954 sec/step)\n",
      "I0902 10:06:15.447361 139792788920128 learning.py:507] global step 44442: loss = 0.2023 (0.951 sec/step)\n",
      "I0902 10:06:16.404898 139792788920128 learning.py:507] global step 44443: loss = 0.1856 (0.956 sec/step)\n",
      "I0902 10:06:17.370510 139792788920128 learning.py:507] global step 44444: loss = 0.1342 (0.964 sec/step)\n",
      "I0902 10:06:18.343753 139792788920128 learning.py:507] global step 44445: loss = 0.1712 (0.972 sec/step)\n",
      "I0902 10:06:19.321723 139792788920128 learning.py:507] global step 44446: loss = 0.0728 (0.976 sec/step)\n",
      "I0902 10:06:20.279618 139792788920128 learning.py:507] global step 44447: loss = 0.0818 (0.956 sec/step)\n",
      "I0902 10:06:21.238420 139792788920128 learning.py:507] global step 44448: loss = 0.0529 (0.957 sec/step)\n",
      "I0902 10:06:22.191044 139792788920128 learning.py:507] global step 44449: loss = 0.1329 (0.951 sec/step)\n",
      "I0902 10:06:23.163498 139792788920128 learning.py:507] global step 44450: loss = 0.0818 (0.971 sec/step)\n",
      "I0902 10:06:24.130645 139792788920128 learning.py:507] global step 44451: loss = 0.1003 (0.965 sec/step)\n",
      "I0902 10:06:25.105027 139792788920128 learning.py:507] global step 44452: loss = 0.1293 (0.973 sec/step)\n",
      "I0902 10:06:26.053556 139792788920128 learning.py:507] global step 44453: loss = 0.0705 (0.947 sec/step)\n",
      "I0902 10:06:27.037082 139792788920128 learning.py:507] global step 44454: loss = 0.2210 (0.982 sec/step)\n",
      "I0902 10:06:28.000471 139792788920128 learning.py:507] global step 44455: loss = 0.1503 (0.962 sec/step)\n",
      "I0902 10:06:28.969846 139792788920128 learning.py:507] global step 44456: loss = 0.0902 (0.968 sec/step)\n",
      "I0902 10:06:29.941902 139792788920128 learning.py:507] global step 44457: loss = 0.0797 (0.970 sec/step)\n",
      "I0902 10:06:30.923999 139792788920128 learning.py:507] global step 44458: loss = 0.1152 (0.980 sec/step)\n",
      "I0902 10:06:31.888831 139792788920128 learning.py:507] global step 44459: loss = 0.1276 (0.963 sec/step)\n",
      "I0902 10:06:32.848865 139792788920128 learning.py:507] global step 44460: loss = 0.0852 (0.958 sec/step)\n",
      "I0902 10:06:33.798848 139792788920128 learning.py:507] global step 44461: loss = 0.0935 (0.948 sec/step)\n",
      "I0902 10:06:34.767661 139792788920128 learning.py:507] global step 44462: loss = 0.2375 (0.967 sec/step)\n",
      "I0902 10:06:35.746187 139792788920128 learning.py:507] global step 44463: loss = 0.2053 (0.977 sec/step)\n",
      "I0902 10:06:36.722513 139792788920128 learning.py:507] global step 44464: loss = 0.1046 (0.975 sec/step)\n",
      "I0902 10:06:37.680617 139792788920128 learning.py:507] global step 44465: loss = 0.0943 (0.957 sec/step)\n",
      "I0902 10:06:38.666645 139792788920128 learning.py:507] global step 44466: loss = 0.1338 (0.984 sec/step)\n",
      "I0902 10:06:39.641419 139792788920128 learning.py:507] global step 44467: loss = 0.1246 (0.973 sec/step)\n",
      "I0902 10:06:40.627666 139792788920128 learning.py:507] global step 44468: loss = 0.0912 (0.985 sec/step)\n",
      "I0902 10:06:41.583922 139792788920128 learning.py:507] global step 44469: loss = 0.1025 (0.955 sec/step)\n",
      "I0902 10:06:42.546632 139792788920128 learning.py:507] global step 44470: loss = 0.1951 (0.961 sec/step)\n",
      "I0902 10:06:43.523929 139792788920128 learning.py:507] global step 44471: loss = 0.0611 (0.976 sec/step)\n",
      "I0902 10:06:44.488203 139792788920128 learning.py:507] global step 44472: loss = 0.1640 (0.963 sec/step)\n",
      "I0902 10:06:45.452956 139792788920128 learning.py:507] global step 44473: loss = 0.0848 (0.963 sec/step)\n",
      "I0902 10:06:46.424311 139792788920128 learning.py:507] global step 44474: loss = 0.0769 (0.970 sec/step)\n",
      "I0902 10:06:47.400936 139792788920128 learning.py:507] global step 44475: loss = 0.0931 (0.975 sec/step)\n",
      "I0902 10:06:48.355547 139792788920128 learning.py:507] global step 44476: loss = 0.4492 (0.953 sec/step)\n",
      "I0902 10:06:49.325289 139792788920128 learning.py:507] global step 44477: loss = 0.1117 (0.968 sec/step)\n",
      "I0902 10:06:50.278212 139792788920128 learning.py:507] global step 44478: loss = 0.0990 (0.951 sec/step)\n",
      "I0902 10:06:51.261986 139792788920128 learning.py:507] global step 44479: loss = 0.0886 (0.982 sec/step)\n",
      "I0902 10:06:52.233549 139792788920128 learning.py:507] global step 44480: loss = 0.1258 (0.970 sec/step)\n",
      "I0902 10:06:53.198183 139792788920128 learning.py:507] global step 44481: loss = 0.0970 (0.963 sec/step)\n",
      "I0902 10:06:54.161859 139792788920128 learning.py:507] global step 44482: loss = 0.0422 (0.962 sec/step)\n",
      "I0902 10:06:55.125432 139792788920128 learning.py:507] global step 44483: loss = 0.0915 (0.962 sec/step)\n",
      "I0902 10:06:56.087358 139792788920128 learning.py:507] global step 44484: loss = 0.0776 (0.960 sec/step)\n",
      "I0902 10:06:57.077849 139792788920128 learning.py:507] global step 44485: loss = 0.0666 (0.989 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:06:58.043713 139792788920128 learning.py:507] global step 44486: loss = 0.2479 (0.964 sec/step)\n",
      "I0902 10:06:59.025843 139792788920128 learning.py:507] global step 44487: loss = 0.1283 (0.980 sec/step)\n",
      "I0902 10:07:00.002435 139792788920128 learning.py:507] global step 44488: loss = 0.0856 (0.975 sec/step)\n",
      "I0902 10:07:00.960310 139792788920128 learning.py:507] global step 44489: loss = 0.0678 (0.956 sec/step)\n",
      "I0902 10:07:01.924247 139792788920128 learning.py:507] global step 44490: loss = 0.1692 (0.962 sec/step)\n",
      "I0902 10:07:02.907893 139792788920128 learning.py:507] global step 44491: loss = 0.1029 (0.982 sec/step)\n",
      "I0902 10:07:03.862447 139792788920128 learning.py:507] global step 44492: loss = 0.1353 (0.953 sec/step)\n",
      "I0902 10:07:04.818449 139792788920128 learning.py:507] global step 44493: loss = 0.0943 (0.954 sec/step)\n",
      "I0902 10:07:05.801921 139792788920128 learning.py:507] global step 44494: loss = 0.1672 (0.982 sec/step)\n",
      "I0902 10:07:06.758662 139792788920128 learning.py:507] global step 44495: loss = 0.0625 (0.955 sec/step)\n",
      "I0902 10:07:07.723221 139792788920128 learning.py:507] global step 44496: loss = 0.0742 (0.963 sec/step)\n",
      "I0902 10:07:08.672367 139792788920128 learning.py:507] global step 44497: loss = 0.0643 (0.947 sec/step)\n",
      "I0902 10:07:09.648357 139792788920128 learning.py:507] global step 44498: loss = 0.1642 (0.974 sec/step)\n",
      "I0902 10:07:10.606719 139792788920128 learning.py:507] global step 44499: loss = 0.1305 (0.957 sec/step)\n",
      "I0902 10:07:11.563611 139792788920128 learning.py:507] global step 44500: loss = 0.0955 (0.955 sec/step)\n",
      "I0902 10:07:12.540817 139792788920128 learning.py:507] global step 44501: loss = 0.1137 (0.975 sec/step)\n",
      "I0902 10:07:13.508203 139792788920128 learning.py:507] global step 44502: loss = 0.1519 (0.966 sec/step)\n",
      "I0902 10:07:14.474531 139792788920128 learning.py:507] global step 44503: loss = 0.1287 (0.964 sec/step)\n",
      "I0902 10:07:15.454524 139792788920128 learning.py:507] global step 44504: loss = 0.1677 (0.978 sec/step)\n",
      "I0902 10:07:16.422698 139792788920128 learning.py:507] global step 44505: loss = 0.0564 (0.967 sec/step)\n",
      "I0902 10:07:17.398796 139792788920128 learning.py:507] global step 44506: loss = 0.1553 (0.975 sec/step)\n",
      "I0902 10:07:18.359265 139792788920128 learning.py:507] global step 44507: loss = 0.1032 (0.959 sec/step)\n",
      "I0902 10:07:19.322541 139792788920128 learning.py:507] global step 44508: loss = 0.1300 (0.962 sec/step)\n",
      "I0902 10:07:20.275277 139792788920128 learning.py:507] global step 44509: loss = 0.1495 (0.951 sec/step)\n",
      "I0902 10:07:21.247074 139792788920128 learning.py:507] global step 44510: loss = 0.1179 (0.970 sec/step)\n",
      "I0902 10:07:22.236806 139792788920128 learning.py:507] global step 44511: loss = 0.1473 (0.988 sec/step)\n",
      "I0902 10:07:23.198914 139792788920128 learning.py:507] global step 44512: loss = 0.0379 (0.960 sec/step)\n",
      "I0902 10:07:24.153534 139792788920128 learning.py:507] global step 44513: loss = 0.1701 (0.953 sec/step)\n",
      "I0902 10:07:25.114631 139792788920128 learning.py:507] global step 44514: loss = 0.1264 (0.959 sec/step)\n",
      "I0902 10:07:26.093908 139792788920128 learning.py:507] global step 44515: loss = 0.1192 (0.978 sec/step)\n",
      "I0902 10:07:27.051317 139792788920128 learning.py:507] global step 44516: loss = 0.1861 (0.956 sec/step)\n",
      "I0902 10:07:28.010300 139792788920128 learning.py:507] global step 44517: loss = 0.0893 (0.957 sec/step)\n",
      "I0902 10:07:28.991955 139792788920128 learning.py:507] global step 44518: loss = 0.2164 (0.980 sec/step)\n",
      "I0902 10:07:29.955650 139792788920128 learning.py:507] global step 44519: loss = 0.2112 (0.962 sec/step)\n",
      "I0902 10:07:30.916112 139792788920128 learning.py:507] global step 44520: loss = 0.0894 (0.959 sec/step)\n",
      "I0902 10:07:31.899023 139792788920128 learning.py:507] global step 44521: loss = 0.1935 (0.981 sec/step)\n",
      "I0902 10:07:32.864407 139792788920128 learning.py:507] global step 44522: loss = 0.0926 (0.964 sec/step)\n",
      "I0902 10:07:33.837823 139792788920128 learning.py:507] global step 44523: loss = 0.3433 (0.972 sec/step)\n",
      "I0902 10:07:34.818747 139792788920128 learning.py:507] global step 44524: loss = 0.0924 (0.979 sec/step)\n",
      "I0902 10:07:35.809681 139792788920128 learning.py:507] global step 44525: loss = 0.1588 (0.989 sec/step)\n",
      "I0902 10:07:36.774576 139792788920128 learning.py:507] global step 44526: loss = 0.2759 (0.963 sec/step)\n",
      "I0902 10:07:37.743793 139792788920128 learning.py:507] global step 44527: loss = 0.0672 (0.968 sec/step)\n",
      "I0902 10:07:38.709673 139792788920128 learning.py:507] global step 44528: loss = 0.1305 (0.964 sec/step)\n",
      "I0902 10:07:39.685211 139792788920128 learning.py:507] global step 44529: loss = 0.1863 (0.974 sec/step)\n",
      "I0902 10:07:40.661784 139792788920128 learning.py:507] global step 44530: loss = 0.1908 (0.975 sec/step)\n",
      "I0902 10:07:41.629323 139792788920128 learning.py:507] global step 44531: loss = 0.0759 (0.966 sec/step)\n",
      "I0902 10:07:42.608866 139792788920128 learning.py:507] global step 44532: loss = 0.0984 (0.978 sec/step)\n",
      "I0902 10:07:43.568864 139792788920128 learning.py:507] global step 44533: loss = 0.0636 (0.958 sec/step)\n",
      "I0902 10:07:44.538417 139792788920128 learning.py:507] global step 44534: loss = 0.1524 (0.968 sec/step)\n",
      "I0902 10:07:45.508603 139792788920128 learning.py:507] global step 44535: loss = 0.1462 (0.969 sec/step)\n",
      "I0902 10:07:46.470634 139792788920128 learning.py:507] global step 44536: loss = 0.0775 (0.960 sec/step)\n",
      "I0902 10:07:47.462528 139792788920128 learning.py:507] global step 44537: loss = 0.1136 (0.990 sec/step)\n",
      "I0902 10:07:48.431242 139792788920128 learning.py:507] global step 44538: loss = 0.0824 (0.967 sec/step)\n",
      "I0902 10:07:49.404882 139792788920128 learning.py:507] global step 44539: loss = 0.2584 (0.958 sec/step)\n",
      "I0902 10:07:50.023915 139778936784640 supervisor.py:1050] Recording summary at step 44539.\n",
      "I0902 10:07:50.627324 139792788920128 learning.py:507] global step 44540: loss = 0.0636 (1.220 sec/step)\n",
      "I0902 10:07:51.604866 139792788920128 learning.py:507] global step 44541: loss = 0.2295 (0.976 sec/step)\n",
      "I0902 10:07:52.574961 139792788920128 learning.py:507] global step 44542: loss = 0.0762 (0.968 sec/step)\n",
      "I0902 10:07:53.537208 139792788920128 learning.py:507] global step 44543: loss = 0.1072 (0.961 sec/step)\n",
      "I0902 10:07:54.515021 139792788920128 learning.py:507] global step 44544: loss = 0.0818 (0.976 sec/step)\n",
      "I0902 10:07:55.492172 139792788920128 learning.py:507] global step 44545: loss = 0.2762 (0.975 sec/step)\n",
      "I0902 10:07:56.464256 139792788920128 learning.py:507] global step 44546: loss = 0.1298 (0.970 sec/step)\n",
      "I0902 10:07:57.436741 139792788920128 learning.py:507] global step 44547: loss = 0.0658 (0.971 sec/step)\n",
      "I0902 10:07:58.424114 139792788920128 learning.py:507] global step 44548: loss = 0.2797 (0.986 sec/step)\n",
      "I0902 10:07:59.397855 139792788920128 learning.py:507] global step 44549: loss = 0.0775 (0.972 sec/step)\n",
      "I0902 10:08:00.356862 139792788920128 learning.py:507] global step 44550: loss = 0.0642 (0.957 sec/step)\n",
      "I0902 10:08:01.301997 139792788920128 learning.py:507] global step 44551: loss = 0.0618 (0.944 sec/step)\n",
      "I0902 10:08:02.296903 139792788920128 learning.py:507] global step 44552: loss = 0.0677 (0.993 sec/step)\n",
      "I0902 10:08:03.253070 139792788920128 learning.py:507] global step 44553: loss = 0.1263 (0.954 sec/step)\n",
      "I0902 10:08:04.215053 139792788920128 learning.py:507] global step 44554: loss = 0.0825 (0.960 sec/step)\n",
      "I0902 10:08:05.178424 139792788920128 learning.py:507] global step 44555: loss = 0.1105 (0.962 sec/step)\n",
      "I0902 10:08:06.147998 139792788920128 learning.py:507] global step 44556: loss = 0.1397 (0.968 sec/step)\n",
      "I0902 10:08:07.108520 139792788920128 learning.py:507] global step 44557: loss = 0.1025 (0.959 sec/step)\n",
      "I0902 10:08:08.062295 139792788920128 learning.py:507] global step 44558: loss = 0.0974 (0.952 sec/step)\n",
      "I0902 10:08:09.049660 139792788920128 learning.py:507] global step 44559: loss = 0.2327 (0.986 sec/step)\n",
      "I0902 10:08:10.011192 139792788920128 learning.py:507] global step 44560: loss = 0.0734 (0.960 sec/step)\n",
      "I0902 10:08:10.979010 139792788920128 learning.py:507] global step 44561: loss = 0.1447 (0.966 sec/step)\n",
      "I0902 10:08:11.941664 139792788920128 learning.py:507] global step 44562: loss = 0.1238 (0.961 sec/step)\n",
      "I0902 10:08:12.892614 139792788920128 learning.py:507] global step 44563: loss = 0.0631 (0.949 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:08:13.871083 139792788920128 learning.py:507] global step 44564: loss = 0.0920 (0.977 sec/step)\n",
      "I0902 10:08:14.858637 139792788920128 learning.py:507] global step 44565: loss = 0.2015 (0.986 sec/step)\n",
      "I0902 10:08:15.838640 139792788920128 learning.py:507] global step 44566: loss = 0.1113 (0.978 sec/step)\n",
      "I0902 10:08:16.790305 139792788920128 learning.py:507] global step 44567: loss = 0.0794 (0.950 sec/step)\n",
      "I0902 10:08:17.760707 139792788920128 learning.py:507] global step 44568: loss = 0.1220 (0.969 sec/step)\n",
      "I0902 10:08:18.729411 139792788920128 learning.py:507] global step 44569: loss = 0.1262 (0.967 sec/step)\n",
      "I0902 10:08:19.702779 139792788920128 learning.py:507] global step 44570: loss = 0.0998 (0.972 sec/step)\n",
      "I0902 10:08:20.659954 139792788920128 learning.py:507] global step 44571: loss = 0.1240 (0.956 sec/step)\n",
      "I0902 10:08:21.628752 139792788920128 learning.py:507] global step 44572: loss = 0.0545 (0.967 sec/step)\n",
      "I0902 10:08:22.610952 139792788920128 learning.py:507] global step 44573: loss = 0.0574 (0.980 sec/step)\n",
      "I0902 10:08:23.581628 139792788920128 learning.py:507] global step 44574: loss = 0.1326 (0.969 sec/step)\n",
      "I0902 10:08:24.552642 139792788920128 learning.py:507] global step 44575: loss = 0.1055 (0.969 sec/step)\n",
      "I0902 10:08:25.526239 139792788920128 learning.py:507] global step 44576: loss = 0.1055 (0.972 sec/step)\n",
      "I0902 10:08:26.493979 139792788920128 learning.py:507] global step 44577: loss = 0.2381 (0.966 sec/step)\n",
      "I0902 10:08:27.461040 139792788920128 learning.py:507] global step 44578: loss = 0.0709 (0.965 sec/step)\n",
      "I0902 10:08:28.438470 139792788920128 learning.py:507] global step 44579: loss = 0.1019 (0.976 sec/step)\n",
      "I0902 10:08:29.405350 139792788920128 learning.py:507] global step 44580: loss = 0.0662 (0.965 sec/step)\n",
      "I0902 10:08:30.376811 139792788920128 learning.py:507] global step 44581: loss = 0.1601 (0.970 sec/step)\n",
      "I0902 10:08:31.376889 139792788920128 learning.py:507] global step 44582: loss = 0.1276 (0.998 sec/step)\n",
      "I0902 10:08:32.347833 139792788920128 learning.py:507] global step 44583: loss = 0.1860 (0.969 sec/step)\n",
      "I0902 10:08:33.309231 139792788920128 learning.py:507] global step 44584: loss = 0.1597 (0.960 sec/step)\n",
      "I0902 10:08:34.277395 139792788920128 learning.py:507] global step 44585: loss = 0.1071 (0.966 sec/step)\n",
      "I0902 10:08:35.251870 139792788920128 learning.py:507] global step 44586: loss = 0.1586 (0.973 sec/step)\n",
      "I0902 10:08:36.234869 139792788920128 learning.py:507] global step 44587: loss = 0.1418 (0.981 sec/step)\n",
      "I0902 10:08:37.205621 139792788920128 learning.py:507] global step 44588: loss = 0.1256 (0.969 sec/step)\n",
      "I0902 10:08:38.186858 139792788920128 learning.py:507] global step 44589: loss = 0.0917 (0.980 sec/step)\n",
      "I0902 10:08:39.175735 139792788920128 learning.py:507] global step 44590: loss = 0.1709 (0.987 sec/step)\n",
      "I0902 10:08:40.149353 139792788920128 learning.py:507] global step 44591: loss = 0.3610 (0.972 sec/step)\n",
      "I0902 10:08:41.113997 139792788920128 learning.py:507] global step 44592: loss = 0.1461 (0.963 sec/step)\n",
      "I0902 10:08:42.069086 139792788920128 learning.py:507] global step 44593: loss = 0.0927 (0.953 sec/step)\n",
      "I0902 10:08:43.049254 139792788920128 learning.py:507] global step 44594: loss = 0.1822 (0.978 sec/step)\n",
      "I0902 10:08:44.017938 139792788920128 learning.py:507] global step 44595: loss = 0.1012 (0.967 sec/step)\n",
      "I0902 10:08:44.968605 139792788920128 learning.py:507] global step 44596: loss = 0.0946 (0.949 sec/step)\n",
      "I0902 10:08:45.942853 139792788920128 learning.py:507] global step 44597: loss = 0.0778 (0.973 sec/step)\n",
      "I0902 10:08:46.911035 139792788920128 learning.py:507] global step 44598: loss = 0.1587 (0.967 sec/step)\n",
      "I0902 10:08:47.896997 139792788920128 learning.py:507] global step 44599: loss = 0.1656 (0.984 sec/step)\n",
      "I0902 10:08:48.878269 139792788920128 learning.py:507] global step 44600: loss = 0.3184 (0.980 sec/step)\n",
      "I0902 10:08:49.857880 139792788920128 learning.py:507] global step 44601: loss = 0.1453 (0.978 sec/step)\n",
      "I0902 10:08:50.853152 139792788920128 learning.py:507] global step 44602: loss = 0.1136 (0.994 sec/step)\n",
      "I0902 10:08:51.814171 139792788920128 learning.py:507] global step 44603: loss = 0.0839 (0.959 sec/step)\n",
      "I0902 10:08:52.823333 139792788920128 learning.py:507] global step 44604: loss = 0.0842 (1.007 sec/step)\n",
      "I0902 10:08:53.812983 139792788920128 learning.py:507] global step 44605: loss = 0.0950 (0.988 sec/step)\n",
      "I0902 10:08:54.807934 139792788920128 learning.py:507] global step 44606: loss = 0.1322 (0.993 sec/step)\n",
      "I0902 10:08:55.758448 139792788920128 learning.py:507] global step 44607: loss = 0.1664 (0.949 sec/step)\n",
      "I0902 10:08:56.743433 139792788920128 learning.py:507] global step 44608: loss = 0.1777 (0.983 sec/step)\n",
      "I0902 10:08:57.717107 139792788920128 learning.py:507] global step 44609: loss = 0.0812 (0.972 sec/step)\n",
      "I0902 10:08:58.682586 139792788920128 learning.py:507] global step 44610: loss = 0.1530 (0.964 sec/step)\n",
      "I0902 10:08:59.652089 139792788920128 learning.py:507] global step 44611: loss = 0.1674 (0.968 sec/step)\n",
      "I0902 10:09:00.619900 139792788920128 learning.py:507] global step 44612: loss = 0.0717 (0.966 sec/step)\n",
      "I0902 10:09:01.595800 139792788920128 learning.py:507] global step 44613: loss = 0.1454 (0.974 sec/step)\n",
      "I0902 10:09:02.560652 139792788920128 learning.py:507] global step 44614: loss = 0.1190 (0.963 sec/step)\n",
      "I0902 10:09:03.541115 139792788920128 learning.py:507] global step 44615: loss = 0.0785 (0.979 sec/step)\n",
      "I0902 10:09:04.508745 139792788920128 learning.py:507] global step 44616: loss = 0.1315 (0.966 sec/step)\n",
      "I0902 10:09:05.462131 139792788920128 learning.py:507] global step 44617: loss = 0.1148 (0.952 sec/step)\n",
      "I0902 10:09:06.427030 139792788920128 learning.py:507] global step 44618: loss = 0.2300 (0.963 sec/step)\n",
      "I0902 10:09:07.385406 139792788920128 learning.py:507] global step 44619: loss = 0.0485 (0.957 sec/step)\n",
      "I0902 10:09:08.338336 139792788920128 learning.py:507] global step 44620: loss = 0.2295 (0.951 sec/step)\n",
      "I0902 10:09:09.312274 139792788920128 learning.py:507] global step 44621: loss = 0.1303 (0.972 sec/step)\n",
      "I0902 10:09:10.286528 139792788920128 learning.py:507] global step 44622: loss = 0.0929 (0.972 sec/step)\n",
      "I0902 10:09:11.251741 139792788920128 learning.py:507] global step 44623: loss = 0.1232 (0.964 sec/step)\n",
      "I0902 10:09:12.210396 139792788920128 learning.py:507] global step 44624: loss = 0.0951 (0.957 sec/step)\n",
      "I0902 10:09:13.179904 139792788920128 learning.py:507] global step 44625: loss = 0.0728 (0.968 sec/step)\n",
      "I0902 10:09:14.124008 139792788920128 learning.py:507] global step 44626: loss = 0.0662 (0.942 sec/step)\n",
      "I0902 10:09:15.091394 139792788920128 learning.py:507] global step 44627: loss = 0.0508 (0.966 sec/step)\n",
      "I0902 10:09:16.055423 139792788920128 learning.py:507] global step 44628: loss = 0.1973 (0.962 sec/step)\n",
      "I0902 10:09:17.036874 139792788920128 learning.py:507] global step 44629: loss = 0.1959 (0.980 sec/step)\n",
      "I0902 10:09:18.015666 139792788920128 learning.py:507] global step 44630: loss = 0.1159 (0.977 sec/step)\n",
      "I0902 10:09:18.964652 139792788920128 learning.py:507] global step 44631: loss = 0.0635 (0.947 sec/step)\n",
      "I0902 10:09:19.924154 139792788920128 learning.py:507] global step 44632: loss = 0.2377 (0.958 sec/step)\n",
      "I0902 10:09:20.886349 139792788920128 learning.py:507] global step 44633: loss = 0.1819 (0.961 sec/step)\n",
      "I0902 10:09:21.854316 139792788920128 learning.py:507] global step 44634: loss = 0.2005 (0.966 sec/step)\n",
      "I0902 10:09:22.819164 139792788920128 learning.py:507] global step 44635: loss = 0.1631 (0.963 sec/step)\n",
      "I0902 10:09:23.784507 139792788920128 learning.py:507] global step 44636: loss = 0.0841 (0.964 sec/step)\n",
      "I0902 10:09:24.745322 139792788920128 learning.py:507] global step 44637: loss = 0.2933 (0.959 sec/step)\n",
      "I0902 10:09:25.720118 139792788920128 learning.py:507] global step 44638: loss = 0.0830 (0.973 sec/step)\n",
      "I0902 10:09:26.683810 139792788920128 learning.py:507] global step 44639: loss = 0.0669 (0.962 sec/step)\n",
      "I0902 10:09:27.637541 139792788920128 learning.py:507] global step 44640: loss = 0.1792 (0.952 sec/step)\n",
      "I0902 10:09:28.594071 139792788920128 learning.py:507] global step 44641: loss = 0.3896 (0.955 sec/step)\n",
      "I0902 10:09:29.571825 139792788920128 learning.py:507] global step 44642: loss = 0.0494 (0.977 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:09:30.552572 139792788920128 learning.py:507] global step 44643: loss = 0.0564 (0.979 sec/step)\n",
      "I0902 10:09:31.526748 139792788920128 learning.py:507] global step 44644: loss = 0.2401 (0.973 sec/step)\n",
      "I0902 10:09:32.489207 139792788920128 learning.py:507] global step 44645: loss = 0.1044 (0.961 sec/step)\n",
      "I0902 10:09:33.454125 139792788920128 learning.py:507] global step 44646: loss = 0.1002 (0.963 sec/step)\n",
      "I0902 10:09:34.414997 139792788920128 learning.py:507] global step 44647: loss = 0.2306 (0.959 sec/step)\n",
      "I0902 10:09:35.365783 139792788920128 learning.py:507] global step 44648: loss = 0.1667 (0.949 sec/step)\n",
      "I0902 10:09:36.332199 139792788920128 learning.py:507] global step 44649: loss = 0.1340 (0.965 sec/step)\n",
      "I0902 10:09:37.313748 139792788920128 learning.py:507] global step 44650: loss = 0.1083 (0.980 sec/step)\n",
      "I0902 10:09:38.276238 139792788920128 learning.py:507] global step 44651: loss = 0.2474 (0.961 sec/step)\n",
      "I0902 10:09:39.237766 139792788920128 learning.py:507] global step 44652: loss = 0.1607 (0.960 sec/step)\n",
      "I0902 10:09:40.214660 139792788920128 learning.py:507] global step 44653: loss = 0.1020 (0.975 sec/step)\n",
      "I0902 10:09:41.189669 139792788920128 learning.py:507] global step 44654: loss = 0.1141 (0.973 sec/step)\n",
      "I0902 10:09:42.168512 139792788920128 learning.py:507] global step 44655: loss = 0.1337 (0.977 sec/step)\n",
      "I0902 10:09:43.123454 139792788920128 learning.py:507] global step 44656: loss = 0.0889 (0.953 sec/step)\n",
      "I0902 10:09:44.081501 139792788920128 learning.py:507] global step 44657: loss = 0.0732 (0.956 sec/step)\n",
      "I0902 10:09:45.048856 139792788920128 learning.py:507] global step 44658: loss = 0.2164 (0.966 sec/step)\n",
      "I0902 10:09:45.990936 139792788920128 learning.py:507] global step 44659: loss = 0.0544 (0.940 sec/step)\n",
      "I0902 10:09:46.974951 139792788920128 learning.py:507] global step 44660: loss = 0.1117 (0.982 sec/step)\n",
      "I0902 10:09:47.941028 139792788920128 learning.py:507] global step 44661: loss = 0.0702 (0.964 sec/step)\n",
      "I0902 10:09:48.911783 139792788920128 learning.py:507] global step 44662: loss = 0.1447 (0.969 sec/step)\n",
      "I0902 10:09:50.002864 139792788920128 learning.py:507] global step 44663: loss = 0.1305 (1.087 sec/step)\n",
      "I0902 10:09:50.332317 139778936784640 supervisor.py:1050] Recording summary at step 44663.\n",
      "I0902 10:09:51.099626 139792788920128 learning.py:507] global step 44664: loss = 0.1134 (1.088 sec/step)\n",
      "I0902 10:09:52.078322 139792788920128 learning.py:507] global step 44665: loss = 0.0846 (0.977 sec/step)\n",
      "I0902 10:09:53.068486 139792788920128 learning.py:507] global step 44666: loss = 0.1337 (0.989 sec/step)\n",
      "I0902 10:09:54.033638 139792788920128 learning.py:507] global step 44667: loss = 0.1510 (0.963 sec/step)\n",
      "I0902 10:09:54.990531 139792788920128 learning.py:507] global step 44668: loss = 0.1790 (0.955 sec/step)\n",
      "I0902 10:09:55.962556 139792788920128 learning.py:507] global step 44669: loss = 0.1276 (0.970 sec/step)\n",
      "I0902 10:09:56.957130 139792788920128 learning.py:507] global step 44670: loss = 0.0792 (0.993 sec/step)\n",
      "I0902 10:09:57.937119 139792788920128 learning.py:507] global step 44671: loss = 0.2662 (0.978 sec/step)\n",
      "I0902 10:09:58.895004 139792788920128 learning.py:507] global step 44672: loss = 0.0787 (0.956 sec/step)\n",
      "I0902 10:09:59.869954 139792788920128 learning.py:507] global step 44673: loss = 0.1049 (0.973 sec/step)\n",
      "I0902 10:10:00.844499 139792788920128 learning.py:507] global step 44674: loss = 0.2488 (0.973 sec/step)\n",
      "I0902 10:10:01.805617 139792788920128 learning.py:507] global step 44675: loss = 0.1086 (0.959 sec/step)\n",
      "I0902 10:10:02.756930 139792788920128 learning.py:507] global step 44676: loss = 0.0908 (0.950 sec/step)\n",
      "I0902 10:10:03.721819 139792788920128 learning.py:507] global step 44677: loss = 0.0857 (0.963 sec/step)\n",
      "I0902 10:10:04.700010 139792788920128 learning.py:507] global step 44678: loss = 0.1226 (0.977 sec/step)\n",
      "I0902 10:10:05.678647 139792788920128 learning.py:507] global step 44679: loss = 0.1346 (0.977 sec/step)\n",
      "I0902 10:10:06.645312 139792788920128 learning.py:507] global step 44680: loss = 0.0978 (0.965 sec/step)\n",
      "I0902 10:10:07.625604 139792788920128 learning.py:507] global step 44681: loss = 0.0960 (0.979 sec/step)\n",
      "I0902 10:10:08.579921 139792788920128 learning.py:507] global step 44682: loss = 0.1614 (0.953 sec/step)\n",
      "I0902 10:10:09.544588 139792788920128 learning.py:507] global step 44683: loss = 0.1257 (0.963 sec/step)\n",
      "I0902 10:10:10.536155 139792788920128 learning.py:507] global step 44684: loss = 0.0873 (0.990 sec/step)\n",
      "I0902 10:10:11.504855 139792788920128 learning.py:507] global step 44685: loss = 0.0991 (0.967 sec/step)\n",
      "I0902 10:10:12.479921 139792788920128 learning.py:507] global step 44686: loss = 0.3366 (0.973 sec/step)\n",
      "I0902 10:10:13.453317 139792788920128 learning.py:507] global step 44687: loss = 0.1497 (0.972 sec/step)\n",
      "I0902 10:10:14.414760 139792788920128 learning.py:507] global step 44688: loss = 0.0652 (0.960 sec/step)\n",
      "I0902 10:10:15.380693 139792788920128 learning.py:507] global step 44689: loss = 0.1333 (0.964 sec/step)\n",
      "I0902 10:10:16.353000 139792788920128 learning.py:507] global step 44690: loss = 0.2083 (0.971 sec/step)\n",
      "I0902 10:10:17.342877 139792788920128 learning.py:507] global step 44691: loss = 0.0915 (0.988 sec/step)\n",
      "I0902 10:10:18.319821 139792788920128 learning.py:507] global step 44692: loss = 0.1368 (0.975 sec/step)\n",
      "I0902 10:10:19.313613 139792788920128 learning.py:507] global step 44693: loss = 0.3291 (0.992 sec/step)\n",
      "I0902 10:10:20.285022 139792788920128 learning.py:507] global step 44694: loss = 0.2248 (0.970 sec/step)\n",
      "I0902 10:10:21.263170 139792788920128 learning.py:507] global step 44695: loss = 0.1347 (0.977 sec/step)\n",
      "I0902 10:10:22.218109 139792788920128 learning.py:507] global step 44696: loss = 0.0912 (0.953 sec/step)\n",
      "I0902 10:10:23.180764 139792788920128 learning.py:507] global step 44697: loss = 0.1142 (0.961 sec/step)\n",
      "I0902 10:10:24.144885 139792788920128 learning.py:507] global step 44698: loss = 0.0651 (0.962 sec/step)\n",
      "I0902 10:10:25.111065 139792788920128 learning.py:507] global step 44699: loss = 0.1085 (0.964 sec/step)\n",
      "I0902 10:10:26.062892 139792788920128 learning.py:507] global step 44700: loss = 0.1370 (0.950 sec/step)\n",
      "I0902 10:10:27.040256 139792788920128 learning.py:507] global step 44701: loss = 0.1375 (0.976 sec/step)\n",
      "I0902 10:10:28.000968 139792788920128 learning.py:507] global step 44702: loss = 0.0982 (0.959 sec/step)\n",
      "I0902 10:10:28.963703 139792788920128 learning.py:507] global step 44703: loss = 0.1082 (0.961 sec/step)\n",
      "I0902 10:10:29.932332 139792788920128 learning.py:507] global step 44704: loss = 0.1421 (0.967 sec/step)\n",
      "I0902 10:10:30.906323 139792788920128 learning.py:507] global step 44705: loss = 0.0581 (0.972 sec/step)\n",
      "I0902 10:10:31.888688 139792788920128 learning.py:507] global step 44706: loss = 0.1207 (0.981 sec/step)\n",
      "I0902 10:10:32.860029 139792788920128 learning.py:507] global step 44707: loss = 0.0810 (0.970 sec/step)\n",
      "I0902 10:10:33.823662 139792788920128 learning.py:507] global step 44708: loss = 0.0995 (0.962 sec/step)\n",
      "I0902 10:10:34.786252 139792788920128 learning.py:507] global step 44709: loss = 0.2333 (0.961 sec/step)\n",
      "I0902 10:10:35.759760 139792788920128 learning.py:507] global step 44710: loss = 0.1127 (0.972 sec/step)\n",
      "I0902 10:10:36.722901 139792788920128 learning.py:507] global step 44711: loss = 0.0678 (0.962 sec/step)\n",
      "I0902 10:10:37.682579 139792788920128 learning.py:507] global step 44712: loss = 0.0568 (0.958 sec/step)\n",
      "I0902 10:10:38.637655 139792788920128 learning.py:507] global step 44713: loss = 0.1692 (0.954 sec/step)\n",
      "I0902 10:10:39.624722 139792788920128 learning.py:507] global step 44714: loss = 0.0987 (0.985 sec/step)\n",
      "I0902 10:10:40.604924 139792788920128 learning.py:507] global step 44715: loss = 0.0962 (0.978 sec/step)\n",
      "I0902 10:10:41.580144 139792788920128 learning.py:507] global step 44716: loss = 0.1328 (0.974 sec/step)\n",
      "I0902 10:10:42.550001 139792788920128 learning.py:507] global step 44717: loss = 0.0832 (0.968 sec/step)\n",
      "I0902 10:10:43.510117 139792788920128 learning.py:507] global step 44718: loss = 0.1002 (0.958 sec/step)\n",
      "I0902 10:10:44.475540 139792788920128 learning.py:507] global step 44719: loss = 0.1474 (0.964 sec/step)\n",
      "I0902 10:10:45.442823 139792788920128 learning.py:507] global step 44720: loss = 0.1395 (0.966 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:10:46.427992 139792788920128 learning.py:507] global step 44721: loss = 0.0898 (0.984 sec/step)\n",
      "I0902 10:10:47.386064 139792788920128 learning.py:507] global step 44722: loss = 0.1916 (0.956 sec/step)\n",
      "I0902 10:10:48.342549 139792788920128 learning.py:507] global step 44723: loss = 0.1805 (0.955 sec/step)\n",
      "I0902 10:10:49.326430 139792788920128 learning.py:507] global step 44724: loss = 0.1320 (0.982 sec/step)\n",
      "I0902 10:10:50.298429 139792788920128 learning.py:507] global step 44725: loss = 0.1168 (0.970 sec/step)\n",
      "I0902 10:10:51.283490 139792788920128 learning.py:507] global step 44726: loss = 0.1239 (0.983 sec/step)\n",
      "I0902 10:10:52.251904 139792788920128 learning.py:507] global step 44727: loss = 0.0967 (0.967 sec/step)\n",
      "I0902 10:10:53.201651 139792788920128 learning.py:507] global step 44728: loss = 0.1701 (0.948 sec/step)\n",
      "I0902 10:10:54.180299 139792788920128 learning.py:507] global step 44729: loss = 0.1123 (0.977 sec/step)\n",
      "I0902 10:10:55.147419 139792788920128 learning.py:507] global step 44730: loss = 0.0972 (0.965 sec/step)\n",
      "I0902 10:10:56.112506 139792788920128 learning.py:507] global step 44731: loss = 0.1525 (0.963 sec/step)\n",
      "I0902 10:10:57.092949 139792788920128 learning.py:507] global step 44732: loss = 0.0780 (0.979 sec/step)\n",
      "I0902 10:10:58.050883 139792788920128 learning.py:507] global step 44733: loss = 0.2247 (0.956 sec/step)\n",
      "I0902 10:10:59.040907 139792788920128 learning.py:507] global step 44734: loss = 0.1421 (0.988 sec/step)\n",
      "I0902 10:11:00.008493 139792788920128 learning.py:507] global step 44735: loss = 0.1961 (0.966 sec/step)\n",
      "I0902 10:11:00.969964 139792788920128 learning.py:507] global step 44736: loss = 0.0840 (0.960 sec/step)\n",
      "I0902 10:11:01.928191 139792788920128 learning.py:507] global step 44737: loss = 0.0660 (0.957 sec/step)\n",
      "I0902 10:11:02.917391 139792788920128 learning.py:507] global step 44738: loss = 0.1778 (0.988 sec/step)\n",
      "I0902 10:11:03.882744 139792788920128 learning.py:507] global step 44739: loss = 0.1554 (0.964 sec/step)\n",
      "I0902 10:11:04.845928 139792788920128 learning.py:507] global step 44740: loss = 0.0559 (0.962 sec/step)\n",
      "I0902 10:11:05.807049 139792788920128 learning.py:507] global step 44741: loss = 0.1533 (0.959 sec/step)\n",
      "I0902 10:11:06.764484 139792788920128 learning.py:507] global step 44742: loss = 0.1552 (0.956 sec/step)\n",
      "I0902 10:11:07.733377 139792788920128 learning.py:507] global step 44743: loss = 0.0962 (0.967 sec/step)\n",
      "I0902 10:11:08.710392 139792788920128 learning.py:507] global step 44744: loss = 0.2142 (0.976 sec/step)\n",
      "I0902 10:11:09.680260 139792788920128 learning.py:507] global step 44745: loss = 0.1051 (0.968 sec/step)\n",
      "I0902 10:11:10.652897 139792788920128 learning.py:507] global step 44746: loss = 0.1718 (0.971 sec/step)\n",
      "I0902 10:11:11.620359 139792788920128 learning.py:507] global step 44747: loss = 0.1228 (0.966 sec/step)\n",
      "I0902 10:11:12.596267 139792788920128 learning.py:507] global step 44748: loss = 0.0944 (0.974 sec/step)\n",
      "I0902 10:11:13.566679 139792788920128 learning.py:507] global step 44749: loss = 0.0587 (0.969 sec/step)\n",
      "I0902 10:11:14.523765 139792788920128 learning.py:507] global step 44750: loss = 0.0816 (0.955 sec/step)\n",
      "I0902 10:11:15.476762 139792788920128 learning.py:507] global step 44751: loss = 0.1612 (0.951 sec/step)\n",
      "I0902 10:11:16.454874 139792788920128 learning.py:507] global step 44752: loss = 0.1497 (0.977 sec/step)\n",
      "I0902 10:11:17.429192 139792788920128 learning.py:507] global step 44753: loss = 0.1464 (0.973 sec/step)\n",
      "I0902 10:11:18.394829 139792788920128 learning.py:507] global step 44754: loss = 0.1516 (0.964 sec/step)\n",
      "I0902 10:11:19.351236 139792788920128 learning.py:507] global step 44755: loss = 0.1281 (0.955 sec/step)\n",
      "I0902 10:11:20.309995 139792788920128 learning.py:507] global step 44756: loss = 0.0719 (0.957 sec/step)\n",
      "I0902 10:11:21.292398 139792788920128 learning.py:507] global step 44757: loss = 0.1414 (0.981 sec/step)\n",
      "I0902 10:11:22.251656 139792788920128 learning.py:507] global step 44758: loss = 0.0664 (0.957 sec/step)\n",
      "I0902 10:11:23.239699 139792788920128 learning.py:507] global step 44759: loss = 0.1875 (0.986 sec/step)\n",
      "I0902 10:11:24.219524 139792788920128 learning.py:507] global step 44760: loss = 0.1309 (0.978 sec/step)\n",
      "I0902 10:11:25.182736 139792788920128 learning.py:507] global step 44761: loss = 0.1190 (0.962 sec/step)\n",
      "I0902 10:11:26.144555 139792788920128 learning.py:507] global step 44762: loss = 0.0950 (0.960 sec/step)\n",
      "I0902 10:11:27.100136 139792788920128 learning.py:507] global step 44763: loss = 0.1311 (0.954 sec/step)\n",
      "I0902 10:11:28.081857 139792788920128 learning.py:507] global step 44764: loss = 0.1807 (0.980 sec/step)\n",
      "I0902 10:11:29.058144 139792788920128 learning.py:507] global step 44765: loss = 0.1776 (0.975 sec/step)\n",
      "I0902 10:11:30.031397 139792788920128 learning.py:507] global step 44766: loss = 0.0829 (0.971 sec/step)\n",
      "I0902 10:11:31.003624 139792788920128 learning.py:507] global step 44767: loss = 0.0940 (0.970 sec/step)\n",
      "I0902 10:11:31.965408 139792788920128 learning.py:507] global step 44768: loss = 0.1365 (0.960 sec/step)\n",
      "I0902 10:11:32.933186 139792788920128 learning.py:507] global step 44769: loss = 0.0426 (0.966 sec/step)\n",
      "I0902 10:11:33.896302 139792788920128 learning.py:507] global step 44770: loss = 0.0574 (0.961 sec/step)\n",
      "I0902 10:11:34.870803 139792788920128 learning.py:507] global step 44771: loss = 0.2009 (0.973 sec/step)\n",
      "I0902 10:11:35.839225 139792788920128 learning.py:507] global step 44772: loss = 0.1754 (0.967 sec/step)\n",
      "I0902 10:11:36.786963 139792788920128 learning.py:507] global step 44773: loss = 0.1560 (0.946 sec/step)\n",
      "I0902 10:11:37.762148 139792788920128 learning.py:507] global step 44774: loss = 0.1158 (0.974 sec/step)\n",
      "I0902 10:11:38.757402 139792788920128 learning.py:507] global step 44775: loss = 0.0764 (0.993 sec/step)\n",
      "I0902 10:11:39.731564 139792788920128 learning.py:507] global step 44776: loss = 0.1626 (0.972 sec/step)\n",
      "I0902 10:11:40.689502 139792788920128 learning.py:507] global step 44777: loss = 0.1480 (0.956 sec/step)\n",
      "I0902 10:11:41.646108 139792788920128 learning.py:507] global step 44778: loss = 0.1379 (0.955 sec/step)\n",
      "I0902 10:11:42.612991 139792788920128 learning.py:507] global step 44779: loss = 0.0774 (0.965 sec/step)\n",
      "I0902 10:11:43.590966 139792788920128 learning.py:507] global step 44780: loss = 0.1157 (0.976 sec/step)\n",
      "I0902 10:11:44.565207 139792788920128 learning.py:507] global step 44781: loss = 0.1716 (0.973 sec/step)\n",
      "I0902 10:11:45.535170 139792788920128 learning.py:507] global step 44782: loss = 0.0954 (0.968 sec/step)\n",
      "I0902 10:11:46.506512 139792788920128 learning.py:507] global step 44783: loss = 0.0965 (0.970 sec/step)\n",
      "I0902 10:11:47.500023 139792788920128 learning.py:507] global step 44784: loss = 0.0723 (0.992 sec/step)\n",
      "I0902 10:11:48.493926 139792788920128 learning.py:507] global step 44785: loss = 0.1041 (0.992 sec/step)\n",
      "I0902 10:11:49.465552 139792788920128 learning.py:507] global step 44786: loss = 0.0618 (0.959 sec/step)\n",
      "I0902 10:11:50.087075 139778936784640 supervisor.py:1050] Recording summary at step 44786.\n",
      "I0902 10:11:50.685723 139792788920128 learning.py:507] global step 44787: loss = 0.0770 (1.217 sec/step)\n",
      "I0902 10:11:51.664890 139792788920128 learning.py:507] global step 44788: loss = 0.1438 (0.977 sec/step)\n",
      "I0902 10:11:52.617301 139792788920128 learning.py:507] global step 44789: loss = 0.0841 (0.951 sec/step)\n",
      "I0902 10:11:53.591469 139792788920128 learning.py:507] global step 44790: loss = 0.2861 (0.972 sec/step)\n",
      "I0902 10:11:54.550088 139792788920128 learning.py:507] global step 44791: loss = 0.1307 (0.957 sec/step)\n",
      "I0902 10:11:55.518747 139792788920128 learning.py:507] global step 44792: loss = 0.2682 (0.967 sec/step)\n",
      "I0902 10:11:56.498365 139792788920128 learning.py:507] global step 44793: loss = 0.1461 (0.978 sec/step)\n",
      "I0902 10:11:57.472462 139792788920128 learning.py:507] global step 44794: loss = 0.1846 (0.972 sec/step)\n",
      "I0902 10:11:58.438273 139792788920128 learning.py:507] global step 44795: loss = 0.0604 (0.964 sec/step)\n",
      "I0902 10:11:59.404850 139792788920128 learning.py:507] global step 44796: loss = 0.0930 (0.965 sec/step)\n",
      "I0902 10:12:00.376633 139792788920128 learning.py:507] global step 44797: loss = 0.0601 (0.970 sec/step)\n",
      "I0902 10:12:01.342162 139792788920128 learning.py:507] global step 44798: loss = 0.1626 (0.964 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:12:02.331905 139792788920128 learning.py:507] global step 44799: loss = 0.1135 (0.988 sec/step)\n",
      "I0902 10:12:03.294420 139792788920128 learning.py:507] global step 44800: loss = 0.0564 (0.961 sec/step)\n",
      "I0902 10:12:04.259991 139792788920128 learning.py:507] global step 44801: loss = 0.1691 (0.964 sec/step)\n",
      "I0902 10:12:05.232784 139792788920128 learning.py:507] global step 44802: loss = 0.0873 (0.971 sec/step)\n",
      "I0902 10:12:06.214034 139792788920128 learning.py:507] global step 44803: loss = 0.1217 (0.980 sec/step)\n",
      "I0902 10:12:07.169393 139792788920128 learning.py:507] global step 44804: loss = 0.0508 (0.954 sec/step)\n",
      "I0902 10:12:08.149612 139792788920128 learning.py:507] global step 44805: loss = 0.1048 (0.979 sec/step)\n",
      "I0902 10:12:09.117052 139792788920128 learning.py:507] global step 44806: loss = 0.0671 (0.966 sec/step)\n",
      "I0902 10:12:10.072480 139792788920128 learning.py:507] global step 44807: loss = 0.0618 (0.954 sec/step)\n",
      "I0902 10:12:11.022742 139792788920128 learning.py:507] global step 44808: loss = 0.1279 (0.949 sec/step)\n",
      "I0902 10:12:11.985170 139792788920128 learning.py:507] global step 44809: loss = 0.0563 (0.960 sec/step)\n",
      "I0902 10:12:12.995684 139792788920128 learning.py:507] global step 44810: loss = 0.1736 (1.008 sec/step)\n",
      "I0902 10:12:13.975884 139792788920128 learning.py:507] global step 44811: loss = 0.1285 (0.979 sec/step)\n",
      "I0902 10:12:14.934181 139792788920128 learning.py:507] global step 44812: loss = 0.1721 (0.957 sec/step)\n",
      "I0902 10:12:15.906510 139792788920128 learning.py:507] global step 44813: loss = 0.0652 (0.971 sec/step)\n",
      "I0902 10:12:16.868827 139792788920128 learning.py:507] global step 44814: loss = 0.1638 (0.961 sec/step)\n",
      "I0902 10:12:17.830733 139792788920128 learning.py:507] global step 44815: loss = 0.1288 (0.960 sec/step)\n",
      "I0902 10:12:18.791764 139792788920128 learning.py:507] global step 44816: loss = 0.0982 (0.960 sec/step)\n",
      "I0902 10:12:19.751356 139792788920128 learning.py:507] global step 44817: loss = 0.0422 (0.958 sec/step)\n",
      "I0902 10:12:20.707734 139792788920128 learning.py:507] global step 44818: loss = 0.1018 (0.955 sec/step)\n",
      "I0902 10:12:21.668888 139792788920128 learning.py:507] global step 44819: loss = 0.1346 (0.959 sec/step)\n",
      "I0902 10:12:22.618759 139792788920128 learning.py:507] global step 44820: loss = 0.1738 (0.948 sec/step)\n",
      "I0902 10:12:23.575374 139792788920128 learning.py:507] global step 44821: loss = 0.2910 (0.955 sec/step)\n",
      "I0902 10:12:24.543617 139792788920128 learning.py:507] global step 44822: loss = 0.0855 (0.967 sec/step)\n",
      "I0902 10:12:25.507644 139792788920128 learning.py:507] global step 44823: loss = 0.4036 (0.962 sec/step)\n",
      "I0902 10:12:26.484356 139792788920128 learning.py:507] global step 44824: loss = 0.1484 (0.975 sec/step)\n",
      "I0902 10:12:27.457945 139792788920128 learning.py:507] global step 44825: loss = 0.0699 (0.972 sec/step)\n",
      "I0902 10:12:28.414378 139792788920128 learning.py:507] global step 44826: loss = 0.1070 (0.955 sec/step)\n",
      "I0902 10:12:29.385820 139792788920128 learning.py:507] global step 44827: loss = 0.1154 (0.970 sec/step)\n",
      "I0902 10:12:30.365796 139792788920128 learning.py:507] global step 44828: loss = 0.1222 (0.978 sec/step)\n",
      "I0902 10:12:31.326972 139792788920128 learning.py:507] global step 44829: loss = 0.1435 (0.959 sec/step)\n",
      "I0902 10:12:32.277406 139792788920128 learning.py:507] global step 44830: loss = 0.2054 (0.949 sec/step)\n",
      "I0902 10:12:33.231262 139792788920128 learning.py:507] global step 44831: loss = 0.0849 (0.952 sec/step)\n",
      "I0902 10:12:34.191963 139792788920128 learning.py:507] global step 44832: loss = 0.1053 (0.959 sec/step)\n",
      "I0902 10:12:35.157185 139792788920128 learning.py:507] global step 44833: loss = 0.1200 (0.964 sec/step)\n",
      "I0902 10:12:36.125076 139792788920128 learning.py:507] global step 44834: loss = 0.1290 (0.966 sec/step)\n",
      "I0902 10:12:37.095232 139792788920128 learning.py:507] global step 44835: loss = 0.1108 (0.969 sec/step)\n",
      "I0902 10:12:38.057373 139792788920128 learning.py:507] global step 44836: loss = 0.1635 (0.961 sec/step)\n",
      "I0902 10:12:39.040059 139792788920128 learning.py:507] global step 44837: loss = 0.2319 (0.981 sec/step)\n",
      "I0902 10:12:40.010021 139792788920128 learning.py:507] global step 44838: loss = 0.0915 (0.968 sec/step)\n",
      "I0902 10:12:40.959897 139792788920128 learning.py:507] global step 44839: loss = 0.1907 (0.948 sec/step)\n",
      "I0902 10:12:41.921100 139792788920128 learning.py:507] global step 44840: loss = 0.0663 (0.959 sec/step)\n",
      "I0902 10:12:42.899051 139792788920128 learning.py:507] global step 44841: loss = 0.1359 (0.976 sec/step)\n",
      "I0902 10:12:43.874912 139792788920128 learning.py:507] global step 44842: loss = 0.1202 (0.974 sec/step)\n",
      "I0902 10:12:44.832334 139792788920128 learning.py:507] global step 44843: loss = 0.1925 (0.956 sec/step)\n",
      "I0902 10:12:45.808086 139792788920128 learning.py:507] global step 44844: loss = 0.0857 (0.974 sec/step)\n",
      "I0902 10:12:46.775382 139792788920128 learning.py:507] global step 44845: loss = 0.1399 (0.966 sec/step)\n",
      "I0902 10:12:47.762266 139792788920128 learning.py:507] global step 44846: loss = 0.1402 (0.985 sec/step)\n",
      "I0902 10:12:48.734500 139792788920128 learning.py:507] global step 44847: loss = 0.0810 (0.971 sec/step)\n",
      "I0902 10:12:49.707753 139792788920128 learning.py:507] global step 44848: loss = 0.1845 (0.972 sec/step)\n",
      "I0902 10:12:50.672176 139792788920128 learning.py:507] global step 44849: loss = 0.1369 (0.963 sec/step)\n",
      "I0902 10:12:51.635789 139792788920128 learning.py:507] global step 44850: loss = 0.1138 (0.962 sec/step)\n",
      "I0902 10:12:52.609183 139792788920128 learning.py:507] global step 44851: loss = 0.1263 (0.972 sec/step)\n",
      "I0902 10:12:53.586334 139792788920128 learning.py:507] global step 44852: loss = 0.0514 (0.976 sec/step)\n",
      "I0902 10:12:54.573130 139792788920128 learning.py:507] global step 44853: loss = 0.1348 (0.985 sec/step)\n",
      "I0902 10:12:55.553313 139792788920128 learning.py:507] global step 44854: loss = 0.1682 (0.979 sec/step)\n",
      "I0902 10:12:56.525523 139792788920128 learning.py:507] global step 44855: loss = 0.2542 (0.971 sec/step)\n",
      "I0902 10:12:57.483603 139792788920128 learning.py:507] global step 44856: loss = 0.1352 (0.957 sec/step)\n",
      "I0902 10:12:58.456724 139792788920128 learning.py:507] global step 44857: loss = 0.1147 (0.971 sec/step)\n",
      "I0902 10:12:59.425313 139792788920128 learning.py:507] global step 44858: loss = 0.0896 (0.967 sec/step)\n",
      "I0902 10:13:00.393337 139792788920128 learning.py:507] global step 44859: loss = 0.0782 (0.966 sec/step)\n",
      "I0902 10:13:01.361380 139792788920128 learning.py:507] global step 44860: loss = 0.0930 (0.966 sec/step)\n",
      "I0902 10:13:02.336312 139792788920128 learning.py:507] global step 44861: loss = 0.1133 (0.973 sec/step)\n",
      "I0902 10:13:03.286668 139792788920128 learning.py:507] global step 44862: loss = 0.2057 (0.949 sec/step)\n",
      "I0902 10:13:04.238481 139792788920128 learning.py:507] global step 44863: loss = 0.0781 (0.950 sec/step)\n",
      "I0902 10:13:05.214040 139792788920128 learning.py:507] global step 44864: loss = 0.1103 (0.974 sec/step)\n",
      "I0902 10:13:06.180625 139792788920128 learning.py:507] global step 44865: loss = 0.0914 (0.965 sec/step)\n",
      "I0902 10:13:07.161290 139792788920128 learning.py:507] global step 44866: loss = 0.0903 (0.979 sec/step)\n",
      "I0902 10:13:08.135598 139792788920128 learning.py:507] global step 44867: loss = 0.2976 (0.973 sec/step)\n",
      "I0902 10:13:09.101762 139792788920128 learning.py:507] global step 44868: loss = 0.1037 (0.964 sec/step)\n",
      "I0902 10:13:10.071923 139792788920128 learning.py:507] global step 44869: loss = 0.1024 (0.969 sec/step)\n",
      "I0902 10:13:11.024733 139792788920128 learning.py:507] global step 44870: loss = 0.1747 (0.951 sec/step)\n",
      "I0902 10:13:11.989378 139792788920128 learning.py:507] global step 44871: loss = 0.0609 (0.963 sec/step)\n",
      "I0902 10:13:12.942852 139792788920128 learning.py:507] global step 44872: loss = 0.0827 (0.952 sec/step)\n",
      "I0902 10:13:13.903888 139792788920128 learning.py:507] global step 44873: loss = 0.1119 (0.959 sec/step)\n",
      "I0902 10:13:14.868390 139792788920128 learning.py:507] global step 44874: loss = 0.0857 (0.963 sec/step)\n",
      "I0902 10:13:15.838288 139792788920128 learning.py:507] global step 44875: loss = 0.1144 (0.968 sec/step)\n",
      "I0902 10:13:16.797128 139792788920128 learning.py:507] global step 44876: loss = 0.0770 (0.957 sec/step)\n",
      "I0902 10:13:17.780864 139792788920128 learning.py:507] global step 44877: loss = 0.1141 (0.982 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:13:18.727850 139792788920128 learning.py:507] global step 44878: loss = 0.1354 (0.945 sec/step)\n",
      "I0902 10:13:19.691730 139792788920128 learning.py:507] global step 44879: loss = 0.1386 (0.962 sec/step)\n",
      "I0902 10:13:20.660186 139792788920128 learning.py:507] global step 44880: loss = 0.1217 (0.966 sec/step)\n",
      "I0902 10:13:21.625464 139792788920128 learning.py:507] global step 44881: loss = 0.2038 (0.963 sec/step)\n",
      "I0902 10:13:22.606935 139792788920128 learning.py:507] global step 44882: loss = 0.1255 (0.980 sec/step)\n",
      "I0902 10:13:23.590553 139792788920128 learning.py:507] global step 44883: loss = 0.1057 (0.982 sec/step)\n",
      "I0902 10:13:24.571351 139792788920128 learning.py:507] global step 44884: loss = 0.1451 (0.979 sec/step)\n",
      "I0902 10:13:25.535942 139792788920128 learning.py:507] global step 44885: loss = 0.2015 (0.963 sec/step)\n",
      "I0902 10:13:26.478177 139792788920128 learning.py:507] global step 44886: loss = 0.2119 (0.940 sec/step)\n",
      "I0902 10:13:27.433401 139792788920128 learning.py:507] global step 44887: loss = 0.1155 (0.954 sec/step)\n",
      "I0902 10:13:28.382516 139792788920128 learning.py:507] global step 44888: loss = 0.1369 (0.947 sec/step)\n",
      "I0902 10:13:29.344092 139792788920128 learning.py:507] global step 44889: loss = 0.0675 (0.960 sec/step)\n",
      "I0902 10:13:30.313322 139792788920128 learning.py:507] global step 44890: loss = 0.1738 (0.967 sec/step)\n",
      "I0902 10:13:31.306519 139792788920128 learning.py:507] global step 44891: loss = 0.1230 (0.992 sec/step)\n",
      "I0902 10:13:32.294765 139792788920128 learning.py:507] global step 44892: loss = 0.1240 (0.987 sec/step)\n",
      "I0902 10:13:33.265202 139792788920128 learning.py:507] global step 44893: loss = 0.1160 (0.969 sec/step)\n",
      "I0902 10:13:34.236831 139792788920128 learning.py:507] global step 44894: loss = 0.0813 (0.970 sec/step)\n",
      "I0902 10:13:35.215220 139792788920128 learning.py:507] global step 44895: loss = 0.0540 (0.977 sec/step)\n",
      "I0902 10:13:36.193383 139792788920128 learning.py:507] global step 44896: loss = 0.0874 (0.977 sec/step)\n",
      "I0902 10:13:37.151093 139792788920128 learning.py:507] global step 44897: loss = 0.0621 (0.956 sec/step)\n",
      "I0902 10:13:38.113372 139792788920128 learning.py:507] global step 44898: loss = 0.1635 (0.961 sec/step)\n",
      "I0902 10:13:39.082111 139792788920128 learning.py:507] global step 44899: loss = 0.1807 (0.967 sec/step)\n",
      "I0902 10:13:40.061023 139792788920128 learning.py:507] global step 44900: loss = 0.0637 (0.977 sec/step)\n",
      "I0902 10:13:41.039908 139792788920128 learning.py:507] global step 44901: loss = 0.1362 (0.977 sec/step)\n",
      "I0902 10:13:42.015487 139792788920128 learning.py:507] global step 44902: loss = 0.1735 (0.974 sec/step)\n",
      "I0902 10:13:42.992291 139792788920128 learning.py:507] global step 44903: loss = 0.2440 (0.975 sec/step)\n",
      "I0902 10:13:43.951401 139792788920128 learning.py:507] global step 44904: loss = 0.0917 (0.957 sec/step)\n",
      "I0902 10:13:44.904824 139792788920128 learning.py:507] global step 44905: loss = 0.2310 (0.952 sec/step)\n",
      "I0902 10:13:45.865373 139792788920128 learning.py:507] global step 44906: loss = 0.1108 (0.959 sec/step)\n",
      "I0902 10:13:46.822088 139792788920128 learning.py:507] global step 44907: loss = 0.1282 (0.955 sec/step)\n",
      "I0902 10:13:47.789685 139792788920128 learning.py:507] global step 44908: loss = 0.2200 (0.966 sec/step)\n",
      "I0902 10:13:48.743355 139792788920128 learning.py:507] global step 44909: loss = 0.1037 (0.952 sec/step)\n",
      "I0902 10:13:49.270382 139778953570048 supervisor.py:1117] Saving checkpoint to path data_dir/mixed_experiment/checkpoints_v2/model.ckpt\n",
      "I0902 10:13:49.870364 139792788920128 learning.py:507] global step 44910: loss = 0.1067 (1.122 sec/step)\n",
      "I0902 10:13:50.184680 139778936784640 supervisor.py:1050] Recording summary at step 44910.\n",
      "I0902 10:13:50.949696 139792788920128 learning.py:507] global step 44911: loss = 0.0825 (1.069 sec/step)\n",
      "I0902 10:13:51.926311 139792788920128 learning.py:507] global step 44912: loss = 0.1032 (0.975 sec/step)\n",
      "I0902 10:13:52.889336 139792788920128 learning.py:507] global step 44913: loss = 0.0533 (0.961 sec/step)\n",
      "I0902 10:13:53.857578 139792788920128 learning.py:507] global step 44914: loss = 0.0737 (0.967 sec/step)\n",
      "I0902 10:13:54.826963 139792788920128 learning.py:507] global step 44915: loss = 0.0784 (0.968 sec/step)\n",
      "I0902 10:13:55.798043 139792788920128 learning.py:507] global step 44916: loss = 0.1302 (0.969 sec/step)\n",
      "I0902 10:13:56.750712 139792788920128 learning.py:507] global step 44917: loss = 0.0609 (0.951 sec/step)\n",
      "I0902 10:13:57.723822 139792788920128 learning.py:507] global step 44918: loss = 0.1095 (0.971 sec/step)\n",
      "I0902 10:13:58.692124 139792788920128 learning.py:507] global step 44919: loss = 0.0599 (0.966 sec/step)\n",
      "I0902 10:13:59.654717 139792788920128 learning.py:507] global step 44920: loss = 0.0457 (0.961 sec/step)\n",
      "I0902 10:14:00.622401 139792788920128 learning.py:507] global step 44921: loss = 0.0864 (0.966 sec/step)\n",
      "I0902 10:14:01.623587 139792788920128 learning.py:507] global step 44922: loss = 0.2540 (1.000 sec/step)\n",
      "I0902 10:14:02.598176 139792788920128 learning.py:507] global step 44923: loss = 0.0785 (0.973 sec/step)\n",
      "I0902 10:14:03.561579 139792788920128 learning.py:507] global step 44924: loss = 0.1064 (0.962 sec/step)\n",
      "I0902 10:14:04.520292 139792788920128 learning.py:507] global step 44925: loss = 0.1465 (0.957 sec/step)\n",
      "I0902 10:14:05.501912 139792788920128 learning.py:507] global step 44926: loss = 0.1387 (0.980 sec/step)\n",
      "I0902 10:14:06.491344 139792788920128 learning.py:507] global step 44927: loss = 0.1336 (0.988 sec/step)\n",
      "I0902 10:14:07.466919 139792788920128 learning.py:507] global step 44928: loss = 0.0563 (0.974 sec/step)\n",
      "I0902 10:14:08.427464 139792788920128 learning.py:507] global step 44929: loss = 0.1624 (0.959 sec/step)\n",
      "I0902 10:14:09.397230 139792788920128 learning.py:507] global step 44930: loss = 0.0813 (0.968 sec/step)\n",
      "I0902 10:14:10.363497 139792788920128 learning.py:507] global step 44931: loss = 0.2214 (0.965 sec/step)\n",
      "I0902 10:14:11.346129 139792788920128 learning.py:507] global step 44932: loss = 0.0542 (0.981 sec/step)\n",
      "I0902 10:14:12.311612 139792788920128 learning.py:507] global step 44933: loss = 0.0612 (0.964 sec/step)\n",
      "I0902 10:14:13.276169 139792788920128 learning.py:507] global step 44934: loss = 0.1435 (0.963 sec/step)\n",
      "I0902 10:14:14.249836 139792788920128 learning.py:507] global step 44935: loss = 0.1774 (0.972 sec/step)\n",
      "I0902 10:14:15.244319 139792788920128 learning.py:507] global step 44936: loss = 0.1323 (0.993 sec/step)\n",
      "I0902 10:14:16.205957 139792788920128 learning.py:507] global step 44937: loss = 0.1737 (0.960 sec/step)\n",
      "I0902 10:14:17.174830 139792788920128 learning.py:507] global step 44938: loss = 0.0822 (0.967 sec/step)\n",
      "I0902 10:14:18.150201 139792788920128 learning.py:507] global step 44939: loss = 0.0812 (0.974 sec/step)\n",
      "I0902 10:14:19.126893 139792788920128 learning.py:507] global step 44940: loss = 0.0889 (0.975 sec/step)\n",
      "I0902 10:14:20.100517 139792788920128 learning.py:507] global step 44941: loss = 0.0719 (0.972 sec/step)\n",
      "I0902 10:14:21.057596 139792788920128 learning.py:507] global step 44942: loss = 0.0923 (0.955 sec/step)\n",
      "I0902 10:14:22.017108 139792788920128 learning.py:507] global step 44943: loss = 0.2530 (0.958 sec/step)\n",
      "I0902 10:14:22.986413 139792788920128 learning.py:507] global step 44944: loss = 0.2071 (0.968 sec/step)\n",
      "I0902 10:14:23.959725 139792788920128 learning.py:507] global step 44945: loss = 0.1259 (0.972 sec/step)\n",
      "I0902 10:14:24.949211 139792788920128 learning.py:507] global step 44946: loss = 0.1097 (0.988 sec/step)\n",
      "I0902 10:14:25.927920 139792788920128 learning.py:507] global step 44947: loss = 0.2853 (0.977 sec/step)\n",
      "I0902 10:14:26.898921 139792788920128 learning.py:507] global step 44948: loss = 0.0607 (0.969 sec/step)\n",
      "I0902 10:14:28.222970 139792788920128 learning.py:507] global step 44949: loss = 0.1070 (1.322 sec/step)\n",
      "I0902 10:14:29.189716 139792788920128 learning.py:507] global step 44950: loss = 0.0942 (0.965 sec/step)\n",
      "I0902 10:14:30.171453 139792788920128 learning.py:507] global step 44951: loss = 0.0623 (0.980 sec/step)\n",
      "I0902 10:14:31.136912 139792788920128 learning.py:507] global step 44952: loss = 0.1824 (0.964 sec/step)\n",
      "I0902 10:14:32.099081 139792788920128 learning.py:507] global step 44953: loss = 0.0597 (0.961 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:14:33.054759 139792788920128 learning.py:507] global step 44954: loss = 0.0687 (0.954 sec/step)\n",
      "I0902 10:14:34.033923 139792788920128 learning.py:507] global step 44955: loss = 0.1212 (0.977 sec/step)\n",
      "I0902 10:14:34.997810 139792788920128 learning.py:507] global step 44956: loss = 0.0520 (0.962 sec/step)\n",
      "I0902 10:14:35.960238 139792788920128 learning.py:507] global step 44957: loss = 0.1599 (0.961 sec/step)\n",
      "I0902 10:14:36.929118 139792788920128 learning.py:507] global step 44958: loss = 0.1468 (0.967 sec/step)\n",
      "I0902 10:14:37.923762 139792788920128 learning.py:507] global step 44959: loss = 0.2498 (0.993 sec/step)\n",
      "I0902 10:14:38.893099 139792788920128 learning.py:507] global step 44960: loss = 0.1032 (0.968 sec/step)\n",
      "I0902 10:14:39.869852 139792788920128 learning.py:507] global step 44961: loss = 0.1522 (0.975 sec/step)\n",
      "I0902 10:14:40.839404 139792788920128 learning.py:507] global step 44962: loss = 0.1158 (0.968 sec/step)\n",
      "I0902 10:14:41.799862 139792788920128 learning.py:507] global step 44963: loss = 0.1346 (0.959 sec/step)\n",
      "I0902 10:14:42.757889 139792788920128 learning.py:507] global step 44964: loss = 0.2476 (0.956 sec/step)\n",
      "I0902 10:14:43.718856 139792788920128 learning.py:507] global step 44965: loss = 0.1191 (0.959 sec/step)\n",
      "I0902 10:14:44.689310 139792788920128 learning.py:507] global step 44966: loss = 0.1636 (0.969 sec/step)\n",
      "I0902 10:14:45.655147 139792788920128 learning.py:507] global step 44967: loss = 0.1056 (0.964 sec/step)\n",
      "I0902 10:14:46.613773 139792788920128 learning.py:507] global step 44968: loss = 0.0996 (0.957 sec/step)\n",
      "I0902 10:14:47.568421 139792788920128 learning.py:507] global step 44969: loss = 0.2135 (0.953 sec/step)\n",
      "I0902 10:14:48.545142 139792788920128 learning.py:507] global step 44970: loss = 0.0583 (0.975 sec/step)\n",
      "I0902 10:14:49.520895 139792788920128 learning.py:507] global step 44971: loss = 0.0570 (0.974 sec/step)\n",
      "I0902 10:14:50.484576 139792788920128 learning.py:507] global step 44972: loss = 0.0994 (0.962 sec/step)\n",
      "I0902 10:14:51.454156 139792788920128 learning.py:507] global step 44973: loss = 0.0620 (0.968 sec/step)\n",
      "I0902 10:14:52.418581 139792788920128 learning.py:507] global step 44974: loss = 0.0743 (0.963 sec/step)\n",
      "I0902 10:14:53.395364 139792788920128 learning.py:507] global step 44975: loss = 0.1474 (0.975 sec/step)\n",
      "I0902 10:14:54.354961 139792788920128 learning.py:507] global step 44976: loss = 0.1474 (0.958 sec/step)\n",
      "I0902 10:14:55.313641 139792788920128 learning.py:507] global step 44977: loss = 0.2139 (0.957 sec/step)\n",
      "I0902 10:14:56.269968 139792788920128 learning.py:507] global step 44978: loss = 0.0717 (0.955 sec/step)\n",
      "I0902 10:14:57.240154 139792788920128 learning.py:507] global step 44979: loss = 0.0517 (0.969 sec/step)\n",
      "I0902 10:14:58.205249 139792788920128 learning.py:507] global step 44980: loss = 0.1269 (0.963 sec/step)\n",
      "I0902 10:14:59.187922 139792788920128 learning.py:507] global step 44981: loss = 0.0763 (0.981 sec/step)\n",
      "I0902 10:15:00.170886 139792788920128 learning.py:507] global step 44982: loss = 0.0485 (0.981 sec/step)\n",
      "I0902 10:15:01.145855 139792788920128 learning.py:507] global step 44983: loss = 0.1963 (0.973 sec/step)\n",
      "I0902 10:15:02.124767 139792788920128 learning.py:507] global step 44984: loss = 0.1467 (0.977 sec/step)\n",
      "I0902 10:15:03.078621 139792788920128 learning.py:507] global step 44985: loss = 0.0845 (0.952 sec/step)\n",
      "I0902 10:15:04.039946 139792788920128 learning.py:507] global step 44986: loss = 0.0753 (0.960 sec/step)\n",
      "I0902 10:15:05.002965 139792788920128 learning.py:507] global step 44987: loss = 0.0895 (0.961 sec/step)\n",
      "I0902 10:15:05.969027 139792788920128 learning.py:507] global step 44988: loss = 0.2333 (0.964 sec/step)\n",
      "I0902 10:15:06.950114 139792788920128 learning.py:507] global step 44989: loss = 0.2073 (0.979 sec/step)\n",
      "I0902 10:15:07.909326 139792788920128 learning.py:507] global step 44990: loss = 0.1929 (0.957 sec/step)\n",
      "I0902 10:15:08.887861 139792788920128 learning.py:507] global step 44991: loss = 0.1134 (0.977 sec/step)\n",
      "I0902 10:15:09.842081 139792788920128 learning.py:507] global step 44992: loss = 0.0689 (0.953 sec/step)\n",
      "I0902 10:15:10.814898 139792788920128 learning.py:507] global step 44993: loss = 0.0798 (0.971 sec/step)\n",
      "I0902 10:15:11.781102 139792788920128 learning.py:507] global step 44994: loss = 0.2343 (0.965 sec/step)\n",
      "I0902 10:15:12.739299 139792788920128 learning.py:507] global step 44995: loss = 0.0763 (0.956 sec/step)\n",
      "I0902 10:15:13.709971 139792788920128 learning.py:507] global step 44996: loss = 0.0790 (0.969 sec/step)\n",
      "I0902 10:15:14.696975 139792788920128 learning.py:507] global step 44997: loss = 0.3355 (0.985 sec/step)\n",
      "I0902 10:15:15.653456 139792788920128 learning.py:507] global step 44998: loss = 0.1265 (0.955 sec/step)\n",
      "I0902 10:15:16.609438 139792788920128 learning.py:507] global step 44999: loss = 0.0722 (0.954 sec/step)\n",
      "I0902 10:15:17.590871 139792788920128 learning.py:507] global step 45000: loss = 0.1027 (0.980 sec/step)\n",
      "I0902 10:15:18.561038 139792788920128 learning.py:507] global step 45001: loss = 0.1248 (0.968 sec/step)\n",
      "I0902 10:15:19.512784 139792788920128 learning.py:507] global step 45002: loss = 0.0785 (0.950 sec/step)\n",
      "I0902 10:15:20.472181 139792788920128 learning.py:507] global step 45003: loss = 0.0800 (0.958 sec/step)\n",
      "I0902 10:15:21.432593 139792788920128 learning.py:507] global step 45004: loss = 0.1290 (0.959 sec/step)\n",
      "I0902 10:15:22.397070 139792788920128 learning.py:507] global step 45005: loss = 0.0945 (0.963 sec/step)\n",
      "I0902 10:15:23.362866 139792788920128 learning.py:507] global step 45006: loss = 0.0770 (0.964 sec/step)\n",
      "I0902 10:15:24.328739 139792788920128 learning.py:507] global step 45007: loss = 0.0875 (0.964 sec/step)\n",
      "I0902 10:15:25.288894 139792788920128 learning.py:507] global step 45008: loss = 0.1252 (0.958 sec/step)\n",
      "I0902 10:15:26.237511 139792788920128 learning.py:507] global step 45009: loss = 0.0910 (0.947 sec/step)\n",
      "I0902 10:15:27.207185 139792788920128 learning.py:507] global step 45010: loss = 0.1674 (0.968 sec/step)\n",
      "I0902 10:15:28.169977 139792788920128 learning.py:507] global step 45011: loss = 0.1930 (0.961 sec/step)\n",
      "I0902 10:15:29.122177 139792788920128 learning.py:507] global step 45012: loss = 0.1451 (0.951 sec/step)\n",
      "I0902 10:15:30.089789 139792788920128 learning.py:507] global step 45013: loss = 0.1017 (0.966 sec/step)\n",
      "I0902 10:15:31.055498 139792788920128 learning.py:507] global step 45014: loss = 0.3444 (0.964 sec/step)\n",
      "I0902 10:15:32.035382 139792788920128 learning.py:507] global step 45015: loss = 0.1205 (0.978 sec/step)\n",
      "I0902 10:15:32.997853 139792788920128 learning.py:507] global step 45016: loss = 0.2421 (0.961 sec/step)\n",
      "I0902 10:15:33.991962 139792788920128 learning.py:507] global step 45017: loss = 0.0847 (0.992 sec/step)\n",
      "I0902 10:15:34.969009 139792788920128 learning.py:507] global step 45018: loss = 0.0893 (0.975 sec/step)\n",
      "I0902 10:15:35.946035 139792788920128 learning.py:507] global step 45019: loss = 0.0570 (0.976 sec/step)\n",
      "I0902 10:15:36.920051 139792788920128 learning.py:507] global step 45020: loss = 0.2532 (0.973 sec/step)\n",
      "I0902 10:15:37.879425 139792788920128 learning.py:507] global step 45021: loss = 0.1146 (0.958 sec/step)\n",
      "I0902 10:15:38.859623 139792788920128 learning.py:507] global step 45022: loss = 0.1726 (0.979 sec/step)\n",
      "I0902 10:15:39.825466 139792788920128 learning.py:507] global step 45023: loss = 0.0789 (0.964 sec/step)\n",
      "I0902 10:15:40.807990 139792788920128 learning.py:507] global step 45024: loss = 0.0790 (0.981 sec/step)\n",
      "I0902 10:15:41.761377 139792788920128 learning.py:507] global step 45025: loss = 0.0866 (0.952 sec/step)\n",
      "I0902 10:15:42.735062 139792788920128 learning.py:507] global step 45026: loss = 0.1963 (0.972 sec/step)\n",
      "I0902 10:15:43.719888 139792788920128 learning.py:507] global step 45027: loss = 0.0807 (0.983 sec/step)\n",
      "I0902 10:15:44.695973 139792788920128 learning.py:507] global step 45028: loss = 0.1336 (0.974 sec/step)\n",
      "I0902 10:15:45.661697 139792788920128 learning.py:507] global step 45029: loss = 0.0661 (0.964 sec/step)\n",
      "I0902 10:15:46.622372 139792788920128 learning.py:507] global step 45030: loss = 0.1120 (0.959 sec/step)\n",
      "I0902 10:15:47.604648 139792788920128 learning.py:507] global step 45031: loss = 0.1072 (0.981 sec/step)\n",
      "I0902 10:15:48.570416 139792788920128 learning.py:507] global step 45032: loss = 0.2135 (0.964 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:15:49.530317 139792788920128 learning.py:507] global step 45033: loss = 0.1446 (0.958 sec/step)\n",
      "I0902 10:15:50.153557 139778936784640 supervisor.py:1050] Recording summary at step 45033.\n",
      "I0902 10:15:50.758671 139792788920128 learning.py:507] global step 45034: loss = 0.1546 (1.226 sec/step)\n",
      "I0902 10:15:51.730150 139792788920128 learning.py:507] global step 45035: loss = 0.1267 (0.970 sec/step)\n",
      "I0902 10:15:52.698973 139792788920128 learning.py:507] global step 45036: loss = 0.1305 (0.967 sec/step)\n",
      "I0902 10:15:53.653860 139792788920128 learning.py:507] global step 45037: loss = 0.0783 (0.953 sec/step)\n",
      "I0902 10:15:54.623844 139792788920128 learning.py:507] global step 45038: loss = 0.0657 (0.968 sec/step)\n",
      "I0902 10:15:55.584692 139792788920128 learning.py:507] global step 45039: loss = 0.0924 (0.959 sec/step)\n",
      "I0902 10:15:56.548114 139792788920128 learning.py:507] global step 45040: loss = 0.0611 (0.962 sec/step)\n",
      "I0902 10:15:57.525159 139792788920128 learning.py:507] global step 45041: loss = 0.1621 (0.976 sec/step)\n",
      "I0902 10:15:58.487199 139792788920128 learning.py:507] global step 45042: loss = 0.3034 (0.961 sec/step)\n",
      "I0902 10:15:59.460317 139792788920128 learning.py:507] global step 45043: loss = 0.1120 (0.972 sec/step)\n",
      "I0902 10:16:00.420618 139792788920128 learning.py:507] global step 45044: loss = 0.0863 (0.959 sec/step)\n",
      "I0902 10:16:01.387109 139792788920128 learning.py:507] global step 45045: loss = 0.1779 (0.965 sec/step)\n",
      "I0902 10:16:02.381648 139792788920128 learning.py:507] global step 45046: loss = 0.1444 (0.993 sec/step)\n",
      "I0902 10:16:03.352237 139792788920128 learning.py:507] global step 45047: loss = 0.1408 (0.969 sec/step)\n",
      "I0902 10:16:04.314471 139792788920128 learning.py:507] global step 45048: loss = 0.1180 (0.961 sec/step)\n",
      "I0902 10:16:05.283411 139792788920128 learning.py:507] global step 45049: loss = 0.1304 (0.968 sec/step)\n",
      "I0902 10:16:06.234694 139792788920128 learning.py:507] global step 45050: loss = 0.1388 (0.950 sec/step)\n",
      "I0902 10:16:07.206158 139792788920128 learning.py:507] global step 45051: loss = 0.1093 (0.970 sec/step)\n",
      "I0902 10:16:08.174734 139792788920128 learning.py:507] global step 45052: loss = 0.0701 (0.967 sec/step)\n",
      "I0902 10:16:09.144393 139792788920128 learning.py:507] global step 45053: loss = 0.1926 (0.968 sec/step)\n",
      "I0902 10:16:10.109617 139792788920128 learning.py:507] global step 45054: loss = 0.0840 (0.963 sec/step)\n",
      "I0902 10:16:11.082359 139792788920128 learning.py:507] global step 45055: loss = 0.0951 (0.971 sec/step)\n",
      "I0902 10:16:12.030226 139792788920128 learning.py:507] global step 45056: loss = 0.2291 (0.946 sec/step)\n",
      "I0902 10:16:13.014108 139792788920128 learning.py:507] global step 45057: loss = 0.1330 (0.982 sec/step)\n",
      "I0902 10:16:13.982059 139792788920128 learning.py:507] global step 45058: loss = 0.0841 (0.966 sec/step)\n",
      "I0902 10:16:14.971343 139792788920128 learning.py:507] global step 45059: loss = 0.0560 (0.988 sec/step)\n",
      "I0902 10:16:15.941189 139792788920128 learning.py:507] global step 45060: loss = 0.1598 (0.968 sec/step)\n",
      "I0902 10:16:16.909832 139792788920128 learning.py:507] global step 45061: loss = 0.1185 (0.967 sec/step)\n",
      "I0902 10:16:17.853949 139792788920128 learning.py:507] global step 45062: loss = 0.0778 (0.942 sec/step)\n",
      "I0902 10:16:18.811048 139792788920128 learning.py:507] global step 45063: loss = 0.1462 (0.955 sec/step)\n",
      "I0902 10:16:19.785238 139792788920128 learning.py:507] global step 45064: loss = 0.1509 (0.973 sec/step)\n",
      "I0902 10:16:20.759162 139792788920128 learning.py:507] global step 45065: loss = 0.0521 (0.972 sec/step)\n",
      "I0902 10:16:21.732371 139792788920128 learning.py:507] global step 45066: loss = 0.0678 (0.971 sec/step)\n",
      "I0902 10:16:22.712213 139792788920128 learning.py:507] global step 45067: loss = 0.1838 (0.978 sec/step)\n",
      "I0902 10:16:23.689116 139792788920128 learning.py:507] global step 45068: loss = 0.1058 (0.975 sec/step)\n",
      "I0902 10:16:24.671582 139792788920128 learning.py:507] global step 45069: loss = 0.1397 (0.981 sec/step)\n",
      "I0902 10:16:25.629122 139792788920128 learning.py:507] global step 45070: loss = 0.1013 (0.956 sec/step)\n",
      "I0902 10:16:26.607579 139792788920128 learning.py:507] global step 45071: loss = 0.1990 (0.977 sec/step)\n",
      "I0902 10:16:27.583494 139792788920128 learning.py:507] global step 45072: loss = 0.0650 (0.974 sec/step)\n",
      "I0902 10:16:28.548779 139792788920128 learning.py:507] global step 45073: loss = 0.0630 (0.964 sec/step)\n",
      "I0902 10:16:29.509613 139792788920128 learning.py:507] global step 45074: loss = 0.1518 (0.959 sec/step)\n",
      "I0902 10:16:30.493535 139792788920128 learning.py:507] global step 45075: loss = 0.1234 (0.982 sec/step)\n",
      "I0902 10:16:31.468498 139792788920128 learning.py:507] global step 45076: loss = 0.3187 (0.973 sec/step)\n",
      "I0902 10:16:32.447082 139792788920128 learning.py:507] global step 45077: loss = 0.0713 (0.977 sec/step)\n",
      "I0902 10:16:33.409739 139792788920128 learning.py:507] global step 45078: loss = 0.0713 (0.961 sec/step)\n",
      "I0902 10:16:34.373400 139792788920128 learning.py:507] global step 45079: loss = 0.1078 (0.962 sec/step)\n",
      "I0902 10:16:35.338970 139792788920128 learning.py:507] global step 45080: loss = 0.1239 (0.964 sec/step)\n",
      "I0902 10:16:36.306048 139792788920128 learning.py:507] global step 45081: loss = 0.0561 (0.965 sec/step)\n",
      "I0902 10:16:37.265980 139792788920128 learning.py:507] global step 45082: loss = 0.0659 (0.958 sec/step)\n",
      "I0902 10:16:38.251788 139792788920128 learning.py:507] global step 45083: loss = 0.5334 (0.984 sec/step)\n",
      "I0902 10:16:39.222458 139792788920128 learning.py:507] global step 45084: loss = 0.1283 (0.969 sec/step)\n",
      "I0902 10:16:40.202735 139792788920128 learning.py:507] global step 45085: loss = 0.1045 (0.979 sec/step)\n",
      "I0902 10:16:41.173513 139792788920128 learning.py:507] global step 45086: loss = 0.0899 (0.969 sec/step)\n",
      "I0902 10:16:42.131144 139792788920128 learning.py:507] global step 45087: loss = 0.1491 (0.956 sec/step)\n",
      "I0902 10:16:43.094735 139792788920128 learning.py:507] global step 45088: loss = 0.1413 (0.962 sec/step)\n",
      "I0902 10:16:44.049427 139792788920128 learning.py:507] global step 45089: loss = 0.3159 (0.953 sec/step)\n",
      "I0902 10:16:44.999676 139792788920128 learning.py:507] global step 45090: loss = 0.1127 (0.949 sec/step)\n",
      "I0902 10:16:45.973210 139792788920128 learning.py:507] global step 45091: loss = 0.0550 (0.972 sec/step)\n",
      "I0902 10:16:46.946726 139792788920128 learning.py:507] global step 45092: loss = 0.3177 (0.972 sec/step)\n",
      "I0902 10:16:47.898530 139792788920128 learning.py:507] global step 45093: loss = 0.1795 (0.950 sec/step)\n",
      "I0902 10:16:48.860255 139792788920128 learning.py:507] global step 45094: loss = 0.1254 (0.960 sec/step)\n",
      "I0902 10:16:49.831714 139792788920128 learning.py:507] global step 45095: loss = 0.1036 (0.970 sec/step)\n",
      "I0902 10:16:50.791041 139792788920128 learning.py:507] global step 45096: loss = 0.1033 (0.958 sec/step)\n",
      "I0902 10:16:51.749799 139792788920128 learning.py:507] global step 45097: loss = 0.0965 (0.957 sec/step)\n",
      "I0902 10:16:52.707724 139792788920128 learning.py:507] global step 45098: loss = 0.1077 (0.956 sec/step)\n",
      "I0902 10:16:53.659595 139792788920128 learning.py:507] global step 45099: loss = 0.1825 (0.950 sec/step)\n",
      "I0902 10:16:54.646596 139792788920128 learning.py:507] global step 45100: loss = 0.1134 (0.986 sec/step)\n",
      "I0902 10:16:55.630835 139792788920128 learning.py:507] global step 45101: loss = 0.0843 (0.983 sec/step)\n",
      "I0902 10:16:56.593210 139792788920128 learning.py:507] global step 45102: loss = 0.1174 (0.961 sec/step)\n",
      "I0902 10:16:57.569523 139792788920128 learning.py:507] global step 45103: loss = 0.0665 (0.975 sec/step)\n",
      "I0902 10:16:58.526734 139792788920128 learning.py:507] global step 45104: loss = 0.0625 (0.956 sec/step)\n",
      "I0902 10:16:59.500535 139792788920128 learning.py:507] global step 45105: loss = 0.1778 (0.972 sec/step)\n",
      "I0902 10:17:00.473396 139792788920128 learning.py:507] global step 45106: loss = 0.1248 (0.971 sec/step)\n",
      "I0902 10:17:01.436964 139792788920128 learning.py:507] global step 45107: loss = 0.0528 (0.962 sec/step)\n",
      "I0902 10:17:02.405580 139792788920128 learning.py:507] global step 45108: loss = 0.1061 (0.967 sec/step)\n",
      "I0902 10:17:03.376406 139792788920128 learning.py:507] global step 45109: loss = 0.0957 (0.969 sec/step)\n",
      "I0902 10:17:04.356637 139792788920128 learning.py:507] global step 45110: loss = 0.0996 (0.978 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:17:05.311459 139792788920128 learning.py:507] global step 45111: loss = 0.1136 (0.953 sec/step)\n",
      "I0902 10:17:06.276503 139792788920128 learning.py:507] global step 45112: loss = 0.0860 (0.963 sec/step)\n",
      "I0902 10:17:07.265105 139792788920128 learning.py:507] global step 45113: loss = 0.2171 (0.987 sec/step)\n",
      "I0902 10:17:08.259076 139792788920128 learning.py:507] global step 45114: loss = 0.2575 (0.993 sec/step)\n",
      "I0902 10:17:09.225644 139792788920128 learning.py:507] global step 45115: loss = 0.1369 (0.965 sec/step)\n",
      "I0902 10:17:10.203709 139792788920128 learning.py:507] global step 45116: loss = 0.1080 (0.976 sec/step)\n",
      "I0902 10:17:11.163036 139792788920128 learning.py:507] global step 45117: loss = 0.1574 (0.958 sec/step)\n",
      "I0902 10:17:12.141671 139792788920128 learning.py:507] global step 45118: loss = 0.0920 (0.977 sec/step)\n",
      "I0902 10:17:13.097916 139792788920128 learning.py:507] global step 45119: loss = 0.1078 (0.955 sec/step)\n",
      "I0902 10:17:14.055325 139792788920128 learning.py:507] global step 45120: loss = 0.1354 (0.956 sec/step)\n",
      "I0902 10:17:15.025981 139792788920128 learning.py:507] global step 45121: loss = 0.0781 (0.969 sec/step)\n",
      "I0902 10:17:16.000797 139792788920128 learning.py:507] global step 45122: loss = 0.2102 (0.973 sec/step)\n",
      "I0902 10:17:16.968459 139792788920128 learning.py:507] global step 45123: loss = 0.1188 (0.966 sec/step)\n",
      "I0902 10:17:17.916998 139792788920128 learning.py:507] global step 45124: loss = 0.0664 (0.947 sec/step)\n",
      "I0902 10:17:18.880705 139792788920128 learning.py:507] global step 45125: loss = 0.0839 (0.962 sec/step)\n",
      "I0902 10:17:19.855263 139792788920128 learning.py:507] global step 45126: loss = 0.0809 (0.973 sec/step)\n",
      "I0902 10:17:20.811980 139792788920128 learning.py:507] global step 45127: loss = 0.2080 (0.955 sec/step)\n",
      "I0902 10:17:21.793470 139792788920128 learning.py:507] global step 45128: loss = 0.0724 (0.980 sec/step)\n",
      "I0902 10:17:22.754126 139792788920128 learning.py:507] global step 45129: loss = 0.0859 (0.959 sec/step)\n",
      "I0902 10:17:23.716108 139792788920128 learning.py:507] global step 45130: loss = 0.1182 (0.961 sec/step)\n",
      "I0902 10:17:24.681049 139792788920128 learning.py:507] global step 45131: loss = 0.1036 (0.963 sec/step)\n",
      "I0902 10:17:25.661227 139792788920128 learning.py:507] global step 45132: loss = 0.0632 (0.978 sec/step)\n",
      "I0902 10:17:26.640984 139792788920128 learning.py:507] global step 45133: loss = 0.0822 (0.978 sec/step)\n",
      "I0902 10:17:27.607009 139792788920128 learning.py:507] global step 45134: loss = 0.1219 (0.964 sec/step)\n",
      "I0902 10:17:28.562514 139792788920128 learning.py:507] global step 45135: loss = 0.1492 (0.954 sec/step)\n",
      "I0902 10:17:29.534896 139792788920128 learning.py:507] global step 45136: loss = 0.2064 (0.971 sec/step)\n",
      "I0902 10:17:30.514488 139792788920128 learning.py:507] global step 45137: loss = 0.0556 (0.978 sec/step)\n",
      "I0902 10:17:31.473034 139792788920128 learning.py:507] global step 45138: loss = 0.1713 (0.957 sec/step)\n",
      "I0902 10:17:32.431539 139792788920128 learning.py:507] global step 45139: loss = 0.1410 (0.957 sec/step)\n",
      "I0902 10:17:33.397378 139792788920128 learning.py:507] global step 45140: loss = 0.1174 (0.964 sec/step)\n",
      "I0902 10:17:34.373615 139792788920128 learning.py:507] global step 45141: loss = 0.1055 (0.975 sec/step)\n",
      "I0902 10:17:35.329073 139792788920128 learning.py:507] global step 45142: loss = 0.1848 (0.954 sec/step)\n",
      "I0902 10:17:36.306926 139792788920128 learning.py:507] global step 45143: loss = 0.0914 (0.977 sec/step)\n",
      "I0902 10:17:37.273965 139792788920128 learning.py:507] global step 45144: loss = 0.2170 (0.965 sec/step)\n",
      "I0902 10:17:38.229032 139792788920128 learning.py:507] global step 45145: loss = 0.2307 (0.953 sec/step)\n",
      "I0902 10:17:39.184802 139792788920128 learning.py:507] global step 45146: loss = 0.0514 (0.954 sec/step)\n",
      "I0902 10:17:40.162341 139792788920128 learning.py:507] global step 45147: loss = 0.0992 (0.976 sec/step)\n",
      "I0902 10:17:41.125341 139792788920128 learning.py:507] global step 45148: loss = 0.1523 (0.961 sec/step)\n",
      "I0902 10:17:42.083709 139792788920128 learning.py:507] global step 45149: loss = 0.2073 (0.957 sec/step)\n",
      "I0902 10:17:43.083204 139792788920128 learning.py:507] global step 45150: loss = 0.1067 (0.998 sec/step)\n",
      "I0902 10:17:44.079419 139792788920128 learning.py:507] global step 45151: loss = 0.1236 (0.995 sec/step)\n",
      "I0902 10:17:45.095555 139792788920128 learning.py:507] global step 45152: loss = 0.1194 (1.015 sec/step)\n",
      "I0902 10:17:46.080146 139792788920128 learning.py:507] global step 45153: loss = 0.1388 (0.983 sec/step)\n",
      "I0902 10:17:47.048453 139792788920128 learning.py:507] global step 45154: loss = 0.0951 (0.967 sec/step)\n",
      "I0902 10:17:48.023463 139792788920128 learning.py:507] global step 45155: loss = 0.1017 (0.974 sec/step)\n",
      "I0902 10:17:48.989225 139792788920128 learning.py:507] global step 45156: loss = 0.1060 (0.964 sec/step)\n",
      "I0902 10:17:50.121115 139792788920128 learning.py:507] global step 45157: loss = 0.2643 (1.127 sec/step)\n",
      "I0902 10:17:50.441456 139778936784640 supervisor.py:1050] Recording summary at step 45157.\n",
      "I0902 10:17:51.225459 139792788920128 learning.py:507] global step 45158: loss = 0.1293 (1.090 sec/step)\n",
      "I0902 10:17:52.189534 139792788920128 learning.py:507] global step 45159: loss = 0.0698 (0.963 sec/step)\n",
      "I0902 10:17:53.139418 139792788920128 learning.py:507] global step 45160: loss = 0.1248 (0.949 sec/step)\n",
      "I0902 10:17:54.089698 139792788920128 learning.py:507] global step 45161: loss = 0.2273 (0.949 sec/step)\n",
      "I0902 10:17:55.061337 139792788920128 learning.py:507] global step 45162: loss = 0.1257 (0.970 sec/step)\n",
      "I0902 10:17:56.025259 139792788920128 learning.py:507] global step 45163: loss = 0.1111 (0.962 sec/step)\n",
      "I0902 10:17:56.996083 139792788920128 learning.py:507] global step 45164: loss = 0.1018 (0.969 sec/step)\n",
      "I0902 10:17:57.963727 139792788920128 learning.py:507] global step 45165: loss = 0.0873 (0.966 sec/step)\n",
      "I0902 10:17:58.920989 139792788920128 learning.py:507] global step 45166: loss = 0.0620 (0.956 sec/step)\n",
      "I0902 10:17:59.882599 139792788920128 learning.py:507] global step 45167: loss = 0.0931 (0.960 sec/step)\n",
      "I0902 10:18:00.849497 139792788920128 learning.py:507] global step 45168: loss = 0.1009 (0.965 sec/step)\n",
      "I0902 10:18:01.818569 139792788920128 learning.py:507] global step 45169: loss = 0.1834 (0.968 sec/step)\n",
      "I0902 10:18:02.791907 139792788920128 learning.py:507] global step 45170: loss = 0.1040 (0.972 sec/step)\n",
      "I0902 10:18:03.793853 139792788920128 learning.py:507] global step 45171: loss = 0.1477 (1.000 sec/step)\n",
      "I0902 10:18:04.759417 139792788920128 learning.py:507] global step 45172: loss = 0.0714 (0.964 sec/step)\n",
      "I0902 10:18:05.741928 139792788920128 learning.py:507] global step 45173: loss = 0.1315 (0.981 sec/step)\n",
      "I0902 10:18:06.704386 139792788920128 learning.py:507] global step 45174: loss = 0.1275 (0.961 sec/step)\n",
      "I0902 10:18:07.668311 139792788920128 learning.py:507] global step 45175: loss = 0.2335 (0.963 sec/step)\n",
      "I0902 10:18:08.636161 139792788920128 learning.py:507] global step 45176: loss = 0.1099 (0.966 sec/step)\n",
      "I0902 10:18:09.608760 139792788920128 learning.py:507] global step 45177: loss = 0.1162 (0.971 sec/step)\n",
      "I0902 10:18:10.577079 139792788920128 learning.py:507] global step 45178: loss = 0.2858 (0.967 sec/step)\n",
      "I0902 10:18:11.564286 139792788920128 learning.py:507] global step 45179: loss = 0.0792 (0.986 sec/step)\n",
      "I0902 10:18:12.525537 139792788920128 learning.py:507] global step 45180: loss = 0.0596 (0.960 sec/step)\n",
      "I0902 10:18:13.477094 139792788920128 learning.py:507] global step 45181: loss = 0.0682 (0.950 sec/step)\n",
      "I0902 10:18:14.445885 139792788920128 learning.py:507] global step 45182: loss = 0.1304 (0.967 sec/step)\n",
      "I0902 10:18:15.412791 139792788920128 learning.py:507] global step 45183: loss = 0.0986 (0.965 sec/step)\n",
      "I0902 10:18:16.377851 139792788920128 learning.py:507] global step 45184: loss = 0.0819 (0.963 sec/step)\n",
      "I0902 10:18:17.334083 139792788920128 learning.py:507] global step 45185: loss = 0.1171 (0.955 sec/step)\n",
      "I0902 10:18:18.289321 139792788920128 learning.py:507] global step 45186: loss = 0.1085 (0.953 sec/step)\n",
      "I0902 10:18:19.275318 139792788920128 learning.py:507] global step 45187: loss = 0.1485 (0.984 sec/step)\n",
      "I0902 10:18:20.241014 139792788920128 learning.py:507] global step 45188: loss = 0.0991 (0.964 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:18:21.198756 139792788920128 learning.py:507] global step 45189: loss = 0.0504 (0.956 sec/step)\n",
      "I0902 10:18:22.161959 139792788920128 learning.py:507] global step 45190: loss = 0.1047 (0.962 sec/step)\n",
      "I0902 10:18:23.112122 139792788920128 learning.py:507] global step 45191: loss = 0.0870 (0.948 sec/step)\n",
      "I0902 10:18:24.071890 139792788920128 learning.py:507] global step 45192: loss = 0.0761 (0.958 sec/step)\n",
      "I0902 10:18:25.042055 139792788920128 learning.py:507] global step 45193: loss = 0.0706 (0.969 sec/step)\n",
      "I0902 10:18:26.024480 139792788920128 learning.py:507] global step 45194: loss = 0.2380 (0.981 sec/step)\n",
      "I0902 10:18:26.991737 139792788920128 learning.py:507] global step 45195: loss = 0.0874 (0.966 sec/step)\n",
      "I0902 10:18:27.961709 139792788920128 learning.py:507] global step 45196: loss = 0.1099 (0.968 sec/step)\n",
      "I0902 10:18:28.926662 139792788920128 learning.py:507] global step 45197: loss = 0.1746 (0.963 sec/step)\n",
      "I0902 10:18:29.872949 139792788920128 learning.py:507] global step 45198: loss = 0.0971 (0.945 sec/step)\n",
      "I0902 10:18:30.844271 139792788920128 learning.py:507] global step 45199: loss = 0.1914 (0.970 sec/step)\n",
      "I0902 10:18:31.803742 139792788920128 learning.py:507] global step 45200: loss = 0.0775 (0.958 sec/step)\n",
      "I0902 10:18:32.782857 139792788920128 learning.py:507] global step 45201: loss = 0.1233 (0.978 sec/step)\n",
      "I0902 10:18:33.756528 139792788920128 learning.py:507] global step 45202: loss = 0.0788 (0.972 sec/step)\n",
      "I0902 10:18:34.739322 139792788920128 learning.py:507] global step 45203: loss = 0.1690 (0.981 sec/step)\n",
      "I0902 10:18:35.727174 139792788920128 learning.py:507] global step 45204: loss = 0.1428 (0.986 sec/step)\n",
      "I0902 10:18:36.691755 139792788920128 learning.py:507] global step 45205: loss = 0.1223 (0.963 sec/step)\n",
      "I0902 10:18:37.659605 139792788920128 learning.py:507] global step 45206: loss = 0.0779 (0.966 sec/step)\n",
      "I0902 10:18:38.615610 139792788920128 learning.py:507] global step 45207: loss = 0.1400 (0.954 sec/step)\n",
      "I0902 10:18:39.616688 139792788920128 learning.py:507] global step 45208: loss = 0.1118 (0.999 sec/step)\n",
      "I0902 10:18:40.611348 139792788920128 learning.py:507] global step 45209: loss = 0.1899 (0.993 sec/step)\n",
      "I0902 10:18:41.617842 139792788920128 learning.py:507] global step 45210: loss = 0.1046 (1.005 sec/step)\n",
      "I0902 10:18:42.612424 139792788920128 learning.py:507] global step 45211: loss = 0.1104 (0.993 sec/step)\n",
      "I0902 10:18:43.580647 139792788920128 learning.py:507] global step 45212: loss = 0.1110 (0.966 sec/step)\n",
      "I0902 10:18:44.545843 139792788920128 learning.py:507] global step 45213: loss = 0.0763 (0.963 sec/step)\n",
      "I0902 10:18:45.520951 139792788920128 learning.py:507] global step 45214: loss = 0.1062 (0.973 sec/step)\n",
      "I0902 10:18:46.518188 139792788920128 learning.py:507] global step 45215: loss = 0.0765 (0.996 sec/step)\n",
      "I0902 10:18:47.506229 139792788920128 learning.py:507] global step 45216: loss = 0.1390 (0.987 sec/step)\n",
      "I0902 10:18:48.473142 139792788920128 learning.py:507] global step 45217: loss = 0.1656 (0.965 sec/step)\n",
      "I0902 10:18:49.414151 139792788920128 learning.py:507] global step 45218: loss = 0.0679 (0.939 sec/step)\n",
      "I0902 10:18:50.400257 139792788920128 learning.py:507] global step 45219: loss = 0.0919 (0.984 sec/step)\n",
      "I0902 10:18:51.385664 139792788920128 learning.py:507] global step 45220: loss = 0.1445 (0.984 sec/step)\n",
      "I0902 10:18:52.354218 139792788920128 learning.py:507] global step 45221: loss = 0.1401 (0.967 sec/step)\n",
      "I0902 10:18:53.319913 139792788920128 learning.py:507] global step 45222: loss = 0.2195 (0.964 sec/step)\n",
      "I0902 10:18:54.285948 139792788920128 learning.py:507] global step 45223: loss = 0.0942 (0.964 sec/step)\n",
      "I0902 10:18:55.263344 139792788920128 learning.py:507] global step 45224: loss = 0.1022 (0.976 sec/step)\n",
      "I0902 10:18:56.222373 139792788920128 learning.py:507] global step 45225: loss = 0.1178 (0.957 sec/step)\n",
      "I0902 10:18:57.197874 139792788920128 learning.py:507] global step 45226: loss = 0.0897 (0.974 sec/step)\n",
      "I0902 10:18:58.143886 139792788920128 learning.py:507] global step 45227: loss = 0.0795 (0.944 sec/step)\n",
      "I0902 10:18:59.149658 139792788920128 learning.py:507] global step 45228: loss = 0.1300 (1.004 sec/step)\n",
      "I0902 10:19:00.116101 139792788920128 learning.py:507] global step 45229: loss = 0.0915 (0.965 sec/step)\n",
      "I0902 10:19:01.064891 139792788920128 learning.py:507] global step 45230: loss = 0.0639 (0.947 sec/step)\n",
      "I0902 10:19:02.038641 139792788920128 learning.py:507] global step 45231: loss = 0.1539 (0.972 sec/step)\n",
      "I0902 10:19:03.002579 139792788920128 learning.py:507] global step 45232: loss = 0.1604 (0.962 sec/step)\n",
      "I0902 10:19:03.965214 139792788920128 learning.py:507] global step 45233: loss = 0.0907 (0.961 sec/step)\n",
      "I0902 10:19:04.946213 139792788920128 learning.py:507] global step 45234: loss = 0.1457 (0.979 sec/step)\n",
      "I0902 10:19:05.954798 139792788920128 learning.py:507] global step 45235: loss = 0.0790 (1.007 sec/step)\n",
      "I0902 10:19:06.929519 139792788920128 learning.py:507] global step 45236: loss = 0.1076 (0.973 sec/step)\n",
      "I0902 10:19:07.930706 139792788920128 learning.py:507] global step 45237: loss = 0.0853 (1.000 sec/step)\n",
      "I0902 10:19:08.932692 139792788920128 learning.py:507] global step 45238: loss = 0.0570 (1.000 sec/step)\n",
      "I0902 10:19:09.901135 139792788920128 learning.py:507] global step 45239: loss = 0.1018 (0.967 sec/step)\n",
      "I0902 10:19:10.872841 139792788920128 learning.py:507] global step 45240: loss = 0.1404 (0.970 sec/step)\n",
      "I0902 10:19:11.859968 139792788920128 learning.py:507] global step 45241: loss = 0.0618 (0.986 sec/step)\n",
      "I0902 10:19:12.830947 139792788920128 learning.py:507] global step 45242: loss = 0.0768 (0.969 sec/step)\n",
      "I0902 10:19:13.807547 139792788920128 learning.py:507] global step 45243: loss = 0.2134 (0.975 sec/step)\n",
      "I0902 10:19:14.773728 139792788920128 learning.py:507] global step 45244: loss = 0.1645 (0.965 sec/step)\n",
      "I0902 10:19:15.753822 139792788920128 learning.py:507] global step 45245: loss = 0.0452 (0.978 sec/step)\n",
      "I0902 10:19:16.733303 139792788920128 learning.py:507] global step 45246: loss = 0.1889 (0.978 sec/step)\n",
      "I0902 10:19:17.692509 139792788920128 learning.py:507] global step 45247: loss = 0.0976 (0.958 sec/step)\n",
      "I0902 10:19:18.674224 139792788920128 learning.py:507] global step 45248: loss = 0.1201 (0.980 sec/step)\n",
      "I0902 10:19:19.641533 139792788920128 learning.py:507] global step 45249: loss = 0.1106 (0.966 sec/step)\n",
      "I0902 10:19:20.619780 139792788920128 learning.py:507] global step 45250: loss = 0.1762 (0.977 sec/step)\n",
      "I0902 10:19:21.586009 139792788920128 learning.py:507] global step 45251: loss = 0.1267 (0.964 sec/step)\n",
      "I0902 10:19:22.547165 139792788920128 learning.py:507] global step 45252: loss = 0.1538 (0.960 sec/step)\n",
      "I0902 10:19:23.510648 139792788920128 learning.py:507] global step 45253: loss = 0.1344 (0.962 sec/step)\n",
      "I0902 10:19:24.473063 139792788920128 learning.py:507] global step 45254: loss = 0.0656 (0.961 sec/step)\n",
      "I0902 10:19:25.456400 139792788920128 learning.py:507] global step 45255: loss = 0.1213 (0.982 sec/step)\n",
      "I0902 10:19:26.419958 139792788920128 learning.py:507] global step 45256: loss = 0.0595 (0.962 sec/step)\n",
      "I0902 10:19:27.380062 139792788920128 learning.py:507] global step 45257: loss = 0.0701 (0.958 sec/step)\n",
      "I0902 10:19:28.349257 139792788920128 learning.py:507] global step 45258: loss = 0.1318 (0.968 sec/step)\n",
      "I0902 10:19:29.338119 139792788920128 learning.py:507] global step 45259: loss = 0.1948 (0.987 sec/step)\n",
      "I0902 10:19:30.310445 139792788920128 learning.py:507] global step 45260: loss = 0.0785 (0.971 sec/step)\n",
      "I0902 10:19:31.285835 139792788920128 learning.py:507] global step 45261: loss = 0.1511 (0.974 sec/step)\n",
      "I0902 10:19:32.252317 139792788920128 learning.py:507] global step 45262: loss = 0.1798 (0.965 sec/step)\n",
      "I0902 10:19:33.229124 139792788920128 learning.py:507] global step 45263: loss = 0.1586 (0.975 sec/step)\n",
      "I0902 10:19:34.184161 139792788920128 learning.py:507] global step 45264: loss = 0.1313 (0.953 sec/step)\n",
      "I0902 10:19:35.150941 139792788920128 learning.py:507] global step 45265: loss = 0.1393 (0.965 sec/step)\n",
      "I0902 10:19:36.133919 139792788920128 learning.py:507] global step 45266: loss = 0.1414 (0.981 sec/step)\n",
      "I0902 10:19:37.110670 139792788920128 learning.py:507] global step 45267: loss = 0.2203 (0.975 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:19:38.088757 139792788920128 learning.py:507] global step 45268: loss = 0.0808 (0.976 sec/step)\n",
      "I0902 10:19:39.059840 139792788920128 learning.py:507] global step 45269: loss = 0.0516 (0.969 sec/step)\n",
      "I0902 10:19:40.009927 139792788920128 learning.py:507] global step 45270: loss = 0.0963 (0.948 sec/step)\n",
      "I0902 10:19:40.988602 139792788920128 learning.py:507] global step 45271: loss = 0.1150 (0.977 sec/step)\n",
      "I0902 10:19:41.960413 139792788920128 learning.py:507] global step 45272: loss = 0.0774 (0.970 sec/step)\n",
      "I0902 10:19:42.948589 139792788920128 learning.py:507] global step 45273: loss = 0.1710 (0.986 sec/step)\n",
      "I0902 10:19:43.930046 139792788920128 learning.py:507] global step 45274: loss = 0.1635 (0.980 sec/step)\n",
      "I0902 10:19:44.888545 139792788920128 learning.py:507] global step 45275: loss = 0.0606 (0.957 sec/step)\n",
      "I0902 10:19:45.871829 139792788920128 learning.py:507] global step 45276: loss = 0.1328 (0.982 sec/step)\n",
      "I0902 10:19:46.859527 139792788920128 learning.py:507] global step 45277: loss = 0.1600 (0.986 sec/step)\n",
      "I0902 10:19:47.822422 139792788920128 learning.py:507] global step 45278: loss = 0.1593 (0.961 sec/step)\n",
      "I0902 10:19:48.787044 139792788920128 learning.py:507] global step 45279: loss = 0.2707 (0.963 sec/step)\n",
      "I0902 10:19:49.915881 139792788920128 learning.py:507] global step 45280: loss = 0.0819 (1.126 sec/step)\n",
      "I0902 10:19:50.227022 139778936784640 supervisor.py:1050] Recording summary at step 45280.\n",
      "I0902 10:19:51.019354 139792788920128 learning.py:507] global step 45281: loss = 0.1554 (1.097 sec/step)\n",
      "I0902 10:19:51.988249 139792788920128 learning.py:507] global step 45282: loss = 0.0934 (0.967 sec/step)\n",
      "I0902 10:19:52.961876 139792788920128 learning.py:507] global step 45283: loss = 0.1288 (0.972 sec/step)\n",
      "I0902 10:19:53.933758 139792788920128 learning.py:507] global step 45284: loss = 0.0516 (0.970 sec/step)\n",
      "I0902 10:19:54.911576 139792788920128 learning.py:507] global step 45285: loss = 0.1344 (0.976 sec/step)\n",
      "I0902 10:19:55.866829 139792788920128 learning.py:507] global step 45286: loss = 0.1027 (0.954 sec/step)\n",
      "I0902 10:19:56.844208 139792788920128 learning.py:507] global step 45287: loss = 0.0457 (0.976 sec/step)\n",
      "I0902 10:19:57.807771 139792788920128 learning.py:507] global step 45288: loss = 0.1198 (0.962 sec/step)\n",
      "I0902 10:19:58.762195 139792788920128 learning.py:507] global step 45289: loss = 0.1726 (0.953 sec/step)\n",
      "I0902 10:19:59.740865 139792788920128 learning.py:507] global step 45290: loss = 0.0819 (0.977 sec/step)\n",
      "I0902 10:20:00.722294 139792788920128 learning.py:507] global step 45291: loss = 0.0816 (0.980 sec/step)\n",
      "I0902 10:20:01.716357 139792788920128 learning.py:507] global step 45292: loss = 0.2999 (0.992 sec/step)\n",
      "I0902 10:20:02.692529 139792788920128 learning.py:507] global step 45293: loss = 0.0940 (0.975 sec/step)\n",
      "I0902 10:20:03.662715 139792788920128 learning.py:507] global step 45294: loss = 0.1480 (0.969 sec/step)\n",
      "I0902 10:20:04.640231 139792788920128 learning.py:507] global step 45295: loss = 0.1000 (0.976 sec/step)\n",
      "I0902 10:20:05.630172 139792788920128 learning.py:507] global step 45296: loss = 0.0761 (0.988 sec/step)\n",
      "I0902 10:20:06.608152 139792788920128 learning.py:507] global step 45297: loss = 0.2066 (0.976 sec/step)\n",
      "I0902 10:20:07.595484 139792788920128 learning.py:507] global step 45298: loss = 0.1502 (0.986 sec/step)\n",
      "I0902 10:20:08.579687 139792788920128 learning.py:507] global step 45299: loss = 0.0880 (0.983 sec/step)\n",
      "I0902 10:20:09.552606 139792788920128 learning.py:507] global step 45300: loss = 0.0725 (0.971 sec/step)\n",
      "I0902 10:20:10.544869 139792788920128 learning.py:507] global step 45301: loss = 0.1507 (0.991 sec/step)\n",
      "I0902 10:20:11.541528 139792788920128 learning.py:507] global step 45302: loss = 0.1235 (0.995 sec/step)\n",
      "I0902 10:20:12.513940 139792788920128 learning.py:507] global step 45303: loss = 0.1169 (0.971 sec/step)\n",
      "I0902 10:20:13.485422 139792788920128 learning.py:507] global step 45304: loss = 0.1729 (0.970 sec/step)\n",
      "I0902 10:20:14.472635 139792788920128 learning.py:507] global step 45305: loss = 0.0563 (0.986 sec/step)\n",
      "I0902 10:20:15.454918 139792788920128 learning.py:507] global step 45306: loss = 0.0875 (0.981 sec/step)\n",
      "I0902 10:20:16.420320 139792788920128 learning.py:507] global step 45307: loss = 0.0918 (0.964 sec/step)\n",
      "I0902 10:20:17.393938 139792788920128 learning.py:507] global step 45308: loss = 0.1721 (0.972 sec/step)\n",
      "I0902 10:20:18.365134 139792788920128 learning.py:507] global step 45309: loss = 0.7174 (0.970 sec/step)\n",
      "I0902 10:20:19.344736 139792788920128 learning.py:507] global step 45310: loss = 0.0808 (0.978 sec/step)\n",
      "I0902 10:20:20.315068 139792788920128 learning.py:507] global step 45311: loss = 0.1805 (0.969 sec/step)\n",
      "I0902 10:20:21.287944 139792788920128 learning.py:507] global step 45312: loss = 0.1265 (0.971 sec/step)\n",
      "I0902 10:20:22.276600 139792788920128 learning.py:507] global step 45313: loss = 0.1291 (0.987 sec/step)\n",
      "I0902 10:20:23.216391 139792788920128 learning.py:507] global step 45314: loss = 0.0974 (0.938 sec/step)\n",
      "I0902 10:20:24.180262 139792788920128 learning.py:507] global step 45315: loss = 0.2212 (0.962 sec/step)\n",
      "I0902 10:20:25.144985 139792788920128 learning.py:507] global step 45316: loss = 0.1362 (0.963 sec/step)\n",
      "I0902 10:20:26.104577 139792788920128 learning.py:507] global step 45317: loss = 0.0591 (0.958 sec/step)\n",
      "I0902 10:20:27.088093 139792788920128 learning.py:507] global step 45318: loss = 0.1545 (0.982 sec/step)\n",
      "I0902 10:20:28.107275 139792788920128 learning.py:507] global step 45319: loss = 0.0923 (1.018 sec/step)\n",
      "I0902 10:20:29.108090 139792788920128 learning.py:507] global step 45320: loss = 0.1507 (0.999 sec/step)\n",
      "I0902 10:20:30.094477 139792788920128 learning.py:507] global step 45321: loss = 0.0680 (0.985 sec/step)\n",
      "I0902 10:20:31.084638 139792788920128 learning.py:507] global step 45322: loss = 0.1183 (0.988 sec/step)\n",
      "I0902 10:20:32.078212 139792788920128 learning.py:507] global step 45323: loss = 0.1485 (0.992 sec/step)\n",
      "I0902 10:20:33.064561 139792788920128 learning.py:507] global step 45324: loss = 0.0739 (0.985 sec/step)\n",
      "I0902 10:20:34.043256 139792788920128 learning.py:507] global step 45325: loss = 0.1059 (0.977 sec/step)\n",
      "I0902 10:20:35.014608 139792788920128 learning.py:507] global step 45326: loss = 0.0529 (0.970 sec/step)\n",
      "I0902 10:20:35.968516 139792788920128 learning.py:507] global step 45327: loss = 0.1755 (0.952 sec/step)\n",
      "I0902 10:20:36.960545 139792788920128 learning.py:507] global step 45328: loss = 0.1463 (0.990 sec/step)\n",
      "I0902 10:20:37.915676 139792788920128 learning.py:507] global step 45329: loss = 0.0864 (0.953 sec/step)\n",
      "I0902 10:20:38.907736 139792788920128 learning.py:507] global step 45330: loss = 0.1630 (0.990 sec/step)\n",
      "I0902 10:20:39.885357 139792788920128 learning.py:507] global step 45331: loss = 0.2282 (0.976 sec/step)\n",
      "I0902 10:20:40.868784 139792788920128 learning.py:507] global step 45332: loss = 0.1023 (0.982 sec/step)\n",
      "I0902 10:20:41.854434 139792788920128 learning.py:507] global step 45333: loss = 0.1082 (0.984 sec/step)\n",
      "I0902 10:20:42.815276 139792788920128 learning.py:507] global step 45334: loss = 0.0813 (0.959 sec/step)\n",
      "I0902 10:20:43.764077 139792788920128 learning.py:507] global step 45335: loss = 0.2407 (0.947 sec/step)\n",
      "I0902 10:20:44.726170 139792788920128 learning.py:507] global step 45336: loss = 0.0764 (0.960 sec/step)\n",
      "I0902 10:20:45.724703 139792788920128 learning.py:507] global step 45337: loss = 0.1428 (0.997 sec/step)\n",
      "I0902 10:20:46.718848 139792788920128 learning.py:507] global step 45338: loss = 0.1526 (0.992 sec/step)\n",
      "I0902 10:20:47.669577 139792788920128 learning.py:507] global step 45339: loss = 0.0878 (0.949 sec/step)\n",
      "I0902 10:20:48.634800 139792788920128 learning.py:507] global step 45340: loss = 0.0880 (0.963 sec/step)\n",
      "I0902 10:20:49.615668 139792788920128 learning.py:507] global step 45341: loss = 0.0894 (0.979 sec/step)\n",
      "I0902 10:20:50.574780 139792788920128 learning.py:507] global step 45342: loss = 0.0504 (0.957 sec/step)\n",
      "I0902 10:20:51.526759 139792788920128 learning.py:507] global step 45343: loss = 0.0503 (0.950 sec/step)\n",
      "I0902 10:20:52.477986 139792788920128 learning.py:507] global step 45344: loss = 0.0753 (0.950 sec/step)\n",
      "I0902 10:20:53.447526 139792788920128 learning.py:507] global step 45345: loss = 0.0652 (0.968 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:20:54.413215 139792788920128 learning.py:507] global step 45346: loss = 0.1489 (0.964 sec/step)\n",
      "I0902 10:20:55.368497 139792788920128 learning.py:507] global step 45347: loss = 0.1284 (0.954 sec/step)\n",
      "I0902 10:20:56.321696 139792788920128 learning.py:507] global step 45348: loss = 0.1476 (0.952 sec/step)\n",
      "I0902 10:20:57.305577 139792788920128 learning.py:507] global step 45349: loss = 0.1130 (0.982 sec/step)\n",
      "I0902 10:20:58.266043 139792788920128 learning.py:507] global step 45350: loss = 0.1168 (0.959 sec/step)\n",
      "I0902 10:20:59.243918 139792788920128 learning.py:507] global step 45351: loss = 0.1207 (0.976 sec/step)\n",
      "I0902 10:21:00.205979 139792788920128 learning.py:507] global step 45352: loss = 0.0929 (0.960 sec/step)\n",
      "I0902 10:21:01.185770 139792788920128 learning.py:507] global step 45353: loss = 0.0863 (0.978 sec/step)\n",
      "I0902 10:21:02.188370 139792788920128 learning.py:507] global step 45354: loss = 0.1379 (1.001 sec/step)\n",
      "I0902 10:21:03.130322 139792788920128 learning.py:507] global step 45355: loss = 0.1125 (0.940 sec/step)\n",
      "I0902 10:21:04.093236 139792788920128 learning.py:507] global step 45356: loss = 0.0689 (0.961 sec/step)\n",
      "I0902 10:21:05.055962 139792788920128 learning.py:507] global step 45357: loss = 0.1161 (0.961 sec/step)\n",
      "I0902 10:21:06.030076 139792788920128 learning.py:507] global step 45358: loss = 0.1154 (0.972 sec/step)\n",
      "I0902 10:21:06.979106 139792788920128 learning.py:507] global step 45359: loss = 0.0936 (0.947 sec/step)\n",
      "I0902 10:21:07.942239 139792788920128 learning.py:507] global step 45360: loss = 0.0432 (0.961 sec/step)\n",
      "I0902 10:21:08.926238 139792788920128 learning.py:507] global step 45361: loss = 0.2133 (0.982 sec/step)\n",
      "I0902 10:21:09.888213 139792788920128 learning.py:507] global step 45362: loss = 0.0719 (0.960 sec/step)\n",
      "I0902 10:21:10.868993 139792788920128 learning.py:507] global step 45363: loss = 0.1439 (0.979 sec/step)\n",
      "I0902 10:21:11.833170 139792788920128 learning.py:507] global step 45364: loss = 0.1936 (0.963 sec/step)\n",
      "I0902 10:21:12.797907 139792788920128 learning.py:507] global step 45365: loss = 0.1339 (0.963 sec/step)\n",
      "I0902 10:21:13.787485 139792788920128 learning.py:507] global step 45366: loss = 0.1129 (0.988 sec/step)\n",
      "I0902 10:21:14.783939 139792788920128 learning.py:507] global step 45367: loss = 0.0951 (0.995 sec/step)\n",
      "I0902 10:21:15.781670 139792788920128 learning.py:507] global step 45368: loss = 0.0929 (0.996 sec/step)\n",
      "I0902 10:21:16.762238 139792788920128 learning.py:507] global step 45369: loss = 0.1060 (0.979 sec/step)\n",
      "I0902 10:21:17.733412 139792788920128 learning.py:507] global step 45370: loss = 0.0787 (0.969 sec/step)\n",
      "I0902 10:21:18.711197 139792788920128 learning.py:507] global step 45371: loss = 0.0916 (0.976 sec/step)\n",
      "I0902 10:21:19.702160 139792788920128 learning.py:507] global step 45372: loss = 0.0738 (0.990 sec/step)\n",
      "I0902 10:21:20.679185 139792788920128 learning.py:507] global step 45373: loss = 0.2326 (0.975 sec/step)\n",
      "I0902 10:21:21.674572 139792788920128 learning.py:507] global step 45374: loss = 0.1173 (0.994 sec/step)\n",
      "I0902 10:21:22.652725 139792788920128 learning.py:507] global step 45375: loss = 0.1121 (0.976 sec/step)\n",
      "I0902 10:21:23.632706 139792788920128 learning.py:507] global step 45376: loss = 0.1853 (0.979 sec/step)\n",
      "I0902 10:21:24.601462 139792788920128 learning.py:507] global step 45377: loss = 0.0954 (0.967 sec/step)\n",
      "I0902 10:21:25.563725 139792788920128 learning.py:507] global step 45378: loss = 0.1384 (0.961 sec/step)\n",
      "I0902 10:21:26.547241 139792788920128 learning.py:507] global step 45379: loss = 0.0637 (0.982 sec/step)\n",
      "I0902 10:21:27.509473 139792788920128 learning.py:507] global step 45380: loss = 0.0766 (0.960 sec/step)\n",
      "I0902 10:21:28.496063 139792788920128 learning.py:507] global step 45381: loss = 0.3889 (0.985 sec/step)\n",
      "I0902 10:21:29.452740 139792788920128 learning.py:507] global step 45382: loss = 0.1417 (0.955 sec/step)\n",
      "I0902 10:21:30.431965 139792788920128 learning.py:507] global step 45383: loss = 0.1402 (0.978 sec/step)\n",
      "I0902 10:21:31.406304 139792788920128 learning.py:507] global step 45384: loss = 0.1709 (0.973 sec/step)\n",
      "I0902 10:21:32.378436 139792788920128 learning.py:507] global step 45385: loss = 0.2191 (0.970 sec/step)\n",
      "I0902 10:21:33.336580 139792788920128 learning.py:507] global step 45386: loss = 0.0829 (0.956 sec/step)\n",
      "I0902 10:21:34.325129 139792788920128 learning.py:507] global step 45387: loss = 0.0454 (0.987 sec/step)\n",
      "I0902 10:21:35.289206 139792788920128 learning.py:507] global step 45388: loss = 0.1047 (0.962 sec/step)\n",
      "I0902 10:21:36.242728 139792788920128 learning.py:507] global step 45389: loss = 0.1793 (0.952 sec/step)\n",
      "I0902 10:21:37.206749 139792788920128 learning.py:507] global step 45390: loss = 0.2667 (0.962 sec/step)\n",
      "I0902 10:21:38.165203 139792788920128 learning.py:507] global step 45391: loss = 0.0667 (0.957 sec/step)\n",
      "I0902 10:21:39.140259 139792788920128 learning.py:507] global step 45392: loss = 0.0836 (0.973 sec/step)\n",
      "I0902 10:21:40.118052 139792788920128 learning.py:507] global step 45393: loss = 0.0915 (0.976 sec/step)\n",
      "I0902 10:21:41.105359 139792788920128 learning.py:507] global step 45394: loss = 0.1469 (0.986 sec/step)\n",
      "I0902 10:21:42.078299 139792788920128 learning.py:507] global step 45395: loss = 0.1080 (0.972 sec/step)\n",
      "I0902 10:21:43.041387 139792788920128 learning.py:507] global step 45396: loss = 0.1083 (0.962 sec/step)\n",
      "I0902 10:21:44.011340 139792788920128 learning.py:507] global step 45397: loss = 0.1360 (0.968 sec/step)\n",
      "I0902 10:21:45.002225 139792788920128 learning.py:507] global step 45398: loss = 0.1117 (0.989 sec/step)\n",
      "I0902 10:21:45.983767 139792788920128 learning.py:507] global step 45399: loss = 0.0593 (0.980 sec/step)\n",
      "I0902 10:21:46.959132 139792788920128 learning.py:507] global step 45400: loss = 0.0818 (0.974 sec/step)\n",
      "I0902 10:21:47.937351 139792788920128 learning.py:507] global step 45401: loss = 0.1529 (0.976 sec/step)\n",
      "I0902 10:21:48.930372 139792788920128 learning.py:507] global step 45402: loss = 0.0646 (0.991 sec/step)\n",
      "I0902 10:21:50.062536 139792788920128 learning.py:507] global step 45403: loss = 0.1682 (1.126 sec/step)\n",
      "I0902 10:21:50.246265 139778936784640 supervisor.py:1050] Recording summary at step 45403.\n",
      "I0902 10:21:51.155935 139792788920128 learning.py:507] global step 45404: loss = 0.1278 (1.087 sec/step)\n",
      "I0902 10:21:52.131211 139792788920128 learning.py:507] global step 45405: loss = 0.1298 (0.974 sec/step)\n",
      "I0902 10:21:53.103322 139792788920128 learning.py:507] global step 45406: loss = 0.1026 (0.970 sec/step)\n",
      "I0902 10:21:54.081488 139792788920128 learning.py:507] global step 45407: loss = 0.0569 (0.976 sec/step)\n",
      "I0902 10:21:55.056524 139792788920128 learning.py:507] global step 45408: loss = 0.0739 (0.973 sec/step)\n",
      "I0902 10:21:56.019348 139792788920128 learning.py:507] global step 45409: loss = 0.2495 (0.961 sec/step)\n",
      "I0902 10:21:56.992306 139792788920128 learning.py:507] global step 45410: loss = 0.0753 (0.971 sec/step)\n",
      "I0902 10:21:57.971858 139792788920128 learning.py:507] global step 45411: loss = 0.1027 (0.978 sec/step)\n",
      "I0902 10:21:58.943273 139792788920128 learning.py:507] global step 45412: loss = 0.0720 (0.970 sec/step)\n",
      "I0902 10:21:59.913919 139792788920128 learning.py:507] global step 45413: loss = 0.1363 (0.969 sec/step)\n",
      "I0902 10:22:00.881423 139792788920128 learning.py:507] global step 45414: loss = 0.0786 (0.966 sec/step)\n",
      "I0902 10:22:01.879043 139792788920128 learning.py:507] global step 45415: loss = 0.0748 (0.996 sec/step)\n",
      "I0902 10:22:02.839725 139792788920128 learning.py:507] global step 45416: loss = 0.0612 (0.959 sec/step)\n",
      "I0902 10:22:03.820028 139792788920128 learning.py:507] global step 45417: loss = 0.0899 (0.979 sec/step)\n",
      "I0902 10:22:04.781481 139792788920128 learning.py:507] global step 45418: loss = 0.0994 (0.960 sec/step)\n",
      "I0902 10:22:05.752057 139792788920128 learning.py:507] global step 45419: loss = 0.1159 (0.969 sec/step)\n",
      "I0902 10:22:06.704129 139792788920128 learning.py:507] global step 45420: loss = 0.1693 (0.950 sec/step)\n",
      "I0902 10:22:07.692903 139792788920128 learning.py:507] global step 45421: loss = 0.0666 (0.987 sec/step)\n",
      "I0902 10:22:08.690708 139792788920128 learning.py:507] global step 45422: loss = 0.1503 (0.996 sec/step)\n",
      "I0902 10:22:09.657229 139792788920128 learning.py:507] global step 45423: loss = 0.0915 (0.965 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:22:10.638099 139792788920128 learning.py:507] global step 45424: loss = 0.2311 (0.979 sec/step)\n",
      "I0902 10:22:11.614459 139792788920128 learning.py:507] global step 45425: loss = 0.0766 (0.975 sec/step)\n",
      "I0902 10:22:12.585097 139792788920128 learning.py:507] global step 45426: loss = 0.1888 (0.969 sec/step)\n",
      "I0902 10:22:13.569791 139792788920128 learning.py:507] global step 45427: loss = 0.0874 (0.983 sec/step)\n",
      "I0902 10:22:14.517724 139792788920128 learning.py:507] global step 45428: loss = 0.0573 (0.946 sec/step)\n",
      "I0902 10:22:15.479012 139792788920128 learning.py:507] global step 45429: loss = 0.4196 (0.960 sec/step)\n",
      "I0902 10:22:16.457875 139792788920128 learning.py:507] global step 45430: loss = 0.1073 (0.977 sec/step)\n",
      "I0902 10:22:17.407866 139792788920128 learning.py:507] global step 45431: loss = 0.0777 (0.948 sec/step)\n",
      "I0902 10:22:18.382015 139792788920128 learning.py:507] global step 45432: loss = 0.2101 (0.972 sec/step)\n",
      "I0902 10:22:19.381408 139792788920128 learning.py:507] global step 45433: loss = 0.0797 (0.998 sec/step)\n",
      "I0902 10:22:20.379798 139792788920128 learning.py:507] global step 45434: loss = 0.1309 (0.997 sec/step)\n",
      "I0902 10:22:21.362769 139792788920128 learning.py:507] global step 45435: loss = 0.2176 (0.981 sec/step)\n",
      "I0902 10:22:22.333720 139792788920128 learning.py:507] global step 45436: loss = 0.0876 (0.969 sec/step)\n",
      "I0902 10:22:23.307984 139792788920128 learning.py:507] global step 45437: loss = 0.0927 (0.973 sec/step)\n",
      "I0902 10:22:24.303255 139792788920128 learning.py:507] global step 45438: loss = 0.1538 (0.994 sec/step)\n",
      "I0902 10:22:25.262871 139792788920128 learning.py:507] global step 45439: loss = 0.0759 (0.958 sec/step)\n",
      "I0902 10:22:26.232184 139792788920128 learning.py:507] global step 45440: loss = 0.1023 (0.968 sec/step)\n",
      "I0902 10:22:27.238510 139792788920128 learning.py:507] global step 45441: loss = 0.0481 (1.005 sec/step)\n",
      "I0902 10:22:28.212692 139792788920128 learning.py:507] global step 45442: loss = 0.1166 (0.973 sec/step)\n",
      "I0902 10:22:29.193812 139792788920128 learning.py:507] global step 45443: loss = 0.1494 (0.979 sec/step)\n",
      "I0902 10:22:30.161218 139792788920128 learning.py:507] global step 45444: loss = 0.1142 (0.966 sec/step)\n",
      "I0902 10:22:31.120522 139792788920128 learning.py:507] global step 45445: loss = 0.1125 (0.958 sec/step)\n",
      "I0902 10:22:32.098305 139792788920128 learning.py:507] global step 45446: loss = 0.0396 (0.976 sec/step)\n",
      "I0902 10:22:33.077139 139792788920128 learning.py:507] global step 45447: loss = 0.3244 (0.977 sec/step)\n",
      "I0902 10:22:34.076265 139792788920128 learning.py:507] global step 45448: loss = 0.0820 (0.997 sec/step)\n",
      "I0902 10:22:35.044237 139792788920128 learning.py:507] global step 45449: loss = 0.0540 (0.966 sec/step)\n",
      "I0902 10:22:36.004879 139792788920128 learning.py:507] global step 45450: loss = 0.0696 (0.959 sec/step)\n",
      "I0902 10:22:36.968115 139792788920128 learning.py:507] global step 45451: loss = 0.0706 (0.962 sec/step)\n",
      "I0902 10:22:37.947199 139792788920128 learning.py:507] global step 45452: loss = 0.0934 (0.977 sec/step)\n",
      "I0902 10:22:38.926995 139792788920128 learning.py:507] global step 45453: loss = 0.0690 (0.978 sec/step)\n",
      "I0902 10:22:39.880836 139792788920128 learning.py:507] global step 45454: loss = 0.0989 (0.952 sec/step)\n",
      "I0902 10:22:40.860229 139792788920128 learning.py:507] global step 45455: loss = 0.0664 (0.978 sec/step)\n",
      "I0902 10:22:41.835738 139792788920128 learning.py:507] global step 45456: loss = 0.0886 (0.974 sec/step)\n",
      "I0902 10:22:42.817129 139792788920128 learning.py:507] global step 45457: loss = 0.0806 (0.980 sec/step)\n",
      "I0902 10:22:43.798039 139792788920128 learning.py:507] global step 45458: loss = 0.1623 (0.979 sec/step)\n",
      "I0902 10:22:44.768851 139792788920128 learning.py:507] global step 45459: loss = 0.0538 (0.969 sec/step)\n",
      "I0902 10:22:45.740265 139792788920128 learning.py:507] global step 45460: loss = 0.0693 (0.970 sec/step)\n",
      "I0902 10:22:46.719533 139792788920128 learning.py:507] global step 45461: loss = 0.0886 (0.978 sec/step)\n",
      "I0902 10:22:47.711698 139792788920128 learning.py:507] global step 45462: loss = 0.1092 (0.991 sec/step)\n",
      "I0902 10:22:48.696113 139792788920128 learning.py:507] global step 45463: loss = 0.2041 (0.983 sec/step)\n",
      "I0902 10:22:49.678929 139792788920128 learning.py:507] global step 45464: loss = 0.0876 (0.981 sec/step)\n",
      "I0902 10:22:50.645083 139792788920128 learning.py:507] global step 45465: loss = 0.2701 (0.964 sec/step)\n",
      "I0902 10:22:51.606469 139792788920128 learning.py:507] global step 45466: loss = 0.0521 (0.960 sec/step)\n",
      "I0902 10:22:52.580829 139792788920128 learning.py:507] global step 45467: loss = 0.0455 (0.973 sec/step)\n",
      "I0902 10:22:53.577439 139792788920128 learning.py:507] global step 45468: loss = 0.0973 (0.995 sec/step)\n",
      "I0902 10:22:54.572349 139792788920128 learning.py:507] global step 45469: loss = 0.1305 (0.993 sec/step)\n",
      "I0902 10:22:55.548252 139792788920128 learning.py:507] global step 45470: loss = 0.2647 (0.974 sec/step)\n",
      "I0902 10:22:56.531862 139792788920128 learning.py:507] global step 45471: loss = 0.1618 (0.982 sec/step)\n",
      "I0902 10:22:57.513993 139792788920128 learning.py:507] global step 45472: loss = 0.1261 (0.981 sec/step)\n",
      "I0902 10:22:58.497149 139792788920128 learning.py:507] global step 45473: loss = 0.1707 (0.981 sec/step)\n",
      "I0902 10:22:59.468355 139792788920128 learning.py:507] global step 45474: loss = 0.0783 (0.970 sec/step)\n",
      "I0902 10:23:00.441177 139792788920128 learning.py:507] global step 45475: loss = 0.2726 (0.971 sec/step)\n",
      "I0902 10:23:01.419989 139792788920128 learning.py:507] global step 45476: loss = 0.0934 (0.977 sec/step)\n",
      "I0902 10:23:02.395803 139792788920128 learning.py:507] global step 45477: loss = 0.1356 (0.974 sec/step)\n",
      "I0902 10:23:03.394064 139792788920128 learning.py:507] global step 45478: loss = 0.0948 (0.997 sec/step)\n",
      "I0902 10:23:04.372325 139792788920128 learning.py:507] global step 45479: loss = 0.1420 (0.977 sec/step)\n",
      "I0902 10:23:05.339836 139792788920128 learning.py:507] global step 45480: loss = 0.2030 (0.966 sec/step)\n",
      "I0902 10:23:06.300129 139792788920128 learning.py:507] global step 45481: loss = 0.1608 (0.959 sec/step)\n",
      "I0902 10:23:07.299575 139792788920128 learning.py:507] global step 45482: loss = 0.1948 (0.998 sec/step)\n",
      "I0902 10:23:08.269261 139792788920128 learning.py:507] global step 45483: loss = 0.0650 (0.968 sec/step)\n",
      "I0902 10:23:09.245374 139792788920128 learning.py:507] global step 45484: loss = 0.0853 (0.974 sec/step)\n",
      "I0902 10:23:10.216512 139792788920128 learning.py:507] global step 45485: loss = 0.1160 (0.970 sec/step)\n",
      "I0902 10:23:11.209753 139792788920128 learning.py:507] global step 45486: loss = 0.1730 (0.992 sec/step)\n",
      "I0902 10:23:12.198345 139792788920128 learning.py:507] global step 45487: loss = 0.0531 (0.987 sec/step)\n",
      "I0902 10:23:13.173872 139792788920128 learning.py:507] global step 45488: loss = 0.1348 (0.974 sec/step)\n",
      "I0902 10:23:14.148758 139792788920128 learning.py:507] global step 45489: loss = 0.0823 (0.973 sec/step)\n",
      "I0902 10:23:15.130280 139792788920128 learning.py:507] global step 45490: loss = 0.1805 (0.980 sec/step)\n",
      "I0902 10:23:16.085793 139792788920128 learning.py:507] global step 45491: loss = 0.1501 (0.954 sec/step)\n",
      "I0902 10:23:17.080967 139792788920128 learning.py:507] global step 45492: loss = 0.3827 (0.993 sec/step)\n",
      "I0902 10:23:18.057077 139792788920128 learning.py:507] global step 45493: loss = 0.1203 (0.975 sec/step)\n",
      "I0902 10:23:19.050835 139792788920128 learning.py:507] global step 45494: loss = 0.1416 (0.992 sec/step)\n",
      "I0902 10:23:20.030910 139792788920128 learning.py:507] global step 45495: loss = 0.0791 (0.979 sec/step)\n",
      "I0902 10:23:21.007442 139792788920128 learning.py:507] global step 45496: loss = 0.0798 (0.975 sec/step)\n",
      "I0902 10:23:21.994979 139792788920128 learning.py:507] global step 45497: loss = 0.1491 (0.986 sec/step)\n",
      "I0902 10:23:22.979451 139792788920128 learning.py:507] global step 45498: loss = 0.0521 (0.983 sec/step)\n",
      "I0902 10:23:23.950382 139792788920128 learning.py:507] global step 45499: loss = 0.0567 (0.969 sec/step)\n",
      "I0902 10:23:24.934446 139792788920128 learning.py:507] global step 45500: loss = 0.2866 (0.983 sec/step)\n",
      "I0902 10:23:25.906957 139792788920128 learning.py:507] global step 45501: loss = 0.1918 (0.971 sec/step)\n",
      "I0902 10:23:26.903081 139792788920128 learning.py:507] global step 45502: loss = 0.1101 (0.995 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:23:27.914563 139792788920128 learning.py:507] global step 45503: loss = 0.1063 (1.010 sec/step)\n",
      "I0902 10:23:28.899063 139792788920128 learning.py:507] global step 45504: loss = 0.1360 (0.983 sec/step)\n",
      "I0902 10:23:29.871650 139792788920128 learning.py:507] global step 45505: loss = 0.1410 (0.971 sec/step)\n",
      "I0902 10:23:30.856222 139792788920128 learning.py:507] global step 45506: loss = 0.0514 (0.983 sec/step)\n",
      "I0902 10:23:31.819792 139792788920128 learning.py:507] global step 45507: loss = 0.1485 (0.962 sec/step)\n",
      "I0902 10:23:32.787506 139792788920128 learning.py:507] global step 45508: loss = 0.1568 (0.966 sec/step)\n",
      "I0902 10:23:33.755799 139792788920128 learning.py:507] global step 45509: loss = 0.0966 (0.967 sec/step)\n",
      "I0902 10:23:34.749440 139792788920128 learning.py:507] global step 45510: loss = 0.0598 (0.992 sec/step)\n",
      "I0902 10:23:35.717285 139792788920128 learning.py:507] global step 45511: loss = 0.1168 (0.967 sec/step)\n",
      "I0902 10:23:36.681342 139792788920128 learning.py:507] global step 45512: loss = 0.1713 (0.963 sec/step)\n",
      "I0902 10:23:37.667226 139792788920128 learning.py:507] global step 45513: loss = 0.0668 (0.984 sec/step)\n",
      "I0902 10:23:38.630166 139792788920128 learning.py:507] global step 45514: loss = 0.0949 (0.962 sec/step)\n",
      "I0902 10:23:39.595153 139792788920128 learning.py:507] global step 45515: loss = 0.0556 (0.964 sec/step)\n",
      "I0902 10:23:40.591587 139792788920128 learning.py:507] global step 45516: loss = 0.1148 (0.995 sec/step)\n",
      "I0902 10:23:41.576350 139792788920128 learning.py:507] global step 45517: loss = 0.1954 (0.983 sec/step)\n",
      "I0902 10:23:42.552512 139792788920128 learning.py:507] global step 45518: loss = 0.1077 (0.974 sec/step)\n",
      "I0902 10:23:43.554933 139792788920128 learning.py:507] global step 45519: loss = 0.0775 (1.001 sec/step)\n",
      "I0902 10:23:44.531253 139792788920128 learning.py:507] global step 45520: loss = 0.1112 (0.974 sec/step)\n",
      "I0902 10:23:45.515716 139792788920128 learning.py:507] global step 45521: loss = 0.0845 (0.983 sec/step)\n",
      "I0902 10:23:46.489817 139792788920128 learning.py:507] global step 45522: loss = 0.1068 (0.972 sec/step)\n",
      "I0902 10:23:47.486264 139792788920128 learning.py:507] global step 45523: loss = 0.0737 (0.995 sec/step)\n",
      "I0902 10:23:48.459399 139792788920128 learning.py:507] global step 45524: loss = 0.0513 (0.971 sec/step)\n",
      "I0902 10:23:49.270363 139778953570048 supervisor.py:1117] Saving checkpoint to path data_dir/mixed_experiment/checkpoints_v2/model.ckpt\n",
      "I0902 10:23:49.471601 139792788920128 learning.py:507] global step 45525: loss = 0.1870 (0.996 sec/step)\n",
      "I0902 10:23:49.940504 139778936784640 supervisor.py:1050] Recording summary at step 45525.\n",
      "I0902 10:23:50.701508 139792788920128 learning.py:507] global step 45526: loss = 0.0728 (1.226 sec/step)\n",
      "I0902 10:23:51.677647 139792788920128 learning.py:507] global step 45527: loss = 0.1561 (0.974 sec/step)\n",
      "I0902 10:23:52.648265 139792788920128 learning.py:507] global step 45528: loss = 0.1701 (0.969 sec/step)\n",
      "I0902 10:23:53.617662 139792788920128 learning.py:507] global step 45529: loss = 0.0777 (0.968 sec/step)\n",
      "I0902 10:23:54.611912 139792788920128 learning.py:507] global step 45530: loss = 0.1435 (0.993 sec/step)\n",
      "I0902 10:23:55.591395 139792788920128 learning.py:507] global step 45531: loss = 0.1527 (0.978 sec/step)\n",
      "I0902 10:23:56.568198 139792788920128 learning.py:507] global step 45532: loss = 0.1152 (0.975 sec/step)\n",
      "I0902 10:23:57.539264 139792788920128 learning.py:507] global step 45533: loss = 0.1228 (0.969 sec/step)\n",
      "I0902 10:23:58.518176 139792788920128 learning.py:507] global step 45534: loss = 0.1080 (0.977 sec/step)\n",
      "I0902 10:23:59.501818 139792788920128 learning.py:507] global step 45535: loss = 0.0770 (0.982 sec/step)\n",
      "I0902 10:24:00.498997 139792788920128 learning.py:507] global step 45536: loss = 0.0508 (0.996 sec/step)\n",
      "I0902 10:24:01.474090 139792788920128 learning.py:507] global step 45537: loss = 0.1353 (0.973 sec/step)\n",
      "I0902 10:24:02.438169 139792788920128 learning.py:507] global step 45538: loss = 0.1145 (0.963 sec/step)\n",
      "I0902 10:24:03.406177 139792788920128 learning.py:507] global step 45539: loss = 0.1128 (0.967 sec/step)\n",
      "I0902 10:24:04.388953 139792788920128 learning.py:507] global step 45540: loss = 0.1463 (0.981 sec/step)\n",
      "I0902 10:24:05.363468 139792788920128 learning.py:507] global step 45541: loss = 0.0684 (0.973 sec/step)\n",
      "I0902 10:24:06.337668 139792788920128 learning.py:507] global step 45542: loss = 0.1347 (0.973 sec/step)\n",
      "I0902 10:24:07.306143 139792788920128 learning.py:507] global step 45543: loss = 0.1608 (0.967 sec/step)\n",
      "I0902 10:24:08.294436 139792788920128 learning.py:507] global step 45544: loss = 0.1369 (0.987 sec/step)\n",
      "I0902 10:24:09.299993 139792788920128 learning.py:507] global step 45545: loss = 0.2263 (1.004 sec/step)\n",
      "I0902 10:24:10.295764 139792788920128 learning.py:507] global step 45546: loss = 0.1095 (0.994 sec/step)\n",
      "I0902 10:24:11.273244 139792788920128 learning.py:507] global step 45547: loss = 0.0992 (0.976 sec/step)\n",
      "I0902 10:24:12.229186 139792788920128 learning.py:507] global step 45548: loss = 0.3240 (0.954 sec/step)\n",
      "I0902 10:24:13.212904 139792788920128 learning.py:507] global step 45549: loss = 0.1211 (0.982 sec/step)\n",
      "I0902 10:24:14.185693 139792788920128 learning.py:507] global step 45550: loss = 0.1618 (0.971 sec/step)\n",
      "I0902 10:24:15.159927 139792788920128 learning.py:507] global step 45551: loss = 0.2669 (0.973 sec/step)\n",
      "I0902 10:24:16.133040 139792788920128 learning.py:507] global step 45552: loss = 0.0968 (0.971 sec/step)\n",
      "I0902 10:24:17.097943 139792788920128 learning.py:507] global step 45553: loss = 0.2562 (0.963 sec/step)\n",
      "I0902 10:24:18.079454 139792788920128 learning.py:507] global step 45554: loss = 0.1562 (0.980 sec/step)\n",
      "I0902 10:24:19.065568 139792788920128 learning.py:507] global step 45555: loss = 0.2473 (0.984 sec/step)\n",
      "I0902 10:24:20.053794 139792788920128 learning.py:507] global step 45556: loss = 0.0515 (0.987 sec/step)\n",
      "I0902 10:24:21.050260 139792788920128 learning.py:507] global step 45557: loss = 0.0582 (0.995 sec/step)\n",
      "I0902 10:24:22.052419 139792788920128 learning.py:507] global step 45558: loss = 0.0889 (1.001 sec/step)\n",
      "I0902 10:24:23.038941 139792788920128 learning.py:507] global step 45559: loss = 0.0897 (0.985 sec/step)\n",
      "I0902 10:24:24.033671 139792788920128 learning.py:507] global step 45560: loss = 0.2648 (0.993 sec/step)\n",
      "I0902 10:24:24.996187 139792788920128 learning.py:507] global step 45561: loss = 0.1580 (0.961 sec/step)\n",
      "I0902 10:24:25.948988 139792788920128 learning.py:507] global step 45562: loss = 0.1722 (0.951 sec/step)\n",
      "I0902 10:24:26.947999 139792788920128 learning.py:507] global step 45563: loss = 0.2008 (0.997 sec/step)\n",
      "I0902 10:24:27.940068 139792788920128 learning.py:507] global step 45564: loss = 0.0822 (0.990 sec/step)\n",
      "I0902 10:24:28.940295 139792788920128 learning.py:507] global step 45565: loss = 0.1784 (0.999 sec/step)\n",
      "I0902 10:24:29.942222 139792788920128 learning.py:507] global step 45566: loss = 0.1711 (1.000 sec/step)\n",
      "I0902 10:24:30.931081 139792788920128 learning.py:507] global step 45567: loss = 0.1739 (0.987 sec/step)\n",
      "I0902 10:24:31.912221 139792788920128 learning.py:507] global step 45568: loss = 0.0703 (0.979 sec/step)\n",
      "I0902 10:24:32.901258 139792788920128 learning.py:507] global step 45569: loss = 0.0785 (0.987 sec/step)\n",
      "I0902 10:24:33.893533 139792788920128 learning.py:507] global step 45570: loss = 0.1524 (0.991 sec/step)\n",
      "I0902 10:24:34.905756 139792788920128 learning.py:507] global step 45571: loss = 0.1389 (1.011 sec/step)\n",
      "I0902 10:24:35.875344 139792788920128 learning.py:507] global step 45572: loss = 0.1560 (0.968 sec/step)\n",
      "I0902 10:24:36.827564 139792788920128 learning.py:507] global step 45573: loss = 0.1153 (0.951 sec/step)\n",
      "I0902 10:24:37.797557 139792788920128 learning.py:507] global step 45574: loss = 0.1029 (0.968 sec/step)\n",
      "I0902 10:24:38.771105 139792788920128 learning.py:507] global step 45575: loss = 0.1046 (0.972 sec/step)\n",
      "I0902 10:24:39.716702 139792788920128 learning.py:507] global step 45576: loss = 0.0786 (0.944 sec/step)\n",
      "I0902 10:24:40.681504 139792788920128 learning.py:507] global step 45577: loss = 0.3914 (0.963 sec/step)\n",
      "I0902 10:24:41.642386 139792788920128 learning.py:507] global step 45578: loss = 0.1379 (0.959 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:24:42.621937 139792788920128 learning.py:507] global step 45579: loss = 0.2713 (0.978 sec/step)\n",
      "I0902 10:24:43.612206 139792788920128 learning.py:507] global step 45580: loss = 0.1582 (0.989 sec/step)\n",
      "I0902 10:24:44.574135 139792788920128 learning.py:507] global step 45581: loss = 0.1930 (0.960 sec/step)\n",
      "I0902 10:24:45.536383 139792788920128 learning.py:507] global step 45582: loss = 0.0811 (0.960 sec/step)\n",
      "I0902 10:24:46.503153 139792788920128 learning.py:507] global step 45583: loss = 0.2127 (0.965 sec/step)\n",
      "I0902 10:24:47.467006 139792788920128 learning.py:507] global step 45584: loss = 0.1210 (0.962 sec/step)\n",
      "I0902 10:24:48.437046 139792788920128 learning.py:507] global step 45585: loss = 0.0745 (0.968 sec/step)\n",
      "I0902 10:24:49.407712 139792788920128 learning.py:507] global step 45586: loss = 0.1596 (0.969 sec/step)\n",
      "I0902 10:24:50.377814 139792788920128 learning.py:507] global step 45587: loss = 0.0969 (0.968 sec/step)\n",
      "I0902 10:24:51.363252 139792788920128 learning.py:507] global step 45588: loss = 0.0689 (0.984 sec/step)\n",
      "I0902 10:24:52.320500 139792788920128 learning.py:507] global step 45589: loss = 0.1934 (0.955 sec/step)\n",
      "I0902 10:24:53.300621 139792788920128 learning.py:507] global step 45590: loss = 0.2830 (0.978 sec/step)\n",
      "I0902 10:24:54.269516 139792788920128 learning.py:507] global step 45591: loss = 0.1062 (0.967 sec/step)\n",
      "I0902 10:24:55.229528 139792788920128 learning.py:507] global step 45592: loss = 0.0809 (0.958 sec/step)\n",
      "I0902 10:24:56.201720 139792788920128 learning.py:507] global step 45593: loss = 0.0475 (0.971 sec/step)\n",
      "I0902 10:24:57.169675 139792788920128 learning.py:507] global step 45594: loss = 0.1167 (0.966 sec/step)\n",
      "I0902 10:24:58.140858 139792788920128 learning.py:507] global step 45595: loss = 0.0668 (0.970 sec/step)\n",
      "I0902 10:24:59.124595 139792788920128 learning.py:507] global step 45596: loss = 0.0750 (0.982 sec/step)\n",
      "I0902 10:25:00.091500 139792788920128 learning.py:507] global step 45597: loss = 0.0986 (0.965 sec/step)\n",
      "I0902 10:25:01.073227 139792788920128 learning.py:507] global step 45598: loss = 0.0956 (0.980 sec/step)\n",
      "I0902 10:25:02.027252 139792788920128 learning.py:507] global step 45599: loss = 0.1315 (0.953 sec/step)\n",
      "I0902 10:25:02.990790 139792788920128 learning.py:507] global step 45600: loss = 0.1138 (0.962 sec/step)\n",
      "I0902 10:25:03.968817 139792788920128 learning.py:507] global step 45601: loss = 0.1854 (0.976 sec/step)\n",
      "I0902 10:25:04.928405 139792788920128 learning.py:507] global step 45602: loss = 0.1248 (0.958 sec/step)\n",
      "I0902 10:25:05.889427 139792788920128 learning.py:507] global step 45603: loss = 0.1837 (0.959 sec/step)\n",
      "I0902 10:25:06.865000 139792788920128 learning.py:507] global step 45604: loss = 0.2246 (0.974 sec/step)\n",
      "I0902 10:25:07.830559 139792788920128 learning.py:507] global step 45605: loss = 0.2285 (0.964 sec/step)\n",
      "I0902 10:25:08.787573 139792788920128 learning.py:507] global step 45606: loss = 0.1639 (0.955 sec/step)\n",
      "I0902 10:25:09.766867 139792788920128 learning.py:507] global step 45607: loss = 0.2888 (0.978 sec/step)\n",
      "I0902 10:25:10.724773 139792788920128 learning.py:507] global step 45608: loss = 0.0790 (0.956 sec/step)\n",
      "I0902 10:25:11.697400 139792788920128 learning.py:507] global step 45609: loss = 0.1772 (0.971 sec/step)\n",
      "I0902 10:25:12.676635 139792788920128 learning.py:507] global step 45610: loss = 0.1423 (0.978 sec/step)\n",
      "I0902 10:25:13.643488 139792788920128 learning.py:507] global step 45611: loss = 0.1122 (0.965 sec/step)\n",
      "I0902 10:25:14.609546 139792788920128 learning.py:507] global step 45612: loss = 0.2564 (0.965 sec/step)\n",
      "I0902 10:25:15.578597 139792788920128 learning.py:507] global step 45613: loss = 0.1466 (0.968 sec/step)\n",
      "I0902 10:25:16.551132 139792788920128 learning.py:507] global step 45614: loss = 0.1278 (0.971 sec/step)\n",
      "I0902 10:25:17.521033 139792788920128 learning.py:507] global step 45615: loss = 0.1370 (0.968 sec/step)\n",
      "I0902 10:25:18.505242 139792788920128 learning.py:507] global step 45616: loss = 0.1655 (0.983 sec/step)\n",
      "I0902 10:25:19.486293 139792788920128 learning.py:507] global step 45617: loss = 0.1643 (0.979 sec/step)\n",
      "I0902 10:25:20.465079 139792788920128 learning.py:507] global step 45618: loss = 0.0587 (0.977 sec/step)\n",
      "I0902 10:25:21.457333 139792788920128 learning.py:507] global step 45619: loss = 0.1070 (0.991 sec/step)\n",
      "I0902 10:25:22.424375 139792788920128 learning.py:507] global step 45620: loss = 0.1296 (0.965 sec/step)\n",
      "I0902 10:25:23.389911 139792788920128 learning.py:507] global step 45621: loss = 0.0733 (0.964 sec/step)\n",
      "I0902 10:25:24.337541 139792788920128 learning.py:507] global step 45622: loss = 0.0926 (0.946 sec/step)\n",
      "I0902 10:25:25.299289 139792788920128 learning.py:507] global step 45623: loss = 0.0861 (0.960 sec/step)\n",
      "I0902 10:25:26.260844 139792788920128 learning.py:507] global step 45624: loss = 0.1541 (0.960 sec/step)\n",
      "I0902 10:25:27.221573 139792788920128 learning.py:507] global step 45625: loss = 0.0928 (0.959 sec/step)\n",
      "I0902 10:25:28.176025 139792788920128 learning.py:507] global step 45626: loss = 0.2342 (0.953 sec/step)\n",
      "I0902 10:25:29.153727 139792788920128 learning.py:507] global step 45627: loss = 0.1554 (0.976 sec/step)\n",
      "I0902 10:25:30.117225 139792788920128 learning.py:507] global step 45628: loss = 0.0948 (0.962 sec/step)\n",
      "I0902 10:25:31.095302 139792788920128 learning.py:507] global step 45629: loss = 0.1742 (0.976 sec/step)\n",
      "I0902 10:25:32.055926 139792788920128 learning.py:507] global step 45630: loss = 0.0777 (0.959 sec/step)\n",
      "I0902 10:25:33.012990 139792788920128 learning.py:507] global step 45631: loss = 0.0917 (0.955 sec/step)\n",
      "I0902 10:25:33.978757 139792788920128 learning.py:507] global step 45632: loss = 0.0885 (0.964 sec/step)\n",
      "I0902 10:25:34.962686 139792788920128 learning.py:507] global step 45633: loss = 0.1256 (0.982 sec/step)\n",
      "I0902 10:25:35.940948 139792788920128 learning.py:507] global step 45634: loss = 0.0972 (0.976 sec/step)\n",
      "I0902 10:25:36.899990 139792788920128 learning.py:507] global step 45635: loss = 0.0859 (0.957 sec/step)\n",
      "I0902 10:25:37.860379 139792788920128 learning.py:507] global step 45636: loss = 0.1409 (0.959 sec/step)\n",
      "I0902 10:25:38.820341 139792788920128 learning.py:507] global step 45637: loss = 0.1884 (0.959 sec/step)\n",
      "I0902 10:25:39.803232 139792788920128 learning.py:507] global step 45638: loss = 0.1565 (0.982 sec/step)\n",
      "I0902 10:25:40.766705 139792788920128 learning.py:507] global step 45639: loss = 0.1062 (0.962 sec/step)\n",
      "I0902 10:25:41.735213 139792788920128 learning.py:507] global step 45640: loss = 0.1081 (0.967 sec/step)\n",
      "I0902 10:25:42.714146 139792788920128 learning.py:507] global step 45641: loss = 0.1239 (0.977 sec/step)\n",
      "I0902 10:25:43.692717 139792788920128 learning.py:507] global step 45642: loss = 0.1235 (0.977 sec/step)\n",
      "I0902 10:25:44.650619 139792788920128 learning.py:507] global step 45643: loss = 0.0982 (0.956 sec/step)\n",
      "I0902 10:25:45.626246 139792788920128 learning.py:507] global step 45644: loss = 0.2091 (0.974 sec/step)\n",
      "I0902 10:25:46.595546 139792788920128 learning.py:507] global step 45645: loss = 0.0705 (0.968 sec/step)\n",
      "I0902 10:25:47.571975 139792788920128 learning.py:507] global step 45646: loss = 0.1361 (0.975 sec/step)\n",
      "I0902 10:25:48.553840 139792788920128 learning.py:507] global step 45647: loss = 0.0980 (0.980 sec/step)\n",
      "I0902 10:25:49.516802 139792788920128 learning.py:507] global step 45648: loss = 0.1206 (0.948 sec/step)\n",
      "I0902 10:25:50.170590 139778936784640 supervisor.py:1050] Recording summary at step 45648.\n",
      "I0902 10:25:50.779609 139792788920128 learning.py:507] global step 45649: loss = 0.1050 (1.261 sec/step)\n",
      "I0902 10:25:51.735562 139792788920128 learning.py:507] global step 45650: loss = 0.0347 (0.954 sec/step)\n",
      "I0902 10:25:52.688956 139792788920128 learning.py:507] global step 45651: loss = 0.1726 (0.952 sec/step)\n",
      "I0902 10:25:53.655986 139792788920128 learning.py:507] global step 45652: loss = 0.0607 (0.965 sec/step)\n",
      "I0902 10:25:54.604091 139792788920128 learning.py:507] global step 45653: loss = 0.0975 (0.947 sec/step)\n",
      "I0902 10:25:55.580585 139792788920128 learning.py:507] global step 45654: loss = 0.1265 (0.975 sec/step)\n",
      "I0902 10:25:56.543766 139792788920128 learning.py:507] global step 45655: loss = 0.1588 (0.961 sec/step)\n",
      "I0902 10:25:57.507115 139792788920128 learning.py:507] global step 45656: loss = 0.0834 (0.962 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:25:58.452279 139792788920128 learning.py:507] global step 45657: loss = 0.1364 (0.944 sec/step)\n",
      "I0902 10:25:59.408257 139792788920128 learning.py:507] global step 45658: loss = 0.0835 (0.954 sec/step)\n",
      "I0902 10:26:00.371489 139792788920128 learning.py:507] global step 45659: loss = 0.1891 (0.962 sec/step)\n",
      "I0902 10:26:01.349498 139792788920128 learning.py:507] global step 45660: loss = 0.0697 (0.976 sec/step)\n",
      "I0902 10:26:02.320064 139792788920128 learning.py:507] global step 45661: loss = 0.2199 (0.969 sec/step)\n",
      "I0902 10:26:03.296574 139792788920128 learning.py:507] global step 45662: loss = 0.1322 (0.975 sec/step)\n",
      "I0902 10:26:04.271929 139792788920128 learning.py:507] global step 45663: loss = 0.1089 (0.974 sec/step)\n",
      "I0902 10:26:05.229459 139792788920128 learning.py:507] global step 45664: loss = 0.0808 (0.956 sec/step)\n",
      "I0902 10:26:06.202134 139792788920128 learning.py:507] global step 45665: loss = 0.1448 (0.971 sec/step)\n",
      "I0902 10:26:07.165456 139792788920128 learning.py:507] global step 45666: loss = 0.0910 (0.962 sec/step)\n",
      "I0902 10:26:08.125583 139792788920128 learning.py:507] global step 45667: loss = 0.1958 (0.958 sec/step)\n",
      "I0902 10:26:09.083665 139792788920128 learning.py:507] global step 45668: loss = 0.1148 (0.956 sec/step)\n",
      "I0902 10:26:10.050671 139792788920128 learning.py:507] global step 45669: loss = 0.1283 (0.965 sec/step)\n",
      "I0902 10:26:11.023867 139792788920128 learning.py:507] global step 45670: loss = 0.1214 (0.971 sec/step)\n",
      "I0902 10:26:11.976571 139792788920128 learning.py:507] global step 45671: loss = 0.1613 (0.951 sec/step)\n",
      "I0902 10:26:12.958570 139792788920128 learning.py:507] global step 45672: loss = 0.1446 (0.980 sec/step)\n",
      "I0902 10:26:13.919344 139792788920128 learning.py:507] global step 45673: loss = 0.1060 (0.959 sec/step)\n",
      "I0902 10:26:14.894102 139792788920128 learning.py:507] global step 45674: loss = 0.0814 (0.973 sec/step)\n",
      "I0902 10:26:15.871451 139792788920128 learning.py:507] global step 45675: loss = 0.1048 (0.975 sec/step)\n",
      "I0902 10:26:16.846448 139792788920128 learning.py:507] global step 45676: loss = 0.1429 (0.973 sec/step)\n",
      "I0902 10:26:17.799520 139792788920128 learning.py:507] global step 45677: loss = 0.1890 (0.951 sec/step)\n",
      "I0902 10:26:18.774137 139792788920128 learning.py:507] global step 45678: loss = 0.1046 (0.973 sec/step)\n",
      "I0902 10:26:19.732143 139792788920128 learning.py:507] global step 45679: loss = 0.1253 (0.956 sec/step)\n",
      "I0902 10:26:20.721049 139792788920128 learning.py:507] global step 45680: loss = 0.2068 (0.988 sec/step)\n",
      "I0902 10:26:21.694762 139792788920128 learning.py:507] global step 45681: loss = 0.0905 (0.972 sec/step)\n",
      "I0902 10:26:22.654570 139792788920128 learning.py:507] global step 45682: loss = 0.1258 (0.958 sec/step)\n",
      "I0902 10:26:23.597251 139792788920128 learning.py:507] global step 45683: loss = 0.1003 (0.941 sec/step)\n",
      "I0902 10:26:24.567083 139792788920128 learning.py:507] global step 45684: loss = 0.1835 (0.968 sec/step)\n",
      "I0902 10:26:25.526240 139792788920128 learning.py:507] global step 45685: loss = 0.0498 (0.958 sec/step)\n",
      "I0902 10:26:26.489168 139792788920128 learning.py:507] global step 45686: loss = 0.0807 (0.961 sec/step)\n",
      "I0902 10:26:27.447465 139792788920128 learning.py:507] global step 45687: loss = 0.1265 (0.956 sec/step)\n",
      "I0902 10:26:28.415155 139792788920128 learning.py:507] global step 45688: loss = 0.0799 (0.966 sec/step)\n",
      "I0902 10:26:29.387261 139792788920128 learning.py:507] global step 45689: loss = 0.0628 (0.971 sec/step)\n",
      "I0902 10:26:30.353390 139792788920128 learning.py:507] global step 45690: loss = 0.1596 (0.964 sec/step)\n",
      "I0902 10:26:31.328001 139792788920128 learning.py:507] global step 45691: loss = 0.1215 (0.973 sec/step)\n",
      "I0902 10:26:32.305505 139792788920128 learning.py:507] global step 45692: loss = 0.1550 (0.976 sec/step)\n",
      "I0902 10:26:33.278768 139792788920128 learning.py:507] global step 45693: loss = 0.1995 (0.972 sec/step)\n",
      "I0902 10:26:34.247018 139792788920128 learning.py:507] global step 45694: loss = 0.1167 (0.967 sec/step)\n",
      "I0902 10:26:35.245749 139792788920128 learning.py:507] global step 45695: loss = 0.0797 (0.997 sec/step)\n",
      "I0902 10:26:36.204803 139792788920128 learning.py:507] global step 45696: loss = 0.0996 (0.957 sec/step)\n",
      "I0902 10:26:37.170824 139792788920128 learning.py:507] global step 45697: loss = 0.0945 (0.964 sec/step)\n",
      "I0902 10:26:38.137306 139792788920128 learning.py:507] global step 45698: loss = 0.0774 (0.965 sec/step)\n",
      "I0902 10:26:39.091005 139792788920128 learning.py:507] global step 45699: loss = 0.0831 (0.952 sec/step)\n",
      "I0902 10:26:40.043583 139792788920128 learning.py:507] global step 45700: loss = 0.2073 (0.951 sec/step)\n",
      "I0902 10:26:41.003467 139792788920128 learning.py:507] global step 45701: loss = 0.1032 (0.958 sec/step)\n",
      "I0902 10:26:41.966475 139792788920128 learning.py:507] global step 45702: loss = 0.1650 (0.961 sec/step)\n",
      "I0902 10:26:42.928929 139792788920128 learning.py:507] global step 45703: loss = 0.1293 (0.961 sec/step)\n",
      "I0902 10:26:43.885450 139792788920128 learning.py:507] global step 45704: loss = 0.1429 (0.955 sec/step)\n",
      "I0902 10:26:44.861533 139792788920128 learning.py:507] global step 45705: loss = 0.0992 (0.974 sec/step)\n",
      "I0902 10:26:45.831999 139792788920128 learning.py:507] global step 45706: loss = 0.1183 (0.969 sec/step)\n",
      "I0902 10:26:46.784215 139792788920128 learning.py:507] global step 45707: loss = 0.1535 (0.951 sec/step)\n",
      "I0902 10:26:47.757522 139792788920128 learning.py:507] global step 45708: loss = 0.0867 (0.972 sec/step)\n",
      "I0902 10:26:48.733697 139792788920128 learning.py:507] global step 45709: loss = 0.1263 (0.975 sec/step)\n",
      "I0902 10:26:49.680209 139792788920128 learning.py:507] global step 45710: loss = 0.1019 (0.945 sec/step)\n",
      "I0902 10:26:50.652042 139792788920128 learning.py:507] global step 45711: loss = 0.0681 (0.970 sec/step)\n",
      "I0902 10:26:51.654754 139792788920128 learning.py:507] global step 45712: loss = 0.1095 (1.001 sec/step)\n",
      "I0902 10:26:52.628492 139792788920128 learning.py:507] global step 45713: loss = 0.0459 (0.972 sec/step)\n",
      "I0902 10:26:53.578464 139792788920128 learning.py:507] global step 45714: loss = 0.1337 (0.948 sec/step)\n",
      "I0902 10:26:54.538520 139792788920128 learning.py:507] global step 45715: loss = 0.1102 (0.958 sec/step)\n",
      "I0902 10:26:55.507969 139792788920128 learning.py:507] global step 45716: loss = 0.2653 (0.968 sec/step)\n",
      "I0902 10:26:56.499285 139792788920128 learning.py:507] global step 45717: loss = 0.0962 (0.990 sec/step)\n",
      "I0902 10:26:57.466564 139792788920128 learning.py:507] global step 45718: loss = 0.1228 (0.966 sec/step)\n",
      "I0902 10:26:58.436298 139792788920128 learning.py:507] global step 45719: loss = 0.0681 (0.968 sec/step)\n",
      "I0902 10:26:59.404564 139792788920128 learning.py:507] global step 45720: loss = 0.1670 (0.966 sec/step)\n",
      "I0902 10:27:00.370349 139792788920128 learning.py:507] global step 45721: loss = 0.0943 (0.964 sec/step)\n",
      "I0902 10:27:01.331785 139792788920128 learning.py:507] global step 45722: loss = 0.1422 (0.960 sec/step)\n",
      "I0902 10:27:02.303926 139792788920128 learning.py:507] global step 45723: loss = 0.1402 (0.970 sec/step)\n",
      "I0902 10:27:03.270310 139792788920128 learning.py:507] global step 45724: loss = 0.0607 (0.965 sec/step)\n",
      "I0902 10:27:04.228019 139792788920128 learning.py:507] global step 45725: loss = 0.1304 (0.956 sec/step)\n",
      "I0902 10:27:05.192926 139792788920128 learning.py:507] global step 45726: loss = 0.3662 (0.963 sec/step)\n",
      "I0902 10:27:06.159410 139792788920128 learning.py:507] global step 45727: loss = 0.1433 (0.965 sec/step)\n",
      "I0902 10:27:07.131974 139792788920128 learning.py:507] global step 45728: loss = 0.1225 (0.971 sec/step)\n",
      "I0902 10:27:08.091681 139792788920128 learning.py:507] global step 45729: loss = 0.0997 (0.958 sec/step)\n",
      "I0902 10:27:09.056735 139792788920128 learning.py:507] global step 45730: loss = 0.2040 (0.963 sec/step)\n",
      "I0902 10:27:10.024633 139792788920128 learning.py:507] global step 45731: loss = 0.1377 (0.966 sec/step)\n",
      "I0902 10:27:11.002611 139792788920128 learning.py:507] global step 45732: loss = 0.0954 (0.976 sec/step)\n",
      "I0902 10:27:11.961735 139792788920128 learning.py:507] global step 45733: loss = 0.1001 (0.957 sec/step)\n",
      "I0902 10:27:12.930466 139792788920128 learning.py:507] global step 45734: loss = 0.0985 (0.967 sec/step)\n",
      "I0902 10:27:13.914973 139792788920128 learning.py:507] global step 45735: loss = 0.0809 (0.983 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:27:14.877143 139792788920128 learning.py:507] global step 45736: loss = 0.2294 (0.961 sec/step)\n",
      "I0902 10:27:15.841167 139792788920128 learning.py:507] global step 45737: loss = 0.0398 (0.962 sec/step)\n",
      "I0902 10:27:16.823723 139792788920128 learning.py:507] global step 45738: loss = 0.1404 (0.981 sec/step)\n",
      "I0902 10:27:17.792677 139792788920128 learning.py:507] global step 45739: loss = 0.0481 (0.967 sec/step)\n",
      "I0902 10:27:18.773417 139792788920128 learning.py:507] global step 45740: loss = 0.0757 (0.979 sec/step)\n",
      "I0902 10:27:19.748474 139792788920128 learning.py:507] global step 45741: loss = 0.1060 (0.974 sec/step)\n",
      "I0902 10:27:20.722283 139792788920128 learning.py:507] global step 45742: loss = 0.1051 (0.972 sec/step)\n",
      "I0902 10:27:21.671828 139792788920128 learning.py:507] global step 45743: loss = 0.0661 (0.948 sec/step)\n",
      "I0902 10:27:22.634606 139792788920128 learning.py:507] global step 45744: loss = 0.1398 (0.961 sec/step)\n",
      "I0902 10:27:23.601897 139792788920128 learning.py:507] global step 45745: loss = 0.1547 (0.966 sec/step)\n",
      "I0902 10:27:24.581328 139792788920128 learning.py:507] global step 45746: loss = 0.0979 (0.978 sec/step)\n",
      "I0902 10:27:25.553072 139792788920128 learning.py:507] global step 45747: loss = 0.0914 (0.970 sec/step)\n",
      "I0902 10:27:26.500802 139792788920128 learning.py:507] global step 45748: loss = 0.0613 (0.946 sec/step)\n",
      "I0902 10:27:27.458610 139792788920128 learning.py:507] global step 45749: loss = 0.1440 (0.956 sec/step)\n",
      "I0902 10:27:28.438219 139792788920128 learning.py:507] global step 45750: loss = 0.1052 (0.978 sec/step)\n",
      "I0902 10:27:29.401412 139792788920128 learning.py:507] global step 45751: loss = 0.1350 (0.962 sec/step)\n",
      "I0902 10:27:30.381838 139792788920128 learning.py:507] global step 45752: loss = 0.1036 (0.979 sec/step)\n",
      "I0902 10:27:31.344559 139792788920128 learning.py:507] global step 45753: loss = 0.1238 (0.961 sec/step)\n",
      "I0902 10:27:32.340154 139792788920128 learning.py:507] global step 45754: loss = 0.1152 (0.994 sec/step)\n",
      "I0902 10:27:33.314057 139792788920128 learning.py:507] global step 45755: loss = 0.1247 (0.972 sec/step)\n",
      "I0902 10:27:34.282807 139792788920128 learning.py:507] global step 45756: loss = 0.1298 (0.967 sec/step)\n",
      "I0902 10:27:35.245304 139792788920128 learning.py:507] global step 45757: loss = 0.1152 (0.961 sec/step)\n",
      "I0902 10:27:36.220390 139792788920128 learning.py:507] global step 45758: loss = 0.0941 (0.973 sec/step)\n",
      "I0902 10:27:37.214192 139792788920128 learning.py:507] global step 45759: loss = 0.0843 (0.992 sec/step)\n",
      "I0902 10:27:38.179681 139792788920128 learning.py:507] global step 45760: loss = 0.0838 (0.964 sec/step)\n",
      "I0902 10:27:39.136790 139792788920128 learning.py:507] global step 45761: loss = 0.2042 (0.955 sec/step)\n",
      "I0902 10:27:40.110585 139792788920128 learning.py:507] global step 45762: loss = 0.1860 (0.972 sec/step)\n",
      "I0902 10:27:41.087306 139792788920128 learning.py:507] global step 45763: loss = 0.0989 (0.975 sec/step)\n",
      "I0902 10:27:42.063702 139792788920128 learning.py:507] global step 45764: loss = 0.1100 (0.975 sec/step)\n",
      "I0902 10:27:43.034473 139792788920128 learning.py:507] global step 45765: loss = 0.1932 (0.969 sec/step)\n",
      "I0902 10:27:43.999157 139792788920128 learning.py:507] global step 45766: loss = 0.0691 (0.963 sec/step)\n",
      "I0902 10:27:44.969654 139792788920128 learning.py:507] global step 45767: loss = 0.0782 (0.969 sec/step)\n",
      "I0902 10:27:45.934378 139792788920128 learning.py:507] global step 45768: loss = 0.1485 (0.963 sec/step)\n",
      "I0902 10:27:46.883864 139792788920128 learning.py:507] global step 45769: loss = 0.1085 (0.948 sec/step)\n",
      "I0902 10:27:47.838165 139792788920128 learning.py:507] global step 45770: loss = 0.1795 (0.953 sec/step)\n",
      "I0902 10:27:48.789518 139792788920128 learning.py:507] global step 45771: loss = 0.0857 (0.950 sec/step)\n",
      "I0902 10:27:49.895812 139792788920128 learning.py:507] global step 45772: loss = 0.1592 (1.099 sec/step)\n",
      "I0902 10:27:50.073387 139778936784640 supervisor.py:1050] Recording summary at step 45772.\n",
      "I0902 10:27:50.992210 139792788920128 learning.py:507] global step 45773: loss = 0.0623 (1.092 sec/step)\n",
      "I0902 10:27:51.948128 139792788920128 learning.py:507] global step 45774: loss = 0.1662 (0.954 sec/step)\n",
      "I0902 10:27:52.905867 139792788920128 learning.py:507] global step 45775: loss = 0.0704 (0.956 sec/step)\n",
      "I0902 10:27:53.881615 139792788920128 learning.py:507] global step 45776: loss = 0.4224 (0.974 sec/step)\n",
      "I0902 10:27:54.871736 139792788920128 learning.py:507] global step 45777: loss = 0.1011 (0.988 sec/step)\n",
      "I0902 10:27:55.844488 139792788920128 learning.py:507] global step 45778: loss = 0.0920 (0.971 sec/step)\n",
      "I0902 10:27:56.828207 139792788920128 learning.py:507] global step 45779: loss = 0.0700 (0.982 sec/step)\n",
      "I0902 10:27:57.809977 139792788920128 learning.py:507] global step 45780: loss = 0.1189 (0.980 sec/step)\n",
      "I0902 10:27:58.769677 139792788920128 learning.py:507] global step 45781: loss = 0.1550 (0.958 sec/step)\n",
      "I0902 10:27:59.732965 139792788920128 learning.py:507] global step 45782: loss = 0.1539 (0.962 sec/step)\n",
      "I0902 10:28:00.712778 139792788920128 learning.py:507] global step 45783: loss = 0.1376 (0.978 sec/step)\n",
      "I0902 10:28:01.671325 139792788920128 learning.py:507] global step 45784: loss = 0.1117 (0.957 sec/step)\n",
      "I0902 10:28:02.636775 139792788920128 learning.py:507] global step 45785: loss = 0.1841 (0.964 sec/step)\n",
      "I0902 10:28:03.593218 139792788920128 learning.py:507] global step 45786: loss = 0.0972 (0.955 sec/step)\n",
      "I0902 10:28:04.563687 139792788920128 learning.py:507] global step 45787: loss = 0.0600 (0.969 sec/step)\n",
      "I0902 10:28:05.526721 139792788920128 learning.py:507] global step 45788: loss = 0.1980 (0.961 sec/step)\n",
      "I0902 10:28:06.491702 139792788920128 learning.py:507] global step 45789: loss = 0.0591 (0.963 sec/step)\n",
      "I0902 10:28:07.462453 139792788920128 learning.py:507] global step 45790: loss = 0.0385 (0.969 sec/step)\n",
      "I0902 10:28:08.420173 139792788920128 learning.py:507] global step 45791: loss = 0.1461 (0.956 sec/step)\n",
      "I0902 10:28:09.371132 139792788920128 learning.py:507] global step 45792: loss = 0.0514 (0.949 sec/step)\n",
      "I0902 10:28:10.339714 139792788920128 learning.py:507] global step 45793: loss = 0.2963 (0.967 sec/step)\n",
      "I0902 10:28:11.313218 139792788920128 learning.py:507] global step 45794: loss = 0.1043 (0.972 sec/step)\n",
      "I0902 10:28:12.268050 139792788920128 learning.py:507] global step 45795: loss = 0.0763 (0.953 sec/step)\n",
      "I0902 10:28:13.234288 139792788920128 learning.py:507] global step 45796: loss = 0.1032 (0.964 sec/step)\n",
      "I0902 10:28:14.223983 139792788920128 learning.py:507] global step 45797: loss = 0.0749 (0.988 sec/step)\n",
      "I0902 10:28:15.202482 139792788920128 learning.py:507] global step 45798: loss = 0.1136 (0.977 sec/step)\n",
      "I0902 10:28:16.160211 139792788920128 learning.py:507] global step 45799: loss = 0.0991 (0.956 sec/step)\n",
      "I0902 10:28:17.133260 139792788920128 learning.py:507] global step 45800: loss = 0.1236 (0.971 sec/step)\n",
      "I0902 10:28:18.100948 139792788920128 learning.py:507] global step 45801: loss = 0.1186 (0.966 sec/step)\n",
      "I0902 10:28:19.065752 139792788920128 learning.py:507] global step 45802: loss = 0.1500 (0.963 sec/step)\n",
      "I0902 10:28:20.045519 139792788920128 learning.py:507] global step 45803: loss = 0.0954 (0.978 sec/step)\n",
      "I0902 10:28:21.020004 139792788920128 learning.py:507] global step 45804: loss = 0.1365 (0.973 sec/step)\n",
      "I0902 10:28:21.975206 139792788920128 learning.py:507] global step 45805: loss = 0.0578 (0.953 sec/step)\n",
      "I0902 10:28:22.942140 139792788920128 learning.py:507] global step 45806: loss = 0.1388 (0.965 sec/step)\n",
      "I0902 10:28:23.902611 139792788920128 learning.py:507] global step 45807: loss = 0.0527 (0.959 sec/step)\n",
      "I0902 10:28:24.865975 139792788920128 learning.py:507] global step 45808: loss = 0.1310 (0.962 sec/step)\n",
      "I0902 10:28:25.822650 139792788920128 learning.py:507] global step 45809: loss = 0.2127 (0.955 sec/step)\n",
      "I0902 10:28:26.790047 139792788920128 learning.py:507] global step 45810: loss = 0.1107 (0.966 sec/step)\n",
      "I0902 10:28:27.736000 139792788920128 learning.py:507] global step 45811: loss = 0.0885 (0.944 sec/step)\n",
      "I0902 10:28:28.703034 139792788920128 learning.py:507] global step 45812: loss = 0.1046 (0.965 sec/step)\n",
      "I0902 10:28:29.673101 139792788920128 learning.py:507] global step 45813: loss = 0.1039 (0.968 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:28:30.634550 139792788920128 learning.py:507] global step 45814: loss = 0.0589 (0.960 sec/step)\n",
      "I0902 10:28:31.604733 139792788920128 learning.py:507] global step 45815: loss = 0.1297 (0.969 sec/step)\n",
      "I0902 10:28:32.574520 139792788920128 learning.py:507] global step 45816: loss = 0.1752 (0.968 sec/step)\n",
      "I0902 10:28:33.537900 139792788920128 learning.py:507] global step 45817: loss = 0.0936 (0.962 sec/step)\n",
      "I0902 10:28:34.500743 139792788920128 learning.py:507] global step 45818: loss = 0.1747 (0.961 sec/step)\n",
      "I0902 10:28:35.487876 139792788920128 learning.py:507] global step 45819: loss = 0.2812 (0.985 sec/step)\n",
      "I0902 10:28:36.470302 139792788920128 learning.py:507] global step 45820: loss = 0.1137 (0.981 sec/step)\n",
      "I0902 10:28:37.456119 139792788920128 learning.py:507] global step 45821: loss = 0.1436 (0.984 sec/step)\n",
      "I0902 10:28:38.420269 139792788920128 learning.py:507] global step 45822: loss = 0.1774 (0.962 sec/step)\n",
      "I0902 10:28:39.377133 139792788920128 learning.py:507] global step 45823: loss = 0.1159 (0.955 sec/step)\n",
      "I0902 10:28:40.367206 139792788920128 learning.py:507] global step 45824: loss = 0.0644 (0.988 sec/step)\n",
      "I0902 10:28:41.334329 139792788920128 learning.py:507] global step 45825: loss = 0.1264 (0.965 sec/step)\n",
      "I0902 10:28:42.300030 139792788920128 learning.py:507] global step 45826: loss = 0.0717 (0.964 sec/step)\n",
      "I0902 10:28:43.251905 139792788920128 learning.py:507] global step 45827: loss = 0.0974 (0.950 sec/step)\n",
      "I0902 10:28:44.229473 139792788920128 learning.py:507] global step 45828: loss = 0.0660 (0.976 sec/step)\n",
      "I0902 10:28:45.209491 139792788920128 learning.py:507] global step 45829: loss = 0.1668 (0.978 sec/step)\n",
      "I0902 10:28:46.163749 139792788920128 learning.py:507] global step 45830: loss = 0.2318 (0.953 sec/step)\n",
      "I0902 10:28:47.142050 139792788920128 learning.py:507] global step 45831: loss = 0.1135 (0.977 sec/step)\n",
      "I0902 10:28:48.107453 139792788920128 learning.py:507] global step 45832: loss = 0.0658 (0.964 sec/step)\n",
      "I0902 10:28:49.053952 139792788920128 learning.py:507] global step 45833: loss = 0.1270 (0.945 sec/step)\n",
      "I0902 10:28:50.017542 139792788920128 learning.py:507] global step 45834: loss = 0.1292 (0.962 sec/step)\n",
      "I0902 10:28:50.979802 139792788920128 learning.py:507] global step 45835: loss = 0.1311 (0.961 sec/step)\n",
      "I0902 10:28:51.961345 139792788920128 learning.py:507] global step 45836: loss = 0.1396 (0.980 sec/step)\n",
      "I0902 10:28:52.919725 139792788920128 learning.py:507] global step 45837: loss = 0.1607 (0.957 sec/step)\n",
      "I0902 10:28:53.893123 139792788920128 learning.py:507] global step 45838: loss = 0.1350 (0.972 sec/step)\n",
      "I0902 10:28:54.870411 139792788920128 learning.py:507] global step 45839: loss = 0.2083 (0.976 sec/step)\n",
      "I0902 10:28:55.822538 139792788920128 learning.py:507] global step 45840: loss = 0.0917 (0.951 sec/step)\n",
      "I0902 10:28:56.796867 139792788920128 learning.py:507] global step 45841: loss = 0.0596 (0.973 sec/step)\n",
      "I0902 10:28:57.773948 139792788920128 learning.py:507] global step 45842: loss = 0.0968 (0.975 sec/step)\n",
      "I0902 10:28:58.741978 139792788920128 learning.py:507] global step 45843: loss = 0.0668 (0.967 sec/step)\n",
      "I0902 10:28:59.688071 139792788920128 learning.py:507] global step 45844: loss = 0.0621 (0.945 sec/step)\n",
      "I0902 10:29:00.657262 139792788920128 learning.py:507] global step 45845: loss = 0.1034 (0.967 sec/step)\n",
      "I0902 10:29:01.615535 139792788920128 learning.py:507] global step 45846: loss = 0.0562 (0.957 sec/step)\n",
      "I0902 10:29:02.584015 139792788920128 learning.py:507] global step 45847: loss = 0.0819 (0.967 sec/step)\n",
      "I0902 10:29:03.546300 139792788920128 learning.py:507] global step 45848: loss = 0.1194 (0.960 sec/step)\n",
      "I0902 10:29:04.514760 139792788920128 learning.py:507] global step 45849: loss = 0.0591 (0.967 sec/step)\n",
      "I0902 10:29:05.479622 139792788920128 learning.py:507] global step 45850: loss = 0.2399 (0.963 sec/step)\n",
      "I0902 10:29:06.457099 139792788920128 learning.py:507] global step 45851: loss = 0.0981 (0.976 sec/step)\n",
      "I0902 10:29:07.430191 139792788920128 learning.py:507] global step 45852: loss = 0.1040 (0.972 sec/step)\n",
      "I0902 10:29:08.417816 139792788920128 learning.py:507] global step 45853: loss = 0.0903 (0.986 sec/step)\n",
      "I0902 10:29:09.382730 139792788920128 learning.py:507] global step 45854: loss = 0.1431 (0.963 sec/step)\n",
      "I0902 10:29:10.336836 139792788920128 learning.py:507] global step 45855: loss = 0.1004 (0.952 sec/step)\n",
      "I0902 10:29:11.300578 139792788920128 learning.py:507] global step 45856: loss = 0.2116 (0.962 sec/step)\n",
      "I0902 10:29:12.301880 139792788920128 learning.py:507] global step 45857: loss = 0.0484 (1.000 sec/step)\n",
      "I0902 10:29:13.270603 139792788920128 learning.py:507] global step 45858: loss = 0.1042 (0.967 sec/step)\n",
      "I0902 10:29:14.241059 139792788920128 learning.py:507] global step 45859: loss = 0.1182 (0.969 sec/step)\n",
      "I0902 10:29:15.207479 139792788920128 learning.py:507] global step 45860: loss = 0.1356 (0.965 sec/step)\n",
      "I0902 10:29:16.181186 139792788920128 learning.py:507] global step 45861: loss = 0.1152 (0.972 sec/step)\n",
      "I0902 10:29:17.138040 139792788920128 learning.py:507] global step 45862: loss = 0.0833 (0.955 sec/step)\n",
      "I0902 10:29:18.086356 139792788920128 learning.py:507] global step 45863: loss = 0.1398 (0.947 sec/step)\n",
      "I0902 10:29:19.066395 139792788920128 learning.py:507] global step 45864: loss = 0.1874 (0.978 sec/step)\n",
      "I0902 10:29:20.043113 139792788920128 learning.py:507] global step 45865: loss = 0.0778 (0.975 sec/step)\n",
      "I0902 10:29:21.015154 139792788920128 learning.py:507] global step 45866: loss = 0.1281 (0.971 sec/step)\n",
      "I0902 10:29:21.973213 139792788920128 learning.py:507] global step 45867: loss = 0.0566 (0.956 sec/step)\n",
      "I0902 10:29:22.937338 139792788920128 learning.py:507] global step 45868: loss = 0.0870 (0.962 sec/step)\n",
      "I0902 10:29:23.911229 139792788920128 learning.py:507] global step 45869: loss = 0.1082 (0.972 sec/step)\n",
      "I0902 10:29:24.875926 139792788920128 learning.py:507] global step 45870: loss = 0.0659 (0.963 sec/step)\n",
      "I0902 10:29:25.835294 139792788920128 learning.py:507] global step 45871: loss = 0.0832 (0.958 sec/step)\n",
      "I0902 10:29:26.789484 139792788920128 learning.py:507] global step 45872: loss = 0.1281 (0.953 sec/step)\n",
      "I0902 10:29:27.762724 139792788920128 learning.py:507] global step 45873: loss = 0.0806 (0.972 sec/step)\n",
      "I0902 10:29:28.731456 139792788920128 learning.py:507] global step 45874: loss = 0.0859 (0.967 sec/step)\n",
      "I0902 10:29:29.709741 139792788920128 learning.py:507] global step 45875: loss = 0.3378 (0.977 sec/step)\n",
      "I0902 10:29:30.670879 139792788920128 learning.py:507] global step 45876: loss = 0.0695 (0.960 sec/step)\n",
      "I0902 10:29:31.626778 139792788920128 learning.py:507] global step 45877: loss = 0.0776 (0.954 sec/step)\n",
      "I0902 10:29:32.582262 139792788920128 learning.py:507] global step 45878: loss = 0.2163 (0.954 sec/step)\n",
      "I0902 10:29:33.545234 139792788920128 learning.py:507] global step 45879: loss = 0.0791 (0.961 sec/step)\n",
      "I0902 10:29:34.526184 139792788920128 learning.py:507] global step 45880: loss = 0.0553 (0.979 sec/step)\n",
      "I0902 10:29:35.518061 139792788920128 learning.py:507] global step 45881: loss = 0.0470 (0.990 sec/step)\n",
      "I0902 10:29:36.490887 139792788920128 learning.py:507] global step 45882: loss = 0.1360 (0.971 sec/step)\n",
      "I0902 10:29:37.445696 139792788920128 learning.py:507] global step 45883: loss = 0.1709 (0.953 sec/step)\n",
      "I0902 10:29:38.390421 139792788920128 learning.py:507] global step 45884: loss = 0.1795 (0.943 sec/step)\n",
      "I0902 10:29:39.361780 139792788920128 learning.py:507] global step 45885: loss = 0.1820 (0.970 sec/step)\n",
      "I0902 10:29:40.338308 139792788920128 learning.py:507] global step 45886: loss = 0.0941 (0.975 sec/step)\n",
      "I0902 10:29:41.316899 139792788920128 learning.py:507] global step 45887: loss = 0.0900 (0.977 sec/step)\n",
      "I0902 10:29:42.279558 139792788920128 learning.py:507] global step 45888: loss = 0.1519 (0.961 sec/step)\n",
      "I0902 10:29:43.265194 139792788920128 learning.py:507] global step 45889: loss = 0.1560 (0.984 sec/step)\n",
      "I0902 10:29:44.232546 139792788920128 learning.py:507] global step 45890: loss = 0.0821 (0.966 sec/step)\n",
      "I0902 10:29:45.217615 139792788920128 learning.py:507] global step 45891: loss = 0.0980 (0.984 sec/step)\n",
      "I0902 10:29:46.211528 139792788920128 learning.py:507] global step 45892: loss = 0.0888 (0.992 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:29:47.175409 139792788920128 learning.py:507] global step 45893: loss = 0.1337 (0.962 sec/step)\n",
      "I0902 10:29:48.126898 139792788920128 learning.py:507] global step 45894: loss = 0.0720 (0.950 sec/step)\n",
      "I0902 10:29:49.111665 139792788920128 learning.py:507] global step 45895: loss = 0.1683 (0.983 sec/step)\n",
      "I0902 10:29:50.364105 139792788920128 learning.py:507] global step 45896: loss = 0.0654 (1.249 sec/step)\n",
      "I0902 10:29:50.376186 139778936784640 supervisor.py:1050] Recording summary at step 45896.\n",
      "I0902 10:29:51.345954 139792788920128 learning.py:507] global step 45897: loss = 0.2427 (0.980 sec/step)\n",
      "I0902 10:29:52.318182 139792788920128 learning.py:507] global step 45898: loss = 0.0643 (0.971 sec/step)\n",
      "I0902 10:29:53.299158 139792788920128 learning.py:507] global step 45899: loss = 0.1838 (0.980 sec/step)\n",
      "I0902 10:29:54.249658 139792788920128 learning.py:507] global step 45900: loss = 0.0710 (0.949 sec/step)\n",
      "I0902 10:29:55.218478 139792788920128 learning.py:507] global step 45901: loss = 0.0872 (0.967 sec/step)\n",
      "I0902 10:29:56.187143 139792788920128 learning.py:507] global step 45902: loss = 0.0906 (0.967 sec/step)\n",
      "I0902 10:29:57.155835 139792788920128 learning.py:507] global step 45903: loss = 0.1131 (0.967 sec/step)\n",
      "I0902 10:29:58.128747 139792788920128 learning.py:507] global step 45904: loss = 0.1790 (0.971 sec/step)\n",
      "I0902 10:29:59.089481 139792788920128 learning.py:507] global step 45905: loss = 0.0990 (0.959 sec/step)\n",
      "I0902 10:30:00.066416 139792788920128 learning.py:507] global step 45906: loss = 0.1095 (0.975 sec/step)\n",
      "I0902 10:30:01.018207 139792788920128 learning.py:507] global step 45907: loss = 0.1120 (0.950 sec/step)\n",
      "I0902 10:30:01.966756 139792788920128 learning.py:507] global step 45908: loss = 0.1858 (0.947 sec/step)\n",
      "I0902 10:30:02.934392 139792788920128 learning.py:507] global step 45909: loss = 0.1009 (0.966 sec/step)\n",
      "I0902 10:30:03.898678 139792788920128 learning.py:507] global step 45910: loss = 0.3306 (0.963 sec/step)\n",
      "I0902 10:30:04.856699 139792788920128 learning.py:507] global step 45911: loss = 0.1948 (0.957 sec/step)\n",
      "I0902 10:30:05.807821 139792788920128 learning.py:507] global step 45912: loss = 0.1337 (0.950 sec/step)\n",
      "I0902 10:30:06.794445 139792788920128 learning.py:507] global step 45913: loss = 0.1073 (0.985 sec/step)\n",
      "I0902 10:30:07.763424 139792788920128 learning.py:507] global step 45914: loss = 0.0695 (0.967 sec/step)\n",
      "I0902 10:30:08.729476 139792788920128 learning.py:507] global step 45915: loss = 0.2089 (0.964 sec/step)\n",
      "I0902 10:30:09.705471 139792788920128 learning.py:507] global step 45916: loss = 0.0867 (0.975 sec/step)\n",
      "I0902 10:30:10.678598 139792788920128 learning.py:507] global step 45917: loss = 0.0795 (0.972 sec/step)\n",
      "I0902 10:30:11.638685 139792788920128 learning.py:507] global step 45918: loss = 0.0729 (0.959 sec/step)\n",
      "I0902 10:30:12.604251 139792788920128 learning.py:507] global step 45919: loss = 0.0897 (0.964 sec/step)\n",
      "I0902 10:30:13.576403 139792788920128 learning.py:507] global step 45920: loss = 0.1008 (0.971 sec/step)\n",
      "I0902 10:30:14.538638 139792788920128 learning.py:507] global step 45921: loss = 0.0569 (0.960 sec/step)\n",
      "I0902 10:30:15.496237 139792788920128 learning.py:507] global step 45922: loss = 0.1061 (0.956 sec/step)\n",
      "I0902 10:30:16.457117 139792788920128 learning.py:507] global step 45923: loss = 0.1175 (0.959 sec/step)\n",
      "I0902 10:30:17.441274 139792788920128 learning.py:507] global step 45924: loss = 0.0827 (0.982 sec/step)\n",
      "I0902 10:30:18.415020 139792788920128 learning.py:507] global step 45925: loss = 0.1420 (0.972 sec/step)\n",
      "I0902 10:30:19.391789 139792788920128 learning.py:507] global step 45926: loss = 0.1092 (0.975 sec/step)\n",
      "I0902 10:30:20.367955 139792788920128 learning.py:507] global step 45927: loss = 0.1066 (0.974 sec/step)\n",
      "I0902 10:30:21.325322 139792788920128 learning.py:507] global step 45928: loss = 0.1397 (0.955 sec/step)\n",
      "I0902 10:30:22.299962 139792788920128 learning.py:507] global step 45929: loss = 0.0881 (0.973 sec/step)\n",
      "I0902 10:30:23.245847 139792788920128 learning.py:507] global step 45930: loss = 0.1166 (0.944 sec/step)\n",
      "I0902 10:30:24.238611 139792788920128 learning.py:507] global step 45931: loss = 0.0671 (0.991 sec/step)\n",
      "I0902 10:30:25.200779 139792788920128 learning.py:507] global step 45932: loss = 0.1417 (0.961 sec/step)\n",
      "I0902 10:30:26.165078 139792788920128 learning.py:507] global step 45933: loss = 0.0778 (0.963 sec/step)\n",
      "I0902 10:30:27.131993 139792788920128 learning.py:507] global step 45934: loss = 0.1782 (0.965 sec/step)\n",
      "I0902 10:30:28.098962 139792788920128 learning.py:507] global step 45935: loss = 0.0879 (0.965 sec/step)\n",
      "I0902 10:30:29.062029 139792788920128 learning.py:507] global step 45936: loss = 0.1683 (0.961 sec/step)\n",
      "I0902 10:30:30.028342 139792788920128 learning.py:507] global step 45937: loss = 0.0969 (0.965 sec/step)\n",
      "I0902 10:30:30.996995 139792788920128 learning.py:507] global step 45938: loss = 0.1948 (0.967 sec/step)\n",
      "I0902 10:30:31.958204 139792788920128 learning.py:507] global step 45939: loss = 0.0674 (0.959 sec/step)\n",
      "I0902 10:30:32.908877 139792788920128 learning.py:507] global step 45940: loss = 0.1226 (0.949 sec/step)\n",
      "I0902 10:30:33.882955 139792788920128 learning.py:507] global step 45941: loss = 0.0517 (0.972 sec/step)\n",
      "I0902 10:30:34.844928 139792788920128 learning.py:507] global step 45942: loss = 0.1932 (0.960 sec/step)\n",
      "I0902 10:30:35.809063 139792788920128 learning.py:507] global step 45943: loss = 0.0552 (0.962 sec/step)\n",
      "I0902 10:30:36.765772 139792788920128 learning.py:507] global step 45944: loss = 0.0865 (0.955 sec/step)\n",
      "I0902 10:30:37.742325 139792788920128 learning.py:507] global step 45945: loss = 0.1347 (0.975 sec/step)\n",
      "I0902 10:30:38.714040 139792788920128 learning.py:507] global step 45946: loss = 0.1607 (0.970 sec/step)\n",
      "I0902 10:30:39.677595 139792788920128 learning.py:507] global step 45947: loss = 0.0648 (0.962 sec/step)\n",
      "I0902 10:30:40.648080 139792788920128 learning.py:507] global step 45948: loss = 0.1147 (0.969 sec/step)\n",
      "I0902 10:30:41.599634 139792788920128 learning.py:507] global step 45949: loss = 0.1374 (0.950 sec/step)\n",
      "I0902 10:30:42.582516 139792788920128 learning.py:507] global step 45950: loss = 0.0630 (0.981 sec/step)\n",
      "I0902 10:30:43.537108 139792788920128 learning.py:507] global step 45951: loss = 0.0939 (0.953 sec/step)\n",
      "I0902 10:30:44.517814 139792788920128 learning.py:507] global step 45952: loss = 0.0671 (0.979 sec/step)\n",
      "I0902 10:30:45.492287 139792788920128 learning.py:507] global step 45953: loss = 0.0820 (0.973 sec/step)\n",
      "I0902 10:30:46.473535 139792788920128 learning.py:507] global step 45954: loss = 0.1214 (0.979 sec/step)\n",
      "I0902 10:30:47.449944 139792788920128 learning.py:507] global step 45955: loss = 0.0776 (0.975 sec/step)\n",
      "I0902 10:30:48.417844 139792788920128 learning.py:507] global step 45956: loss = 0.0838 (0.966 sec/step)\n",
      "I0902 10:30:49.389644 139792788920128 learning.py:507] global step 45957: loss = 0.1059 (0.970 sec/step)\n",
      "I0902 10:30:50.355267 139792788920128 learning.py:507] global step 45958: loss = 0.1085 (0.964 sec/step)\n",
      "I0902 10:30:51.300985 139792788920128 learning.py:507] global step 45959: loss = 0.0766 (0.944 sec/step)\n",
      "I0902 10:30:52.277130 139792788920128 learning.py:507] global step 45960: loss = 0.1319 (0.975 sec/step)\n",
      "I0902 10:30:53.241743 139792788920128 learning.py:507] global step 45961: loss = 0.1204 (0.963 sec/step)\n",
      "I0902 10:30:54.197352 139792788920128 learning.py:507] global step 45962: loss = 0.0574 (0.954 sec/step)\n",
      "I0902 10:30:55.157048 139792788920128 learning.py:507] global step 45963: loss = 0.1715 (0.958 sec/step)\n",
      "I0902 10:30:56.139160 139792788920128 learning.py:507] global step 45964: loss = 0.1423 (0.981 sec/step)\n",
      "I0902 10:30:57.101723 139792788920128 learning.py:507] global step 45965: loss = 0.0809 (0.961 sec/step)\n",
      "I0902 10:30:58.072412 139792788920128 learning.py:507] global step 45966: loss = 0.0995 (0.969 sec/step)\n",
      "I0902 10:30:59.027474 139792788920128 learning.py:507] global step 45967: loss = 0.1008 (0.953 sec/step)\n",
      "I0902 10:31:00.003201 139792788920128 learning.py:507] global step 45968: loss = 0.1189 (0.974 sec/step)\n",
      "I0902 10:31:00.973288 139792788920128 learning.py:507] global step 45969: loss = 0.1688 (0.968 sec/step)\n",
      "I0902 10:31:01.940327 139792788920128 learning.py:507] global step 45970: loss = 0.1268 (0.965 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:31:02.891132 139792788920128 learning.py:507] global step 45971: loss = 0.1129 (0.949 sec/step)\n",
      "I0902 10:31:03.864595 139792788920128 learning.py:507] global step 45972: loss = 0.1564 (0.972 sec/step)\n",
      "I0902 10:31:04.843989 139792788920128 learning.py:507] global step 45973: loss = 0.0956 (0.978 sec/step)\n",
      "I0902 10:31:05.816500 139792788920128 learning.py:507] global step 45974: loss = 0.1062 (0.971 sec/step)\n",
      "I0902 10:31:06.781787 139792788920128 learning.py:507] global step 45975: loss = 0.1011 (0.964 sec/step)\n",
      "I0902 10:31:07.753520 139792788920128 learning.py:507] global step 45976: loss = 0.0757 (0.970 sec/step)\n",
      "I0902 10:31:08.723898 139792788920128 learning.py:507] global step 45977: loss = 0.0900 (0.969 sec/step)\n",
      "I0902 10:31:09.693327 139792788920128 learning.py:507] global step 45978: loss = 0.3087 (0.968 sec/step)\n",
      "I0902 10:31:10.658976 139792788920128 learning.py:507] global step 45979: loss = 0.0451 (0.964 sec/step)\n",
      "I0902 10:31:11.628190 139792788920128 learning.py:507] global step 45980: loss = 0.0806 (0.968 sec/step)\n",
      "I0902 10:31:12.594012 139792788920128 learning.py:507] global step 45981: loss = 0.0533 (0.964 sec/step)\n",
      "I0902 10:31:13.583212 139792788920128 learning.py:507] global step 45982: loss = 0.0574 (0.988 sec/step)\n",
      "I0902 10:31:14.561786 139792788920128 learning.py:507] global step 45983: loss = 0.1426 (0.977 sec/step)\n",
      "I0902 10:31:15.516966 139792788920128 learning.py:507] global step 45984: loss = 0.2061 (0.953 sec/step)\n",
      "I0902 10:31:16.483467 139792788920128 learning.py:507] global step 45985: loss = 0.1135 (0.965 sec/step)\n",
      "I0902 10:31:17.440809 139792788920128 learning.py:507] global step 45986: loss = 0.1219 (0.956 sec/step)\n",
      "I0902 10:31:18.415487 139792788920128 learning.py:507] global step 45987: loss = 0.0882 (0.973 sec/step)\n",
      "I0902 10:31:19.372333 139792788920128 learning.py:507] global step 45988: loss = 0.1631 (0.955 sec/step)\n",
      "I0902 10:31:20.341650 139792788920128 learning.py:507] global step 45989: loss = 0.1209 (0.968 sec/step)\n",
      "I0902 10:31:21.301019 139792788920128 learning.py:507] global step 45990: loss = 0.1128 (0.958 sec/step)\n",
      "I0902 10:31:22.260860 139792788920128 learning.py:507] global step 45991: loss = 0.1478 (0.958 sec/step)\n",
      "I0902 10:31:23.240555 139792788920128 learning.py:507] global step 45992: loss = 0.1065 (0.978 sec/step)\n",
      "I0902 10:31:24.208731 139792788920128 learning.py:507] global step 45993: loss = 0.1563 (0.966 sec/step)\n",
      "I0902 10:31:25.178655 139792788920128 learning.py:507] global step 45994: loss = 0.0864 (0.968 sec/step)\n",
      "I0902 10:31:26.144119 139792788920128 learning.py:507] global step 45995: loss = 0.1006 (0.964 sec/step)\n",
      "I0902 10:31:27.123532 139792788920128 learning.py:507] global step 45996: loss = 0.1333 (0.978 sec/step)\n",
      "I0902 10:31:28.077924 139792788920128 learning.py:507] global step 45997: loss = 0.0721 (0.953 sec/step)\n",
      "I0902 10:31:29.059265 139792788920128 learning.py:507] global step 45998: loss = 0.0904 (0.980 sec/step)\n",
      "I0902 10:31:30.046495 139792788920128 learning.py:507] global step 45999: loss = 0.0955 (0.986 sec/step)\n",
      "I0902 10:31:31.014876 139792788920128 learning.py:507] global step 46000: loss = 0.0695 (0.967 sec/step)\n",
      "I0902 10:31:31.970168 139792788920128 learning.py:507] global step 46001: loss = 0.1131 (0.954 sec/step)\n",
      "I0902 10:31:32.946254 139792788920128 learning.py:507] global step 46002: loss = 0.2864 (0.974 sec/step)\n",
      "I0902 10:31:33.909325 139792788920128 learning.py:507] global step 46003: loss = 0.1041 (0.961 sec/step)\n",
      "I0902 10:31:34.895660 139792788920128 learning.py:507] global step 46004: loss = 0.0469 (0.985 sec/step)\n",
      "I0902 10:31:35.845677 139792788920128 learning.py:507] global step 46005: loss = 0.0975 (0.948 sec/step)\n",
      "I0902 10:31:36.812019 139792788920128 learning.py:507] global step 46006: loss = 0.0779 (0.965 sec/step)\n",
      "I0902 10:31:37.800525 139792788920128 learning.py:507] global step 46007: loss = 0.1044 (0.987 sec/step)\n",
      "I0902 10:31:38.756848 139792788920128 learning.py:507] global step 46008: loss = 0.1121 (0.955 sec/step)\n",
      "I0902 10:31:39.704470 139792788920128 learning.py:507] global step 46009: loss = 0.1205 (0.946 sec/step)\n",
      "I0902 10:31:40.657380 139792788920128 learning.py:507] global step 46010: loss = 0.0636 (0.951 sec/step)\n",
      "I0902 10:31:41.636295 139792788920128 learning.py:507] global step 46011: loss = 0.1771 (0.977 sec/step)\n",
      "I0902 10:31:42.623001 139792788920128 learning.py:507] global step 46012: loss = 0.0433 (0.985 sec/step)\n",
      "I0902 10:31:43.593620 139792788920128 learning.py:507] global step 46013: loss = 0.1272 (0.969 sec/step)\n",
      "I0902 10:31:44.560857 139792788920128 learning.py:507] global step 46014: loss = 0.1413 (0.965 sec/step)\n",
      "I0902 10:31:45.530512 139792788920128 learning.py:507] global step 46015: loss = 0.1211 (0.968 sec/step)\n",
      "I0902 10:31:46.496504 139792788920128 learning.py:507] global step 46016: loss = 0.1502 (0.964 sec/step)\n",
      "I0902 10:31:47.471982 139792788920128 learning.py:507] global step 46017: loss = 0.1165 (0.974 sec/step)\n",
      "I0902 10:31:48.434144 139792788920128 learning.py:507] global step 46018: loss = 0.0833 (0.960 sec/step)\n",
      "I0902 10:31:49.401551 139792788920128 learning.py:507] global step 46019: loss = 0.1189 (0.959 sec/step)\n",
      "I0902 10:31:50.022894 139778936784640 supervisor.py:1050] Recording summary at step 46019.\n",
      "I0902 10:31:50.652196 139792788920128 learning.py:507] global step 46020: loss = 0.0687 (1.247 sec/step)\n",
      "I0902 10:31:51.625866 139792788920128 learning.py:507] global step 46021: loss = 0.0538 (0.972 sec/step)\n",
      "I0902 10:31:52.570543 139792788920128 learning.py:507] global step 46022: loss = 0.1573 (0.943 sec/step)\n",
      "I0902 10:31:53.517280 139792788920128 learning.py:507] global step 46023: loss = 0.1482 (0.945 sec/step)\n",
      "I0902 10:31:54.478292 139792788920128 learning.py:507] global step 46024: loss = 0.0746 (0.959 sec/step)\n",
      "I0902 10:31:55.449558 139792788920128 learning.py:507] global step 46025: loss = 0.1786 (0.970 sec/step)\n",
      "I0902 10:31:56.395930 139792788920128 learning.py:507] global step 46026: loss = 0.1084 (0.945 sec/step)\n",
      "I0902 10:31:57.370270 139792788920128 learning.py:507] global step 46027: loss = 0.1178 (0.973 sec/step)\n",
      "I0902 10:31:58.360918 139792788920128 learning.py:507] global step 46028: loss = 0.0864 (0.989 sec/step)\n",
      "I0902 10:31:59.350508 139792788920128 learning.py:507] global step 46029: loss = 0.1103 (0.988 sec/step)\n",
      "I0902 10:32:00.302772 139792788920128 learning.py:507] global step 46030: loss = 0.1447 (0.951 sec/step)\n",
      "I0902 10:32:01.265314 139792788920128 learning.py:507] global step 46031: loss = 0.0691 (0.961 sec/step)\n",
      "I0902 10:32:02.242111 139792788920128 learning.py:507] global step 46032: loss = 0.2069 (0.975 sec/step)\n",
      "I0902 10:32:03.223436 139792788920128 learning.py:507] global step 46033: loss = 0.1192 (0.980 sec/step)\n",
      "I0902 10:32:04.177858 139792788920128 learning.py:507] global step 46034: loss = 0.1654 (0.953 sec/step)\n",
      "I0902 10:32:05.151660 139792788920128 learning.py:507] global step 46035: loss = 0.0971 (0.972 sec/step)\n",
      "I0902 10:32:06.133845 139792788920128 learning.py:507] global step 46036: loss = 0.0816 (0.981 sec/step)\n",
      "I0902 10:32:07.093953 139792788920128 learning.py:507] global step 46037: loss = 0.0861 (0.958 sec/step)\n",
      "I0902 10:32:08.049142 139792788920128 learning.py:507] global step 46038: loss = 0.0863 (0.954 sec/step)\n",
      "I0902 10:32:09.016017 139792788920128 learning.py:507] global step 46039: loss = 0.1650 (0.965 sec/step)\n",
      "I0902 10:32:09.981981 139792788920128 learning.py:507] global step 46040: loss = 0.0893 (0.964 sec/step)\n",
      "I0902 10:32:10.940848 139792788920128 learning.py:507] global step 46041: loss = 0.2164 (0.957 sec/step)\n",
      "I0902 10:32:11.905418 139792788920128 learning.py:507] global step 46042: loss = 0.1934 (0.963 sec/step)\n",
      "I0902 10:32:12.880544 139792788920128 learning.py:507] global step 46043: loss = 0.1705 (0.973 sec/step)\n",
      "I0902 10:32:13.840049 139792788920128 learning.py:507] global step 46044: loss = 0.0826 (0.958 sec/step)\n",
      "I0902 10:32:14.784622 139792788920128 learning.py:507] global step 46045: loss = 0.1356 (0.943 sec/step)\n",
      "I0902 10:32:15.769573 139792788920128 learning.py:507] global step 46046: loss = 0.0608 (0.984 sec/step)\n",
      "I0902 10:32:16.719364 139792788920128 learning.py:507] global step 46047: loss = 0.0708 (0.948 sec/step)\n",
      "I0902 10:32:17.682916 139792788920128 learning.py:507] global step 46048: loss = 0.1085 (0.962 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:32:18.649088 139792788920128 learning.py:507] global step 46049: loss = 0.0576 (0.964 sec/step)\n",
      "I0902 10:32:19.607399 139792788920128 learning.py:507] global step 46050: loss = 0.2782 (0.957 sec/step)\n",
      "I0902 10:32:20.591527 139792788920128 learning.py:507] global step 46051: loss = 0.0909 (0.982 sec/step)\n",
      "I0902 10:32:21.572357 139792788920128 learning.py:507] global step 46052: loss = 0.0752 (0.979 sec/step)\n",
      "I0902 10:32:22.542937 139792788920128 learning.py:507] global step 46053: loss = 0.0600 (0.969 sec/step)\n",
      "I0902 10:32:23.509748 139792788920128 learning.py:507] global step 46054: loss = 0.1123 (0.965 sec/step)\n",
      "I0902 10:32:24.477821 139792788920128 learning.py:507] global step 46055: loss = 0.0751 (0.966 sec/step)\n",
      "I0902 10:32:25.434360 139792788920128 learning.py:507] global step 46056: loss = 0.0821 (0.955 sec/step)\n",
      "I0902 10:32:26.384122 139792788920128 learning.py:507] global step 46057: loss = 0.0960 (0.948 sec/step)\n",
      "I0902 10:32:27.344640 139792788920128 learning.py:507] global step 46058: loss = 0.0617 (0.959 sec/step)\n",
      "I0902 10:32:28.328614 139792788920128 learning.py:507] global step 46059: loss = 0.1781 (0.982 sec/step)\n",
      "I0902 10:32:29.308935 139792788920128 learning.py:507] global step 46060: loss = 0.0687 (0.979 sec/step)\n",
      "I0902 10:32:30.270077 139792788920128 learning.py:507] global step 46061: loss = 0.1082 (0.960 sec/step)\n",
      "I0902 10:32:31.225618 139792788920128 learning.py:507] global step 46062: loss = 0.0883 (0.954 sec/step)\n",
      "I0902 10:32:32.186528 139792788920128 learning.py:507] global step 46063: loss = 0.0985 (0.959 sec/step)\n",
      "I0902 10:32:33.157039 139792788920128 learning.py:507] global step 46064: loss = 0.2260 (0.969 sec/step)\n",
      "I0902 10:32:34.132994 139792788920128 learning.py:507] global step 46065: loss = 0.1009 (0.974 sec/step)\n",
      "I0902 10:32:35.099088 139792788920128 learning.py:507] global step 46066: loss = 0.1025 (0.964 sec/step)\n",
      "I0902 10:32:36.078575 139792788920128 learning.py:507] global step 46067: loss = 0.0571 (0.978 sec/step)\n",
      "I0902 10:32:37.059111 139792788920128 learning.py:507] global step 46068: loss = 0.1386 (0.979 sec/step)\n",
      "I0902 10:32:38.033828 139792788920128 learning.py:507] global step 46069: loss = 0.0622 (0.973 sec/step)\n",
      "I0902 10:32:38.982027 139792788920128 learning.py:507] global step 46070: loss = 0.2641 (0.947 sec/step)\n",
      "I0902 10:32:39.958747 139792788920128 learning.py:507] global step 46071: loss = 0.0839 (0.975 sec/step)\n",
      "I0902 10:32:40.926729 139792788920128 learning.py:507] global step 46072: loss = 0.0316 (0.966 sec/step)\n",
      "I0902 10:32:41.908330 139792788920128 learning.py:507] global step 46073: loss = 0.0740 (0.980 sec/step)\n",
      "I0902 10:32:42.873252 139792788920128 learning.py:507] global step 46074: loss = 0.1094 (0.963 sec/step)\n",
      "I0902 10:32:43.855734 139792788920128 learning.py:507] global step 46075: loss = 0.0888 (0.981 sec/step)\n",
      "I0902 10:32:44.825030 139792788920128 learning.py:507] global step 46076: loss = 0.1020 (0.968 sec/step)\n",
      "I0902 10:32:45.776112 139792788920128 learning.py:507] global step 46077: loss = 0.1359 (0.949 sec/step)\n",
      "I0902 10:32:46.768283 139792788920128 learning.py:507] global step 46078: loss = 0.0796 (0.990 sec/step)\n",
      "I0902 10:32:47.742517 139792788920128 learning.py:507] global step 46079: loss = 0.0688 (0.972 sec/step)\n",
      "I0902 10:32:48.713791 139792788920128 learning.py:507] global step 46080: loss = 0.1498 (0.970 sec/step)\n",
      "I0902 10:32:49.661520 139792788920128 learning.py:507] global step 46081: loss = 0.1210 (0.946 sec/step)\n",
      "I0902 10:32:50.618843 139792788920128 learning.py:507] global step 46082: loss = 0.0618 (0.956 sec/step)\n",
      "I0902 10:32:51.592273 139792788920128 learning.py:507] global step 46083: loss = 0.1023 (0.972 sec/step)\n",
      "I0902 10:32:52.582239 139792788920128 learning.py:507] global step 46084: loss = 0.2108 (0.988 sec/step)\n",
      "I0902 10:32:53.560235 139792788920128 learning.py:507] global step 46085: loss = 0.1136 (0.976 sec/step)\n",
      "I0902 10:32:54.511464 139792788920128 learning.py:507] global step 46086: loss = 0.1499 (0.950 sec/step)\n",
      "I0902 10:32:55.469359 139792788920128 learning.py:507] global step 46087: loss = 0.0554 (0.956 sec/step)\n",
      "I0902 10:32:56.444907 139792788920128 learning.py:507] global step 46088: loss = 0.0745 (0.974 sec/step)\n",
      "I0902 10:32:57.405330 139792788920128 learning.py:507] global step 46089: loss = 0.0746 (0.959 sec/step)\n",
      "I0902 10:32:58.365904 139792788920128 learning.py:507] global step 46090: loss = 0.0704 (0.959 sec/step)\n",
      "I0902 10:32:59.351274 139792788920128 learning.py:507] global step 46091: loss = 0.0977 (0.984 sec/step)\n",
      "I0902 10:33:00.319057 139792788920128 learning.py:507] global step 46092: loss = 0.0626 (0.966 sec/step)\n",
      "I0902 10:33:01.270258 139792788920128 learning.py:507] global step 46093: loss = 0.1471 (0.950 sec/step)\n",
      "I0902 10:33:02.233231 139792788920128 learning.py:507] global step 46094: loss = 0.1249 (0.961 sec/step)\n",
      "I0902 10:33:03.222633 139792788920128 learning.py:507] global step 46095: loss = 0.3219 (0.988 sec/step)\n",
      "I0902 10:33:04.165942 139792788920128 learning.py:507] global step 46096: loss = 0.0892 (0.942 sec/step)\n",
      "I0902 10:33:05.139550 139792788920128 learning.py:507] global step 46097: loss = 0.1945 (0.972 sec/step)\n",
      "I0902 10:33:06.134122 139792788920128 learning.py:507] global step 46098: loss = 0.1712 (0.993 sec/step)\n",
      "I0902 10:33:07.093646 139792788920128 learning.py:507] global step 46099: loss = 0.1272 (0.958 sec/step)\n",
      "I0902 10:33:08.081237 139792788920128 learning.py:507] global step 46100: loss = 0.1809 (0.986 sec/step)\n",
      "I0902 10:33:09.055457 139792788920128 learning.py:507] global step 46101: loss = 0.0754 (0.973 sec/step)\n",
      "I0902 10:33:10.028980 139792788920128 learning.py:507] global step 46102: loss = 0.0913 (0.972 sec/step)\n",
      "I0902 10:33:10.992035 139792788920128 learning.py:507] global step 46103: loss = 0.2097 (0.961 sec/step)\n",
      "I0902 10:33:11.966615 139792788920128 learning.py:507] global step 46104: loss = 0.1640 (0.973 sec/step)\n",
      "I0902 10:33:12.945057 139792788920128 learning.py:507] global step 46105: loss = 0.1104 (0.977 sec/step)\n",
      "I0902 10:33:13.913350 139792788920128 learning.py:507] global step 46106: loss = 0.1911 (0.967 sec/step)\n",
      "I0902 10:33:14.884367 139792788920128 learning.py:507] global step 46107: loss = 0.0530 (0.969 sec/step)\n",
      "I0902 10:33:15.845477 139792788920128 learning.py:507] global step 46108: loss = 0.0839 (0.959 sec/step)\n",
      "I0902 10:33:16.802124 139792788920128 learning.py:507] global step 46109: loss = 0.0808 (0.955 sec/step)\n",
      "I0902 10:33:17.767868 139792788920128 learning.py:507] global step 46110: loss = 0.1310 (0.964 sec/step)\n",
      "I0902 10:33:18.737471 139792788920128 learning.py:507] global step 46111: loss = 0.1039 (0.968 sec/step)\n",
      "I0902 10:33:19.701053 139792788920128 learning.py:507] global step 46112: loss = 0.1248 (0.962 sec/step)\n",
      "I0902 10:33:20.673384 139792788920128 learning.py:507] global step 46113: loss = 0.1613 (0.971 sec/step)\n",
      "I0902 10:33:21.651051 139792788920128 learning.py:507] global step 46114: loss = 0.1174 (0.976 sec/step)\n",
      "I0902 10:33:22.654206 139792788920128 learning.py:507] global step 46115: loss = 0.1242 (1.001 sec/step)\n",
      "I0902 10:33:23.633447 139792788920128 learning.py:507] global step 46116: loss = 0.1524 (0.978 sec/step)\n",
      "I0902 10:33:24.629619 139792788920128 learning.py:507] global step 46117: loss = 0.1322 (0.994 sec/step)\n",
      "I0902 10:33:25.613952 139792788920128 learning.py:507] global step 46118: loss = 0.1188 (0.983 sec/step)\n",
      "I0902 10:33:26.594684 139792788920128 learning.py:507] global step 46119: loss = 0.1450 (0.979 sec/step)\n",
      "I0902 10:33:27.568314 139792788920128 learning.py:507] global step 46120: loss = 0.0894 (0.972 sec/step)\n",
      "I0902 10:33:28.545385 139792788920128 learning.py:507] global step 46121: loss = 0.1015 (0.975 sec/step)\n",
      "I0902 10:33:29.520021 139792788920128 learning.py:507] global step 46122: loss = 0.1338 (0.973 sec/step)\n",
      "I0902 10:33:30.499377 139792788920128 learning.py:507] global step 46123: loss = 0.1024 (0.978 sec/step)\n",
      "I0902 10:33:31.480061 139792788920128 learning.py:507] global step 46124: loss = 0.1211 (0.979 sec/step)\n",
      "I0902 10:33:32.448160 139792788920128 learning.py:507] global step 46125: loss = 0.0383 (0.966 sec/step)\n",
      "I0902 10:33:33.426308 139792788920128 learning.py:507] global step 46126: loss = 0.1203 (0.976 sec/step)\n",
      "I0902 10:33:34.404809 139792788920128 learning.py:507] global step 46127: loss = 0.2191 (0.977 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0902 10:33:35.372174 139792788920128 learning.py:507] global step 46128: loss = 0.0959 (0.966 sec/step)\n",
      "I0902 10:33:36.366474 139792788920128 learning.py:507] global step 46129: loss = 0.1728 (0.993 sec/step)\n",
      "I0902 10:33:37.344244 139792788920128 learning.py:507] global step 46130: loss = 0.1233 (0.976 sec/step)\n",
      "I0902 10:33:38.329514 139792788920128 learning.py:507] global step 46131: loss = 0.0715 (0.984 sec/step)\n",
      "I0902 10:33:39.296503 139792788920128 learning.py:507] global step 46132: loss = 0.1036 (0.965 sec/step)\n",
      "I0902 10:33:40.284081 139792788920128 learning.py:507] global step 46133: loss = 0.1184 (0.986 sec/step)\n",
      "I0902 10:33:41.232973 139792788920128 learning.py:507] global step 46134: loss = 0.2208 (0.947 sec/step)\n",
      "I0902 10:33:42.195984 139792788920128 learning.py:507] global step 46135: loss = 0.0798 (0.961 sec/step)\n",
      "I0902 10:33:43.177818 139792788920128 learning.py:507] global step 46136: loss = 0.1312 (0.980 sec/step)\n",
      "I0902 10:33:44.166986 139792788920128 learning.py:507] global step 46137: loss = 0.0726 (0.988 sec/step)\n",
      "I0902 10:33:45.162946 139792788920128 learning.py:507] global step 46138: loss = 0.1186 (0.994 sec/step)\n",
      "I0902 10:33:46.134488 139792788920128 learning.py:507] global step 46139: loss = 0.1169 (0.970 sec/step)\n",
      "I0902 10:33:47.115498 139792788920128 learning.py:507] global step 46140: loss = 0.1746 (0.979 sec/step)\n",
      "I0902 10:33:48.087473 139792788920128 learning.py:507] global step 46141: loss = 0.2323 (0.970 sec/step)\n",
      "I0902 10:33:49.048088 139792788920128 learning.py:507] global step 46142: loss = 0.2072 (0.959 sec/step)\n",
      "I0902 10:33:49.270376 139778953570048 supervisor.py:1117] Saving checkpoint to path data_dir/mixed_experiment/checkpoints_v2/model.ckpt\n",
      "I0902 10:33:50.209485 139792788920128 learning.py:507] global step 46143: loss = 0.1047 (1.141 sec/step)\n",
      "I0902 10:33:50.394034 139778936784640 supervisor.py:1050] Recording summary at step 46143.\n",
      "I0902 10:33:51.474942 139792788920128 learning.py:507] global step 46144: loss = 0.0737 (1.062 sec/step)\n",
      "I0902 10:33:52.454862 139792788920128 learning.py:507] global step 46145: loss = 0.1764 (0.978 sec/step)\n",
      "I0902 10:33:53.436741 139792788920128 learning.py:507] global step 46146: loss = 0.1460 (0.980 sec/step)\n",
      "I0902 10:33:54.401044 139792788920128 learning.py:507] global step 46147: loss = 0.1746 (0.963 sec/step)\n",
      "I0902 10:33:55.382406 139792788920128 learning.py:507] global step 46148: loss = 0.2663 (0.980 sec/step)\n",
      "I0902 10:33:56.364373 139792788920128 learning.py:507] global step 46149: loss = 0.1449 (0.981 sec/step)\n",
      "I0902 10:33:57.325343 139792788920128 learning.py:507] global step 46150: loss = 0.0453 (0.959 sec/step)\n",
      "I0902 10:33:58.280521 139792788920128 learning.py:507] global step 46151: loss = 0.1079 (0.953 sec/step)\n",
      "I0902 10:33:59.240865 139792788920128 learning.py:507] global step 46152: loss = 0.0765 (0.959 sec/step)\n",
      "I0902 10:34:00.202075 139792788920128 learning.py:507] global step 46153: loss = 0.0586 (0.960 sec/step)\n",
      "I0902 10:34:01.174718 139792788920128 learning.py:507] global step 46154: loss = 0.1545 (0.971 sec/step)\n",
      "I0902 10:34:02.133455 139792788920128 learning.py:507] global step 46155: loss = 0.1336 (0.957 sec/step)\n",
      "I0902 10:34:03.106217 139792788920128 learning.py:507] global step 46156: loss = 0.1184 (0.971 sec/step)\n",
      "I0902 10:34:04.084682 139792788920128 learning.py:507] global step 46157: loss = 0.1296 (0.977 sec/step)\n",
      "I0902 10:34:05.061143 139792788920128 learning.py:507] global step 46158: loss = 0.1043 (0.975 sec/step)\n",
      "I0902 10:34:06.041619 139792788920128 learning.py:507] global step 46159: loss = 0.2067 (0.979 sec/step)\n",
      "I0902 10:34:07.013770 139792788920128 learning.py:507] global step 46160: loss = 0.1927 (0.971 sec/step)\n",
      "I0902 10:34:07.979052 139792788920128 learning.py:507] global step 46161: loss = 0.2077 (0.964 sec/step)\n",
      "I0902 10:34:08.949662 139792788920128 learning.py:507] global step 46162: loss = 0.0932 (0.969 sec/step)\n",
      "I0902 10:34:09.896316 139792788920128 learning.py:507] global step 46163: loss = 0.1008 (0.945 sec/step)\n",
      "I0902 10:34:10.863059 139792788920128 learning.py:507] global step 46164: loss = 0.1065 (0.965 sec/step)\n",
      "I0902 10:34:11.823185 139792788920128 learning.py:507] global step 46165: loss = 0.0805 (0.958 sec/step)\n",
      "I0902 10:34:12.791468 139792788920128 learning.py:507] global step 46166: loss = 0.1235 (0.967 sec/step)\n",
      "I0902 10:34:13.787493 139792788920128 learning.py:507] global step 46167: loss = 0.0938 (0.994 sec/step)\n",
      "I0902 10:34:14.758290 139792788920128 learning.py:507] global step 46168: loss = 0.4069 (0.969 sec/step)\n",
      "I0902 10:34:15.726546 139792788920128 learning.py:507] global step 46169: loss = 0.1558 (0.967 sec/step)\n",
      "I0902 10:34:16.676554 139792788920128 learning.py:507] global step 46170: loss = 0.1483 (0.948 sec/step)\n",
      "I0902 10:34:17.653477 139792788920128 learning.py:507] global step 46171: loss = 0.1740 (0.975 sec/step)\n",
      "I0902 10:34:18.638923 139792788920128 learning.py:507] global step 46172: loss = 0.2596 (0.984 sec/step)\n",
      "I0902 10:34:19.644733 139792788920128 learning.py:507] global step 46173: loss = 0.2073 (1.004 sec/step)\n",
      "I0902 10:34:20.608218 139792788920128 learning.py:507] global step 46174: loss = 0.1053 (0.962 sec/step)\n",
      "I0902 10:34:21.578598 139792788920128 learning.py:507] global step 46175: loss = 0.1064 (0.969 sec/step)\n",
      "I0902 10:34:22.542326 139792788920128 learning.py:507] global step 46176: loss = 0.1281 (0.962 sec/step)\n",
      "I0902 10:34:23.544179 139792788920128 learning.py:507] global step 46177: loss = 0.3041 (1.000 sec/step)\n",
      "I0902 10:34:24.521189 139792788920128 learning.py:507] global step 46178: loss = 0.0942 (0.975 sec/step)\n",
      "I0902 10:34:25.493088 139792788920128 learning.py:507] global step 46179: loss = 0.0609 (0.970 sec/step)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!export PYTHONPATH=$PYTHONPATH:/home/alexeygrigoriev/Projects/TD/models/research:/home/alexeygrigoriev/Projects/TD/models/research/slim; python /home/alexeygrigoriev/Projects/TD/models/research/object_detection/legacy/train.py \\\n",
    "    --pipeline_config_path=data_dir/mixed_experiment/tf_api_v2.config \\\n",
    "    --train_dir=data_dir/mixed_experiment/checkpoints_v2 \\\n",
    "    --num_clones=1\\\n",
    "    --ps_tasks=1\\\n",
    "    --logtostderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "colab_type": "code",
    "id": "bOgs4Habg0e2",
    "outputId": "20bc8735-8b30-4516-a83f-f74b7fb9f342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\t\t\t       model.ckpt-194779.index\r\n",
      "events.out.tfevents.1567182388.miptai  model.ckpt-194779.meta\r\n",
      "graph.pbtxt\t\t\t       model.ckpt-197608.data-00000-of-00001\r\n",
      "model.ckpt-189126.data-00000-of-00001  model.ckpt-197608.index\r\n",
      "model.ckpt-189126.index\t\t       model.ckpt-197608.meta\r\n",
      "model.ckpt-189126.meta\t\t       model.ckpt-200000.data-00000-of-00001\r\n",
      "model.ckpt-191952.data-00000-of-00001  model.ckpt-200000.index\r\n",
      "model.ckpt-191952.index\t\t       model.ckpt-200000.meta\r\n",
      "model.ckpt-191952.meta\t\t       pipeline.config\r\n",
      "model.ckpt-194779.data-00000-of-00001\r\n"
     ]
    }
   ],
   "source": [
    "# obtained checkpoints\n",
    "!cd data_dir/dtrans_experiment/checkpoints;ls"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "td",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
